{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.264150943396228, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -10.132075471698114, "policy1": -10.132075471698114}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 18.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -40.0, 26.0, -20.0, -40.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14904283341907318, "mean_inference_ms": 1.4309999015596175, "mean_action_processing_ms": 0.09315046999189587, "mean_env_wait_ms": 0.15732787904285253, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1007, "timesteps_this_iter": 32, "agent_timesteps_total": 2014, "timers": {"learn_time_ms": 323.416, "learn_throughput": 98.944, "update_time_ms": 4.977}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1007, "num_agent_steps_sampled": 2014, "num_steps_trained": 32, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64, "last_target_update_ts": 1007, "num_target_updates": 1}, "done": false, "episodes_total": 53, "training_iteration": 1, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-24", "timestamp": 1648816104, "time_this_iter_s": 2.821289539337158, "time_total_s": 2.821289539337158, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb803ddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81fbdd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb803ddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81fbdd0>"}, "time_since_restore": 2.821289539337158, "timesteps_since_restore": 32, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 14.36, "ram_util_percent": 47.92}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.620689655172413, "episode_len_mean": 19.086206896551722, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -10.810344827586206, "policy1": -10.810344827586206}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 18.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -40.0, 26.0, -20.0, -40.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14906421972518336, "mean_inference_ms": 1.430652445340626, "mean_action_processing_ms": 0.0931809820553319, "mean_env_wait_ms": 0.15737963158931417, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1107, "timesteps_this_iter": 32, "agent_timesteps_total": 2214, "timers": {"learn_time_ms": 59.386, "learn_throughput": 538.845, "update_time_ms": 4.64}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1107, "num_agent_steps_sampled": 2214, "num_steps_trained": 192, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 384, "last_target_update_ts": 1007, "num_target_updates": 1}, "done": false, "episodes_total": 58, "training_iteration": 2, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-24", "timestamp": 1648816104, "time_this_iter_s": 0.3262050151824951, "time_total_s": 3.1474945545196533, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c74d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82c73b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c74d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82c73b0>"}, "time_since_restore": 3.1474945545196533, "timesteps_since_restore": 64, "iterations_since_restore": 2, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -22.444444444444443, "episode_len_mean": 19.158730158730158, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -11.222222222222221, "policy1": -11.222222222222221}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 18.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -40.0, 26.0, -20.0, -40.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1490411380585616, "mean_inference_ms": 1.4298768697542619, "mean_action_processing_ms": 0.09320451135639081, "mean_env_wait_ms": 0.1574089638962358, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1207, "timesteps_this_iter": 32, "agent_timesteps_total": 2414, "timers": {"learn_time_ms": 6.213, "learn_throughput": 5150.631, "update_time_ms": 4.378}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1207, "num_agent_steps_sampled": 2414, "num_steps_trained": 352, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 704, "last_target_update_ts": 1127, "num_target_updates": 2}, "done": false, "episodes_total": 63, "training_iteration": 3, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-25", "timestamp": 1648816105, "time_this_iter_s": 0.30566859245300293, "time_total_s": 3.4531631469726562, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb806f200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81c19e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb806f200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81c19e0>"}, "time_since_restore": 3.4531631469726562, "timesteps_since_restore": 96, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 15.1, "ram_util_percent": 48.1}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.147058823529413, "episode_len_mean": 19.220588235294116, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -11.573529411764707, "policy1": -11.573529411764707}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 18.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -40.0, 26.0, -20.0, -40.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1489928482078825, "mean_inference_ms": 1.428600373631187, "mean_action_processing_ms": 0.09319899082760694, "mean_env_wait_ms": 0.1573756563651383, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1307, "timesteps_this_iter": 32, "agent_timesteps_total": 2614, "timers": {"learn_time_ms": 5.957, "learn_throughput": 5372.233, "update_time_ms": 3.927}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1307, "num_agent_steps_sampled": 2614, "num_steps_trained": 512, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 1024, "last_target_update_ts": 1247, "num_target_updates": 3}, "done": false, "episodes_total": 68, "training_iteration": 4, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-25", "timestamp": 1648816105, "time_this_iter_s": 0.2976102828979492, "time_total_s": 3.7507734298706055, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c73b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81c5680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c73b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81c5680>"}, "time_since_restore": 3.7507734298706055, "timesteps_since_restore": 128, "iterations_since_restore": 4, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.753424657534246, "episode_len_mean": 19.273972602739725, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -11.876712328767123, "policy1": -11.876712328767123}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 18.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -40.0, 26.0, -20.0, -40.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1489960586694722, "mean_inference_ms": 1.427702803204704, "mean_action_processing_ms": 0.09324081220724752, "mean_env_wait_ms": 0.15743197025463088, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1407, "timesteps_this_iter": 32, "agent_timesteps_total": 2814, "timers": {"learn_time_ms": 6.315, "learn_throughput": 5067.459, "update_time_ms": 3.783}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1407, "num_agent_steps_sampled": 2814, "num_steps_trained": 672, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 1344, "last_target_update_ts": 1367, "num_target_updates": 4}, "done": false, "episodes_total": 73, "training_iteration": 5, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-25", "timestamp": 1648816105, "time_this_iter_s": 0.32601022720336914, "time_total_s": 4.076783657073975, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb803db90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81fbef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb803db90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81fbef0>"}, "time_since_restore": 4.076783657073975, "timesteps_since_restore": 160, "iterations_since_restore": 5, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.512820512820515, "episode_len_mean": 19.32051282051282, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -11.756410256410257, "policy1": -11.756410256410257}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 18.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -40.0, 26.0, -20.0, -40.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1490033595045849, "mean_inference_ms": 1.4268736657857095, "mean_action_processing_ms": 0.09330198460155034, "mean_env_wait_ms": 0.1575299750165639, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1507, "timesteps_this_iter": 32, "agent_timesteps_total": 3014, "timers": {"learn_time_ms": 6.359, "learn_throughput": 5032.007, "update_time_ms": 4.347}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1507, "num_agent_steps_sampled": 3014, "num_steps_trained": 832, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 1664, "last_target_update_ts": 1487, "num_target_updates": 5}, "done": false, "episodes_total": 78, "training_iteration": 6, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-26", "timestamp": 1648816106, "time_this_iter_s": 0.3191382884979248, "time_total_s": 4.395921945571899, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c73b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb826b5f0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c73b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb826b5f0>"}, "time_since_restore": 4.395921945571899, "timesteps_since_restore": 192, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 17.5, "ram_util_percent": 48.1}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.02409638554217, "episode_len_mean": 19.36144578313253, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -12.012048192771084, "policy1": -12.012048192771084}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 18.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -40.0, 26.0, -20.0, -40.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1489776056574695, "mean_inference_ms": 1.4256304105965905, "mean_action_processing_ms": 0.09334291331496333, "mean_env_wait_ms": 0.15760010331488794, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1607, "timesteps_this_iter": 32, "agent_timesteps_total": 3214, "timers": {"learn_time_ms": 6.086, "learn_throughput": 5257.647, "update_time_ms": 4.561}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1607, "num_agent_steps_sampled": 3214, "num_steps_trained": 992, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 1984, "last_target_update_ts": 1607, "num_target_updates": 6}, "done": false, "episodes_total": 83, "training_iteration": 7, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-26", "timestamp": 1648816106, "time_this_iter_s": 0.2960379123687744, "time_total_s": 4.691959857940674, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb803ddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82caa70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb803ddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82caa70>"}, "time_since_restore": 4.691959857940674, "timesteps_since_restore": 224, "iterations_since_restore": 7, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.382022471910112, "episode_len_mean": 19.382022471910112, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -12.191011235955056, "policy1": -12.191011235955056}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 18.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -40.0, 26.0, -20.0, -40.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14894753770579744, "mean_inference_ms": 1.424036828431925, "mean_action_processing_ms": 0.09339048312123739, "mean_env_wait_ms": 0.15767305409497187, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1725, "timesteps_this_iter": 32, "agent_timesteps_total": 3450, "timers": {"learn_time_ms": 6.069, "learn_throughput": 5272.766, "update_time_ms": 4.409}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1725, "num_agent_steps_sampled": 3450, "num_steps_trained": 1184, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 2368, "last_target_update_ts": 1725, "num_target_updates": 7}, "done": false, "episodes_total": 89, "training_iteration": 8, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-26", "timestamp": 1648816106, "time_this_iter_s": 0.36283326148986816, "time_total_s": 5.054793119430542, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81c5830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82c7cb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81c5830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82c7cb0>"}, "time_since_restore": 5.054793119430542, "timesteps_since_restore": 256, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 18.2, "ram_util_percent": 48.1}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.936842105263157, "episode_len_mean": 19.33684210526316, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -11.968421052631578, "policy1": -11.968421052631578}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 18.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -40.0, 26.0, -20.0, -40.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20], "policy_policy0_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14892042800704045, "mean_inference_ms": 1.4223048772293767, "mean_action_processing_ms": 0.09342425759977298, "mean_env_wait_ms": 0.15773406289763037, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1837, "timesteps_this_iter": 32, "agent_timesteps_total": 3674, "timers": {"learn_time_ms": 6.068, "learn_throughput": 5273.18, "update_time_ms": 4.268}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1837, "num_agent_steps_sampled": 3674, "num_steps_trained": 1376, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 2752, "last_target_update_ts": 1837, "num_target_updates": 8}, "done": false, "episodes_total": 95, "training_iteration": 9, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-27", "timestamp": 1648816107, "time_this_iter_s": 0.345073938369751, "time_total_s": 5.399867057800293, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb803d5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82caa70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb803d5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82caa70>"}, "time_since_restore": 5.399867057800293, "timesteps_since_restore": 288, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 16.7, "ram_util_percent": 48.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.24, "episode_len_mean": 19.22, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -11.62, "policy1": -11.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -40.0, 26.0, -20.0, -40.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [11, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20], "policy_policy0_reward": [9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [9.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14889727219051246, "mean_inference_ms": 1.4204012431849997, "mean_action_processing_ms": 0.09345263100961879, "mean_env_wait_ms": 0.15778971371343964, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1942, "timesteps_this_iter": 32, "agent_timesteps_total": 3884, "timers": {"learn_time_ms": 6.069, "learn_throughput": 5272.538, "update_time_ms": 3.816}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1942, "num_agent_steps_sampled": 3884, "num_steps_trained": 1568, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 3136, "last_target_update_ts": 1942, "num_target_updates": 9}, "done": false, "episodes_total": 101, "training_iteration": 10, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-27", "timestamp": 1648816107, "time_this_iter_s": 0.3302009105682373, "time_total_s": 5.73006796836853, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c74d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81c5830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c74d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81c5830>"}, "time_since_restore": 5.73006796836853, "timesteps_since_restore": 320, "iterations_since_restore": 10, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.16, "episode_len_mean": 19.18, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -11.58, "policy1": -11.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -20.0, -40.0, 26.0, -20.0, -40.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 7, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20], "policy_policy0_reward": [0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [0.0, -10.0, -20.0, 13.0, -10.0, -20.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14884861070929975, "mean_inference_ms": 1.4177852797414916, "mean_action_processing_ms": 0.09348029328296374, "mean_env_wait_ms": 0.15784700428576223, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2049, "timesteps_this_iter": 32, "agent_timesteps_total": 4098, "timers": {"learn_time_ms": 5.887, "learn_throughput": 5435.699, "update_time_ms": 3.683}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2049, "num_agent_steps_sampled": 4098, "num_steps_trained": 1760, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 3520, "last_target_update_ts": 2049, "num_target_updates": 10}, "done": false, "episodes_total": 107, "training_iteration": 11, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-27", "timestamp": 1648816107, "time_this_iter_s": 0.3263676166534424, "time_total_s": 6.056435585021973, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fbdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb803db90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fbdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb803db90>"}, "time_since_restore": 6.056435585021973, "timesteps_since_restore": 352, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 15.9, "ram_util_percent": 48.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.42, "episode_len_mean": 19.21, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -11.71, "policy1": -11.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1487766224899932, "mean_inference_ms": 1.414843995826714, "mean_action_processing_ms": 0.09349391625566401, "mean_env_wait_ms": 0.15788692709839064, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2159, "timesteps_this_iter": 32, "agent_timesteps_total": 4318, "timers": {"learn_time_ms": 5.917, "learn_throughput": 5408.254, "update_time_ms": 3.827}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2159, "num_agent_steps_sampled": 4318, "num_steps_trained": 1952, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 3904, "last_target_update_ts": 2159, "num_target_updates": 11}, "done": false, "episodes_total": 113, "training_iteration": 12, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-28", "timestamp": 1648816108, "time_this_iter_s": 0.3347334861755371, "time_total_s": 6.39116907119751, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81c5710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb80617a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81c5710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb80617a0>"}, "time_since_restore": 6.39116907119751, "timesteps_since_restore": 384, "iterations_since_restore": 12, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -22.46, "episode_len_mean": 18.93, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -11.23, "policy1": -11.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1486982543730627, "mean_inference_ms": 1.4111967708810118, "mean_action_processing_ms": 0.09350411986773065, "mean_env_wait_ms": 0.1579107791092212, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2269, "timesteps_this_iter": 32, "agent_timesteps_total": 4538, "timers": {"learn_time_ms": 6.155, "learn_throughput": 5198.772, "update_time_ms": 3.827}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2269, "num_agent_steps_sampled": 4538, "num_steps_trained": 2176, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 4352, "last_target_update_ts": 2269, "num_target_updates": 12}, "done": false, "episodes_total": 120, "training_iteration": 13, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-28", "timestamp": 1648816108, "time_this_iter_s": 0.47948122024536133, "time_total_s": 6.870650291442871, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fbdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8061ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fbdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8061ef0>"}, "time_since_restore": 6.870650291442871, "timesteps_since_restore": 416, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 16.9, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -22.66, "episode_len_mean": 18.93, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -11.33, "policy1": -11.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14862995621659572, "mean_inference_ms": 1.4083887673531388, "mean_action_processing_ms": 0.09350145253891898, "mean_env_wait_ms": 0.15789833578633294, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2369, "timesteps_this_iter": 32, "agent_timesteps_total": 4738, "timers": {"learn_time_ms": 6.116, "learn_throughput": 5231.824, "update_time_ms": 3.783}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2369, "num_agent_steps_sampled": 4738, "num_steps_trained": 2336, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 4672, "last_target_update_ts": 2269, "num_target_updates": 12}, "done": false, "episodes_total": 125, "training_iteration": 14, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-29", "timestamp": 1648816109, "time_this_iter_s": 0.2930722236633301, "time_total_s": 7.163722515106201, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8061710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81c57a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8061710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81c57a0>"}, "time_since_restore": 7.163722515106201, "timesteps_since_restore": 448, "iterations_since_restore": 14, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.98, "episode_len_mean": 18.79, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -10.99, "policy1": -10.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, 18.0, -20.0, -20.0, 0.0, -40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0], "episode_lengths": [20, 20, 20, 11, 20, 20, 20, 20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12], "policy_policy0_reward": [-20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, 9.0, -10.0, -10.0, 0.0, -20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14854650448663917, "mean_inference_ms": 1.4048991030101279, "mean_action_processing_ms": 0.09348913697393396, "mean_env_wait_ms": 0.15787380888080918, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2475, "timesteps_this_iter": 32, "agent_timesteps_total": 4950, "timers": {"learn_time_ms": 5.914, "learn_throughput": 5410.5, "update_time_ms": 3.812}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2475, "num_agent_steps_sampled": 4950, "num_steps_trained": 2528, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 5056, "last_target_update_ts": 2383, "num_target_updates": 13}, "done": false, "episodes_total": 131, "training_iteration": 15, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-29", "timestamp": 1648816109, "time_this_iter_s": 0.33271050453186035, "time_total_s": 7.4964330196380615, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81c5c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8042cb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81c5c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8042cb0>"}, "time_since_restore": 7.4964330196380615, "timesteps_since_restore": 480, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 16.1, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.14, "episode_len_mean": 18.67, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -10.57, "policy1": -10.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 28.0, 6.0, 6.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0], "episode_lengths": [20, 6, 17, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20], "policy_policy0_reward": [-20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0], "policy_policy1_reward": [-20.0, 14.0, 3.0, 3.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14847424964606032, "mean_inference_ms": 1.4008058051171388, "mean_action_processing_ms": 0.09348440284535436, "mean_env_wait_ms": 0.157876323071336, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2594, "timesteps_this_iter": 32, "agent_timesteps_total": 5188, "timers": {"learn_time_ms": 6.126, "learn_throughput": 5223.659, "update_time_ms": 3.827}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2594, "num_agent_steps_sampled": 5188, "num_steps_trained": 2752, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 5504, "last_target_update_ts": 2495, "num_target_updates": 14}, "done": false, "episodes_total": 138, "training_iteration": 16, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-29", "timestamp": 1648816109, "time_this_iter_s": 0.3890259265899658, "time_total_s": 7.885458946228027, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81c5710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8061830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81c5710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8061830>"}, "time_since_restore": 7.885458946228027, "timesteps_since_restore": 512, "iterations_since_restore": 16, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.9, "episode_len_mean": 18.85, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -10.95, "policy1": -10.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14840863344083474, "mean_inference_ms": 1.3972364766075542, "mean_action_processing_ms": 0.09347904637314584, "mean_env_wait_ms": 0.15786918357042776, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2712, "timesteps_this_iter": 32, "agent_timesteps_total": 5424, "timers": {"learn_time_ms": 6.453, "learn_throughput": 4958.832, "update_time_ms": 3.876}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2712, "num_agent_steps_sampled": 5424, "num_steps_trained": 2944, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 5888, "last_target_update_ts": 2612, "num_target_updates": 15}, "done": false, "episodes_total": 144, "training_iteration": 17, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-30", "timestamp": 1648816110, "time_this_iter_s": 0.36569786071777344, "time_total_s": 8.2511568069458, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8042cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8230440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8042cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8230440>"}, "time_since_restore": 8.2511568069458, "timesteps_since_restore": 544, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 16.8, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -22.1, "episode_len_mean": 18.85, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -11.05, "policy1": -11.05}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14836882622964903, "mean_inference_ms": 1.3943893886307563, "mean_action_processing_ms": 0.09348808556926279, "mean_env_wait_ms": 0.15788143878101432, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2812, "timesteps_this_iter": 32, "agent_timesteps_total": 5624, "timers": {"learn_time_ms": 6.474, "learn_throughput": 4943.071, "update_time_ms": 3.935}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2812, "num_agent_steps_sampled": 5624, "num_steps_trained": 3104, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 6208, "last_target_update_ts": 2732, "num_target_updates": 16}, "done": false, "episodes_total": 149, "training_iteration": 18, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-30", "timestamp": 1648816110, "time_this_iter_s": 0.31883883476257324, "time_total_s": 8.569995641708374, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8061830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81c57a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8061830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81c57a0>"}, "time_since_restore": 8.569995641708374, "timesteps_since_restore": 576, "iterations_since_restore": 18, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.5, "episode_len_mean": 18.85, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -10.75, "policy1": -10.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14835118965616365, "mean_inference_ms": 1.3917993276703606, "mean_action_processing_ms": 0.09350891534033291, "mean_env_wait_ms": 0.15791202813657962, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2912, "timesteps_this_iter": 32, "agent_timesteps_total": 5824, "timers": {"learn_time_ms": 6.492, "learn_throughput": 4929.003, "update_time_ms": 3.855}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2912, "num_agent_steps_sampled": 5824, "num_steps_trained": 3264, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 6528, "last_target_update_ts": 2852, "num_target_updates": 17}, "done": false, "episodes_total": 154, "training_iteration": 19, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-30", "timestamp": 1648816110, "time_this_iter_s": 0.3307521343231201, "time_total_s": 8.900747776031494, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fbdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82087a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fbdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82087a0>"}, "time_since_restore": 8.900747776031494, "timesteps_since_restore": 608, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 17.5, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.66, "episode_len_mean": 18.73, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -10.33, "policy1": -10.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14835194163536977, "mean_inference_ms": 1.3892041274026077, "mean_action_processing_ms": 0.09353241720123076, "mean_env_wait_ms": 0.15795912878126342, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3020, "timesteps_this_iter": 32, "agent_timesteps_total": 6040, "timers": {"learn_time_ms": 6.568, "learn_throughput": 4872.388, "update_time_ms": 3.939}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3020, "num_agent_steps_sampled": 6040, "num_steps_trained": 3456, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 6912, "last_target_update_ts": 2960, "num_target_updates": 18}, "done": false, "episodes_total": 160, "training_iteration": 20, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-31", "timestamp": 1648816111, "time_this_iter_s": 0.36182141304016113, "time_total_s": 9.262569189071655, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c7cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb80617a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c7cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb80617a0>"}, "time_since_restore": 9.262569189071655, "timesteps_since_restore": 640, "iterations_since_restore": 20, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.98, "episode_len_mean": 18.69, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.99, "policy1": -9.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14839258835241656, "mean_inference_ms": 1.3871639796486395, "mean_action_processing_ms": 0.09357160242124916, "mean_env_wait_ms": 0.15804694852709086, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3136, "timesteps_this_iter": 32, "agent_timesteps_total": 6272, "timers": {"learn_time_ms": 6.377, "learn_throughput": 5017.935, "update_time_ms": 4.16}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3136, "num_agent_steps_sampled": 6272, "num_steps_trained": 3648, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 7296, "last_target_update_ts": 3076, "num_target_updates": 19}, "done": false, "episodes_total": 166, "training_iteration": 21, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-31", "timestamp": 1648816111, "time_this_iter_s": 0.3741950988769531, "time_total_s": 9.636764287948608, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fbef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a4d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fbef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a4d0>"}, "time_since_restore": 9.636764287948608, "timesteps_since_restore": 672, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 16.7, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.92, "episode_len_mean": 18.46, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.96, "policy1": -8.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14843784437544474, "mean_inference_ms": 1.3848688170450771, "mean_action_processing_ms": 0.09359065706260788, "mean_env_wait_ms": 0.15810008637822218, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3253, "timesteps_this_iter": 32, "agent_timesteps_total": 6506, "timers": {"learn_time_ms": 6.437, "learn_throughput": 4971.082, "update_time_ms": 3.745}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3253, "num_agent_steps_sampled": 6506, "num_steps_trained": 3872, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 7744, "last_target_update_ts": 3189, "num_target_updates": 20}, "done": false, "episodes_total": 173, "training_iteration": 22, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-32", "timestamp": 1648816112, "time_this_iter_s": 0.38518619537353516, "time_total_s": 10.021950483322144, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82087a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82087a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a830>"}, "time_since_restore": 10.021950483322144, "timesteps_since_restore": 704, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 15.8, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.72, "episode_len_mean": 18.46, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.36, "policy1": -9.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14845198168092635, "mean_inference_ms": 1.3831621791759965, "mean_action_processing_ms": 0.09357114776488348, "mean_env_wait_ms": 0.15807844539298807, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3353, "timesteps_this_iter": 32, "agent_timesteps_total": 6706, "timers": {"learn_time_ms": 6.359, "learn_throughput": 5031.875, "update_time_ms": 3.703}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3353, "num_agent_steps_sampled": 6706, "num_steps_trained": 4032, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 8064, "last_target_update_ts": 3293, "num_target_updates": 21}, "done": false, "episodes_total": 178, "training_iteration": 23, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-32", "timestamp": 1648816112, "time_this_iter_s": 0.3027040958404541, "time_total_s": 10.324654579162598, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fbef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fbef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208710>"}, "time_since_restore": 10.324654579162598, "timesteps_since_restore": 736, "iterations_since_restore": 23, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.84, "episode_len_mean": 18.42, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.92, "policy1": -8.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20], "policy_policy0_reward": [2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [2.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.148510012532896, "mean_inference_ms": 1.381681416262114, "mean_action_processing_ms": 0.09356643067272817, "mean_env_wait_ms": 0.15807880647014547, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3469, "timesteps_this_iter": 32, "agent_timesteps_total": 6938, "timers": {"learn_time_ms": 6.318, "learn_throughput": 5065.126, "update_time_ms": 3.942}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3469, "num_agent_steps_sampled": 6938, "num_steps_trained": 4224, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 8448, "last_target_update_ts": 3409, "num_target_updates": 22}, "done": false, "episodes_total": 184, "training_iteration": 24, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-32", "timestamp": 1648816112, "time_this_iter_s": 0.3708302974700928, "time_total_s": 10.69548487663269, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb821a560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82309e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb821a560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82309e0>"}, "time_since_restore": 10.69548487663269, "timesteps_since_restore": 768, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 18.1, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.6, "episode_len_mean": 18.4, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.8, "policy1": -8.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 16.0, -40.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0], "episode_lengths": [20, 12, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20], "policy_policy0_reward": [-10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 8.0, -20.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14856681859129675, "mean_inference_ms": 1.3803866055298881, "mean_action_processing_ms": 0.09355997352037076, "mean_env_wait_ms": 0.1580709718203946, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3585, "timesteps_this_iter": 32, "agent_timesteps_total": 7170, "timers": {"learn_time_ms": 6.391, "learn_throughput": 5006.985, "update_time_ms": 3.895}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3585, "num_agent_steps_sampled": 7170, "num_steps_trained": 4416, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 8832, "last_target_update_ts": 3529, "num_target_updates": 23}, "done": false, "episodes_total": 190, "training_iteration": 25, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-33", "timestamp": 1648816113, "time_this_iter_s": 0.3558821678161621, "time_total_s": 11.051367044448853, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82caef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82013b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82caef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82013b0>"}, "time_since_restore": 11.051367044448853, "timesteps_since_restore": 800, "iterations_since_restore": 25, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.06, "episode_len_mean": 18.43, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.03, "policy1": -9.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1486441049788176, "mean_inference_ms": 1.3794755034097588, "mean_action_processing_ms": 0.09356878505095796, "mean_env_wait_ms": 0.15807422609372604, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3685, "timesteps_this_iter": 32, "agent_timesteps_total": 7370, "timers": {"learn_time_ms": 6.603, "learn_throughput": 4846.595, "update_time_ms": 3.958}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3685, "num_agent_steps_sampled": 7370, "num_steps_trained": 4608, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 9216, "last_target_update_ts": 3645, "num_target_updates": 24}, "done": false, "episodes_total": 196, "training_iteration": 26, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-33", "timestamp": 1648816113, "time_this_iter_s": 0.34682464599609375, "time_total_s": 11.398191690444946, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb821a440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201a70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb821a440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201a70>"}, "time_since_restore": 11.398191690444946, "timesteps_since_restore": 832, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 18.2, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.26, "episode_len_mean": 18.43, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.13, "policy1": -9.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0], "episode_lengths": [20, 20, 7, 20, 20, 20, 20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14869482541607149, "mean_inference_ms": 1.3788199258811233, "mean_action_processing_ms": 0.09357268998677305, "mean_env_wait_ms": 0.15806499758870657, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3785, "timesteps_this_iter": 32, "agent_timesteps_total": 7570, "timers": {"learn_time_ms": 6.49, "learn_throughput": 4930.687, "update_time_ms": 3.985}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3785, "num_agent_steps_sampled": 7570, "num_steps_trained": 4768, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 9536, "last_target_update_ts": 3765, "num_target_updates": 25}, "done": false, "episodes_total": 201, "training_iteration": 27, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-33", "timestamp": 1648816113, "time_this_iter_s": 0.29819273948669434, "time_total_s": 11.69638442993164, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201320>"}, "time_since_restore": 11.69638442993164, "timesteps_since_restore": 864, "iterations_since_restore": 27, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.38, "episode_len_mean": 18.49, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.19, "policy1": -9.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 20.0, -40.0, -20.0, -20.0, 32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0], "episode_lengths": [20, 20, 10, 20, 20, 20, 4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14], "policy_policy0_reward": [-10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0], "policy_policy1_reward": [-10.0, -20.0, 10.0, -20.0, -10.0, -10.0, 16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1487675308514764, "mean_inference_ms": 1.378168025335857, "mean_action_processing_ms": 0.0935839596563763, "mean_env_wait_ms": 0.1580642493368605, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3898, "timesteps_this_iter": 32, "agent_timesteps_total": 7796, "timers": {"learn_time_ms": 6.054, "learn_throughput": 5285.973, "update_time_ms": 3.724}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3898, "num_agent_steps_sampled": 7796, "num_steps_trained": 4960, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 9920, "last_target_update_ts": 3884, "num_target_updates": 26}, "done": false, "episodes_total": 207, "training_iteration": 28, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-34", "timestamp": 1648816114, "time_this_iter_s": 0.34132885932922363, "time_total_s": 12.037713289260864, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8230440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8225320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8230440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8225320>"}, "time_since_restore": 12.037713289260864, "timesteps_since_restore": 896, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 16.3, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.36, "episode_len_mean": 18.58, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.18, "policy1": -9.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.0, -20.0, 0.0, 22.0, 6.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0], "episode_lengths": [4, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20], "policy_policy0_reward": [16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0], "policy_policy1_reward": [16.0, -10.0, 0.0, 11.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14885757254332949, "mean_inference_ms": 1.3778482261462455, "mean_action_processing_ms": 0.09361100130233253, "mean_env_wait_ms": 0.15809127123327696, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4017, "timesteps_this_iter": 32, "agent_timesteps_total": 8034, "timers": {"learn_time_ms": 6.21, "learn_throughput": 5152.905, "update_time_ms": 3.819}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4017, "num_agent_steps_sampled": 8034, "num_steps_trained": 5152, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 10304, "last_target_update_ts": 3997, "num_target_updates": 27}, "done": false, "episodes_total": 213, "training_iteration": 29, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-34", "timestamp": 1648816114, "time_this_iter_s": 0.37755703926086426, "time_total_s": 12.415270328521729, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82caef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82caef0>"}, "time_since_restore": 12.415270328521729, "timesteps_since_restore": 928, "iterations_since_restore": 29, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.0, "episode_len_mean": 18.8, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.5, "policy1": -9.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1489339557922955, "mean_inference_ms": 1.377603410825479, "mean_action_processing_ms": 0.093636643957888, "mean_env_wait_ms": 0.15812904004122516, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4129, "timesteps_this_iter": 32, "agent_timesteps_total": 8258, "timers": {"learn_time_ms": 6.162, "learn_throughput": 5192.718, "update_time_ms": 3.721}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4129, "num_agent_steps_sampled": 8258, "num_steps_trained": 5344, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 10688, "last_target_update_ts": 4109, "num_target_updates": 28}, "done": false, "episodes_total": 219, "training_iteration": 30, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-35", "timestamp": 1648816115, "time_this_iter_s": 0.34043073654174805, "time_total_s": 12.755701065063477, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201950>"}, "time_since_restore": 12.755701065063477, "timesteps_since_restore": 960, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 15.8, "ram_util_percent": 48.3}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.52, "episode_len_mean": 18.66, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.26, "policy1": -9.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, -20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0], "episode_lengths": [14, 20, 20, 20, 20, 12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20], "policy_policy0_reward": [6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [6.0, -10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1490158109054601, "mean_inference_ms": 1.3774452407241762, "mean_action_processing_ms": 0.09366622718354685, "mean_env_wait_ms": 0.15819448686975826, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4235, "timesteps_this_iter": 32, "agent_timesteps_total": 8470, "timers": {"learn_time_ms": 6.122, "learn_throughput": 5226.751, "update_time_ms": 3.636}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4235, "num_agent_steps_sampled": 8470, "num_steps_trained": 5536, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 11072, "last_target_update_ts": 4215, "num_target_updates": 29}, "done": false, "episodes_total": 225, "training_iteration": 31, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-35", "timestamp": 1648816115, "time_this_iter_s": 0.32614803314208984, "time_total_s": 13.081849098205566, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a440>"}, "time_since_restore": 13.081849098205566, "timesteps_since_restore": 992, "iterations_since_restore": 31, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.04, "episode_len_mean": 18.72, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.52, "policy1": -9.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, -20.0, -40.0, 4.0, 12.0, 26.0, 0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [12, 20, 20, 18, 14, 7, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [8.0, -10.0, -20.0, 2.0, 6.0, 13.0, 0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1490860116181561, "mean_inference_ms": 1.377405933247498, "mean_action_processing_ms": 0.09369928667046551, "mean_env_wait_ms": 0.15825968495078555, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4335, "timesteps_this_iter": 32, "agent_timesteps_total": 8670, "timers": {"learn_time_ms": 6.184, "learn_throughput": 5174.3, "update_time_ms": 3.769}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4335, "num_agent_steps_sampled": 8670, "num_steps_trained": 5696, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 11392, "last_target_update_ts": 4335, "num_target_updates": 30}, "done": false, "episodes_total": 230, "training_iteration": 32, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-35", "timestamp": 1648816115, "time_this_iter_s": 0.306002140045166, "time_total_s": 13.387851238250732, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82019e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82088c0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82019e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82088c0>"}, "time_since_restore": 13.387851238250732, "timesteps_since_restore": 1024, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 16.0, "ram_util_percent": 48.3}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.78, "episode_len_mean": 18.89, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.89, "policy1": -9.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20], "policy_policy0_reward": [0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [0.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14914749762070126, "mean_inference_ms": 1.3772383482453363, "mean_action_processing_ms": 0.09372441454953083, "mean_env_wait_ms": 0.15830024421891853, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4443, "timesteps_this_iter": 32, "agent_timesteps_total": 8886, "timers": {"learn_time_ms": 6.256, "learn_throughput": 5115.434, "update_time_ms": 3.894}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4443, "num_agent_steps_sampled": 8886, "num_steps_trained": 5888, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 11776, "last_target_update_ts": 4443, "num_target_updates": 31}, "done": false, "episodes_total": 236, "training_iteration": 33, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-36", "timestamp": 1648816116, "time_this_iter_s": 0.33453965187072754, "time_total_s": 13.72239089012146, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb821a5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8061170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb821a5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8061170>"}, "time_since_restore": 13.72239089012146, "timesteps_since_restore": 1056, "iterations_since_restore": 33, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.74, "episode_len_mean": 18.77, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.87, "policy1": -9.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1492093933445392, "mean_inference_ms": 1.377027510788925, "mean_action_processing_ms": 0.09374857830017025, "mean_env_wait_ms": 0.1583381326003226, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4549, "timesteps_this_iter": 32, "agent_timesteps_total": 9098, "timers": {"learn_time_ms": 6.255, "learn_throughput": 5116.292, "update_time_ms": 3.778}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4549, "num_agent_steps_sampled": 9098, "num_steps_trained": 6080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 12160, "last_target_update_ts": 4549, "num_target_updates": 32}, "done": false, "episodes_total": 242, "training_iteration": 34, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-36", "timestamp": 1648816116, "time_this_iter_s": 0.3324925899505615, "time_total_s": 14.054883480072021, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8225cb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8225cb0>"}, "time_since_restore": 14.054883480072021, "timesteps_since_restore": 1088, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 15.4, "ram_util_percent": 48.3}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.14, "episode_len_mean": 18.77, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.57, "policy1": -9.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14925439364878884, "mean_inference_ms": 1.3767903507047055, "mean_action_processing_ms": 0.09376601735153937, "mean_env_wait_ms": 0.15836471918876735, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4649, "timesteps_this_iter": 32, "agent_timesteps_total": 9298, "timers": {"learn_time_ms": 6.21, "learn_throughput": 5153.202, "update_time_ms": 3.734}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4649, "num_agent_steps_sampled": 9298, "num_steps_trained": 6240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 12480, "last_target_update_ts": 4549, "num_target_updates": 32}, "done": false, "episodes_total": 247, "training_iteration": 35, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-36", "timestamp": 1648816116, "time_this_iter_s": 0.3085954189300537, "time_total_s": 14.363478899002075, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a440>"}, "time_since_restore": 14.363478899002075, "timesteps_since_restore": 1120, "iterations_since_restore": 35, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.14, "episode_len_mean": 18.77, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.57, "policy1": -9.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 8, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1492711129641423, "mean_inference_ms": 1.376296326522766, "mean_action_processing_ms": 0.0937623899664002, "mean_env_wait_ms": 0.15835878833127776, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4749, "timesteps_this_iter": 32, "agent_timesteps_total": 9498, "timers": {"learn_time_ms": 6.052, "learn_throughput": 5287.764, "update_time_ms": 3.691}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4749, "num_agent_steps_sampled": 9498, "num_steps_trained": 6400, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 12800, "last_target_update_ts": 4669, "num_target_updates": 33}, "done": false, "episodes_total": 252, "training_iteration": 36, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-37", "timestamp": 1648816117, "time_this_iter_s": 0.2959315776824951, "time_total_s": 14.65941047668457, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232e60>"}, "time_since_restore": 14.65941047668457, "timesteps_since_restore": 1152, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 17.1, "ram_util_percent": 48.3}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.58, "episode_len_mean": 18.89, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.79, "policy1": -9.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14928714831194004, "mean_inference_ms": 1.3758503765748937, "mean_action_processing_ms": 0.0937662275384269, "mean_env_wait_ms": 0.15835415239085815, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4849, "timesteps_this_iter": 32, "agent_timesteps_total": 9698, "timers": {"learn_time_ms": 6.192, "learn_throughput": 5168.203, "update_time_ms": 4.027}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4849, "num_agent_steps_sampled": 9698, "num_steps_trained": 6560, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 13120, "last_target_update_ts": 4789, "num_target_updates": 34}, "done": false, "episodes_total": 257, "training_iteration": 37, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-37", "timestamp": 1648816117, "time_this_iter_s": 0.3432626724243164, "time_total_s": 15.002673149108887, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb821a5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8061170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb821a5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8061170>"}, "time_since_restore": 15.002673149108887, "timesteps_since_restore": 1184, "iterations_since_restore": 37, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.66, "episode_len_mean": 18.93, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.83, "policy1": -9.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 13, 20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14928809027651155, "mean_inference_ms": 1.3752742824604371, "mean_action_processing_ms": 0.09376118824648155, "mean_env_wait_ms": 0.15833039869261956, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4949, "timesteps_this_iter": 32, "agent_timesteps_total": 9898, "timers": {"learn_time_ms": 6.29, "learn_throughput": 5087.3, "update_time_ms": 4.024}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4949, "num_agent_steps_sampled": 9898, "num_steps_trained": 6720, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 13440, "last_target_update_ts": 4909, "num_target_updates": 35}, "done": false, "episodes_total": 262, "training_iteration": 38, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-37", "timestamp": 1648816117, "time_this_iter_s": 0.29935264587402344, "time_total_s": 15.30202579498291, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203440>"}, "time_since_restore": 15.30202579498291, "timesteps_since_restore": 1216, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 17.0, "ram_util_percent": 48.3}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.86, "episode_len_mean": 18.73, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.43, "policy1": -9.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 28.0, 4.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0], "episode_lengths": [20, 6, 18, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20], "policy_policy0_reward": [-10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0], "policy_policy1_reward": [-10.0, 14.0, 2.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1492931454295384, "mean_inference_ms": 1.3745703747983993, "mean_action_processing_ms": 0.09376205242620575, "mean_env_wait_ms": 0.15831789100342092, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5062, "timesteps_this_iter": 32, "agent_timesteps_total": 10124, "timers": {"learn_time_ms": 6.464, "learn_throughput": 4950.546, "update_time_ms": 3.99}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5062, "num_agent_steps_sampled": 10124, "num_steps_trained": 6944, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 13888, "last_target_update_ts": 5015, "num_target_updates": 36}, "done": false, "episodes_total": 269, "training_iteration": 39, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-38", "timestamp": 1648816118, "time_this_iter_s": 0.39568614959716797, "time_total_s": 15.697711944580078, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82088c0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82088c0>"}, "time_since_restore": 15.697711944580078, "timesteps_since_restore": 1248, "iterations_since_restore": 39, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.7, "episode_len_mean": 18.75, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.35, "policy1": -9.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14930397590813263, "mean_inference_ms": 1.37407774105082, "mean_action_processing_ms": 0.09377311625655378, "mean_env_wait_ms": 0.15832820433892006, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5168, "timesteps_this_iter": 32, "agent_timesteps_total": 10336, "timers": {"learn_time_ms": 6.378, "learn_throughput": 5016.923, "update_time_ms": 3.779}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5168, "num_agent_steps_sampled": 10336, "num_steps_trained": 7136, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 14272, "last_target_update_ts": 5128, "num_target_updates": 37}, "done": false, "episodes_total": 275, "training_iteration": 40, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-38", "timestamp": 1648816118, "time_this_iter_s": 0.3525722026824951, "time_total_s": 16.050284147262573, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82019e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82019e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b00>"}, "time_since_restore": 16.050284147262573, "timesteps_since_restore": 1280, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 16.9, "ram_util_percent": 48.3}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.78, "episode_len_mean": 18.79, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.39, "policy1": -9.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14930918949112398, "mean_inference_ms": 1.3736427457196865, "mean_action_processing_ms": 0.09377972769510468, "mean_env_wait_ms": 0.1583265108695969, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5268, "timesteps_this_iter": 32, "agent_timesteps_total": 10536, "timers": {"learn_time_ms": 6.289, "learn_throughput": 5088.052, "update_time_ms": 3.73}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5268, "num_agent_steps_sampled": 10536, "num_steps_trained": 7296, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 14592, "last_target_update_ts": 5248, "num_target_updates": 38}, "done": false, "episodes_total": 280, "training_iteration": 41, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-38", "timestamp": 1648816118, "time_this_iter_s": 0.2985677719116211, "time_total_s": 16.348851919174194, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb821a440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb821a440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "time_since_restore": 16.348851919174194, "timesteps_since_restore": 1312, "iterations_since_restore": 41, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.12, "episode_len_mean": 18.66, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.06, "policy1": -9.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 8.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0], "episode_lengths": [20, 16, 20, 20, 20, 20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10], "policy_policy0_reward": [-20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0], "policy_policy1_reward": [-20.0, 4.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14931255523338394, "mean_inference_ms": 1.3730915271343656, "mean_action_processing_ms": 0.09378113639626573, "mean_env_wait_ms": 0.15831778002367347, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5375, "timesteps_this_iter": 32, "agent_timesteps_total": 10750, "timers": {"learn_time_ms": 6.159, "learn_throughput": 5195.471, "update_time_ms": 3.704}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5375, "num_agent_steps_sampled": 10750, "num_steps_trained": 7488, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 14976, "last_target_update_ts": 5365, "num_target_updates": 39}, "done": false, "episodes_total": 286, "training_iteration": 42, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-39", "timestamp": 1648816119, "time_this_iter_s": 0.337327241897583, "time_total_s": 16.686179161071777, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82019e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82019e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203e60>"}, "time_since_restore": 16.686179161071777, "timesteps_since_restore": 1344, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 17.1, "ram_util_percent": 48.3}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.0, "episode_len_mean": 18.7, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.0, "policy1": -9.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, 30.0, 10.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 5, 15, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, 15.0, 5.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14931697314104908, "mean_inference_ms": 1.3726771124783097, "mean_action_processing_ms": 0.09378251799667675, "mean_env_wait_ms": 0.1583156988350411, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5475, "timesteps_this_iter": 32, "agent_timesteps_total": 10950, "timers": {"learn_time_ms": 6.366, "learn_throughput": 5026.862, "update_time_ms": 4.055}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5475, "num_agent_steps_sampled": 10950, "num_steps_trained": 7648, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 15296, "last_target_update_ts": 5475, "num_target_updates": 40}, "done": false, "episodes_total": 291, "training_iteration": 43, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-39", "timestamp": 1648816119, "time_this_iter_s": 0.3179810047149658, "time_total_s": 17.004160165786743, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201b90>"}, "time_since_restore": 17.004160165786743, "timesteps_since_restore": 1376, "iterations_since_restore": 43, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.2, "episode_len_mean": 18.8, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.1, "policy1": -9.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 0.0, -40.0, -20.0, 2.0, -40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 19, 20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20], "policy_policy0_reward": [-10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, 0.0, -20.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14931006692789225, "mean_inference_ms": 1.3721755508411715, "mean_action_processing_ms": 0.0937800647707972, "mean_env_wait_ms": 0.15831896803583814, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5585, "timesteps_this_iter": 32, "agent_timesteps_total": 11170, "timers": {"learn_time_ms": 6.596, "learn_throughput": 4851.711, "update_time_ms": 4.094}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5585, "num_agent_steps_sampled": 11170, "num_steps_trained": 7840, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 15680, "last_target_update_ts": 5585, "num_target_updates": 41}, "done": false, "episodes_total": 297, "training_iteration": 44, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-40", "timestamp": 1648816120, "time_this_iter_s": 0.3545081615447998, "time_total_s": 17.358668327331543, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff170>"}, "time_since_restore": 17.358668327331543, "timesteps_since_restore": 1408, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 15.2, "ram_util_percent": 48.3}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.82, "episode_len_mean": 18.81, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.41, "policy1": -9.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 14, 20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14931143886738765, "mean_inference_ms": 1.3718057866635132, "mean_action_processing_ms": 0.09378129882966171, "mean_env_wait_ms": 0.15833262355054067, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5685, "timesteps_this_iter": 32, "agent_timesteps_total": 11370, "timers": {"learn_time_ms": 6.609, "learn_throughput": 4842.136, "update_time_ms": 3.819}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5685, "num_agent_steps_sampled": 11370, "num_steps_trained": 8000, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 16000, "last_target_update_ts": 5585, "num_target_updates": 41}, "done": false, "episodes_total": 302, "training_iteration": 45, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-40", "timestamp": 1648816120, "time_this_iter_s": 0.3049662113189697, "time_total_s": 17.663634538650513, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b90>"}, "time_since_restore": 17.663634538650513, "timesteps_since_restore": 1440, "iterations_since_restore": 45, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.14, "episode_len_mean": 18.87, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.57, "policy1": -9.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 19, 20, 19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14931757494029888, "mean_inference_ms": 1.3715299632803806, "mean_action_processing_ms": 0.09379039700184905, "mean_env_wait_ms": 0.1583531732391079, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5785, "timesteps_this_iter": 32, "agent_timesteps_total": 11570, "timers": {"learn_time_ms": 6.489, "learn_throughput": 4931.375, "update_time_ms": 3.87}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5785, "num_agent_steps_sampled": 11570, "num_steps_trained": 8160, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 16320, "last_target_update_ts": 5705, "num_target_updates": 42}, "done": false, "episodes_total": 307, "training_iteration": 46, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-40", "timestamp": 1648816120, "time_this_iter_s": 0.30919909477233887, "time_total_s": 17.97283363342285, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82033b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82033b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203290>"}, "time_since_restore": 17.97283363342285, "timesteps_since_restore": 1472, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 16.9, "ram_util_percent": 48.4}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.2, "episode_len_mean": 18.8, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.6, "policy1": -9.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [19, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20], "policy_policy0_reward": [1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [1.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1493221060929721, "mean_inference_ms": 1.3710729226908938, "mean_action_processing_ms": 0.0937917678060302, "mean_env_wait_ms": 0.15835364336694935, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5897, "timesteps_this_iter": 32, "agent_timesteps_total": 11794, "timers": {"learn_time_ms": 6.078, "learn_throughput": 5264.514, "update_time_ms": 3.668}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5897, "num_agent_steps_sampled": 11794, "num_steps_trained": 8352, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 16704, "last_target_update_ts": 5817, "num_target_updates": 43}, "done": false, "episodes_total": 313, "training_iteration": 47, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-41", "timestamp": 1648816121, "time_this_iter_s": 0.33757495880126953, "time_total_s": 18.31040859222412, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232c20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232c20>"}, "time_since_restore": 18.31040859222412, "timesteps_since_restore": 1504, "iterations_since_restore": 47, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.86, "episode_len_mean": 18.83, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.93, "policy1": -9.93}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 28.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0], "episode_lengths": [20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20], "policy_policy0_reward": [-10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 14.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14933100133103885, "mean_inference_ms": 1.3706603093380914, "mean_action_processing_ms": 0.09379720548511687, "mean_env_wait_ms": 0.15835464128990237, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6012, "timesteps_this_iter": 32, "agent_timesteps_total": 12024, "timers": {"learn_time_ms": 6.007, "learn_throughput": 5327.432, "update_time_ms": 4.038}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6012, "num_agent_steps_sampled": 12024, "num_steps_trained": 8544, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 17088, "last_target_update_ts": 5937, "num_target_updates": 44}, "done": false, "episodes_total": 319, "training_iteration": 48, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-41", "timestamp": 1648816121, "time_this_iter_s": 0.3526418209075928, "time_total_s": 18.663050413131714, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82033b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82033b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203440>"}, "time_since_restore": 18.663050413131714, "timesteps_since_restore": 1536, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 17.1, "ram_util_percent": 48.4}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.94, "episode_len_mean": 18.97, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.97, "policy1": -9.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1493390500431104, "mean_inference_ms": 1.3703648823485906, "mean_action_processing_ms": 0.09380352095936421, "mean_env_wait_ms": 0.15835248189423543, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6112, "timesteps_this_iter": 32, "agent_timesteps_total": 12224, "timers": {"learn_time_ms": 5.945, "learn_throughput": 5382.963, "update_time_ms": 4.291}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6112, "num_agent_steps_sampled": 12224, "num_steps_trained": 8704, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 17408, "last_target_update_ts": 6052, "num_target_updates": 45}, "done": false, "episodes_total": 324, "training_iteration": 49, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-41", "timestamp": 1648816121, "time_this_iter_s": 0.29807376861572266, "time_total_s": 18.961124181747437, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "time_since_restore": 18.961124181747437, "timesteps_since_restore": 1568, "iterations_since_restore": 49, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.64, "episode_len_mean": 18.82, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.82, "policy1": -9.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14934393379227603, "mean_inference_ms": 1.36996661157994, "mean_action_processing_ms": 0.09380496409680691, "mean_env_wait_ms": 0.15834113114303566, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6217, "timesteps_this_iter": 32, "agent_timesteps_total": 12434, "timers": {"learn_time_ms": 6.058, "learn_throughput": 5282.187, "update_time_ms": 4.147}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6217, "num_agent_steps_sampled": 12434, "num_steps_trained": 8896, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 17792, "last_target_update_ts": 6157, "num_target_updates": 46}, "done": false, "episodes_total": 330, "training_iteration": 50, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-42", "timestamp": 1648816122, "time_this_iter_s": 0.326657772064209, "time_total_s": 19.287781953811646, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82033b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82033b0>"}, "time_since_restore": 19.287781953811646, "timesteps_since_restore": 1600, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 16.6, "ram_util_percent": 48.4}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.92, "episode_len_mean": 18.86, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.96, "policy1": -9.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14934651180294076, "mean_inference_ms": 1.3696312967626028, "mean_action_processing_ms": 0.09380623355895752, "mean_env_wait_ms": 0.15833394542464987, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6329, "timesteps_this_iter": 32, "agent_timesteps_total": 12658, "timers": {"learn_time_ms": 6.097, "learn_throughput": 5248.108, "update_time_ms": 3.785}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6329, "num_agent_steps_sampled": 12658, "num_steps_trained": 9088, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 18176, "last_target_update_ts": 6269, "num_target_updates": 47}, "done": false, "episodes_total": 336, "training_iteration": 51, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-42", "timestamp": 1648816122, "time_this_iter_s": 0.3353414535522461, "time_total_s": 19.62312340736389, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "time_since_restore": 19.62312340736389, "timesteps_since_restore": 1632, "iterations_since_restore": 51, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.16, "episode_len_mean": 18.98, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -10.08, "policy1": -10.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14933891149446193, "mean_inference_ms": 1.3692983679346875, "mean_action_processing_ms": 0.09380288796989614, "mean_env_wait_ms": 0.15831808097126143, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6447, "timesteps_this_iter": 32, "agent_timesteps_total": 12894, "timers": {"learn_time_ms": 6.011, "learn_throughput": 5323.861, "update_time_ms": 3.631}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6447, "num_agent_steps_sampled": 12894, "num_steps_trained": 9280, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 18560, "last_target_update_ts": 6387, "num_target_updates": 48}, "done": false, "episodes_total": 342, "training_iteration": 52, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-42", "timestamp": 1648816122, "time_this_iter_s": 0.3493027687072754, "time_total_s": 19.972426176071167, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208e60>"}, "time_since_restore": 19.972426176071167, "timesteps_since_restore": 1664, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 15.3, "ram_util_percent": 48.4}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.96, "episode_len_mean": 18.88, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.98, "policy1": -9.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14932876740149226, "mean_inference_ms": 1.3689136937484256, "mean_action_processing_ms": 0.09378929011568139, "mean_env_wait_ms": 0.15828864567018486, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6557, "timesteps_this_iter": 32, "agent_timesteps_total": 13114, "timers": {"learn_time_ms": 5.944, "learn_throughput": 5383.158, "update_time_ms": 3.596}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6557, "num_agent_steps_sampled": 13114, "num_steps_trained": 9472, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 18944, "last_target_update_ts": 6507, "num_target_updates": 49}, "done": false, "episodes_total": 348, "training_iteration": 53, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-43", "timestamp": 1648816123, "time_this_iter_s": 0.3324239253997803, "time_total_s": 20.304850101470947, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82013b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82013b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201ef0>"}, "time_since_restore": 20.304850101470947, "timesteps_since_restore": 1696, "iterations_since_restore": 53, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.64, "episode_len_mean": 18.72, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.82, "policy1": -9.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14931475989045928, "mean_inference_ms": 1.3684462317959243, "mean_action_processing_ms": 0.09376787917780477, "mean_env_wait_ms": 0.15824959949548834, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6661, "timesteps_this_iter": 32, "agent_timesteps_total": 13322, "timers": {"learn_time_ms": 5.984, "learn_throughput": 5347.767, "update_time_ms": 3.598}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6661, "num_agent_steps_sampled": 13322, "num_steps_trained": 9664, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 19328, "last_target_update_ts": 6621, "num_target_updates": 50}, "done": false, "episodes_total": 354, "training_iteration": 54, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-43", "timestamp": 1648816123, "time_this_iter_s": 0.320300817489624, "time_total_s": 20.62515091896057, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff0e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff0e0>"}, "time_since_restore": 20.62515091896057, "timesteps_since_restore": 1728, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 16.5, "ram_util_percent": 48.4}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.96, "episode_len_mean": 18.38, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.98, "policy1": -8.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, 8.0, 20.0, -20.0, 26.0, -20.0, 20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0], "episode_lengths": [20, 20, 20, 16, 10, 20, 7, 20, 10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17], "policy_policy0_reward": [-10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, 4.0, 10.0, -10.0, 13.0, -10.0, 10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14928419621628494, "mean_inference_ms": 1.3676239375854606, "mean_action_processing_ms": 0.09371732656277185, "mean_env_wait_ms": 0.15816950406622993, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6767, "timesteps_this_iter": 32, "agent_timesteps_total": 13534, "timers": {"learn_time_ms": 6.089, "learn_throughput": 5255.032, "update_time_ms": 3.69}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6767, "num_agent_steps_sampled": 13534, "num_steps_trained": 9888, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 19776, "last_target_update_ts": 6740, "num_target_updates": 51}, "done": false, "episodes_total": 361, "training_iteration": 55, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-43", "timestamp": 1648816123, "time_this_iter_s": 0.3463551998138428, "time_total_s": 20.971506118774414, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82013b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82013b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff440>"}, "time_since_restore": 20.971506118774414, "timesteps_since_restore": 1760, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 16.9, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.82, "episode_len_mean": 18.21, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.91, "policy1": -8.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 8.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0], "episode_lengths": [10, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20], "policy_policy0_reward": [10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0], "policy_policy1_reward": [10.0, 4.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1492392512726834, "mean_inference_ms": 1.3664928234865619, "mean_action_processing_ms": 0.09364606088716969, "mean_env_wait_ms": 0.15804669922394782, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6883, "timesteps_this_iter": 32, "agent_timesteps_total": 13766, "timers": {"learn_time_ms": 6.056, "learn_throughput": 5283.684, "update_time_ms": 3.687}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6883, "num_agent_steps_sampled": 13766, "num_steps_trained": 10112, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 20224, "last_target_update_ts": 6847, "num_target_updates": 52}, "done": false, "episodes_total": 369, "training_iteration": 56, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-44", "timestamp": 1648816124, "time_this_iter_s": 0.3645670413970947, "time_total_s": 21.33607316017151, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff8c0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff8c0>"}, "time_since_restore": 21.33607316017151, "timesteps_since_restore": 1792, "iterations_since_restore": 56, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.9, "episode_len_mean": 18.35, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.45, "policy1": -9.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1491938655130409, "mean_inference_ms": 1.3656623100438703, "mean_action_processing_ms": 0.09358925420281232, "mean_env_wait_ms": 0.15794711768072997, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6983, "timesteps_this_iter": 32, "agent_timesteps_total": 13966, "timers": {"learn_time_ms": 6.068, "learn_throughput": 5273.595, "update_time_ms": 3.628}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6983, "num_agent_steps_sampled": 13966, "num_steps_trained": 10272, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 20544, "last_target_update_ts": 6963, "num_target_updates": 53}, "done": false, "episodes_total": 374, "training_iteration": 57, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-44", "timestamp": 1648816124, "time_this_iter_s": 0.2936666011810303, "time_total_s": 21.62973976135254, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "time_since_restore": 21.62973976135254, "timesteps_since_restore": 1824, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 15.4, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.7, "episode_len_mean": 18.35, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.35, "policy1": -9.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, 6.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 17, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, 3.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1491470441763647, "mean_inference_ms": 1.3648252439497872, "mean_action_processing_ms": 0.09353086521025357, "mean_env_wait_ms": 0.15784921535193447, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7083, "timesteps_this_iter": 32, "agent_timesteps_total": 14166, "timers": {"learn_time_ms": 6.071, "learn_throughput": 5271.026, "update_time_ms": 3.631}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7083, "num_agent_steps_sampled": 14166, "num_steps_trained": 10432, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 20864, "last_target_update_ts": 7083, "num_target_updates": 54}, "done": false, "episodes_total": 379, "training_iteration": 58, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-45", "timestamp": 1648816125, "time_this_iter_s": 0.29324865341186523, "time_total_s": 21.922988414764404, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff830>"}, "time_since_restore": 21.922988414764404, "timesteps_since_restore": 1856, "iterations_since_restore": 58, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.76, "episode_len_mean": 18.38, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.38, "policy1": -9.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14909563700799347, "mean_inference_ms": 1.3639764298104091, "mean_action_processing_ms": 0.09347040370091428, "mean_env_wait_ms": 0.15774759487284082, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7183, "timesteps_this_iter": 32, "agent_timesteps_total": 14366, "timers": {"learn_time_ms": 6.074, "learn_throughput": 5268.151, "update_time_ms": 3.607}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7183, "num_agent_steps_sampled": 14366, "num_steps_trained": 10592, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 21184, "last_target_update_ts": 7083, "num_target_updates": 54}, "done": false, "episodes_total": 384, "training_iteration": 59, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-45", "timestamp": 1648816125, "time_this_iter_s": 0.2915778160095215, "time_total_s": 22.214566230773926, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffd40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffd40>"}, "time_since_restore": 22.214566230773926, "timesteps_since_restore": 1888, "iterations_since_restore": 59, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.32, "episode_len_mean": 18.06, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.16, "policy1": -9.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14901340990930748, "mean_inference_ms": 1.3625153640943035, "mean_action_processing_ms": 0.09336481474325653, "mean_env_wait_ms": 0.1575641067057933, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7301, "timesteps_this_iter": 32, "agent_timesteps_total": 14602, "timers": {"learn_time_ms": 6.128, "learn_throughput": 5221.565, "update_time_ms": 3.608}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7301, "num_agent_steps_sampled": 14602, "num_steps_trained": 10816, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 21632, "last_target_update_ts": 7206, "num_target_updates": 55}, "done": false, "episodes_total": 392, "training_iteration": 60, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-45", "timestamp": 1648816125, "time_this_iter_s": 0.37180328369140625, "time_total_s": 22.586369514465332, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff320>"}, "time_since_restore": 22.586369514465332, "timesteps_since_restore": 1920, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 15.3, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.58, "episode_len_mean": 17.99, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.79, "policy1": -8.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14894943088978602, "mean_inference_ms": 1.3613404604045087, "mean_action_processing_ms": 0.0932813717711682, "mean_env_wait_ms": 0.1574093880397373, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7404, "timesteps_this_iter": 32, "agent_timesteps_total": 14808, "timers": {"learn_time_ms": 6.187, "learn_throughput": 5171.848, "update_time_ms": 3.685}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7404, "num_agent_steps_sampled": 14808, "num_steps_trained": 11008, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 22016, "last_target_update_ts": 7325, "num_target_updates": 56}, "done": false, "episodes_total": 398, "training_iteration": 61, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-46", "timestamp": 1648816126, "time_this_iter_s": 0.32256340980529785, "time_total_s": 22.90893292427063, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201f80>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201f80>"}, "time_since_restore": 22.90893292427063, "timesteps_since_restore": 1952, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 15.1, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.54, "episode_len_mean": 17.77, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.27, "policy1": -8.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -40.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14887914672162952, "mean_inference_ms": 1.3599462102979054, "mean_action_processing_ms": 0.09318282739068039, "mean_env_wait_ms": 0.1572227556408473, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7522, "timesteps_this_iter": 32, "agent_timesteps_total": 15044, "timers": {"learn_time_ms": 6.145, "learn_throughput": 5207.768, "update_time_ms": 3.708}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7522, "num_agent_steps_sampled": 15044, "num_steps_trained": 11232, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 22464, "last_target_update_ts": 7432, "num_target_updates": 57}, "done": false, "episodes_total": 405, "training_iteration": 62, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-46", "timestamp": 1648816126, "time_this_iter_s": 0.36875414848327637, "time_total_s": 23.277687072753906, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb90>"}, "time_since_restore": 23.277687072753906, "timesteps_since_restore": 1984, "iterations_since_restore": 62, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.58, "episode_len_mean": 17.79, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.29, "policy1": -8.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1488215717669547, "mean_inference_ms": 1.3588150907244432, "mean_action_processing_ms": 0.09309906961165136, "mean_env_wait_ms": 0.15706564524615213, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7636, "timesteps_this_iter": 32, "agent_timesteps_total": 15272, "timers": {"learn_time_ms": 6.118, "learn_throughput": 5230.784, "update_time_ms": 3.686}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7636, "num_agent_steps_sampled": 15272, "num_steps_trained": 11424, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 22848, "last_target_update_ts": 7542, "num_target_updates": 58}, "done": false, "episodes_total": 411, "training_iteration": 63, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-46", "timestamp": 1648816126, "time_this_iter_s": 0.35190725326538086, "time_total_s": 23.629594326019287, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82013b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82087a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82013b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82087a0>"}, "time_since_restore": 23.629594326019287, "timesteps_since_restore": 2016, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 17.9, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.28, "episode_len_mean": 17.74, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.14, "policy1": -8.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14876873631139062, "mean_inference_ms": 1.3577331947361997, "mean_action_processing_ms": 0.09301584889808467, "mean_env_wait_ms": 0.15691687947793412, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7746, "timesteps_this_iter": 32, "agent_timesteps_total": 15492, "timers": {"learn_time_ms": 6.098, "learn_throughput": 5247.861, "update_time_ms": 3.694}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7746, "num_agent_steps_sampled": 15492, "num_steps_trained": 11616, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 23232, "last_target_update_ts": 7656, "num_target_updates": 59}, "done": false, "episodes_total": 417, "training_iteration": 64, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-47", "timestamp": 1648816127, "time_this_iter_s": 0.33741021156311035, "time_total_s": 23.967004537582397, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff4d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff4d0>"}, "time_since_restore": 23.967004537582397, "timesteps_since_restore": 2048, "iterations_since_restore": 64, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.12, "episode_len_mean": 17.66, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.06, "policy1": -8.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -40.0, 30.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0], "episode_lengths": [20, 20, 20, 5, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, 15.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.148716868721108, "mean_inference_ms": 1.3566573587575612, "mean_action_processing_ms": 0.09293259163381672, "mean_env_wait_ms": 0.1567687036390233, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7858, "timesteps_this_iter": 32, "agent_timesteps_total": 15716, "timers": {"learn_time_ms": 6.012, "learn_throughput": 5322.615, "update_time_ms": 3.73}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7858, "num_agent_steps_sampled": 15716, "num_steps_trained": 11808, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 23616, "last_target_update_ts": 7766, "num_target_updates": 60}, "done": false, "episodes_total": 423, "training_iteration": 65, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-47", "timestamp": 1648816127, "time_this_iter_s": 0.340282678604126, "time_total_s": 24.307287216186523, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201ef0>"}, "time_since_restore": 24.307287216186523, "timesteps_since_restore": 2080, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 16.6, "ram_util_percent": 48.5}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.62, "episode_len_mean": 17.81, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.31, "policy1": -8.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14867366578747848, "mean_inference_ms": 1.3557982151104617, "mean_action_processing_ms": 0.09286662013734664, "mean_env_wait_ms": 0.15664878137541824, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7958, "timesteps_this_iter": 32, "agent_timesteps_total": 15916, "timers": {"learn_time_ms": 6.06, "learn_throughput": 5280.691, "update_time_ms": 3.661}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7958, "num_agent_steps_sampled": 15916, "num_steps_trained": 11968, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 23936, "last_target_update_ts": 7878, "num_target_updates": 61}, "done": false, "episodes_total": 428, "training_iteration": 66, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-47", "timestamp": 1648816127, "time_this_iter_s": 0.29373931884765625, "time_total_s": 24.60102653503418, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffe60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffe60>"}, "time_since_restore": 24.60102653503418, "timesteps_since_restore": 2112, "iterations_since_restore": 66, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.98, "episode_len_mean": 17.89, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.49, "policy1": -8.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14863099085636577, "mean_inference_ms": 1.3549519146936135, "mean_action_processing_ms": 0.09280362157963463, "mean_env_wait_ms": 0.15653266978923686, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8058, "timesteps_this_iter": 32, "agent_timesteps_total": 16116, "timers": {"learn_time_ms": 6.118, "learn_throughput": 5230.519, "update_time_ms": 3.629}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8058, "num_agent_steps_sampled": 16116, "num_steps_trained": 12128, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 24256, "last_target_update_ts": 7998, "num_target_updates": 62}, "done": false, "episodes_total": 433, "training_iteration": 67, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-48", "timestamp": 1648816128, "time_this_iter_s": 0.2942233085632324, "time_total_s": 24.895249843597412, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82309e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8225440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82309e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8225440>"}, "time_since_restore": 24.895249843597412, "timesteps_since_restore": 2144, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 16.8, "ram_util_percent": 48.5}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.98, "episode_len_mean": 17.89, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.49, "policy1": -8.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1485890202176513, "mean_inference_ms": 1.3541112425383954, "mean_action_processing_ms": 0.09274312312326512, "mean_env_wait_ms": 0.15641872942177265, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8158, "timesteps_this_iter": 32, "agent_timesteps_total": 16316, "timers": {"learn_time_ms": 6.044, "learn_throughput": 5294.251, "update_time_ms": 3.602}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8158, "num_agent_steps_sampled": 16316, "num_steps_trained": 12288, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 24576, "last_target_update_ts": 8118, "num_target_updates": 63}, "done": false, "episodes_total": 438, "training_iteration": 68, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-48", "timestamp": 1648816128, "time_this_iter_s": 0.2911350727081299, "time_total_s": 25.186384916305542, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201290>"}, "time_since_restore": 25.186384916305542, "timesteps_since_restore": 2176, "iterations_since_restore": 68, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.16, "episode_len_mean": 17.68, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.08, "policy1": -8.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -20.0, -20.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [10, 20, 20, 4, 20, 20, 20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20], "policy_policy0_reward": [10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [10.0, -10.0, -10.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1485390873199443, "mean_inference_ms": 1.352968876356964, "mean_action_processing_ms": 0.0926593696932309, "mean_env_wait_ms": 0.15626674676799843, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8275, "timesteps_this_iter": 32, "agent_timesteps_total": 16550, "timers": {"learn_time_ms": 6.093, "learn_throughput": 5251.968, "update_time_ms": 3.614}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8275, "num_agent_steps_sampled": 16550, "num_steps_trained": 12512, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 25024, "last_target_update_ts": 8235, "num_target_updates": 64}, "done": false, "episodes_total": 445, "training_iteration": 69, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-48", "timestamp": 1648816128, "time_this_iter_s": 0.3672337532043457, "time_total_s": 25.553618669509888, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232ef0>"}, "time_since_restore": 25.553618669509888, "timesteps_since_restore": 2208, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 16.3, "ram_util_percent": 48.5}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.36, "episode_len_mean": 17.78, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.18, "policy1": -8.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, 10.0, 12.0, 20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 15, 14, 10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, 5.0, 6.0, 10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14849556806651174, "mean_inference_ms": 1.3520274516189041, "mean_action_processing_ms": 0.09259066056882953, "mean_env_wait_ms": 0.1561417106079424, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8379, "timesteps_this_iter": 32, "agent_timesteps_total": 16758, "timers": {"learn_time_ms": 6.115, "learn_throughput": 5233.19, "update_time_ms": 3.661}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8379, "num_agent_steps_sampled": 16758, "num_steps_trained": 12704, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 25408, "last_target_update_ts": 8339, "num_target_updates": 65}, "done": false, "episodes_total": 451, "training_iteration": 70, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-49", "timestamp": 1648816129, "time_this_iter_s": 0.3211677074432373, "time_total_s": 25.874786376953125, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203320>"}, "time_since_restore": 25.874786376953125, "timesteps_since_restore": 2240, "iterations_since_restore": 70, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.78, "episode_len_mean": 17.89, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.39, "policy1": -8.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -20.0, -20.0, 20.0, 6.0, -40.0, 30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [10, 20, 20, 10, 17, 20, 5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [10.0, -10.0, -10.0, 10.0, 3.0, -20.0, 15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14847273520534732, "mean_inference_ms": 1.3514212754830186, "mean_action_processing_ms": 0.09254854278544432, "mean_env_wait_ms": 0.1560601477573516, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8479, "timesteps_this_iter": 32, "agent_timesteps_total": 16958, "timers": {"learn_time_ms": 6.561, "learn_throughput": 4877.115, "update_time_ms": 3.824}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8479, "num_agent_steps_sampled": 16958, "num_steps_trained": 12864, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 25728, "last_target_update_ts": 8459, "num_target_updates": 66}, "done": false, "episodes_total": 456, "training_iteration": 71, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-49", "timestamp": 1648816129, "time_this_iter_s": 0.3431217670440674, "time_total_s": 26.217908143997192, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232e60>"}, "time_since_restore": 26.217908143997192, "timesteps_since_restore": 2272, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 17.7, "ram_util_percent": 48.5}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.44, "episode_len_mean": 18.02, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.72, "policy1": -8.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, -40.0, -20.0, 34.0, 16.0, 8.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [5, 20, 20, 3, 12, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20], "policy_policy0_reward": [15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [15.0, -20.0, -10.0, 17.0, 8.0, 4.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14844251661758995, "mean_inference_ms": 1.3507256739750986, "mean_action_processing_ms": 0.09250090350475242, "mean_env_wait_ms": 0.1559664671989144, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8589, "timesteps_this_iter": 32, "agent_timesteps_total": 17178, "timers": {"learn_time_ms": 6.579, "learn_throughput": 4864.177, "update_time_ms": 3.885}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8589, "num_agent_steps_sampled": 17178, "num_steps_trained": 13056, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 26112, "last_target_update_ts": 8569, "num_target_updates": 67}, "done": false, "episodes_total": 462, "training_iteration": 72, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-50", "timestamp": 1648816130, "time_this_iter_s": 0.3351125717163086, "time_total_s": 26.5530207157135, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "time_since_restore": 26.5530207157135, "timesteps_since_restore": 2304, "iterations_since_restore": 72, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.64, "episode_len_mean": 18.42, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.32, "policy1": -9.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1484042427031335, "mean_inference_ms": 1.3500537606266323, "mean_action_processing_ms": 0.09245453964328487, "mean_env_wait_ms": 0.15587874053512965, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8705, "timesteps_this_iter": 32, "agent_timesteps_total": 17410, "timers": {"learn_time_ms": 6.016, "learn_throughput": 5319.072, "update_time_ms": 3.708}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8705, "num_agent_steps_sampled": 17410, "num_steps_trained": 13248, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 26496, "last_target_update_ts": 8685, "num_target_updates": 68}, "done": false, "episodes_total": 468, "training_iteration": 73, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-50", "timestamp": 1648816130, "time_this_iter_s": 0.34821248054504395, "time_total_s": 26.901233196258545, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203ef0>"}, "time_since_restore": 26.901233196258545, "timesteps_since_restore": 2336, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 18.3, "ram_util_percent": 48.5}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.86, "episode_len_mean": 18.33, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.93, "policy1": -8.93}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14836708402293536, "mean_inference_ms": 1.3493982316695374, "mean_action_processing_ms": 0.09241113907485847, "mean_env_wait_ms": 0.15579671291069794, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8816, "timesteps_this_iter": 32, "agent_timesteps_total": 17632, "timers": {"learn_time_ms": 6.017, "learn_throughput": 5318.545, "update_time_ms": 3.603}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8816, "num_agent_steps_sampled": 17632, "num_steps_trained": 13440, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 26880, "last_target_update_ts": 8796, "num_target_updates": 69}, "done": false, "episodes_total": 474, "training_iteration": 74, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-50", "timestamp": 1648816130, "time_this_iter_s": 0.3333241939544678, "time_total_s": 27.234557390213013, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208e60>"}, "time_since_restore": 27.234557390213013, "timesteps_since_restore": 2368, "iterations_since_restore": 74, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.86, "episode_len_mean": 18.33, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.93, "policy1": -8.93}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1483382128383322, "mean_inference_ms": 1.3488744944647095, "mean_action_processing_ms": 0.09237664393936709, "mean_env_wait_ms": 0.15572901695539929, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8916, "timesteps_this_iter": 32, "agent_timesteps_total": 17832, "timers": {"learn_time_ms": 6.074, "learn_throughput": 5268.378, "update_time_ms": 3.613}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8916, "num_agent_steps_sampled": 17832, "num_steps_trained": 13600, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 27200, "last_target_update_ts": 8916, "num_target_updates": 70}, "done": false, "episodes_total": 479, "training_iteration": 75, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-51", "timestamp": 1648816131, "time_this_iter_s": 0.29203271865844727, "time_total_s": 27.52659010887146, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffe60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffe60>"}, "time_since_restore": 27.52659010887146, "timesteps_since_restore": 2400, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 15.5, "ram_util_percent": 48.5}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.66, "episode_len_mean": 18.33, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.83, "policy1": -8.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, -40.0, 18.0, 32.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [3, 20, 11, 4, 20, 20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [17.0, -20.0, 9.0, 16.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14831125907902462, "mean_inference_ms": 1.3483758720557901, "mean_action_processing_ms": 0.09234516719811964, "mean_env_wait_ms": 0.15566619980622914, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9016, "timesteps_this_iter": 32, "agent_timesteps_total": 18032, "timers": {"learn_time_ms": 5.989, "learn_throughput": 5343.254, "update_time_ms": 3.68}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9016, "num_agent_steps_sampled": 18032, "num_steps_trained": 13760, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 27520, "last_target_update_ts": 8916, "num_target_updates": 70}, "done": false, "episodes_total": 484, "training_iteration": 76, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-51", "timestamp": 1648816131, "time_this_iter_s": 0.29499125480651855, "time_total_s": 27.82158136367798, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82087a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82087a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232e60>"}, "time_since_restore": 27.82158136367798, "timesteps_since_restore": 2432, "iterations_since_restore": 76, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.3, "episode_len_mean": 18.75, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.65, "policy1": -9.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, 32.0, -20.0, -40.0, 2.0, -20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 4, 20, 20, 19, 20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, 16.0, -10.0, -20.0, 1.0, -10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1482773863877569, "mean_inference_ms": 1.3479157778671762, "mean_action_processing_ms": 0.09231557056229611, "mean_env_wait_ms": 0.15561194604516423, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9116, "timesteps_this_iter": 32, "agent_timesteps_total": 18232, "timers": {"learn_time_ms": 6.104, "learn_throughput": 5242.348, "update_time_ms": 3.71}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9116, "num_agent_steps_sampled": 18232, "num_steps_trained": 13920, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 27840, "last_target_update_ts": 9036, "num_target_updates": 71}, "done": false, "episodes_total": 489, "training_iteration": 77, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-51", "timestamp": 1648816131, "time_this_iter_s": 0.2981705665588379, "time_total_s": 28.119751930236816, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff710>"}, "time_since_restore": 28.119751930236816, "timesteps_since_restore": 2464, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 15.9, "ram_util_percent": 48.5}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.72, "episode_len_mean": 18.66, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.36, "policy1": -9.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0], "episode_lengths": [20, 20, 8, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20], "policy_policy0_reward": [-10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14822911016104393, "mean_inference_ms": 1.3472548374873652, "mean_action_processing_ms": 0.09227318173068925, "mean_env_wait_ms": 0.15553715419373032, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9230, "timesteps_this_iter": 32, "agent_timesteps_total": 18460, "timers": {"learn_time_ms": 6.07, "learn_throughput": 5271.627, "update_time_ms": 3.648}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9230, "num_agent_steps_sampled": 18460, "num_steps_trained": 14144, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 28288, "last_target_update_ts": 9147, "num_target_updates": 72}, "done": false, "episodes_total": 496, "training_iteration": 78, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-52", "timestamp": 1648816132, "time_this_iter_s": 0.3585488796234131, "time_total_s": 28.47830080986023, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff200>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff200>"}, "time_since_restore": 28.47830080986023, "timesteps_since_restore": 2496, "iterations_since_restore": 78, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.32, "episode_len_mean": 18.86, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.66, "policy1": -9.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1481832381520589, "mean_inference_ms": 1.3467142838746782, "mean_action_processing_ms": 0.09223681833459926, "mean_env_wait_ms": 0.1554741220868613, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9348, "timesteps_this_iter": 32, "agent_timesteps_total": 18696, "timers": {"learn_time_ms": 5.979, "learn_throughput": 5351.627, "update_time_ms": 3.572}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9348, "num_agent_steps_sampled": 18696, "num_steps_trained": 14336, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 28672, "last_target_update_ts": 9250, "num_target_updates": 73}, "done": false, "episodes_total": 502, "training_iteration": 79, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-52", "timestamp": 1648816132, "time_this_iter_s": 0.35209178924560547, "time_total_s": 28.830392599105835, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff710>"}, "time_since_restore": 28.830392599105835, "timesteps_since_restore": 2528, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 16.2, "ram_util_percent": 48.5}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.92, "episode_len_mean": 18.86, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.46, "policy1": -9.46}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 12.0, -40.0, -20.0, 20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 6.0, -20.0, -10.0, 10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14814129319835756, "mean_inference_ms": 1.3462545761552405, "mean_action_processing_ms": 0.09220688830138155, "mean_env_wait_ms": 0.1554242203625771, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9448, "timesteps_this_iter": 32, "agent_timesteps_total": 18896, "timers": {"learn_time_ms": 6.006, "learn_throughput": 5327.855, "update_time_ms": 3.571}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9448, "num_agent_steps_sampled": 18896, "num_steps_trained": 14496, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 28992, "last_target_update_ts": 9368, "num_target_updates": 74}, "done": false, "episodes_total": 507, "training_iteration": 80, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-52", "timestamp": 1648816132, "time_this_iter_s": 0.29282212257385254, "time_total_s": 29.123214721679688, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffc20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffc20>"}, "time_since_restore": 29.123214721679688, "timesteps_since_restore": 2560, "iterations_since_restore": 80, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.2, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.6, "policy1": -9.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14808875728839158, "mean_inference_ms": 1.3456745086054134, "mean_action_processing_ms": 0.09217106376636189, "mean_env_wait_ms": 0.15536898054355358, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9566, "timesteps_this_iter": 32, "agent_timesteps_total": 19132, "timers": {"learn_time_ms": 5.987, "learn_throughput": 5344.935, "update_time_ms": 3.588}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9566, "num_agent_steps_sampled": 19132, "num_steps_trained": 14688, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 29376, "last_target_update_ts": 9486, "num_target_updates": 75}, "done": false, "episodes_total": 513, "training_iteration": 81, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-53", "timestamp": 1648816133, "time_this_iter_s": 0.34880518913269043, "time_total_s": 29.472019910812378, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201290>"}, "time_since_restore": 29.472019910812378, "timesteps_since_restore": 2592, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 16.4, "ram_util_percent": 48.6}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.8, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.4, "policy1": -9.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14804117696676297, "mean_inference_ms": 1.3451777589992526, "mean_action_processing_ms": 0.0921398505124878, "mean_env_wait_ms": 0.15532159895216868, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9666, "timesteps_this_iter": 32, "agent_timesteps_total": 19332, "timers": {"learn_time_ms": 6.015, "learn_throughput": 5319.873, "update_time_ms": 3.628}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9666, "num_agent_steps_sampled": 19332, "num_steps_trained": 14848, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 29696, "last_target_update_ts": 9606, "num_target_updates": 76}, "done": false, "episodes_total": 518, "training_iteration": 82, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-53", "timestamp": 1648816133, "time_this_iter_s": 0.2899456024169922, "time_total_s": 29.76196551322937, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "time_since_restore": 29.76196551322937, "timesteps_since_restore": 2624, "iterations_since_restore": 82, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.8, "episode_len_mean": 18.7, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.9, "policy1": -8.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14799529867275096, "mean_inference_ms": 1.3446099528830593, "mean_action_processing_ms": 0.09210586847311773, "mean_env_wait_ms": 0.15526828499139314, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9768, "timesteps_this_iter": 32, "agent_timesteps_total": 19536, "timers": {"learn_time_ms": 6.342, "learn_throughput": 5045.988, "update_time_ms": 3.812}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9768, "num_agent_steps_sampled": 19536, "num_steps_trained": 15040, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 30080, "last_target_update_ts": 9714, "num_target_updates": 77}, "done": false, "episodes_total": 525, "training_iteration": 83, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-53", "timestamp": 1648816133, "time_this_iter_s": 0.3501853942871094, "time_total_s": 30.11215090751648, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82c7170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82c7170>"}, "time_since_restore": 30.11215090751648, "timesteps_since_restore": 2656, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 18.2, "ram_util_percent": 48.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.2, "episode_len_mean": 18.6, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.6, "policy1": -8.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14797781873652288, "mean_inference_ms": 1.3443356167507812, "mean_action_processing_ms": 0.092094207729495, "mean_env_wait_ms": 0.15525442618458815, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9878, "timesteps_this_iter": 32, "agent_timesteps_total": 19756, "timers": {"learn_time_ms": 6.567, "learn_throughput": 4873.078, "update_time_ms": 3.968}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9878, "num_agent_steps_sampled": 19756, "num_steps_trained": 15232, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 30464, "last_target_update_ts": 9828, "num_target_updates": 78}, "done": false, "episodes_total": 531, "training_iteration": 84, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-54", "timestamp": 1648816134, "time_this_iter_s": 0.38768482208251953, "time_total_s": 30.499835729599, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8225cb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8225cb0>"}, "time_since_restore": 30.499835729599, "timesteps_since_restore": 2688, "iterations_since_restore": 84, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.28, "episode_len_mean": 18.34, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.64, "policy1": -7.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 24.0, 22.0, -20.0, -20.0, -20.0, -20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0], "episode_lengths": [20, 8, 9, 20, 20, 20, 20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18], "policy_policy0_reward": [-20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0], "policy_policy1_reward": [-20.0, 12.0, 11.0, -10.0, -10.0, -10.0, -10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1479666416146192, "mean_inference_ms": 1.344062319104148, "mean_action_processing_ms": 0.09208060561820798, "mean_env_wait_ms": 0.15524091263812395, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9992, "timesteps_this_iter": 32, "agent_timesteps_total": 19984, "timers": {"learn_time_ms": 6.216, "learn_throughput": 5148.122, "update_time_ms": 3.764}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9992, "num_agent_steps_sampled": 19984, "num_steps_trained": 15424, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 30848, "last_target_update_ts": 9938, "num_target_updates": 79}, "done": false, "episodes_total": 538, "training_iteration": 85, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-54", "timestamp": 1648816134, "time_this_iter_s": 0.34847116470336914, "time_total_s": 30.848306894302368, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c7170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c7170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b90>"}, "time_since_restore": 30.848306894302368, "timesteps_since_restore": 2720, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 19.0, "ram_util_percent": 48.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.68, "episode_len_mean": 18.44, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.84, "policy1": -7.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 28.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0], "episode_lengths": [20, 6, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20], "policy_policy0_reward": [-10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0], "policy_policy1_reward": [-10.0, 14.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14796098627946427, "mean_inference_ms": 1.3439171469724849, "mean_action_processing_ms": 0.09207523728417107, "mean_env_wait_ms": 0.15524142043276556, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10099, "timesteps_this_iter": 32, "agent_timesteps_total": 20198, "timers": {"learn_time_ms": 6.442, "learn_throughput": 4967.329, "update_time_ms": 4.089}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10099, "num_agent_steps_sampled": 20198, "num_steps_trained": 15616, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 31232, "last_target_update_ts": 10052, "num_target_updates": 80}, "done": false, "episodes_total": 544, "training_iteration": 86, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-55", "timestamp": 1648816135, "time_this_iter_s": 0.34967470169067383, "time_total_s": 31.197981595993042, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8046050>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8046050>"}, "time_since_restore": 31.197981595993042, "timesteps_since_restore": 2752, "iterations_since_restore": 86, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.08, "episode_len_mean": 18.54, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.04, "policy1": -8.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14797043864581141, "mean_inference_ms": 1.3439247160512104, "mean_action_processing_ms": 0.09208168244539654, "mean_env_wait_ms": 0.15525970445969556, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10213, "timesteps_this_iter": 32, "agent_timesteps_total": 20426, "timers": {"learn_time_ms": 6.692, "learn_throughput": 4781.979, "update_time_ms": 4.086}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10213, "num_agent_steps_sampled": 20426, "num_steps_trained": 15808, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 31616, "last_target_update_ts": 10153, "num_target_updates": 81}, "done": false, "episodes_total": 550, "training_iteration": 87, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-55", "timestamp": 1648816135, "time_this_iter_s": 0.5358765125274658, "time_total_s": 31.733858108520508, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b90>"}, "time_since_restore": 31.733858108520508, "timesteps_since_restore": 2784, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 15.1, "ram_util_percent": 48.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.88, "episode_len_mean": 18.14, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.44, "policy1": -7.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0], "episode_lengths": [10, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20], "policy_policy0_reward": [10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0], "policy_policy1_reward": [10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14797089536810418, "mean_inference_ms": 1.3437552982914587, "mean_action_processing_ms": 0.09207500297396294, "mean_env_wait_ms": 0.15526016764429187, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10313, "timesteps_this_iter": 32, "agent_timesteps_total": 20626, "timers": {"learn_time_ms": 6.107, "learn_throughput": 5240.076, "update_time_ms": 3.688}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10313, "num_agent_steps_sampled": 20626, "num_steps_trained": 16032, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 32064, "last_target_update_ts": 10261, "num_target_updates": 82}, "done": false, "episodes_total": 557, "training_iteration": 88, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-55", "timestamp": 1648816135, "time_this_iter_s": 0.33213257789611816, "time_total_s": 32.065990686416626, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c7ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c7ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a7a0>"}, "time_since_restore": 32.065990686416626, "timesteps_since_restore": 2816, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 15.1, "ram_util_percent": 48.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.28, "episode_len_mean": 18.24, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.64, "policy1": -7.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 16, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14796632638632573, "mean_inference_ms": 1.3436064639178034, "mean_action_processing_ms": 0.09206790526954775, "mean_env_wait_ms": 0.15525789162606476, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10413, "timesteps_this_iter": 32, "agent_timesteps_total": 20826, "timers": {"learn_time_ms": 5.98, "learn_throughput": 5351.584, "update_time_ms": 3.629}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10413, "num_agent_steps_sampled": 20826, "num_steps_trained": 16192, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 32384, "last_target_update_ts": 10373, "num_target_updates": 83}, "done": false, "episodes_total": 562, "training_iteration": 89, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-56", "timestamp": 1648816136, "time_this_iter_s": 0.2924766540527344, "time_total_s": 32.35846734046936, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201b90>"}, "time_since_restore": 32.35846734046936, "timesteps_since_restore": 2848, "iterations_since_restore": 89, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.0, "episode_len_mean": 18.1, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.5, "policy1": -7.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 2.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0], "episode_lengths": [20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20], "policy_policy0_reward": [-20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0], "policy_policy1_reward": [-20.0, 1.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14797454804381785, "mean_inference_ms": 1.343533555700265, "mean_action_processing_ms": 0.09206836517143735, "mean_env_wait_ms": 0.15526826232322197, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10515, "timesteps_this_iter": 32, "agent_timesteps_total": 21030, "timers": {"learn_time_ms": 6.468, "learn_throughput": 4947.627, "update_time_ms": 3.933}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10515, "num_agent_steps_sampled": 21030, "num_steps_trained": 16384, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 32768, "last_target_update_ts": 10481, "num_target_updates": 84}, "done": false, "episodes_total": 568, "training_iteration": 90, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-56", "timestamp": 1648816136, "time_this_iter_s": 0.3547360897064209, "time_total_s": 32.71320343017578, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c7050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c7050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201ef0>"}, "time_since_restore": 32.71320343017578, "timesteps_since_restore": 2880, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 16.7, "ram_util_percent": 48.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.38, "episode_len_mean": 18.19, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.69, "policy1": -7.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1479882741280176, "mean_inference_ms": 1.3435606324810383, "mean_action_processing_ms": 0.0920760319264826, "mean_env_wait_ms": 0.15529029914776962, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10615, "timesteps_this_iter": 32, "agent_timesteps_total": 21230, "timers": {"learn_time_ms": 6.545, "learn_throughput": 4889.57, "update_time_ms": 4.049}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10615, "num_agent_steps_sampled": 21230, "num_steps_trained": 16544, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 33088, "last_target_update_ts": 10595, "num_target_updates": 85}, "done": false, "episodes_total": 573, "training_iteration": 91, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-57", "timestamp": 1648816137, "time_this_iter_s": 0.3252847194671631, "time_total_s": 33.038488149642944, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201200>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201200>"}, "time_since_restore": 33.038488149642944, "timesteps_since_restore": 2912, "iterations_since_restore": 91, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.86, "episode_len_mean": 18.13, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.43, "policy1": -7.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14800723733345578, "mean_inference_ms": 1.3436093114550158, "mean_action_processing_ms": 0.0920884857719578, "mean_env_wait_ms": 0.15532360117922775, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10729, "timesteps_this_iter": 32, "agent_timesteps_total": 21458, "timers": {"learn_time_ms": 6.131, "learn_throughput": 5219.23, "update_time_ms": 3.862}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10729, "num_agent_steps_sampled": 21458, "num_steps_trained": 16736, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 33472, "last_target_update_ts": 10713, "num_target_updates": 86}, "done": false, "episodes_total": 579, "training_iteration": 92, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-57", "timestamp": 1648816137, "time_this_iter_s": 0.3472433090209961, "time_total_s": 33.38573145866394, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c7050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff0e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82c7050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff0e0>"}, "time_since_restore": 33.38573145866394, "timesteps_since_restore": 2944, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 17.4, "ram_util_percent": 48.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.8, "episode_len_mean": 17.9, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.9, "policy1": -6.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -40.0, 18.0, -20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 11, 20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -20.0, 9.0, -10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1480412516051293, "mean_inference_ms": 1.3437249272720293, "mean_action_processing_ms": 0.09210630082661009, "mean_env_wait_ms": 0.1553741627670808, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10846, "timesteps_this_iter": 32, "agent_timesteps_total": 21692, "timers": {"learn_time_ms": 6.377, "learn_throughput": 5017.992, "update_time_ms": 3.749}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10846, "num_agent_steps_sampled": 21692, "num_steps_trained": 16960, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 33920, "last_target_update_ts": 10826, "num_target_updates": 87}, "done": false, "episodes_total": 586, "training_iteration": 93, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-57", "timestamp": 1648816137, "time_this_iter_s": 0.3838045597076416, "time_total_s": 33.76953601837158, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82cacb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82cacb0>"}, "time_since_restore": 33.76953601837158, "timesteps_since_restore": 2976, "iterations_since_restore": 93, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.78, "episode_len_mean": 17.99, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.89, "policy1": -6.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 14.0, -20.0, 20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 13, 20, 10, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 7.0, -10.0, 10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14807141105100047, "mean_inference_ms": 1.3438588019544253, "mean_action_processing_ms": 0.0921240188125912, "mean_env_wait_ms": 0.15541762496520065, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10946, "timesteps_this_iter": 32, "agent_timesteps_total": 21892, "timers": {"learn_time_ms": 6.7, "learn_throughput": 4776.024, "update_time_ms": 3.912}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10946, "num_agent_steps_sampled": 21892, "num_steps_trained": 17120, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 34240, "last_target_update_ts": 10946, "num_target_updates": 88}, "done": false, "episodes_total": 591, "training_iteration": 94, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-58", "timestamp": 1648816138, "time_this_iter_s": 0.31598448753356934, "time_total_s": 34.08552050590515, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff9e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff9e0>"}, "time_since_restore": 34.08552050590515, "timesteps_since_restore": 3008, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 15.3, "ram_util_percent": 48.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.8, "episode_len_mean": 18.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.9, "policy1": -6.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0], "episode_lengths": [20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20], "policy_policy0_reward": [-10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14811135611743542, "mean_inference_ms": 1.3440597595621582, "mean_action_processing_ms": 0.09214893471354905, "mean_env_wait_ms": 0.15547517656222312, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11050, "timesteps_this_iter": 32, "agent_timesteps_total": 22100, "timers": {"learn_time_ms": 6.555, "learn_throughput": 4881.656, "update_time_ms": 3.937}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11050, "num_agent_steps_sampled": 22100, "num_steps_trained": 17312, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 34624, "last_target_update_ts": 11050, "num_target_updates": 89}, "done": false, "episodes_total": 597, "training_iteration": 95, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-58", "timestamp": 1648816138, "time_this_iter_s": 0.3357686996459961, "time_total_s": 34.42128920555115, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a7a0>"}, "time_since_restore": 34.42128920555115, "timesteps_since_restore": 3040, "iterations_since_restore": 95, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.46, "episode_len_mean": 17.93, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.23, "policy1": -7.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1481624460772903, "mean_inference_ms": 1.3443912726155214, "mean_action_processing_ms": 0.09218445729002994, "mean_env_wait_ms": 0.1555480048850961, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11161, "timesteps_this_iter": 32, "agent_timesteps_total": 22322, "timers": {"learn_time_ms": 6.361, "learn_throughput": 5030.951, "update_time_ms": 4.054}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11161, "num_agent_steps_sampled": 22322, "num_steps_trained": 17504, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 35008, "last_target_update_ts": 11161, "num_target_updates": 90}, "done": false, "episodes_total": 603, "training_iteration": 96, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-58", "timestamp": 1648816138, "time_this_iter_s": 0.37277841567993164, "time_total_s": 34.79406762123108, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff4d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff4d0>"}, "time_since_restore": 34.79406762123108, "timesteps_since_restore": 3072, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 16.2, "ram_util_percent": 48.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.42, "episode_len_mean": 17.91, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.21, "policy1": -7.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14822458832991284, "mean_inference_ms": 1.344870914762418, "mean_action_processing_ms": 0.09223125002011467, "mean_env_wait_ms": 0.15563361102315576, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11277, "timesteps_this_iter": 32, "agent_timesteps_total": 22554, "timers": {"learn_time_ms": 6.672, "learn_throughput": 4796.471, "update_time_ms": 4.069}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11277, "num_agent_steps_sampled": 22554, "num_steps_trained": 17696, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 35392, "last_target_update_ts": 11277, "num_target_updates": 91}, "done": false, "episodes_total": 609, "training_iteration": 97, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-59", "timestamp": 1648816139, "time_this_iter_s": 0.38831496238708496, "time_total_s": 35.182382583618164, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82cacb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82cacb0>"}, "time_since_restore": 35.182382583618164, "timesteps_since_restore": 3104, "iterations_since_restore": 97, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.06, "episode_len_mean": 17.73, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.03, "policy1": -7.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, 34.0, 30.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0], "episode_lengths": [20, 20, 20, 20, 3, 5, 20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, 17.0, 15.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14829192435442895, "mean_inference_ms": 1.3453775192591422, "mean_action_processing_ms": 0.09227897908965296, "mean_env_wait_ms": 0.155717608163645, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11379, "timesteps_this_iter": 32, "agent_timesteps_total": 22758, "timers": {"learn_time_ms": 6.396, "learn_throughput": 5002.991, "update_time_ms": 3.839}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11379, "num_agent_steps_sampled": 22758, "num_steps_trained": 17888, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 35776, "last_target_update_ts": 11379, "num_target_updates": 92}, "done": false, "episodes_total": 615, "training_iteration": 98, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-28-59", "timestamp": 1648816139, "time_this_iter_s": 0.3229713439941406, "time_total_s": 35.505353927612305, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82087a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82087a0>"}, "time_since_restore": 35.505353927612305, "timesteps_since_restore": 3136, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 16.8, "ram_util_percent": 48.7}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.78, "episode_len_mean": 17.89, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.39, "policy1": -7.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 14, 20, 20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1483573341705494, "mean_inference_ms": 1.345851394118393, "mean_action_processing_ms": 0.09232448772829692, "mean_env_wait_ms": 0.1557977144972888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11483, "timesteps_this_iter": 32, "agent_timesteps_total": 22966, "timers": {"learn_time_ms": 6.15, "learn_throughput": 5203.024, "update_time_ms": 3.627}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11483, "num_agent_steps_sampled": 22966, "num_steps_trained": 18080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 36160, "last_target_update_ts": 11483, "num_target_updates": 93}, "done": false, "episodes_total": 621, "training_iteration": 99, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-00", "timestamp": 1648816140, "time_this_iter_s": 0.3221004009246826, "time_total_s": 35.82745432853699, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff9e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff9e0>"}, "time_since_restore": 35.82745432853699, "timesteps_since_restore": 3168, "iterations_since_restore": 99, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.7, "episode_len_mean": 17.95, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.35, "policy1": -7.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 12, 18, 20, 20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1484133171974531, "mean_inference_ms": 1.3463116780013902, "mean_action_processing_ms": 0.0923677931479388, "mean_env_wait_ms": 0.15587168696249926, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11583, "timesteps_this_iter": 32, "agent_timesteps_total": 23166, "timers": {"learn_time_ms": 6.454, "learn_throughput": 4958.301, "update_time_ms": 3.803}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11583, "num_agent_steps_sampled": 23166, "num_steps_trained": 18240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 36480, "last_target_update_ts": 11483, "num_target_updates": 93}, "done": false, "episodes_total": 626, "training_iteration": 100, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-00", "timestamp": 1648816140, "time_this_iter_s": 0.3473167419433594, "time_total_s": 36.17477107048035, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82087a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82caef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82087a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82caef0>"}, "time_since_restore": 36.17477107048035, "timesteps_since_restore": 3200, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 15.9, "ram_util_percent": 48.7}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.82, "episode_len_mean": 17.91, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.41, "policy1": -7.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 34.0, 0.0, 14.0, 4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 3, 20, 13, 18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, 17.0, 0.0, 7.0, 2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.148472625921596, "mean_inference_ms": 1.346757566391583, "mean_action_processing_ms": 0.09240952835670009, "mean_env_wait_ms": 0.1559427619809367, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11689, "timesteps_this_iter": 32, "agent_timesteps_total": 23378, "timers": {"learn_time_ms": 6.383, "learn_throughput": 5013.399, "update_time_ms": 3.764}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11689, "num_agent_steps_sampled": 23378, "num_steps_trained": 18432, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 36864, "last_target_update_ts": 11603, "num_target_updates": 94}, "done": false, "episodes_total": 632, "training_iteration": 101, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-00", "timestamp": 1648816140, "time_this_iter_s": 0.3414170742034912, "time_total_s": 36.51618814468384, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203830>"}, "time_since_restore": 36.51618814468384, "timesteps_since_restore": 3232, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 16.9, "ram_util_percent": 48.7}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.7, "episode_len_mean": 18.15, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.85, "policy1": -7.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, -20.0, -20.0, -40.0, -20.0, 26.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0], "episode_lengths": [18, 20, 20, 20, 20, 7, 20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0], "policy_policy1_reward": [2.0, -10.0, -10.0, -20.0, -10.0, 13.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14852551279693388, "mean_inference_ms": 1.3471880221136388, "mean_action_processing_ms": 0.09244891414799492, "mean_env_wait_ms": 0.15601187157051669, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11789, "timesteps_this_iter": 32, "agent_timesteps_total": 23578, "timers": {"learn_time_ms": 6.507, "learn_throughput": 4917.643, "update_time_ms": 3.938}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11789, "num_agent_steps_sampled": 23578, "num_steps_trained": 18592, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 37184, "last_target_update_ts": 11709, "num_target_updates": 95}, "done": false, "episodes_total": 637, "training_iteration": 102, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-01", "timestamp": 1648816141, "time_this_iter_s": 0.32863903045654297, "time_total_s": 36.84482717514038, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208ef0>"}, "time_since_restore": 36.84482717514038, "timesteps_since_restore": 3264, "iterations_since_restore": 102, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.78, "episode_len_mean": 18.19, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.89, "policy1": -7.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 14, 20, 20, 20, 20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14858687573653523, "mean_inference_ms": 1.3476860506667396, "mean_action_processing_ms": 0.09249614374600977, "mean_env_wait_ms": 0.15609472784559075, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11898, "timesteps_this_iter": 32, "agent_timesteps_total": 23796, "timers": {"learn_time_ms": 6.474, "learn_throughput": 4942.598, "update_time_ms": 3.895}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11898, "num_agent_steps_sampled": 23796, "num_steps_trained": 18784, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 37568, "last_target_update_ts": 11829, "num_target_updates": 96}, "done": false, "episodes_total": 643, "training_iteration": 103, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-01", "timestamp": 1648816141, "time_this_iter_s": 0.3480854034423828, "time_total_s": 37.192912578582764, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff7a0>"}, "time_since_restore": 37.192912578582764, "timesteps_since_restore": 3296, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 14.9, "ram_util_percent": 48.7}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.82, "episode_len_mean": 18.11, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.91, "policy1": -7.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, 24.0, 28.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 8, 6, 20, 6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, 12.0, 14.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1486492915808195, "mean_inference_ms": 1.3481808255041587, "mean_action_processing_ms": 0.09254375448735995, "mean_env_wait_ms": 0.1561850918888219, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12004, "timesteps_this_iter": 32, "agent_timesteps_total": 24008, "timers": {"learn_time_ms": 6.449, "learn_throughput": 4961.93, "update_time_ms": 3.897}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12004, "num_agent_steps_sampled": 24008, "num_steps_trained": 18976, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 37952, "last_target_update_ts": 11944, "num_target_updates": 97}, "done": false, "episodes_total": 649, "training_iteration": 104, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-01", "timestamp": 1648816141, "time_this_iter_s": 0.3735527992248535, "time_total_s": 37.56646537780762, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82329e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82329e0>"}, "time_since_restore": 37.56646537780762, "timesteps_since_restore": 3328, "iterations_since_restore": 104, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.12, "episode_len_mean": 18.26, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.06, "policy1": -8.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [6, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20], "policy_policy0_reward": [14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1487093939965882, "mean_inference_ms": 1.3486980137579052, "mean_action_processing_ms": 0.092593472887621, "mean_env_wait_ms": 0.15627783865096428, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12113, "timesteps_this_iter": 32, "agent_timesteps_total": 24226, "timers": {"learn_time_ms": 6.487, "learn_throughput": 4933.097, "update_time_ms": 3.897}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12113, "num_agent_steps_sampled": 24226, "num_steps_trained": 19168, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 38336, "last_target_update_ts": 12053, "num_target_updates": 98}, "done": false, "episodes_total": 655, "training_iteration": 105, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-02", "timestamp": 1648816142, "time_this_iter_s": 0.3513758182525635, "time_total_s": 37.91784119606018, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff830>"}, "time_since_restore": 37.91784119606018, "timesteps_since_restore": 3360, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 16.8, "ram_util_percent": 48.7}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.28, "episode_len_mean": 18.34, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.14, "policy1": -8.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 24.0, -40.0, -20.0, 12.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 8, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, 12.0, -20.0, -10.0, 6.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14877462538885297, "mean_inference_ms": 1.3492436469711049, "mean_action_processing_ms": 0.09264516542447496, "mean_env_wait_ms": 0.15637090371660314, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12227, "timesteps_this_iter": 32, "agent_timesteps_total": 24454, "timers": {"learn_time_ms": 6.434, "learn_throughput": 4973.477, "update_time_ms": 3.92}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12227, "num_agent_steps_sampled": 24454, "num_steps_trained": 19360, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 38720, "last_target_update_ts": 12167, "num_target_updates": 99}, "done": false, "episodes_total": 661, "training_iteration": 106, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-02", "timestamp": 1648816142, "time_this_iter_s": 0.3579368591308594, "time_total_s": 38.27577805519104, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208ef0>"}, "time_since_restore": 38.27577805519104, "timesteps_since_restore": 3392, "iterations_since_restore": 106, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.82, "episode_len_mean": 18.51, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.41, "policy1": -8.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20], "policy_policy0_reward": [0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1488337406015302, "mean_inference_ms": 1.3497317064513725, "mean_action_processing_ms": 0.0926912938567606, "mean_env_wait_ms": 0.15645483932335974, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12346, "timesteps_this_iter": 32, "agent_timesteps_total": 24692, "timers": {"learn_time_ms": 6.182, "learn_throughput": 5175.976, "update_time_ms": 3.712}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12346, "num_agent_steps_sampled": 24692, "num_steps_trained": 19552, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 39104, "last_target_update_ts": 12286, "num_target_updates": 100}, "done": false, "episodes_total": 667, "training_iteration": 107, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-03", "timestamp": 1648816143, "time_this_iter_s": 0.3604543209075928, "time_total_s": 38.63623237609863, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff7a0>"}, "time_since_restore": 38.63623237609863, "timesteps_since_restore": 3424, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 16.8, "ram_util_percent": 48.7}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.54, "episode_len_mean": 18.37, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.27, "policy1": -8.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, 4.0, 8.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 18, 16, 20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, 2.0, 4.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14888526677367475, "mean_inference_ms": 1.350127592739609, "mean_action_processing_ms": 0.09272954327433798, "mean_env_wait_ms": 0.1565231030678544, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12452, "timesteps_this_iter": 32, "agent_timesteps_total": 24904, "timers": {"learn_time_ms": 6.123, "learn_throughput": 5226.486, "update_time_ms": 3.717}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12452, "num_agent_steps_sampled": 24904, "num_steps_trained": 19744, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 39488, "last_target_update_ts": 12406, "num_target_updates": 101}, "done": false, "episodes_total": 673, "training_iteration": 108, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-03", "timestamp": 1648816143, "time_this_iter_s": 0.3274855613708496, "time_total_s": 38.96371793746948, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82329e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82329e0>"}, "time_since_restore": 38.96371793746948, "timesteps_since_restore": 3456, "iterations_since_restore": 108, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.04, "episode_len_mean": 18.42, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.52, "policy1": -8.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0], "episode_lengths": [20, 5, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20], "policy_policy0_reward": [-10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14894893688039423, "mean_inference_ms": 1.3506946427517397, "mean_action_processing_ms": 0.0927804187655024, "mean_env_wait_ms": 0.15660882223422667, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12571, "timesteps_this_iter": 32, "agent_timesteps_total": 25142, "timers": {"learn_time_ms": 6.463, "learn_throughput": 4951.112, "update_time_ms": 4.029}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12571, "num_agent_steps_sampled": 25142, "num_steps_trained": 19936, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 39872, "last_target_update_ts": 12512, "num_target_updates": 102}, "done": false, "episodes_total": 679, "training_iteration": 109, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-03", "timestamp": 1648816143, "time_this_iter_s": 0.415616512298584, "time_total_s": 39.379334449768066, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff830>"}, "time_since_restore": 39.379334449768066, "timesteps_since_restore": 3488, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 18.0, "ram_util_percent": 48.7}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.08, "episode_len_mean": 18.44, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.54, "policy1": -8.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, 4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14902210909807428, "mean_inference_ms": 1.3514100879961626, "mean_action_processing_ms": 0.09284479887866878, "mean_env_wait_ms": 0.1567117461669315, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12690, "timesteps_this_iter": 32, "agent_timesteps_total": 25380, "timers": {"learn_time_ms": 6.526, "learn_throughput": 4903.146, "update_time_ms": 4.01}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12690, "num_agent_steps_sampled": 25380, "num_steps_trained": 20160, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 40320, "last_target_update_ts": 12619, "num_target_updates": 103}, "done": false, "episodes_total": 686, "training_iteration": 110, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-04", "timestamp": 1648816144, "time_this_iter_s": 0.4047536849975586, "time_total_s": 39.784088134765625, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff560>"}, "time_since_restore": 39.784088134765625, "timesteps_since_restore": 3520, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 14.6, "ram_util_percent": 48.7}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.68, "episode_len_mean": 18.44, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.84, "policy1": -8.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 0.0, -20.0, 28.0, -20.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0], "episode_lengths": [18, 20, 20, 6, 20, 20, 20, 11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [2.0, 0.0, -10.0, 14.0, -10.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14907752690569104, "mean_inference_ms": 1.351961646810202, "mean_action_processing_ms": 0.09289383444495063, "mean_env_wait_ms": 0.1567884776438182, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12790, "timesteps_this_iter": 32, "agent_timesteps_total": 25580, "timers": {"learn_time_ms": 6.342, "learn_throughput": 5045.438, "update_time_ms": 3.985}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12790, "num_agent_steps_sampled": 25580, "num_steps_trained": 20320, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 40640, "last_target_update_ts": 12730, "num_target_updates": 104}, "done": false, "episodes_total": 691, "training_iteration": 111, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-04", "timestamp": 1648816144, "time_this_iter_s": 0.33110928535461426, "time_total_s": 40.11519742012024, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81f2d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff9e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81f2d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff9e0>"}, "time_since_restore": 40.11519742012024, "timesteps_since_restore": 3552, "iterations_since_restore": 111, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.8, "episode_len_mean": 18.2, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.4, "policy1": -8.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.0, -40.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0], "episode_lengths": [11, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20], "policy_policy0_reward": [9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0], "policy_policy1_reward": [9.0, -20.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14915723568675052, "mean_inference_ms": 1.352724363044656, "mean_action_processing_ms": 0.0929606767163143, "mean_env_wait_ms": 0.15689940718825418, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12890, "timesteps_this_iter": 32, "agent_timesteps_total": 25780, "timers": {"learn_time_ms": 6.267, "learn_throughput": 5106.229, "update_time_ms": 4.021}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12890, "num_agent_steps_sampled": 25780, "num_steps_trained": 20544, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 41088, "last_target_update_ts": 12836, "num_target_updates": 105}, "done": false, "episodes_total": 698, "training_iteration": 112, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-05", "timestamp": 1648816145, "time_this_iter_s": 0.35195350646972656, "time_total_s": 40.467150926589966, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8061950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8061950>"}, "time_since_restore": 40.467150926589966, "timesteps_since_restore": 3584, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 16.5, "ram_util_percent": 48.7}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.78, "episode_len_mean": 18.29, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.39, "policy1": -8.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [16, 20, 20, 20, 20, 20, 20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14920891786655727, "mean_inference_ms": 1.3531972302249387, "mean_action_processing_ms": 0.09300225099692622, "mean_env_wait_ms": 0.15697022683147088, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12990, "timesteps_this_iter": 32, "agent_timesteps_total": 25980, "timers": {"learn_time_ms": 6.155, "learn_throughput": 5198.993, "update_time_ms": 3.813}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12990, "num_agent_steps_sampled": 25980, "num_steps_trained": 20704, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 41408, "last_target_update_ts": 12950, "num_target_updates": 106}, "done": false, "episodes_total": 703, "training_iteration": 113, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-05", "timestamp": 1648816145, "time_this_iter_s": 0.29885435104370117, "time_total_s": 40.76600527763367, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232f80>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232f80>"}, "time_since_restore": 40.76600527763367, "timesteps_since_restore": 3616, "iterations_since_restore": 113, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.44, "episode_len_mean": 18.22, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.22, "policy1": -8.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, 22.0, 14.0, -20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 9, 13, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, 11.0, 7.0, -10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1492688484055167, "mean_inference_ms": 1.3536716322786444, "mean_action_processing_ms": 0.09304375726560538, "mean_env_wait_ms": 0.15704452350261236, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13099, "timesteps_this_iter": 32, "agent_timesteps_total": 26198, "timers": {"learn_time_ms": 6.179, "learn_throughput": 5178.792, "update_time_ms": 3.809}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13099, "num_agent_steps_sampled": 26198, "num_steps_trained": 20896, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 41792, "last_target_update_ts": 13059, "num_target_updates": 107}, "done": false, "episodes_total": 709, "training_iteration": 114, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-05", "timestamp": 1648816145, "time_this_iter_s": 0.34757161140441895, "time_total_s": 41.113576889038086, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82cadd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82cadd0>"}, "time_since_restore": 41.113576889038086, "timesteps_since_restore": 3648, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 16.1, "ram_util_percent": 48.8}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.8, "episode_len_mean": 18.4, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.4, "policy1": -8.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 32.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 16.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14931733718242157, "mean_inference_ms": 1.3540694372902777, "mean_action_processing_ms": 0.09307905550319547, "mean_env_wait_ms": 0.1571069511036117, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13199, "timesteps_this_iter": 32, "agent_timesteps_total": 26398, "timers": {"learn_time_ms": 6.2, "learn_throughput": 5161.208, "update_time_ms": 3.789}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13199, "num_agent_steps_sampled": 26398, "num_steps_trained": 21056, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 42112, "last_target_update_ts": 13179, "num_target_updates": 108}, "done": false, "episodes_total": 714, "training_iteration": 115, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-06", "timestamp": 1648816146, "time_this_iter_s": 0.3015162944793701, "time_total_s": 41.415093183517456, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff830>"}, "time_since_restore": 41.415093183517456, "timesteps_since_restore": 3680, "iterations_since_restore": 115, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.12, "episode_len_mean": 18.56, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.56, "policy1": -8.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14936249729286327, "mean_inference_ms": 1.3544737827373174, "mean_action_processing_ms": 0.09311415558916039, "mean_env_wait_ms": 0.15716668663133404, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13299, "timesteps_this_iter": 32, "agent_timesteps_total": 26598, "timers": {"learn_time_ms": 6.132, "learn_throughput": 5218.338, "update_time_ms": 3.69}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13299, "num_agent_steps_sampled": 26598, "num_steps_trained": 21216, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 42432, "last_target_update_ts": 13299, "num_target_updates": 109}, "done": false, "episodes_total": 719, "training_iteration": 116, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-06", "timestamp": 1648816146, "time_this_iter_s": 0.2975037097930908, "time_total_s": 41.71259689331055, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb90>"}, "time_since_restore": 41.71259689331055, "timesteps_since_restore": 3712, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 16.4, "ram_util_percent": 48.8}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.28, "episode_len_mean": 18.54, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.64, "policy1": -8.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 22.0, 6.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 9, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, 11.0, 3.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14940936986271297, "mean_inference_ms": 1.3548813960272685, "mean_action_processing_ms": 0.09314898255787016, "mean_env_wait_ms": 0.15722862744896005, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13417, "timesteps_this_iter": 32, "agent_timesteps_total": 26834, "timers": {"learn_time_ms": 6.084, "learn_throughput": 5259.913, "update_time_ms": 3.679}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13417, "num_agent_steps_sampled": 26834, "num_steps_trained": 21408, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 42816, "last_target_update_ts": 13417, "num_target_updates": 110}, "done": false, "episodes_total": 725, "training_iteration": 117, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-06", "timestamp": 1648816146, "time_this_iter_s": 0.3635227680206299, "time_total_s": 42.07611966133118, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232f80>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232f80>"}, "time_since_restore": 42.07611966133118, "timesteps_since_restore": 3744, "iterations_since_restore": 117, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.16, "episode_len_mean": 18.68, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.08, "policy1": -9.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14944238844286864, "mean_inference_ms": 1.3551752218017783, "mean_action_processing_ms": 0.09317433203919435, "mean_env_wait_ms": 0.15727373082470286, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13517, "timesteps_this_iter": 32, "agent_timesteps_total": 27034, "timers": {"learn_time_ms": 6.204, "learn_throughput": 5157.975, "update_time_ms": 3.761}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13517, "num_agent_steps_sampled": 27034, "num_steps_trained": 21568, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 43136, "last_target_update_ts": 13417, "num_target_updates": 110}, "done": false, "episodes_total": 730, "training_iteration": 118, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-07", "timestamp": 1648816147, "time_this_iter_s": 0.30785632133483887, "time_total_s": 42.383975982666016, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203200>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203200>"}, "time_since_restore": 42.383975982666016, "timesteps_since_restore": 3776, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 17.1, "ram_util_percent": 48.8}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.78, "episode_len_mean": 18.59, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.89, "policy1": -8.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 9, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14947815258664232, "mean_inference_ms": 1.3554835016694062, "mean_action_processing_ms": 0.09320254441123335, "mean_env_wait_ms": 0.15732428112574992, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13628, "timesteps_this_iter": 32, "agent_timesteps_total": 27256, "timers": {"learn_time_ms": 6.148, "learn_throughput": 5205.345, "update_time_ms": 3.753}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13628, "num_agent_steps_sampled": 27256, "num_steps_trained": 21760, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 43520, "last_target_update_ts": 13537, "num_target_updates": 111}, "done": false, "episodes_total": 736, "training_iteration": 119, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-07", "timestamp": 1648816147, "time_this_iter_s": 0.3450489044189453, "time_total_s": 42.72902488708496, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffd40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffd40>"}, "time_since_restore": 42.72902488708496, "timesteps_since_restore": 3808, "iterations_since_restore": 119, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.3, "episode_len_mean": 18.55, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.65, "policy1": -8.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0], "episode_lengths": [20, 20, 6, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11], "policy_policy0_reward": [-10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0], "policy_policy1_reward": [-10.0, -20.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495111981705029, "mean_inference_ms": 1.355762622124607, "mean_action_processing_ms": 0.09322885468930499, "mean_env_wait_ms": 0.15736835823914427, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13733, "timesteps_this_iter": 32, "agent_timesteps_total": 27466, "timers": {"learn_time_ms": 6.239, "learn_throughput": 5128.765, "update_time_ms": 3.772}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13733, "num_agent_steps_sampled": 27466, "num_steps_trained": 21952, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 43904, "last_target_update_ts": 13648, "num_target_updates": 112}, "done": false, "episodes_total": 742, "training_iteration": 120, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-07", "timestamp": 1648816147, "time_this_iter_s": 0.330474853515625, "time_total_s": 43.059499740600586, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b00>"}, "time_since_restore": 43.059499740600586, "timesteps_since_restore": 3840, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 16.8, "ram_util_percent": 48.8}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.86, "episode_len_mean": 18.63, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.93, "policy1": -8.93}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 9, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14953299332846354, "mean_inference_ms": 1.3559366734890594, "mean_action_processing_ms": 0.09324692233925007, "mean_env_wait_ms": 0.15739156055468342, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13847, "timesteps_this_iter": 32, "agent_timesteps_total": 27694, "timers": {"learn_time_ms": 5.994, "learn_throughput": 5339.109, "update_time_ms": 3.668}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13847, "num_agent_steps_sampled": 27694, "num_steps_trained": 22144, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 44288, "last_target_update_ts": 13753, "num_target_updates": 113}, "done": false, "episodes_total": 748, "training_iteration": 121, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-08", "timestamp": 1648816148, "time_this_iter_s": 0.3455772399902344, "time_total_s": 43.40507698059082, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232f80>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232f80>"}, "time_since_restore": 43.40507698059082, "timesteps_since_restore": 3872, "iterations_since_restore": 121, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.28, "episode_len_mean": 18.74, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.14, "policy1": -9.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14954652143136957, "mean_inference_ms": 1.356040599492319, "mean_action_processing_ms": 0.09325895100660408, "mean_env_wait_ms": 0.1574053868270938, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13947, "timesteps_this_iter": 32, "agent_timesteps_total": 27894, "timers": {"learn_time_ms": 6.018, "learn_throughput": 5317.196, "update_time_ms": 3.716}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13947, "num_agent_steps_sampled": 27894, "num_steps_trained": 22304, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 44608, "last_target_update_ts": 13867, "num_target_updates": 114}, "done": false, "episodes_total": 753, "training_iteration": 122, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-08", "timestamp": 1648816148, "time_this_iter_s": 0.2988722324371338, "time_total_s": 43.703949213027954, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cadd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82037a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cadd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82037a0>"}, "time_since_restore": 43.703949213027954, "timesteps_since_restore": 3904, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 16.5, "ram_util_percent": 48.8}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.18, "episode_len_mean": 18.69, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.09, "policy1": -9.09}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495586041504159, "mean_inference_ms": 1.3561320255925735, "mean_action_processing_ms": 0.0932705233128675, "mean_env_wait_ms": 0.1574200624267048, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14056, "timesteps_this_iter": 32, "agent_timesteps_total": 28112, "timers": {"learn_time_ms": 6.21, "learn_throughput": 5152.826, "update_time_ms": 3.809}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14056, "num_agent_steps_sampled": 28112, "num_steps_trained": 22496, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 44992, "last_target_update_ts": 13982, "num_target_updates": 115}, "done": false, "episodes_total": 759, "training_iteration": 123, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-08", "timestamp": 1648816148, "time_this_iter_s": 0.33632683753967285, "time_total_s": 44.04027605056763, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff9e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff9e0>"}, "time_since_restore": 44.04027605056763, "timesteps_since_restore": 3936, "iterations_since_restore": 123, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.82, "episode_len_mean": 18.51, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.91, "policy1": -8.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0], "episode_lengths": [20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14957109759053241, "mean_inference_ms": 1.3562242555439752, "mean_action_processing_ms": 0.09328282195932143, "mean_env_wait_ms": 0.15743717882517322, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14157, "timesteps_this_iter": 32, "agent_timesteps_total": 28314, "timers": {"learn_time_ms": 6.247, "learn_throughput": 5122.501, "update_time_ms": 3.708}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14157, "num_agent_steps_sampled": 28314, "num_steps_trained": 22688, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 45376, "last_target_update_ts": 14094, "num_target_updates": 116}, "done": false, "episodes_total": 765, "training_iteration": 124, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-09", "timestamp": 1648816149, "time_this_iter_s": 0.32255125045776367, "time_total_s": 44.36282730102539, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215170>"}, "time_since_restore": 44.36282730102539, "timesteps_since_restore": 3968, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 17.8, "ram_util_percent": 48.8}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.82, "episode_len_mean": 18.21, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.91, "policy1": -7.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, 2.0, -40.0, -20.0, 24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0], "episode_lengths": [20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, 1.0, -20.0, -10.0, 12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14959324252360495, "mean_inference_ms": 1.3563484292518921, "mean_action_processing_ms": 0.09330078421282932, "mean_env_wait_ms": 0.15745932787309225, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14273, "timesteps_this_iter": 32, "agent_timesteps_total": 28546, "timers": {"learn_time_ms": 6.242, "learn_throughput": 5126.845, "update_time_ms": 3.755}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14273, "num_agent_steps_sampled": 28546, "num_steps_trained": 22944, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 45888, "last_target_update_ts": 14197, "num_target_updates": 117}, "done": false, "episodes_total": 773, "training_iteration": 125, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-09", "timestamp": 1648816149, "time_this_iter_s": 0.38897180557250977, "time_total_s": 44.7517991065979, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff830>"}, "time_since_restore": 44.7517991065979, "timesteps_since_restore": 4000, "iterations_since_restore": 125, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.32, "episode_len_mean": 18.06, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.66, "policy1": -7.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0], "episode_lengths": [8, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20], "policy_policy0_reward": [12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0], "policy_policy1_reward": [12.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.149599423717206, "mean_inference_ms": 1.356283824049934, "mean_action_processing_ms": 0.09330151243125158, "mean_env_wait_ms": 0.15745855682168114, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14377, "timesteps_this_iter": 32, "agent_timesteps_total": 28754, "timers": {"learn_time_ms": 6.268, "learn_throughput": 5105.393, "update_time_ms": 3.783}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14377, "num_agent_steps_sampled": 28754, "num_steps_trained": 23136, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 46272, "last_target_update_ts": 14309, "num_target_updates": 118}, "done": false, "episodes_total": 779, "training_iteration": 126, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-10", "timestamp": 1648816150, "time_this_iter_s": 0.33267712593078613, "time_total_s": 45.08447623252869, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82037a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82037a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215170>"}, "time_since_restore": 45.08447623252869, "timesteps_since_restore": 4032, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 14.8, "ram_util_percent": 48.8}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.52, "episode_len_mean": 18.16, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.76, "policy1": -7.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14960153806143575, "mean_inference_ms": 1.3561565341209774, "mean_action_processing_ms": 0.09329614022623897, "mean_env_wait_ms": 0.15744939926631915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14486, "timesteps_this_iter": 32, "agent_timesteps_total": 28972, "timers": {"learn_time_ms": 6.283, "learn_throughput": 5093.169, "update_time_ms": 3.674}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14486, "num_agent_steps_sampled": 28972, "num_steps_trained": 23328, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 46656, "last_target_update_ts": 14417, "num_target_updates": 119}, "done": false, "episodes_total": 785, "training_iteration": 127, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-10", "timestamp": 1648816150, "time_this_iter_s": 0.3358316421508789, "time_total_s": 45.420307874679565, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cadd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cadd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208d40>"}, "time_since_restore": 45.420307874679565, "timesteps_since_restore": 4064, "iterations_since_restore": 127, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.52, "episode_len_mean": 17.96, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.26, "policy1": -7.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 28.0, 28.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0], "episode_lengths": [20, 20, 6, 6, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17], "policy_policy0_reward": [-10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0], "policy_policy1_reward": [-10.0, -10.0, 14.0, 14.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495974647285339, "mean_inference_ms": 1.3559394669881022, "mean_action_processing_ms": 0.09328442654844363, "mean_env_wait_ms": 0.1574307989413145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14586, "timesteps_this_iter": 32, "agent_timesteps_total": 29172, "timers": {"learn_time_ms": 6.172, "learn_throughput": 5184.654, "update_time_ms": 3.748}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14586, "num_agent_steps_sampled": 29172, "num_steps_trained": 23488, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 46976, "last_target_update_ts": 14526, "num_target_updates": 120}, "done": false, "episodes_total": 791, "training_iteration": 128, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-10", "timestamp": 1648816150, "time_this_iter_s": 0.297313928604126, "time_total_s": 45.71762180328369, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82155f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215dd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82155f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215dd0>"}, "time_since_restore": 45.71762180328369, "timesteps_since_restore": 4096, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 16.6, "ram_util_percent": 48.8}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.28, "episode_len_mean": 18.14, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.64, "policy1": -7.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14958786240061808, "mean_inference_ms": 1.3556494431188202, "mean_action_processing_ms": 0.09326709633173003, "mean_env_wait_ms": 0.15739764377816903, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14704, "timesteps_this_iter": 32, "agent_timesteps_total": 29408, "timers": {"learn_time_ms": 6.346, "learn_throughput": 5042.197, "update_time_ms": 3.846}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14704, "num_agent_steps_sampled": 29408, "num_steps_trained": 23712, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 47424, "last_target_update_ts": 14632, "num_target_updates": 121}, "done": false, "episodes_total": 798, "training_iteration": 129, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-11", "timestamp": 1648816151, "time_this_iter_s": 0.3778247833251953, "time_total_s": 46.09544658660889, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215950>"}, "time_since_restore": 46.09544658660889, "timesteps_since_restore": 4128, "iterations_since_restore": 129, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.38, "episode_len_mean": 17.89, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.19, "policy1": -7.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0], "episode_lengths": [9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20], "policy_policy0_reward": [11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0], "policy_policy1_reward": [11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14958158202772612, "mean_inference_ms": 1.3553718278915352, "mean_action_processing_ms": 0.09324952287849403, "mean_env_wait_ms": 0.1573652640909908, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14819, "timesteps_this_iter": 32, "agent_timesteps_total": 29638, "timers": {"learn_time_ms": 6.723, "learn_throughput": 4759.916, "update_time_ms": 4.114}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14819, "num_agent_steps_sampled": 29638, "num_steps_trained": 23904, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 47808, "last_target_update_ts": 14744, "num_target_updates": 122}, "done": false, "episodes_total": 805, "training_iteration": 130, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-11", "timestamp": 1648816151, "time_this_iter_s": 0.3687596321105957, "time_total_s": 46.46420621871948, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215440>"}, "time_since_restore": 46.46420621871948, "timesteps_since_restore": 4160, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 19.2, "ram_util_percent": 48.8}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.4, "episode_len_mean": 18.0, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.7, "policy1": -7.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14957354040806173, "mean_inference_ms": 1.3551585225527025, "mean_action_processing_ms": 0.09323598067926277, "mean_env_wait_ms": 0.15734043337533843, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14919, "timesteps_this_iter": 32, "agent_timesteps_total": 29838, "timers": {"learn_time_ms": 6.768, "learn_throughput": 4728.174, "update_time_ms": 4.451}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14919, "num_agent_steps_sampled": 29838, "num_steps_trained": 24064, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 48128, "last_target_update_ts": 14859, "num_target_updates": 123}, "done": false, "episodes_total": 810, "training_iteration": 131, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-11", "timestamp": 1648816151, "time_this_iter_s": 0.3019561767578125, "time_total_s": 46.766162395477295, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82cadd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82cadd0>"}, "time_since_restore": 46.766162395477295, "timesteps_since_restore": 4192, "iterations_since_restore": 131, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.3, "episode_len_mean": 17.65, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.15, "policy1": -7.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0], "episode_lengths": [20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20], "policy_policy0_reward": [-10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14956731082434985, "mean_inference_ms": 1.3548805801234796, "mean_action_processing_ms": 0.09321942122293098, "mean_env_wait_ms": 0.1573105130218215, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15024, "timesteps_this_iter": 32, "agent_timesteps_total": 30048, "timers": {"learn_time_ms": 6.274, "learn_throughput": 5100.679, "update_time_ms": 4.32}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15024, "num_agent_steps_sampled": 30048, "num_steps_trained": 24288, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 48576, "last_target_update_ts": 14968, "num_target_updates": 124}, "done": false, "episodes_total": 817, "training_iteration": 132, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-12", "timestamp": 1648816152, "time_this_iter_s": 0.3576009273529053, "time_total_s": 47.1237633228302, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82155f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203f80>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82155f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203f80>"}, "time_since_restore": 47.1237633228302, "timesteps_since_restore": 4224, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 15.8, "ram_util_percent": 48.8}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.16, "episode_len_mean": 17.38, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.58, "policy1": -6.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495667750351769, "mean_inference_ms": 1.3546042943411465, "mean_action_processing_ms": 0.09320542716073023, "mean_env_wait_ms": 0.15728844325490152, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15135, "timesteps_this_iter": 32, "agent_timesteps_total": 30270, "timers": {"learn_time_ms": 6.118, "learn_throughput": 5230.315, "update_time_ms": 3.882}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15135, "num_agent_steps_sampled": 30270, "num_steps_trained": 24512, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 49024, "last_target_update_ts": 15084, "num_target_updates": 125}, "done": false, "episodes_total": 824, "training_iteration": 133, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-12", "timestamp": 1648816152, "time_this_iter_s": 0.36325931549072266, "time_total_s": 47.48702263832092, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cacb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cacb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215950>"}, "time_since_restore": 47.48702263832092, "timesteps_since_restore": 4256, "iterations_since_restore": 133, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.76, "episode_len_mean": 17.38, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.38, "policy1": -6.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 11, 20, 20, 20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14956447159209396, "mean_inference_ms": 1.3543876944967375, "mean_action_processing_ms": 0.09319356555224946, "mean_env_wait_ms": 0.15727000536781877, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15235, "timesteps_this_iter": 32, "agent_timesteps_total": 30470, "timers": {"learn_time_ms": 6.116, "learn_throughput": 5232.558, "update_time_ms": 3.926}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15235, "num_agent_steps_sampled": 30470, "num_steps_trained": 24672, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 49344, "last_target_update_ts": 15195, "num_target_updates": 126}, "done": false, "episodes_total": 829, "training_iteration": 134, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-13", "timestamp": 1648816153, "time_this_iter_s": 0.29925012588500977, "time_total_s": 47.78627276420593, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82038c0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82038c0>"}, "time_since_restore": 47.78627276420593, "timesteps_since_restore": 4288, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 16.8, "ram_util_percent": 48.8}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.58, "episode_len_mean": 17.39, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.29, "policy1": -6.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 8.0, 4.0, -20.0, -20.0, 18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0], "episode_lengths": [20, 20, 16, 18, 20, 20, 11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20], "policy_policy0_reward": [-10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 4.0, 2.0, -10.0, -10.0, 9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14955826763401267, "mean_inference_ms": 1.354112111278115, "mean_action_processing_ms": 0.09317820108329108, "mean_env_wait_ms": 0.15724517691923176, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15347, "timesteps_this_iter": 32, "agent_timesteps_total": 30694, "timers": {"learn_time_ms": 6.061, "learn_throughput": 5279.86, "update_time_ms": 3.847}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15347, "num_agent_steps_sampled": 30694, "num_steps_trained": 24864, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 49728, "last_target_update_ts": 15315, "num_target_updates": 127}, "done": false, "episodes_total": 835, "training_iteration": 135, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-13", "timestamp": 1648816153, "time_this_iter_s": 0.3391439914703369, "time_total_s": 48.12541675567627, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cacb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cacb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203320>"}, "time_since_restore": 48.12541675567627, "timesteps_since_restore": 4320, "iterations_since_restore": 135, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.06, "episode_len_mean": 17.33, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.53, "policy1": -6.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.0, -40.0, -20.0, 12.0, -40.0, -20.0, -40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0], "episode_lengths": [11, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20], "policy_policy0_reward": [9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0], "policy_policy1_reward": [9.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495507471747857, "mean_inference_ms": 1.3538362769560053, "mean_action_processing_ms": 0.0931618298661125, "mean_env_wait_ms": 0.15721817185233022, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15455, "timesteps_this_iter": 32, "agent_timesteps_total": 30910, "timers": {"learn_time_ms": 6.202, "learn_throughput": 5159.521, "update_time_ms": 3.77}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15455, "num_agent_steps_sampled": 30910, "num_steps_trained": 25056, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 50112, "last_target_update_ts": 15435, "num_target_updates": 128}, "done": false, "episodes_total": 841, "training_iteration": 136, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-13", "timestamp": 1648816153, "time_this_iter_s": 0.3397233486175537, "time_total_s": 48.46514010429382, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82155f0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82155f0>"}, "time_since_restore": 48.46514010429382, "timesteps_since_restore": 4352, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 16.1, "ram_util_percent": 48.8}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.86, "episode_len_mean": 17.33, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.43, "policy1": -6.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, 0.0, -40.0, -40.0, -20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14954344558820198, "mean_inference_ms": 1.3535516174951185, "mean_action_processing_ms": 0.09314458154695891, "mean_env_wait_ms": 0.15719411208751222, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15560, "timesteps_this_iter": 32, "agent_timesteps_total": 31120, "timers": {"learn_time_ms": 6.149, "learn_throughput": 5204.356, "update_time_ms": 3.771}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15560, "num_agent_steps_sampled": 31120, "num_steps_trained": 25248, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 50496, "last_target_update_ts": 15540, "num_target_updates": 129}, "done": false, "episodes_total": 847, "training_iteration": 137, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-14", "timestamp": 1648816154, "time_this_iter_s": 0.32347893714904785, "time_total_s": 48.78861904144287, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b00>"}, "time_since_restore": 48.78861904144287, "timesteps_since_restore": 4384, "iterations_since_restore": 137, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.82, "episode_len_mean": 17.21, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -5.91, "policy1": -5.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 10.0, 12.0, -20.0, -20.0, -40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0], "episode_lengths": [20, 15, 14, 20, 20, 20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20], "policy_policy0_reward": [-10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 5.0, 6.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14953679303734393, "mean_inference_ms": 1.3532731794466628, "mean_action_processing_ms": 0.09312720427687632, "mean_env_wait_ms": 0.1571701666348077, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15668, "timesteps_this_iter": 32, "agent_timesteps_total": 31336, "timers": {"learn_time_ms": 6.064, "learn_throughput": 5276.684, "update_time_ms": 3.697}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15668, "num_agent_steps_sampled": 31336, "num_steps_trained": 25440, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 50880, "last_target_update_ts": 15648, "num_target_updates": 130}, "done": false, "episodes_total": 853, "training_iteration": 138, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-14", "timestamp": 1648816154, "time_this_iter_s": 0.33295583724975586, "time_total_s": 49.12157487869263, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82038c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215cb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82038c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215cb0>"}, "time_since_restore": 49.12157487869263, "timesteps_since_restore": 4416, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 16.2, "ram_util_percent": 48.9}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.64, "episode_len_mean": 17.32, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.32, "policy1": -6.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 4.0, -40.0, -20.0, 14.0, -40.0, 20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 18, 20, 20, 13, 20, 10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 2.0, -20.0, -10.0, 7.0, -20.0, 10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14953116409328193, "mean_inference_ms": 1.3530594909969806, "mean_action_processing_ms": 0.09311352838504597, "mean_env_wait_ms": 0.15715016311293917, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15768, "timesteps_this_iter": 32, "agent_timesteps_total": 31536, "timers": {"learn_time_ms": 6.163, "learn_throughput": 5192.476, "update_time_ms": 3.772}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15768, "num_agent_steps_sampled": 31536, "num_steps_trained": 25600, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 51200, "last_target_update_ts": 15768, "num_target_updates": 131}, "done": false, "episodes_total": 858, "training_iteration": 139, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-14", "timestamp": 1648816154, "time_this_iter_s": 0.30031251907348633, "time_total_s": 49.42188739776611, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82033b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82033b0>"}, "time_since_restore": 49.42188739776611, "timesteps_since_restore": 4448, "iterations_since_restore": 139, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.76, "episode_len_mean": 17.28, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -5.88, "policy1": -5.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -20.0, -20.0, 24.0, 6.0, 24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0], "episode_lengths": [10, 20, 20, 8, 17, 8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14], "policy_policy0_reward": [10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0], "policy_policy1_reward": [10.0, -10.0, -10.0, 12.0, 3.0, 12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14952332753321254, "mean_inference_ms": 1.352790516142275, "mean_action_processing_ms": 0.09309677888913231, "mean_env_wait_ms": 0.15712530905348193, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15875, "timesteps_this_iter": 32, "agent_timesteps_total": 31750, "timers": {"learn_time_ms": 6.184, "learn_throughput": 5174.6, "update_time_ms": 3.926}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15875, "num_agent_steps_sampled": 31750, "num_steps_trained": 25792, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 51584, "last_target_update_ts": 15875, "num_target_updates": 132}, "done": false, "episodes_total": 864, "training_iteration": 140, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-15", "timestamp": 1648816155, "time_this_iter_s": 0.33347225189208984, "time_total_s": 49.7553596496582, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82155f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82150e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82155f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82150e0>"}, "time_since_restore": 49.7553596496582, "timesteps_since_restore": 4480, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 15.9, "ram_util_percent": 48.9}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.26, "episode_len_mean": 17.53, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.63, "policy1": -6.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, 2.0, 32.0, -20.0, -20.0, 8.0, -20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [8, 19, 4, 20, 20, 16, 20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20], "policy_policy0_reward": [12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [12.0, 1.0, 16.0, -10.0, -10.0, 4.0, -10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495162798159998, "mean_inference_ms": 1.3525996253656873, "mean_action_processing_ms": 0.09308439736245751, "mean_env_wait_ms": 0.1571094524291466, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15975, "timesteps_this_iter": 32, "agent_timesteps_total": 31950, "timers": {"learn_time_ms": 6.267, "learn_throughput": 5106.481, "update_time_ms": 3.96}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15975, "num_agent_steps_sampled": 31950, "num_steps_trained": 25952, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 51904, "last_target_update_ts": 15875, "num_target_updates": 132}, "done": false, "episodes_total": 869, "training_iteration": 141, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-15", "timestamp": 1648816155, "time_this_iter_s": 0.3131527900695801, "time_total_s": 50.06851243972778, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b00>"}, "time_since_restore": 50.06851243972778, "timesteps_since_restore": 4512, "iterations_since_restore": 141, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.48, "episode_len_mean": 17.74, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.24, "policy1": -7.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 24.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0], "episode_lengths": [20, 8, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20], "policy_policy0_reward": [-10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0], "policy_policy1_reward": [-10.0, 12.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495074332005329, "mean_inference_ms": 1.3523763477250121, "mean_action_processing_ms": 0.09307018685095027, "mean_env_wait_ms": 0.15708960770259447, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16083, "timesteps_this_iter": 32, "agent_timesteps_total": 32166, "timers": {"learn_time_ms": 6.321, "learn_throughput": 5062.298, "update_time_ms": 3.77}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16083, "num_agent_steps_sampled": 32166, "num_steps_trained": 26144, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 52288, "last_target_update_ts": 15995, "num_target_updates": 133}, "done": false, "episodes_total": 875, "training_iteration": 142, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-15", "timestamp": 1648816155, "time_this_iter_s": 0.34000372886657715, "time_total_s": 50.40851616859436, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82038c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215dd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82038c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215dd0>"}, "time_since_restore": 50.40851616859436, "timesteps_since_restore": 4544, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 18.4, "ram_util_percent": 48.9}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.6, "episode_len_mean": 17.7, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.3, "policy1": -7.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0], "episode_lengths": [9, 20, 20, 20, 20, 20, 20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20], "policy_policy0_reward": [11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [11.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1494966124626612, "mean_inference_ms": 1.3521476172216773, "mean_action_processing_ms": 0.0930556926847324, "mean_env_wait_ms": 0.15706683091260923, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16187, "timesteps_this_iter": 32, "agent_timesteps_total": 32374, "timers": {"learn_time_ms": 6.373, "learn_throughput": 5020.864, "update_time_ms": 3.751}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16187, "num_agent_steps_sampled": 32374, "num_steps_trained": 26336, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 52672, "last_target_update_ts": 16103, "num_target_updates": 134}, "done": false, "episodes_total": 881, "training_iteration": 143, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-16", "timestamp": 1648816156, "time_this_iter_s": 0.32797694206237793, "time_total_s": 50.73649311065674, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203cb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203cb0>"}, "time_since_restore": 50.73649311065674, "timesteps_since_restore": 4576, "iterations_since_restore": 143, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.88, "episode_len_mean": 17.74, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.44, "policy1": -7.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 34.0, 6.0, 28.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0], "episode_lengths": [20, 20, 3, 17, 6, 20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20], "policy_policy0_reward": [-10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, 17.0, 3.0, 14.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14948349115955328, "mean_inference_ms": 1.3519162554894846, "mean_action_processing_ms": 0.09304138963849716, "mean_env_wait_ms": 0.15704180598579104, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16300, "timesteps_this_iter": 32, "agent_timesteps_total": 32600, "timers": {"learn_time_ms": 6.239, "learn_throughput": 5129.039, "update_time_ms": 3.719}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16300, "num_agent_steps_sampled": 32600, "num_steps_trained": 26528, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 53056, "last_target_update_ts": 16207, "num_target_updates": 135}, "done": false, "episodes_total": 887, "training_iteration": 144, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-16", "timestamp": 1648816156, "time_this_iter_s": 0.33713579177856445, "time_total_s": 51.0736289024353, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232c20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232c20>"}, "time_since_restore": 51.0736289024353, "timesteps_since_restore": 4608, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 16.5, "ram_util_percent": 48.9}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.36, "episode_len_mean": 18.08, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.18, "policy1": -8.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 12, 20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.149470392957701, "mean_inference_ms": 1.351731446937449, "mean_action_processing_ms": 0.09302944549155391, "mean_env_wait_ms": 0.15702151786929838, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16400, "timesteps_this_iter": 32, "agent_timesteps_total": 32800, "timers": {"learn_time_ms": 6.157, "learn_throughput": 5197.503, "update_time_ms": 3.593}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16400, "num_agent_steps_sampled": 32800, "num_steps_trained": 26688, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 53376, "last_target_update_ts": 16320, "num_target_updates": 136}, "done": false, "episodes_total": 892, "training_iteration": 145, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-16", "timestamp": 1648816156, "time_this_iter_s": 0.297041654586792, "time_total_s": 51.370670557022095, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203200>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203200>"}, "time_since_restore": 51.370670557022095, "timesteps_since_restore": 4640, "iterations_since_restore": 145, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.92, "episode_len_mean": 18.16, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.46, "policy1": -8.46}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, 34.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 3, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, 17.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14945497139906286, "mean_inference_ms": 1.351534928049847, "mean_action_processing_ms": 0.09301786124397003, "mean_env_wait_ms": 0.15700135816095867, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16500, "timesteps_this_iter": 32, "agent_timesteps_total": 33000, "timers": {"learn_time_ms": 6.134, "learn_throughput": 5216.411, "update_time_ms": 3.671}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16500, "num_agent_steps_sampled": 33000, "num_steps_trained": 26848, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 53696, "last_target_update_ts": 16440, "num_target_updates": 137}, "done": false, "episodes_total": 897, "training_iteration": 146, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-17", "timestamp": 1648816157, "time_this_iter_s": 0.3005101680755615, "time_total_s": 51.671180725097656, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215170>"}, "time_since_restore": 51.671180725097656, "timesteps_since_restore": 4672, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 16.4, "ram_util_percent": 48.9}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.86, "episode_len_mean": 18.23, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.43, "policy1": -8.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0], "episode_lengths": [12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20], "policy_policy0_reward": [8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0], "policy_policy1_reward": [8.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14944090432545754, "mean_inference_ms": 1.3513523526914712, "mean_action_processing_ms": 0.09300897542265915, "mean_env_wait_ms": 0.1569848027745297, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16610, "timesteps_this_iter": 32, "agent_timesteps_total": 33220, "timers": {"learn_time_ms": 6.517, "learn_throughput": 4910.554, "update_time_ms": 3.98}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16610, "num_agent_steps_sampled": 33220, "num_steps_trained": 27040, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 54080, "last_target_update_ts": 16560, "num_target_updates": 138}, "done": false, "episodes_total": 903, "training_iteration": 147, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-17", "timestamp": 1648816157, "time_this_iter_s": 0.37404656410217285, "time_total_s": 52.04522728919983, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203cb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203cb0>"}, "time_since_restore": 52.04522728919983, "timesteps_since_restore": 4704, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 14.9, "ram_util_percent": 48.9}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.86, "episode_len_mean": 18.23, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.43, "policy1": -8.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 22.0, -40.0, -20.0, 28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 9, 20, 20, 6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, 11.0, -20.0, -10.0, 14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14942885289545862, "mean_inference_ms": 1.3512022616940136, "mean_action_processing_ms": 0.09300202762377224, "mean_env_wait_ms": 0.15696875175349526, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16722, "timesteps_this_iter": 32, "agent_timesteps_total": 33444, "timers": {"learn_time_ms": 6.438, "learn_throughput": 4970.824, "update_time_ms": 3.954}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16722, "num_agent_steps_sampled": 33444, "num_steps_trained": 27232, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 54464, "last_target_update_ts": 16662, "num_target_updates": 139}, "done": false, "episodes_total": 909, "training_iteration": 148, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-18", "timestamp": 1648816158, "time_this_iter_s": 0.3615691661834717, "time_total_s": 52.4067964553833, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82038c0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82038c0>"}, "time_since_restore": 52.4067964553833, "timesteps_since_restore": 4736, "iterations_since_restore": 148, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.08, "episode_len_mean": 18.34, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.54, "policy1": -8.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [6, 10, 20, 20, 20, 20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [14.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1494235909688704, "mean_inference_ms": 1.3511398837653683, "mean_action_processing_ms": 0.0930016124976026, "mean_env_wait_ms": 0.15696325067346822, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16822, "timesteps_this_iter": 32, "agent_timesteps_total": 33644, "timers": {"learn_time_ms": 6.471, "learn_throughput": 4945.33, "update_time_ms": 3.919}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16822, "num_agent_steps_sampled": 33644, "num_steps_trained": 27392, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 54784, "last_target_update_ts": 16782, "num_target_updates": 140}, "done": false, "episodes_total": 914, "training_iteration": 149, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-18", "timestamp": 1648816158, "time_this_iter_s": 0.33437156677246094, "time_total_s": 52.74116802215576, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb00>"}, "time_since_restore": 52.74116802215576, "timesteps_since_restore": 4768, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 15.9, "ram_util_percent": 48.9}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.16, "episode_len_mean": 18.58, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.08, "policy1": -9.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 26.0, 16.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 7, 12, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, 13.0, 8.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14941586631147924, "mean_inference_ms": 1.3510723185379474, "mean_action_processing_ms": 0.09300044545252188, "mean_env_wait_ms": 0.15695581355489727, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16922, "timesteps_this_iter": 32, "agent_timesteps_total": 33844, "timers": {"learn_time_ms": 6.536, "learn_throughput": 4896.241, "update_time_ms": 3.86}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16922, "num_agent_steps_sampled": 33844, "num_steps_trained": 27552, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 55104, "last_target_update_ts": 16902, "num_target_updates": 141}, "done": false, "episodes_total": 919, "training_iteration": 150, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-18", "timestamp": 1648816158, "time_this_iter_s": 0.30324816703796387, "time_total_s": 53.044416189193726, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215170>"}, "time_since_restore": 53.044416189193726, "timesteps_since_restore": 4800, "iterations_since_restore": 150, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.76, "episode_len_mean": 18.78, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.38, "policy1": -9.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.149404697363363, "mean_inference_ms": 1.350990151546812, "mean_action_processing_ms": 0.09299818124133825, "mean_env_wait_ms": 0.15694433771261362, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17033, "timesteps_this_iter": 32, "agent_timesteps_total": 34066, "timers": {"learn_time_ms": 6.229, "learn_throughput": 5137.403, "update_time_ms": 3.843}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17033, "num_agent_steps_sampled": 34066, "num_steps_trained": 27744, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 55488, "last_target_update_ts": 17013, "num_target_updates": 142}, "done": false, "episodes_total": 925, "training_iteration": 151, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-19", "timestamp": 1648816159, "time_this_iter_s": 0.34409618377685547, "time_total_s": 53.38851237297058, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8225c20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8225c20>"}, "time_since_restore": 53.38851237297058, "timesteps_since_restore": 4832, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 18.1, "ram_util_percent": 48.9}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.56, "episode_len_mean": 18.68, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.28, "policy1": -9.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0], "episode_lengths": [20, 20, 12, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20], "policy_policy0_reward": [-10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14939565152627007, "mean_inference_ms": 1.3509195403023548, "mean_action_processing_ms": 0.0929971659557171, "mean_env_wait_ms": 0.15693576805749643, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17143, "timesteps_this_iter": 32, "agent_timesteps_total": 34286, "timers": {"learn_time_ms": 6.026, "learn_throughput": 5310.191, "update_time_ms": 3.766}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17143, "num_agent_steps_sampled": 34286, "num_steps_trained": 27936, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 55872, "last_target_update_ts": 17123, "num_target_updates": 143}, "done": false, "episodes_total": 931, "training_iteration": 152, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-19", "timestamp": 1648816159, "time_this_iter_s": 0.3399317264556885, "time_total_s": 53.72844409942627, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208710>"}, "time_since_restore": 53.72844409942627, "timesteps_since_restore": 4864, "iterations_since_restore": 152, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.32, "episode_len_mean": 18.76, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.66, "policy1": -9.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 24.0, -40.0, -20.0, 24.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 8, 20, 20, 8, 20, 20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, 12.0, -20.0, -10.0, 12.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14938943036435073, "mean_inference_ms": 1.3508761673953413, "mean_action_processing_ms": 0.09299706801107385, "mean_env_wait_ms": 0.15693027490514336, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17243, "timesteps_this_iter": 32, "agent_timesteps_total": 34486, "timers": {"learn_time_ms": 6.154, "learn_throughput": 5199.92, "update_time_ms": 3.88}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17243, "num_agent_steps_sampled": 34486, "num_steps_trained": 28096, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 56192, "last_target_update_ts": 17243, "num_target_updates": 144}, "done": false, "episodes_total": 936, "training_iteration": 153, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-19", "timestamp": 1648816159, "time_this_iter_s": 0.3059237003326416, "time_total_s": 54.03436779975891, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201200>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201200>"}, "time_since_restore": 54.03436779975891, "timesteps_since_restore": 4896, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 15.6, "ram_util_percent": 48.9}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.34, "episode_len_mean": 18.77, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.67, "policy1": -9.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 6.0, -20.0, -40.0, -20.0, 12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0], "episode_lengths": [20, 17, 20, 20, 20, 14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20], "policy_policy0_reward": [-10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0], "policy_policy1_reward": [-10.0, 3.0, -10.0, -20.0, -10.0, 6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14938381181990615, "mean_inference_ms": 1.3508269929969277, "mean_action_processing_ms": 0.09299869290626434, "mean_env_wait_ms": 0.15692607318893004, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17360, "timesteps_this_iter": 32, "agent_timesteps_total": 34720, "timers": {"learn_time_ms": 6.334, "learn_throughput": 5051.914, "update_time_ms": 3.904}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17360, "num_agent_steps_sampled": 34720, "num_steps_trained": 28320, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 56640, "last_target_update_ts": 17360, "num_target_updates": 145}, "done": false, "episodes_total": 943, "training_iteration": 154, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-20", "timestamp": 1648816160, "time_this_iter_s": 0.3793621063232422, "time_total_s": 54.41372990608215, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb821a7a0>"}, "time_since_restore": 54.41372990608215, "timesteps_since_restore": 4928, "iterations_since_restore": 154, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.6, "episode_len_mean": 18.8, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.8, "policy1": -9.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, -40.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [14, 20, 14, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [6.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14938124431140373, "mean_inference_ms": 1.350831917158244, "mean_action_processing_ms": 0.09300263261529801, "mean_env_wait_ms": 0.15692814837590435, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17460, "timesteps_this_iter": 32, "agent_timesteps_total": 34920, "timers": {"learn_time_ms": 6.315, "learn_throughput": 5067.44, "update_time_ms": 3.889}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17460, "num_agent_steps_sampled": 34920, "num_steps_trained": 28480, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 56960, "last_target_update_ts": 17360, "num_target_updates": 145}, "done": false, "episodes_total": 948, "training_iteration": 155, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-20", "timestamp": 1648816160, "time_this_iter_s": 0.31730103492736816, "time_total_s": 54.73103094100952, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff320>"}, "time_since_restore": 54.73103094100952, "timesteps_since_restore": 4960, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 17.1, "ram_util_percent": 49.0}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.44, "episode_len_mean": 18.92, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -10.22, "policy1": -10.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1493774006152926, "mean_inference_ms": 1.3508245047936562, "mean_action_processing_ms": 0.09300575935595655, "mean_env_wait_ms": 0.15692998805209504, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17560, "timesteps_this_iter": 32, "agent_timesteps_total": 35120, "timers": {"learn_time_ms": 6.226, "learn_throughput": 5139.842, "update_time_ms": 3.884}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17560, "num_agent_steps_sampled": 35120, "num_steps_trained": 28640, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 57280, "last_target_update_ts": 17480, "num_target_updates": 146}, "done": false, "episodes_total": 953, "training_iteration": 156, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-20", "timestamp": 1648816160, "time_this_iter_s": 0.2959482669830322, "time_total_s": 55.026979207992554, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82014d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82014d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208ef0>"}, "time_since_restore": 55.026979207992554, "timesteps_since_restore": 4992, "iterations_since_restore": 156, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.38, "episode_len_mean": 18.89, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -10.19, "policy1": -10.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 0.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 0.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1493817411784055, "mean_inference_ms": 1.3508776524344313, "mean_action_processing_ms": 0.09301586130348614, "mean_env_wait_ms": 0.15694251878109147, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17670, "timesteps_this_iter": 32, "agent_timesteps_total": 35340, "timers": {"learn_time_ms": 6.667, "learn_throughput": 4800.039, "update_time_ms": 3.852}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17670, "num_agent_steps_sampled": 35340, "num_steps_trained": 28832, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 57664, "last_target_update_ts": 17600, "num_target_updates": 147}, "done": false, "episodes_total": 959, "training_iteration": 157, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-21", "timestamp": 1648816161, "time_this_iter_s": 0.37369561195373535, "time_total_s": 55.40067481994629, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff710>"}, "time_since_restore": 55.40067481994629, "timesteps_since_restore": 5024, "iterations_since_restore": 157, "perf": {"cpu_util_percent": 16.5, "ram_util_percent": 49.0}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.26, "episode_len_mean": 18.83, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -10.13, "policy1": -10.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1493867584710703, "mean_inference_ms": 1.3509441000994185, "mean_action_processing_ms": 0.09302642659125925, "mean_env_wait_ms": 0.15695492189312346, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17778, "timesteps_this_iter": 32, "agent_timesteps_total": 35556, "timers": {"learn_time_ms": 6.636, "learn_throughput": 4822.304, "update_time_ms": 3.897}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17778, "num_agent_steps_sampled": 35556, "num_steps_trained": 29024, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 58048, "last_target_update_ts": 17710, "num_target_updates": 148}, "done": false, "episodes_total": 965, "training_iteration": 158, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-21", "timestamp": 1648816161, "time_this_iter_s": 0.3438072204589844, "time_total_s": 55.74448204040527, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82309e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82309e0>"}, "time_since_restore": 55.74448204040527, "timesteps_since_restore": 5056, "iterations_since_restore": 158, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.56, "episode_len_mean": 18.68, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.78, "policy1": -9.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -40.0, 4.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [10, 20, 18, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20], "policy_policy0_reward": [10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [10.0, -20.0, 2.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1493934760139606, "mean_inference_ms": 1.351008724262129, "mean_action_processing_ms": 0.09303678696678333, "mean_env_wait_ms": 0.15696807117158695, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17883, "timesteps_this_iter": 32, "agent_timesteps_total": 35766, "timers": {"learn_time_ms": 6.221, "learn_throughput": 5144.156, "update_time_ms": 3.848}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17883, "num_agent_steps_sampled": 35766, "num_steps_trained": 29216, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 58432, "last_target_update_ts": 17823, "num_target_updates": 149}, "done": false, "episodes_total": 971, "training_iteration": 159, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-22", "timestamp": 1648816162, "time_this_iter_s": 0.34064483642578125, "time_total_s": 56.085126876831055, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb00>"}, "time_since_restore": 56.085126876831055, "timesteps_since_restore": 5088, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 17.4, "ram_util_percent": 49.0}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.0, "episode_len_mean": 18.8, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -10.0, "policy1": -10.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [4, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [16.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14940239448779427, "mean_inference_ms": 1.3511249753575354, "mean_action_processing_ms": 0.09304997626118787, "mean_env_wait_ms": 0.1569874396367912, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17983, "timesteps_this_iter": 32, "agent_timesteps_total": 35966, "timers": {"learn_time_ms": 6.418, "learn_throughput": 4986.244, "update_time_ms": 3.949}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17983, "num_agent_steps_sampled": 35966, "num_steps_trained": 29376, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 58752, "last_target_update_ts": 17943, "num_target_updates": 150}, "done": false, "episodes_total": 976, "training_iteration": 160, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-22", "timestamp": 1648816162, "time_this_iter_s": 0.3391544818878174, "time_total_s": 56.42428135871887, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208ef0>"}, "time_since_restore": 56.42428135871887, "timesteps_since_restore": 5120, "iterations_since_restore": 160, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.2, "episode_len_mean": 18.8, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.6, "policy1": -9.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, 14.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0], "episode_lengths": [20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14], "policy_policy0_reward": [-10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14941638656408532, "mean_inference_ms": 1.3512793048764882, "mean_action_processing_ms": 0.09306673934473167, "mean_env_wait_ms": 0.15701305023232226, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18087, "timesteps_this_iter": 32, "agent_timesteps_total": 36174, "timers": {"learn_time_ms": 6.428, "learn_throughput": 4978.606, "update_time_ms": 3.899}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18087, "num_agent_steps_sampled": 36174, "num_steps_trained": 29568, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 59136, "last_target_update_ts": 18053, "num_target_updates": 151}, "done": false, "episodes_total": 982, "training_iteration": 161, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-22", "timestamp": 1648816162, "time_this_iter_s": 0.33617305755615234, "time_total_s": 56.760454416275024, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82013b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff9e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82013b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff9e0>"}, "time_since_restore": 56.760454416275024, "timesteps_since_restore": 5152, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 17.4, "ram_util_percent": 49.0}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.04, "episode_len_mean": 18.62, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.02, "policy1": -9.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14943923503841158, "mean_inference_ms": 1.3514814482261182, "mean_action_processing_ms": 0.09308883134599587, "mean_env_wait_ms": 0.1570472513581353, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18202, "timesteps_this_iter": 32, "agent_timesteps_total": 36404, "timers": {"learn_time_ms": 6.213, "learn_throughput": 5150.335, "update_time_ms": 3.78}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18202, "num_agent_steps_sampled": 36404, "num_steps_trained": 29792, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 59584, "last_target_update_ts": 18159, "num_target_updates": 152}, "done": false, "episodes_total": 989, "training_iteration": 162, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-23", "timestamp": 1648816163, "time_this_iter_s": 0.3760721683502197, "time_total_s": 57.136526584625244, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82014d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82014d0>"}, "time_since_restore": 57.136526584625244, "timesteps_since_restore": 5184, "iterations_since_restore": 162, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.6, "episode_len_mean": 18.5, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.3, "policy1": -8.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20], "policy_policy0_reward": [-10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1494606996921149, "mean_inference_ms": 1.351663179791889, "mean_action_processing_ms": 0.09310736753059494, "mean_env_wait_ms": 0.15707641354519908, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18310, "timesteps_this_iter": 32, "agent_timesteps_total": 36620, "timers": {"learn_time_ms": 6.246, "learn_throughput": 5123.205, "update_time_ms": 3.739}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18310, "num_agent_steps_sampled": 36620, "num_steps_trained": 29984, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 59968, "last_target_update_ts": 18277, "num_target_updates": 153}, "done": false, "episodes_total": 995, "training_iteration": 163, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-23", "timestamp": 1648816163, "time_this_iter_s": 0.33570361137390137, "time_total_s": 57.472230195999146, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb90>"}, "time_since_restore": 57.472230195999146, "timesteps_since_restore": 5216, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 17.1, "ram_util_percent": 49.0}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.2, "episode_len_mean": 18.5, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.6, "policy1": -8.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, 10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1494731931149214, "mean_inference_ms": 1.3517805049100122, "mean_action_processing_ms": 0.09311953562013443, "mean_env_wait_ms": 0.15709607121544394, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18410, "timesteps_this_iter": 32, "agent_timesteps_total": 36820, "timers": {"learn_time_ms": 6.233, "learn_throughput": 5133.964, "update_time_ms": 3.701}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18410, "num_agent_steps_sampled": 36820, "num_steps_trained": 30144, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 60288, "last_target_update_ts": 18390, "num_target_updates": 154}, "done": false, "episodes_total": 1000, "training_iteration": 164, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-23", "timestamp": 1648816163, "time_this_iter_s": 0.297879695892334, "time_total_s": 57.77010989189148, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201b90>"}, "time_since_restore": 57.77010989189148, "timesteps_since_restore": 5248, "iterations_since_restore": 164, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.8, "episode_len_mean": 18.6, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.9, "policy1": -8.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14948674392897285, "mean_inference_ms": 1.3518889821126536, "mean_action_processing_ms": 0.09313120873511992, "mean_env_wait_ms": 0.15711723434887526, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18522, "timesteps_this_iter": 32, "agent_timesteps_total": 37044, "timers": {"learn_time_ms": 6.104, "learn_throughput": 5242.675, "update_time_ms": 3.632}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18522, "num_agent_steps_sampled": 37044, "num_steps_trained": 30336, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 60672, "last_target_update_ts": 18502, "num_target_updates": 155}, "done": false, "episodes_total": 1006, "training_iteration": 165, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-24", "timestamp": 1648816164, "time_this_iter_s": 0.3473670482635498, "time_total_s": 58.11747694015503, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff560>"}, "time_since_restore": 58.11747694015503, "timesteps_since_restore": 5280, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 16.3, "ram_util_percent": 49.0}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.02, "episode_len_mean": 18.51, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.51, "policy1": -8.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1494945434891488, "mean_inference_ms": 1.3519312648450628, "mean_action_processing_ms": 0.09313815484705275, "mean_env_wait_ms": 0.15713096123142845, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18633, "timesteps_this_iter": 32, "agent_timesteps_total": 37266, "timers": {"learn_time_ms": 6.067, "learn_throughput": 5274.776, "update_time_ms": 3.586}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18633, "num_agent_steps_sampled": 37266, "num_steps_trained": 30528, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 61056, "last_target_update_ts": 18613, "num_target_updates": 156}, "done": false, "episodes_total": 1012, "training_iteration": 166, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-24", "timestamp": 1648816164, "time_this_iter_s": 0.33619260787963867, "time_total_s": 58.45366954803467, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82014d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82014d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208d40>"}, "time_since_restore": 58.45366954803467, "timesteps_since_restore": 5312, "iterations_since_restore": 166, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.62, "episode_len_mean": 18.51, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.31, "policy1": -8.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14949664653739847, "mean_inference_ms": 1.351926009185201, "mean_action_processing_ms": 0.09314033929501349, "mean_env_wait_ms": 0.15713686685940445, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18733, "timesteps_this_iter": 32, "agent_timesteps_total": 37466, "timers": {"learn_time_ms": 6.203, "learn_throughput": 5158.451, "update_time_ms": 3.547}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18733, "num_agent_steps_sampled": 37466, "num_steps_trained": 30688, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 61376, "last_target_update_ts": 18733, "num_target_updates": 157}, "done": false, "episodes_total": 1017, "training_iteration": 167, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-24", "timestamp": 1648816164, "time_this_iter_s": 0.29299187660217285, "time_total_s": 58.74666142463684, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff560>"}, "time_since_restore": 58.74666142463684, "timesteps_since_restore": 5344, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 16.9, "ram_util_percent": 49.0}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.14, "episode_len_mean": 18.57, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.57, "policy1": -8.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14950079633554803, "mean_inference_ms": 1.3519275169643024, "mean_action_processing_ms": 0.09314415306456979, "mean_env_wait_ms": 0.15714464239885426, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18850, "timesteps_this_iter": 32, "agent_timesteps_total": 37700, "timers": {"learn_time_ms": 6.176, "learn_throughput": 5181.732, "update_time_ms": 3.649}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18850, "num_agent_steps_sampled": 37700, "num_steps_trained": 30880, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 61760, "last_target_update_ts": 18850, "num_target_updates": 158}, "done": false, "episodes_total": 1023, "training_iteration": 168, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-25", "timestamp": 1648816165, "time_this_iter_s": 0.359389066696167, "time_total_s": 59.10605049133301, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201b90>"}, "time_since_restore": 59.10605049133301, "timesteps_since_restore": 5376, "iterations_since_restore": 168, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.24, "episode_len_mean": 18.32, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.12, "policy1": -8.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12], "policy_policy0_reward": [-10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14950855712041916, "mean_inference_ms": 1.3519272458364333, "mean_action_processing_ms": 0.09314778464487201, "mean_env_wait_ms": 0.15715272746610642, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18955, "timesteps_this_iter": 32, "agent_timesteps_total": 37910, "timers": {"learn_time_ms": 6.196, "learn_throughput": 5164.366, "update_time_ms": 3.824}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18955, "num_agent_steps_sampled": 37910, "num_steps_trained": 31104, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 62208, "last_target_update_ts": 18955, "num_target_updates": 159}, "done": false, "episodes_total": 1030, "training_iteration": 169, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-25", "timestamp": 1648816165, "time_this_iter_s": 0.35083961486816406, "time_total_s": 59.45689010620117, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201e60>"}, "time_since_restore": 59.45689010620117, "timesteps_since_restore": 5408, "iterations_since_restore": 169, "perf": {"cpu_util_percent": 17.8, "ram_util_percent": 49.0}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.14, "episode_len_mean": 18.17, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.57, "policy1": -7.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, 4.0, -20.0, -40.0, -20.0, 18.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0], "episode_lengths": [8, 18, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20], "policy_policy0_reward": [12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0], "policy_policy1_reward": [12.0, 2.0, -10.0, -20.0, -10.0, 9.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495164793744851, "mean_inference_ms": 1.3519206475303769, "mean_action_processing_ms": 0.09315009150961436, "mean_env_wait_ms": 0.15715681499466583, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19060, "timesteps_this_iter": 32, "agent_timesteps_total": 38120, "timers": {"learn_time_ms": 5.976, "learn_throughput": 5355.129, "update_time_ms": 3.658}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19060, "num_agent_steps_sampled": 38120, "num_steps_trained": 31296, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 62592, "last_target_update_ts": 19060, "num_target_updates": 160}, "done": false, "episodes_total": 1036, "training_iteration": 170, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-26", "timestamp": 1648816166, "time_this_iter_s": 0.32819318771362305, "time_total_s": 59.785083293914795, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82014d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232dd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82014d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232dd0>"}, "time_since_restore": 59.785083293914795, "timesteps_since_restore": 5440, "iterations_since_restore": 170, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.84, "episode_len_mean": 18.12, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.42, "policy1": -7.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.149524152448584, "mean_inference_ms": 1.3518980412379726, "mean_action_processing_ms": 0.09315027986227027, "mean_env_wait_ms": 0.15716031174944142, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19172, "timesteps_this_iter": 32, "agent_timesteps_total": 38344, "timers": {"learn_time_ms": 6.044, "learn_throughput": 5294.752, "update_time_ms": 3.72}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19172, "num_agent_steps_sampled": 38344, "num_steps_trained": 31520, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 63040, "last_target_update_ts": 19172, "num_target_updates": 161}, "done": false, "episodes_total": 1043, "training_iteration": 171, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-26", "timestamp": 1648816166, "time_this_iter_s": 0.3573892116546631, "time_total_s": 60.14247250556946, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215b90>"}, "time_since_restore": 60.14247250556946, "timesteps_since_restore": 5472, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 17.3, "ram_util_percent": 49.0}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.76, "episode_len_mean": 17.68, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.38, "policy1": -6.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14953588628365563, "mean_inference_ms": 1.3518190636338414, "mean_action_processing_ms": 0.09314715688195932, "mean_env_wait_ms": 0.15715640141063922, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19288, "timesteps_this_iter": 32, "agent_timesteps_total": 38576, "timers": {"learn_time_ms": 6.268, "learn_throughput": 5105.238, "update_time_ms": 3.778}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19288, "num_agent_steps_sampled": 38576, "num_steps_trained": 31776, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 63552, "last_target_update_ts": 19288, "num_target_updates": 162}, "done": false, "episodes_total": 1051, "training_iteration": 172, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-26", "timestamp": 1648816166, "time_this_iter_s": 0.3869941234588623, "time_total_s": 60.52946662902832, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215ef0>"}, "time_since_restore": 60.52946662902832, "timesteps_since_restore": 5504, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 18.0, "ram_util_percent": 49.0}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.64, "episode_len_mean": 17.62, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.32, "policy1": -6.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 0.0, 24.0, -20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 8, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 0.0, 12.0, -10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14954102146820422, "mean_inference_ms": 1.35173110564478, "mean_action_processing_ms": 0.09314213209271209, "mean_env_wait_ms": 0.15714917511946166, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19392, "timesteps_this_iter": 32, "agent_timesteps_total": 38784, "timers": {"learn_time_ms": 6.114, "learn_throughput": 5234.109, "update_time_ms": 3.75}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19392, "num_agent_steps_sampled": 38784, "num_steps_trained": 31968, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 63936, "last_target_update_ts": 19392, "num_target_updates": 163}, "done": false, "episodes_total": 1057, "training_iteration": 173, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-27", "timestamp": 1648816167, "time_this_iter_s": 0.32523512840270996, "time_total_s": 60.85470175743103, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215f80>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215f80>"}, "time_since_restore": 60.85470175743103, "timesteps_since_restore": 5536, "iterations_since_restore": 173, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.48, "episode_len_mean": 17.74, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.74, "policy1": -6.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495427696044554, "mean_inference_ms": 1.3516414505719907, "mean_action_processing_ms": 0.09313748489679387, "mean_env_wait_ms": 0.157142593119915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19492, "timesteps_this_iter": 32, "agent_timesteps_total": 38984, "timers": {"learn_time_ms": 6.16, "learn_throughput": 5195.049, "update_time_ms": 3.772}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19492, "num_agent_steps_sampled": 38984, "num_steps_trained": 32128, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64256, "last_target_update_ts": 19392, "num_target_updates": 163}, "done": false, "episodes_total": 1062, "training_iteration": 174, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-27", "timestamp": 1648816167, "time_this_iter_s": 0.30416440963745117, "time_total_s": 61.15886616706848, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82014d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82157a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82014d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82157a0>"}, "time_since_restore": 61.15886616706848, "timesteps_since_restore": 5568, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 17.1, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.94, "episode_len_mean": 17.67, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.47, "policy1": -6.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495439057627796, "mean_inference_ms": 1.3514883143729315, "mean_action_processing_ms": 0.09312875517017088, "mean_env_wait_ms": 0.1571296062250336, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19610, "timesteps_this_iter": 32, "agent_timesteps_total": 39220, "timers": {"learn_time_ms": 6.079, "learn_throughput": 5263.709, "update_time_ms": 3.585}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19610, "num_agent_steps_sampled": 39220, "num_steps_trained": 32352, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64704, "last_target_update_ts": 19610, "num_target_updates": 165}, "done": false, "episodes_total": 1069, "training_iteration": 175, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-27", "timestamp": 1648816167, "time_this_iter_s": 0.36962223052978516, "time_total_s": 61.52848839759827, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82ca290>"}, "time_since_restore": 61.52848839759827, "timesteps_since_restore": 5600, "iterations_since_restore": 175, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.66, "episode_len_mean": 17.53, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.33, "policy1": -6.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 16.0, -20.0, 4.0, -20.0, -40.0, 12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 12, 20, 18, 20, 20, 14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20], "policy_policy0_reward": [-10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, 8.0, -10.0, 2.0, -10.0, -20.0, 6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14954186516945403, "mean_inference_ms": 1.3513087849811416, "mean_action_processing_ms": 0.0931172920787022, "mean_env_wait_ms": 0.15711239002094832, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19716, "timesteps_this_iter": 32, "agent_timesteps_total": 39432, "timers": {"learn_time_ms": 6.043, "learn_throughput": 5295.817, "update_time_ms": 3.715}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19716, "num_agent_steps_sampled": 39432, "num_steps_trained": 32544, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 65088, "last_target_update_ts": 19716, "num_target_updates": 166}, "done": false, "episodes_total": 1075, "training_iteration": 176, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-28", "timestamp": 1648816168, "time_this_iter_s": 0.3391432762145996, "time_total_s": 61.867631673812866, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82157a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82157a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203b00>"}, "time_since_restore": 61.867631673812866, "timesteps_since_restore": 5632, "iterations_since_restore": 176, "perf": {"cpu_util_percent": 15.1, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.9, "episode_len_mean": 17.45, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -5.95, "policy1": -5.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, 16.0, -20.0, -40.0, -20.0, -20.0, 30.0, 4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0], "episode_lengths": [14, 12, 20, 20, 20, 20, 5, 18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12], "policy_policy0_reward": [6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0], "policy_policy1_reward": [6.0, 8.0, -10.0, -20.0, -10.0, -10.0, 15.0, 2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14953619257422812, "mean_inference_ms": 1.3510928598362424, "mean_action_processing_ms": 0.09310322399938874, "mean_env_wait_ms": 0.1570902301755815, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19818, "timesteps_this_iter": 32, "agent_timesteps_total": 39636, "timers": {"learn_time_ms": 6.052, "learn_throughput": 5287.16, "update_time_ms": 3.822}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19818, "num_agent_steps_sampled": 39636, "num_steps_trained": 32736, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 65472, "last_target_update_ts": 19818, "num_target_updates": 167}, "done": false, "episodes_total": 1081, "training_iteration": 177, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-28", "timestamp": 1648816168, "time_this_iter_s": 0.3193180561065674, "time_total_s": 62.186949729919434, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82033b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82033b0>"}, "time_since_restore": 62.186949729919434, "timesteps_since_restore": 5664, "iterations_since_restore": 177, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.12, "episode_len_mean": 17.46, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.06, "policy1": -6.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 8.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [18, 16, 19, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20], "policy_policy0_reward": [2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [2.0, 4.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14952771663193182, "mean_inference_ms": 1.3508281973623792, "mean_action_processing_ms": 0.09308413232909302, "mean_env_wait_ms": 0.15706090441810688, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19930, "timesteps_this_iter": 32, "agent_timesteps_total": 39860, "timers": {"learn_time_ms": 6.068, "learn_throughput": 5273.429, "update_time_ms": 3.634}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19930, "num_agent_steps_sampled": 39860, "num_steps_trained": 32960, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 65920, "last_target_update_ts": 19930, "num_target_updates": 168}, "done": false, "episodes_total": 1088, "training_iteration": 178, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-29", "timestamp": 1648816169, "time_this_iter_s": 0.35877442359924316, "time_total_s": 62.54572415351868, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82039e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82039e0>"}, "time_since_restore": 62.54572415351868, "timesteps_since_restore": 5696, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 16.6, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.46, "episode_len_mean": 17.53, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.73, "policy1": -6.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0], "episode_lengths": [13, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14951914292786112, "mean_inference_ms": 1.3506302996095787, "mean_action_processing_ms": 0.09307005056824175, "mean_env_wait_ms": 0.15703934762365215, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20030, "timesteps_this_iter": 32, "agent_timesteps_total": 40060, "timers": {"learn_time_ms": 6.049, "learn_throughput": 5289.931, "update_time_ms": 3.612}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20030, "num_agent_steps_sampled": 40060, "num_steps_trained": 33120, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 66240, "last_target_update_ts": 19930, "num_target_updates": 168}, "done": false, "episodes_total": 1093, "training_iteration": 179, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-29", "timestamp": 1648816169, "time_this_iter_s": 0.472243070602417, "time_total_s": 63.017967224121094, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82309e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82309e0>"}, "time_since_restore": 63.017967224121094, "timesteps_since_restore": 5728, "iterations_since_restore": 179, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.38, "episode_len_mean": 17.29, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.19, "policy1": -6.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0], "episode_lengths": [20, 20, 12, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20], "policy_policy0_reward": [-10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14951117883426723, "mean_inference_ms": 1.3503458066746734, "mean_action_processing_ms": 0.09305045486845966, "mean_env_wait_ms": 0.15700659953458918, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20139, "timesteps_this_iter": 32, "agent_timesteps_total": 40278, "timers": {"learn_time_ms": 6.064, "learn_throughput": 5276.933, "update_time_ms": 3.588}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20139, "num_agent_steps_sampled": 40278, "num_steps_trained": 33344, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 66688, "last_target_update_ts": 20040, "num_target_updates": 169}, "done": false, "episodes_total": 1100, "training_iteration": 180, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-29", "timestamp": 1648816169, "time_this_iter_s": 0.3509519100189209, "time_total_s": 63.368919134140015, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215440>"}, "time_since_restore": 63.368919134140015, "timesteps_since_restore": 5760, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 14.0, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.3, "episode_len_mean": 17.15, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -5.65, "policy1": -5.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0], "episode_lengths": [20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20], "policy_policy0_reward": [-10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495035310694773, "mean_inference_ms": 1.3500486064608292, "mean_action_processing_ms": 0.09303133202300334, "mean_env_wait_ms": 0.1569723895305772, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20257, "timesteps_this_iter": 32, "agent_timesteps_total": 40514, "timers": {"learn_time_ms": 6.163, "learn_throughput": 5192.396, "update_time_ms": 3.596}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20257, "num_agent_steps_sampled": 40514, "num_steps_trained": 33568, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 67136, "last_target_update_ts": 20257, "num_target_updates": 171}, "done": false, "episodes_total": 1107, "training_iteration": 181, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-30", "timestamp": 1648816170, "time_this_iter_s": 0.36916232109069824, "time_total_s": 63.73808145523071, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82124d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82124d0>"}, "time_since_restore": 63.73808145523071, "timesteps_since_restore": 5792, "iterations_since_restore": 181, "perf": {"cpu_util_percent": 18.1, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.16, "episode_len_mean": 17.18, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -5.58, "policy1": -5.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14949934707512638, "mean_inference_ms": 1.3498102488850372, "mean_action_processing_ms": 0.0930159899528514, "mean_env_wait_ms": 0.15694438462936702, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20371, "timesteps_this_iter": 32, "agent_timesteps_total": 40742, "timers": {"learn_time_ms": 6.406, "learn_throughput": 4995.189, "update_time_ms": 3.665}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20371, "num_agent_steps_sampled": 40742, "num_steps_trained": 33760, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 67520, "last_target_update_ts": 20371, "num_target_updates": 172}, "done": false, "episodes_total": 1113, "training_iteration": 182, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-30", "timestamp": 1648816170, "time_this_iter_s": 0.34841156005859375, "time_total_s": 64.0864930152893, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203ef0>"}, "time_since_restore": 64.0864930152893, "timesteps_since_restore": 5824, "iterations_since_restore": 182, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.22, "episode_len_mean": 17.11, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -5.61, "policy1": -5.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 6.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 17, 20, 20, 9, 20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, 3.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1494968346202319, "mean_inference_ms": 1.3495813845140796, "mean_action_processing_ms": 0.09300040498470859, "mean_env_wait_ms": 0.15691565270879984, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20484, "timesteps_this_iter": 32, "agent_timesteps_total": 40968, "timers": {"learn_time_ms": 6.387, "learn_throughput": 5010.517, "update_time_ms": 3.809}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20484, "num_agent_steps_sampled": 40968, "num_steps_trained": 33952, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 67904, "last_target_update_ts": 20484, "num_target_updates": 173}, "done": false, "episodes_total": 1119, "training_iteration": 183, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-31", "timestamp": 1648816171, "time_this_iter_s": 0.3505082130432129, "time_total_s": 64.43700122833252, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212710>"}, "time_since_restore": 64.43700122833252, "timesteps_since_restore": 5856, "iterations_since_restore": 183, "perf": {"cpu_util_percent": 15.0, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.18, "episode_len_mean": 17.09, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -5.59, "policy1": -5.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, 32.0, 16.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 4, 12, 20, 20, 20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, 16.0, 8.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14949898844558837, "mean_inference_ms": 1.3493684800593322, "mean_action_processing_ms": 0.0929867945897878, "mean_env_wait_ms": 0.15689241345589836, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20588, "timesteps_this_iter": 32, "agent_timesteps_total": 41176, "timers": {"learn_time_ms": 6.224, "learn_throughput": 5141.437, "update_time_ms": 4.06}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20588, "num_agent_steps_sampled": 41176, "num_steps_trained": 34144, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 68288, "last_target_update_ts": 20588, "num_target_updates": 174}, "done": false, "episodes_total": 1125, "training_iteration": 184, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-31", "timestamp": 1648816171, "time_this_iter_s": 0.34365177154541016, "time_total_s": 64.78065299987793, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82123b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82123b0>"}, "time_since_restore": 64.78065299987793, "timesteps_since_restore": 5888, "iterations_since_restore": 184, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -10.3, "episode_len_mean": 16.95, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -5.15, "policy1": -5.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 30.0, -20.0, 8.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0], "episode_lengths": [20, 20, 5, 20, 16, 8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11], "policy_policy0_reward": [-10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0], "policy_policy1_reward": [-10.0, -10.0, 15.0, -10.0, 4.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14950404259044195, "mean_inference_ms": 1.3491491258195005, "mean_action_processing_ms": 0.09297452019270974, "mean_env_wait_ms": 0.15686874066031334, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20690, "timesteps_this_iter": 32, "agent_timesteps_total": 41380, "timers": {"learn_time_ms": 6.51, "learn_throughput": 4915.338, "update_time_ms": 4.111}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20690, "num_agent_steps_sampled": 41380, "num_steps_trained": 34368, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 68736, "last_target_update_ts": 20690, "num_target_updates": 175}, "done": false, "episodes_total": 1132, "training_iteration": 185, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-31", "timestamp": 1648816171, "time_this_iter_s": 0.36340785026550293, "time_total_s": 65.14406085014343, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82128c0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82128c0>"}, "time_since_restore": 65.14406085014343, "timesteps_since_restore": 5920, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 16.2, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.48, "episode_len_mean": 17.14, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -5.74, "policy1": -5.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0], "episode_lengths": [8, 20, 8, 20, 20, 20, 20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20], "policy_policy0_reward": [12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14950901224732796, "mean_inference_ms": 1.3490163037047767, "mean_action_processing_ms": 0.09296898776838994, "mean_env_wait_ms": 0.15685797477327912, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20790, "timesteps_this_iter": 32, "agent_timesteps_total": 41580, "timers": {"learn_time_ms": 6.567, "learn_throughput": 4872.742, "update_time_ms": 4.239}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20790, "num_agent_steps_sampled": 41580, "num_steps_trained": 34528, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 69056, "last_target_update_ts": 20690, "num_target_updates": 175}, "done": false, "episodes_total": 1137, "training_iteration": 186, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-32", "timestamp": 1648816172, "time_this_iter_s": 0.32657313346862793, "time_total_s": 65.47063398361206, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203200>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203200>"}, "time_since_restore": 65.47063398361206, "timesteps_since_restore": 5952, "iterations_since_restore": 186, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.22, "episode_len_mean": 17.21, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -5.61, "policy1": -5.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 28.0, 22.0, 18.0, 20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0], "episode_lengths": [20, 20, 6, 9, 11, 10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, 14.0, 11.0, 9.0, 10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14951701595451508, "mean_inference_ms": 1.348881775192825, "mean_action_processing_ms": 0.09296489516449108, "mean_env_wait_ms": 0.15684733131120662, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20893, "timesteps_this_iter": 32, "agent_timesteps_total": 41786, "timers": {"learn_time_ms": 6.447, "learn_throughput": 4963.839, "update_time_ms": 4.213}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20893, "num_agent_steps_sampled": 41786, "num_steps_trained": 34720, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 69440, "last_target_update_ts": 20810, "num_target_updates": 176}, "done": false, "episodes_total": 1143, "training_iteration": 187, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-32", "timestamp": 1648816172, "time_this_iter_s": 0.3395805358886719, "time_total_s": 65.81021451950073, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8225440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212440>"}, "time_since_restore": 65.81021451950073, "timesteps_since_restore": 5984, "iterations_since_restore": 187, "perf": {"cpu_util_percent": 15.4, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.3, "episode_len_mean": 17.55, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.15, "policy1": -6.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -20.0, -20.0, -20.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [10, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [10.0, -10.0, -10.0, -10.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14952326933112006, "mean_inference_ms": 1.3488104854239418, "mean_action_processing_ms": 0.09296522957583556, "mean_env_wait_ms": 0.1568424077072551, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20993, "timesteps_this_iter": 32, "agent_timesteps_total": 41986, "timers": {"learn_time_ms": 6.454, "learn_throughput": 4958.191, "update_time_ms": 4.064}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20993, "num_agent_steps_sampled": 41986, "num_steps_trained": 34880, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 69760, "last_target_update_ts": 20913, "num_target_updates": 177}, "done": false, "episodes_total": 1148, "training_iteration": 188, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-32", "timestamp": 1648816172, "time_this_iter_s": 0.32625389099121094, "time_total_s": 66.13646841049194, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82014d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82014d0>"}, "time_since_restore": 66.13646841049194, "timesteps_since_restore": 6016, "iterations_since_restore": 188, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.42, "episode_len_mean": 17.81, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.71, "policy1": -6.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14952864225518564, "mean_inference_ms": 1.3487363181023337, "mean_action_processing_ms": 0.0929654554270611, "mean_env_wait_ms": 0.15683602163237953, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21093, "timesteps_this_iter": 32, "agent_timesteps_total": 42186, "timers": {"learn_time_ms": 6.304, "learn_throughput": 5075.949, "update_time_ms": 3.85}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21093, "num_agent_steps_sampled": 42186, "num_steps_trained": 35040, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 70080, "last_target_update_ts": 21033, "num_target_updates": 178}, "done": false, "episodes_total": 1153, "training_iteration": 189, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-33", "timestamp": 1648816173, "time_this_iter_s": 0.30084919929504395, "time_total_s": 66.43731760978699, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201e60>"}, "time_since_restore": 66.43731760978699, "timesteps_since_restore": 6048, "iterations_since_restore": 189, "perf": {"cpu_util_percent": 16.1, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.72, "episode_len_mean": 17.66, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.36, "policy1": -6.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, 20.0, -20.0, 20.0, -40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0], "episode_lengths": [20, 20, 20, 10, 20, 10, 20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8], "policy_policy0_reward": [-20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, 10.0, -10.0, 10.0, -20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14953657118436453, "mean_inference_ms": 1.3486639993122005, "mean_action_processing_ms": 0.09296660708692002, "mean_env_wait_ms": 0.15683002618355812, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21198, "timesteps_this_iter": 32, "agent_timesteps_total": 42396, "timers": {"learn_time_ms": 6.277, "learn_throughput": 5098.141, "update_time_ms": 3.735}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21198, "num_agent_steps_sampled": 42396, "num_steps_trained": 35232, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 70464, "last_target_update_ts": 21153, "num_target_updates": 179}, "done": false, "episodes_total": 1159, "training_iteration": 190, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-33", "timestamp": 1648816173, "time_this_iter_s": 0.3398873805999756, "time_total_s": 66.77720499038696, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212d40>"}, "time_since_restore": 66.77720499038696, "timesteps_since_restore": 6080, "iterations_since_restore": 190, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.98, "episode_len_mean": 17.79, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.49, "policy1": -6.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 4.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0], "episode_lengths": [20, 18, 20, 20, 20, 20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20], "policy_policy0_reward": [-20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 2.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14954272141471123, "mean_inference_ms": 1.3485893801012956, "mean_action_processing_ms": 0.09296624651019915, "mean_env_wait_ms": 0.15682186807368748, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21311, "timesteps_this_iter": 32, "agent_timesteps_total": 42622, "timers": {"learn_time_ms": 6.297, "learn_throughput": 5081.907, "update_time_ms": 3.823}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21311, "num_agent_steps_sampled": 42622, "num_steps_trained": 35424, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 70848, "last_target_update_ts": 21255, "num_target_updates": 180}, "done": false, "episodes_total": 1165, "training_iteration": 191, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-33", "timestamp": 1648816173, "time_this_iter_s": 0.3446664810180664, "time_total_s": 67.12187147140503, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82124d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82124d0>"}, "time_since_restore": 67.12187147140503, "timesteps_since_restore": 6112, "iterations_since_restore": 191, "perf": {"cpu_util_percent": 16.8, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.82, "episode_len_mean": 17.81, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.41, "policy1": -6.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 6, 20, 20, 20, 20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14954622017217786, "mean_inference_ms": 1.3485223889383031, "mean_action_processing_ms": 0.0929655126415368, "mean_env_wait_ms": 0.15681301230071598, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21411, "timesteps_this_iter": 32, "agent_timesteps_total": 42822, "timers": {"learn_time_ms": 6.292, "learn_throughput": 5085.854, "update_time_ms": 3.813}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21411, "num_agent_steps_sampled": 42822, "num_steps_trained": 35584, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 71168, "last_target_update_ts": 21371, "num_target_updates": 181}, "done": false, "episodes_total": 1170, "training_iteration": 192, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-34", "timestamp": 1648816174, "time_this_iter_s": 0.2960848808288574, "time_total_s": 67.41795635223389, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82033b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82033b0>"}, "time_since_restore": 67.41795635223389, "timesteps_since_restore": 6144, "iterations_since_restore": 192, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.1, "episode_len_mean": 17.95, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.55, "policy1": -6.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 10.0, -20.0, 4.0, 6.0, 16.0, -40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 15, 20, 18, 17, 12, 20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 5.0, -10.0, 2.0, 3.0, 8.0, -20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495479015989074, "mean_inference_ms": 1.3484416893602031, "mean_action_processing_ms": 0.09296293376976589, "mean_env_wait_ms": 0.15680159658019124, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21511, "timesteps_this_iter": 32, "agent_timesteps_total": 43022, "timers": {"learn_time_ms": 6.279, "learn_throughput": 5096.476, "update_time_ms": 3.852}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21511, "num_agent_steps_sampled": 43022, "num_steps_trained": 35744, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 71488, "last_target_update_ts": 21491, "num_target_updates": 182}, "done": false, "episodes_total": 1175, "training_iteration": 193, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-34", "timestamp": 1648816174, "time_this_iter_s": 0.2992665767669678, "time_total_s": 67.71722292900085, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cadd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cadd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203950>"}, "time_since_restore": 67.71722292900085, "timesteps_since_restore": 6176, "iterations_since_restore": 193, "perf": {"cpu_util_percent": 15.8, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.94, "episode_len_mean": 18.07, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.97, "policy1": -6.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 24.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 8, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20], "policy_policy0_reward": [-20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 12.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14954911170265206, "mean_inference_ms": 1.3483498995335361, "mean_action_processing_ms": 0.0929591441854108, "mean_env_wait_ms": 0.15678882961729287, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21625, "timesteps_this_iter": 32, "agent_timesteps_total": 43250, "timers": {"learn_time_ms": 6.158, "learn_throughput": 5196.236, "update_time_ms": 3.775}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21625, "num_agent_steps_sampled": 43250, "num_steps_trained": 35936, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 71872, "last_target_update_ts": 21605, "num_target_updates": 183}, "done": false, "episodes_total": 1181, "training_iteration": 194, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-34", "timestamp": 1648816174, "time_this_iter_s": 0.3423943519592285, "time_total_s": 68.05961728096008, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82014d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82014d0>"}, "time_since_restore": 68.05961728096008, "timesteps_since_restore": 6208, "iterations_since_restore": 194, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.1, "episode_len_mean": 18.35, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.55, "policy1": -7.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14954907621083213, "mean_inference_ms": 1.3482748677583658, "mean_action_processing_ms": 0.09295684511703282, "mean_env_wait_ms": 0.1567789614163631, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21725, "timesteps_this_iter": 32, "agent_timesteps_total": 43450, "timers": {"learn_time_ms": 6.137, "learn_throughput": 5214.485, "update_time_ms": 3.621}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21725, "num_agent_steps_sampled": 43450, "num_steps_trained": 36096, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 72192, "last_target_update_ts": 21725, "num_target_updates": 184}, "done": false, "episodes_total": 1186, "training_iteration": 195, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-35", "timestamp": 1648816175, "time_this_iter_s": 0.29449915885925293, "time_total_s": 68.35411643981934, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212d40>"}, "time_since_restore": 68.35411643981934, "timesteps_since_restore": 6240, "iterations_since_restore": 195, "perf": {"cpu_util_percent": 16.6, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.2, "episode_len_mean": 18.2, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.1, "policy1": -7.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 20.0, -20.0, 16.0, -40.0, -20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 10, 20, 12, 20, 20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20], "policy_policy0_reward": [-20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, 10.0, -10.0, 8.0, -20.0, -10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14954973399541716, "mean_inference_ms": 1.3481850363984467, "mean_action_processing_ms": 0.0929543571871949, "mean_env_wait_ms": 0.1567675656720459, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21830, "timesteps_this_iter": 32, "agent_timesteps_total": 43660, "timers": {"learn_time_ms": 6.193, "learn_throughput": 5167.05, "update_time_ms": 3.633}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21830, "num_agent_steps_sampled": 43660, "num_steps_trained": 36288, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 72576, "last_target_update_ts": 21830, "num_target_updates": 185}, "done": false, "episodes_total": 1192, "training_iteration": 196, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-35", "timestamp": 1648816175, "time_this_iter_s": 0.33086681365966797, "time_total_s": 68.684983253479, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203200>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203200>"}, "time_since_restore": 68.684983253479, "timesteps_since_restore": 6272, "iterations_since_restore": 196, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.56, "episode_len_mean": 18.38, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.28, "policy1": -7.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 26.0, -20.0, 28.0, -20.0, -20.0, -20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 7, 20, 6, 20, 20, 20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 13.0, -10.0, 14.0, -10.0, -10.0, -10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14954829332494046, "mean_inference_ms": 1.348123602413802, "mean_action_processing_ms": 0.09295284685731325, "mean_env_wait_ms": 0.15675997531789662, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21930, "timesteps_this_iter": 32, "agent_timesteps_total": 43860, "timers": {"learn_time_ms": 6.252, "learn_throughput": 5118.243, "update_time_ms": 3.7}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21930, "num_agent_steps_sampled": 43860, "num_steps_trained": 36448, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 72896, "last_target_update_ts": 21830, "num_target_updates": 185}, "done": false, "episodes_total": 1197, "training_iteration": 197, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-35", "timestamp": 1648816175, "time_this_iter_s": 0.2973167896270752, "time_total_s": 68.98230004310608, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cadd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215f80>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cadd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215f80>"}, "time_since_restore": 68.98230004310608, "timesteps_since_restore": 6304, "iterations_since_restore": 197, "perf": {"cpu_util_percent": 15.6, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.64, "episode_len_mean": 18.62, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.82, "policy1": -7.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 4.0, 12.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 18, 14, 20, 20, 20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, 2.0, 6.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14954334233612052, "mean_inference_ms": 1.3480424837414413, "mean_action_processing_ms": 0.0929497720702841, "mean_env_wait_ms": 0.156748304015165, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22047, "timesteps_this_iter": 32, "agent_timesteps_total": 44094, "timers": {"learn_time_ms": 6.216, "learn_throughput": 5147.688, "update_time_ms": 3.728}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22047, "num_agent_steps_sampled": 44094, "num_steps_trained": 36640, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 73280, "last_target_update_ts": 21947, "num_target_updates": 186}, "done": false, "episodes_total": 1203, "training_iteration": 198, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-36", "timestamp": 1648816176, "time_this_iter_s": 0.3438410758972168, "time_total_s": 69.3261411190033, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82014d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82014d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215290>"}, "time_since_restore": 69.3261411190033, "timesteps_since_restore": 6336, "iterations_since_restore": 198, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.4, "episode_len_mean": 18.7, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.2, "policy1": -8.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 10.0, -20.0, 2.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 15, 20, 19, 13, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 5.0, -10.0, 1.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14953720055688208, "mean_inference_ms": 1.3479721906609894, "mean_action_processing_ms": 0.092947020935888, "mean_env_wait_ms": 0.1567385973193373, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22147, "timesteps_this_iter": 32, "agent_timesteps_total": 44294, "timers": {"learn_time_ms": 6.103, "learn_throughput": 5243.187, "update_time_ms": 3.656}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22147, "num_agent_steps_sampled": 44294, "num_steps_trained": 36800, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 73600, "last_target_update_ts": 22067, "num_target_updates": 187}, "done": false, "episodes_total": 1208, "training_iteration": 199, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-36", "timestamp": 1648816176, "time_this_iter_s": 0.2922947406768799, "time_total_s": 69.61843585968018, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203200>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203200>"}, "time_since_restore": 69.61843585968018, "timesteps_since_restore": 6368, "iterations_since_restore": 199, "perf": {"cpu_util_percent": 16.9, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.06, "episode_len_mean": 18.73, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.53, "policy1": -8.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -40.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -20.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14952884840248287, "mean_inference_ms": 1.3478946620050964, "mean_action_processing_ms": 0.09294383166094698, "mean_env_wait_ms": 0.1567285319677558, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22257, "timesteps_this_iter": 32, "agent_timesteps_total": 44514, "timers": {"learn_time_ms": 6.238, "learn_throughput": 5129.922, "update_time_ms": 3.749}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22257, "num_agent_steps_sampled": 44514, "num_steps_trained": 36992, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 73984, "last_target_update_ts": 22177, "num_target_updates": 188}, "done": false, "episodes_total": 1214, "training_iteration": 200, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-37", "timestamp": 1648816177, "time_this_iter_s": 0.34254002571105957, "time_total_s": 69.96097588539124, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82033b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82033b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215290>"}, "time_since_restore": 69.96097588539124, "timesteps_since_restore": 6400, "iterations_since_restore": 200, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.66, "episode_len_mean": 18.73, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.33, "policy1": -8.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.0, -20.0, -20.0, -20.0, -20.0, -40.0, 10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [4, 20, 20, 20, 20, 20, 15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [16.0, -10.0, -10.0, -10.0, -10.0, -20.0, 5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495259046566519, "mean_inference_ms": 1.3478522632362964, "mean_action_processing_ms": 0.09294743457707648, "mean_env_wait_ms": 0.15672465131911373, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22357, "timesteps_this_iter": 32, "agent_timesteps_total": 44714, "timers": {"learn_time_ms": 6.232, "learn_throughput": 5134.808, "update_time_ms": 3.996}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22357, "num_agent_steps_sampled": 44714, "num_steps_trained": 37152, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 74304, "last_target_update_ts": 22297, "num_target_updates": 189}, "done": false, "episodes_total": 1219, "training_iteration": 201, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-37", "timestamp": 1648816177, "time_this_iter_s": 0.3215298652648926, "time_total_s": 70.28250575065613, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82039e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82150e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82039e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82150e0>"}, "time_since_restore": 70.28250575065613, "timesteps_since_restore": 6432, "iterations_since_restore": 201, "perf": {"cpu_util_percent": 16.9, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.84, "episode_len_mean": 18.72, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.42, "policy1": -8.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.0, 24.0, -20.0, -20.0, -20.0, 24.0, 18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0], "episode_lengths": [15, 8, 20, 20, 20, 8, 11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20], "policy_policy0_reward": [5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0], "policy_policy1_reward": [5.0, 12.0, -10.0, -10.0, -10.0, 12.0, 9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14951693118043705, "mean_inference_ms": 1.3477845170046043, "mean_action_processing_ms": 0.09294921091379486, "mean_env_wait_ms": 0.15671513709991633, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22460, "timesteps_this_iter": 32, "agent_timesteps_total": 44920, "timers": {"learn_time_ms": 6.082, "learn_throughput": 5261.047, "update_time_ms": 3.922}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22460, "num_agent_steps_sampled": 44920, "num_steps_trained": 37312, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 74624, "last_target_update_ts": 22417, "num_target_updates": 190}, "done": false, "episodes_total": 1225, "training_iteration": 202, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-37", "timestamp": 1648816177, "time_this_iter_s": 0.30995702743530273, "time_total_s": 70.59246277809143, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208d40>"}, "time_since_restore": 70.59246277809143, "timesteps_since_restore": 6464, "iterations_since_restore": 202, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.84, "episode_len_mean": 18.92, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.92, "policy1": -8.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0], "episode_lengths": [11, 20, 20, 20, 20, 20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20], "policy_policy0_reward": [9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [9.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14950589768113107, "mean_inference_ms": 1.347710741658728, "mean_action_processing_ms": 0.09294903841724425, "mean_env_wait_ms": 0.1567045893449051, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22571, "timesteps_this_iter": 32, "agent_timesteps_total": 45142, "timers": {"learn_time_ms": 6.279, "learn_throughput": 5096.514, "update_time_ms": 3.899}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22571, "num_agent_steps_sampled": 45142, "num_steps_trained": 37504, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 75008, "last_target_update_ts": 22531, "num_target_updates": 191}, "done": false, "episodes_total": 1231, "training_iteration": 203, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-38", "timestamp": 1648816178, "time_this_iter_s": 0.35369014739990234, "time_total_s": 70.94615292549133, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203950>"}, "time_since_restore": 70.94615292549133, "timesteps_since_restore": 6496, "iterations_since_restore": 203, "perf": {"cpu_util_percent": 14.9, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.82, "episode_len_mean": 19.01, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.91, "policy1": -8.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 22.0, 12.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 9, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 11.0, 6.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14949694469019403, "mean_inference_ms": 1.3476556029975908, "mean_action_processing_ms": 0.0929488067660175, "mean_env_wait_ms": 0.15669502995317963, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22671, "timesteps_this_iter": 32, "agent_timesteps_total": 45342, "timers": {"learn_time_ms": 6.467, "learn_throughput": 4948.21, "update_time_ms": 3.938}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22671, "num_agent_steps_sampled": 45342, "num_steps_trained": 37664, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 75328, "last_target_update_ts": 22651, "num_target_updates": 192}, "done": false, "episodes_total": 1236, "training_iteration": 204, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-38", "timestamp": 1648816178, "time_this_iter_s": 0.31879186630249023, "time_total_s": 71.26494479179382, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212320>"}, "time_since_restore": 71.26494479179382, "timesteps_since_restore": 6528, "iterations_since_restore": 204, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.76, "episode_len_mean": 19.18, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.38, "policy1": -9.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14948640971001492, "mean_inference_ms": 1.3475978201397596, "mean_action_processing_ms": 0.09294809939745009, "mean_env_wait_ms": 0.15668371743865575, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22771, "timesteps_this_iter": 32, "agent_timesteps_total": 45542, "timers": {"learn_time_ms": 6.616, "learn_throughput": 4836.849, "update_time_ms": 3.93}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22771, "num_agent_steps_sampled": 45542, "num_steps_trained": 37824, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 75648, "last_target_update_ts": 22771, "num_target_updates": 193}, "done": false, "episodes_total": 1241, "training_iteration": 205, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-38", "timestamp": 1648816178, "time_this_iter_s": 0.3111710548400879, "time_total_s": 71.57611584663391, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff050>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff050>"}, "time_since_restore": 71.57611584663391, "timesteps_since_restore": 6560, "iterations_since_restore": 205, "perf": {"cpu_util_percent": 15.3, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.86, "episode_len_mean": 19.13, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.43, "policy1": -9.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14947435934050965, "mean_inference_ms": 1.347521434824452, "mean_action_processing_ms": 0.09294544917524039, "mean_env_wait_ms": 0.15666786268325558, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22886, "timesteps_this_iter": 32, "agent_timesteps_total": 45772, "timers": {"learn_time_ms": 6.487, "learn_throughput": 4932.934, "update_time_ms": 3.926}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22886, "num_agent_steps_sampled": 45772, "num_steps_trained": 38016, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 76032, "last_target_update_ts": 22886, "num_target_updates": 194}, "done": false, "episodes_total": 1247, "training_iteration": 206, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-39", "timestamp": 1648816179, "time_this_iter_s": 0.3635127544403076, "time_total_s": 71.93962860107422, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffa70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffa70>"}, "time_since_restore": 71.93962860107422, "timesteps_since_restore": 6592, "iterations_since_restore": 206, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.26, "episode_len_mean": 19.13, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.63, "policy1": -9.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -20.0, 6.0, 24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 17, 8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, 3.0, 12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14946477322344076, "mean_inference_ms": 1.3474600129472043, "mean_action_processing_ms": 0.09294247002416814, "mean_env_wait_ms": 0.1566557050763859, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22986, "timesteps_this_iter": 32, "agent_timesteps_total": 45972, "timers": {"learn_time_ms": 6.201, "learn_throughput": 5160.315, "update_time_ms": 3.914}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22986, "num_agent_steps_sampled": 45972, "num_steps_trained": 38176, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 76352, "last_target_update_ts": 22886, "num_target_updates": 194}, "done": false, "episodes_total": 1252, "training_iteration": 207, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-39", "timestamp": 1648816179, "time_this_iter_s": 0.31012797355651855, "time_total_s": 72.24975657463074, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffcb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffcb0>"}, "time_since_restore": 72.24975657463074, "timesteps_since_restore": 6624, "iterations_since_restore": 207, "perf": {"cpu_util_percent": 15.2, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.24, "episode_len_mean": 19.02, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.62, "policy1": -9.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, -40.0, -20.0, 6.0, 8.0, -20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0], "episode_lengths": [8, 20, 20, 17, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20], "policy_policy0_reward": [12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [12.0, -20.0, -10.0, 3.0, 4.0, -10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1494613051995248, "mean_inference_ms": 1.3474638490108413, "mean_action_processing_ms": 0.0929446626626923, "mean_env_wait_ms": 0.15665139775000309, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23092, "timesteps_this_iter": 32, "agent_timesteps_total": 46184, "timers": {"learn_time_ms": 6.544, "learn_throughput": 4889.802, "update_time_ms": 4.131}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23092, "num_agent_steps_sampled": 46184, "num_steps_trained": 38368, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 76736, "last_target_update_ts": 23006, "num_target_updates": 195}, "done": false, "episodes_total": 1258, "training_iteration": 208, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-39", "timestamp": 1648816179, "time_this_iter_s": 0.39081335067749023, "time_total_s": 72.64056992530823, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232b90>"}, "time_since_restore": 72.64056992530823, "timesteps_since_restore": 6656, "iterations_since_restore": 208, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.42, "episode_len_mean": 19.21, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -10.21, "policy1": -10.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 0.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 0.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14946304705364313, "mean_inference_ms": 1.3475019322594048, "mean_action_processing_ms": 0.09294976971291323, "mean_env_wait_ms": 0.15665189636165233, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23192, "timesteps_this_iter": 32, "agent_timesteps_total": 46384, "timers": {"learn_time_ms": 6.976, "learn_throughput": 4586.868, "update_time_ms": 4.022}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23192, "num_agent_steps_sampled": 46384, "num_steps_trained": 38528, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 77056, "last_target_update_ts": 23112, "num_target_updates": 196}, "done": false, "episodes_total": 1263, "training_iteration": 209, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-40", "timestamp": 1648816180, "time_this_iter_s": 0.3287231922149658, "time_total_s": 72.9692931175232, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffa70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffa70>"}, "time_since_restore": 72.9692931175232, "timesteps_since_restore": 6688, "iterations_since_restore": 209, "perf": {"cpu_util_percent": 15.6, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.16, "episode_len_mean": 19.08, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -10.08, "policy1": -10.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14946834282293284, "mean_inference_ms": 1.3475751085567247, "mean_action_processing_ms": 0.0929577690215886, "mean_env_wait_ms": 0.15665629569073755, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23299, "timesteps_this_iter": 32, "agent_timesteps_total": 46598, "timers": {"learn_time_ms": 6.776, "learn_throughput": 4722.435, "update_time_ms": 3.913}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23299, "num_agent_steps_sampled": 46598, "num_steps_trained": 38720, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 77440, "last_target_update_ts": 23232, "num_target_updates": 197}, "done": false, "episodes_total": 1269, "training_iteration": 210, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-40", "timestamp": 1648816180, "time_this_iter_s": 0.35234498977661133, "time_total_s": 73.3216381072998, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208e60>"}, "time_since_restore": 73.3216381072998, "timesteps_since_restore": 6720, "iterations_since_restore": 210, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.16, "episode_len_mean": 19.08, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -10.08, "policy1": -10.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14947475574619967, "mean_inference_ms": 1.3476517207963072, "mean_action_processing_ms": 0.0929667129370875, "mean_env_wait_ms": 0.15666365945712843, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23399, "timesteps_this_iter": 32, "agent_timesteps_total": 46798, "timers": {"learn_time_ms": 6.561, "learn_throughput": 4877.027, "update_time_ms": 3.903}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23399, "num_agent_steps_sampled": 46798, "num_steps_trained": 38880, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 77760, "last_target_update_ts": 23339, "num_target_updates": 198}, "done": false, "episodes_total": 1274, "training_iteration": 211, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-41", "timestamp": 1648816181, "time_this_iter_s": 0.3069906234741211, "time_total_s": 73.62862873077393, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82309e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82309e0>"}, "time_since_restore": 73.62862873077393, "timesteps_since_restore": 6752, "iterations_since_restore": 211, "perf": {"cpu_util_percent": 18.3, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.86, "episode_len_mean": 19.03, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.93, "policy1": -9.93}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14948968064232368, "mean_inference_ms": 1.3477968472185409, "mean_action_processing_ms": 0.09298281743942224, "mean_env_wait_ms": 0.1566818701447889, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23508, "timesteps_this_iter": 32, "agent_timesteps_total": 47016, "timers": {"learn_time_ms": 6.55, "learn_throughput": 4885.548, "update_time_ms": 4.068}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23508, "num_agent_steps_sampled": 47016, "num_steps_trained": 39072, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 78144, "last_target_update_ts": 23448, "num_target_updates": 199}, "done": false, "episodes_total": 1280, "training_iteration": 212, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-41", "timestamp": 1648816181, "time_this_iter_s": 0.37622499465942383, "time_total_s": 74.00485372543335, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215f80>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215f80>"}, "time_since_restore": 74.00485372543335, "timesteps_since_restore": 6784, "iterations_since_restore": 212, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.66, "episode_len_mean": 19.03, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.83, "policy1": -9.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 16.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 12, 13, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, 8.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14950433738311414, "mean_inference_ms": 1.3479521677596429, "mean_action_processing_ms": 0.09299896779764222, "mean_env_wait_ms": 0.15670170401762676, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23608, "timesteps_this_iter": 32, "agent_timesteps_total": 47216, "timers": {"learn_time_ms": 6.852, "learn_throughput": 4670.295, "update_time_ms": 4.092}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23608, "num_agent_steps_sampled": 47216, "num_steps_trained": 39232, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 78464, "last_target_update_ts": 23568, "num_target_updates": 200}, "done": false, "episodes_total": 1285, "training_iteration": 213, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-41", "timestamp": 1648816181, "time_this_iter_s": 0.3239150047302246, "time_total_s": 74.32876873016357, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215560>"}, "time_since_restore": 74.32876873016357, "timesteps_since_restore": 6816, "iterations_since_restore": 213, "perf": {"cpu_util_percent": 18.9, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.56, "episode_len_mean": 19.18, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -10.28, "policy1": -10.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1495190748421204, "mean_inference_ms": 1.348118857269481, "mean_action_processing_ms": 0.09301520691476753, "mean_env_wait_ms": 0.15672233292935583, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23708, "timesteps_this_iter": 32, "agent_timesteps_total": 47416, "timers": {"learn_time_ms": 6.493, "learn_throughput": 4928.387, "update_time_ms": 4.143}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23708, "num_agent_steps_sampled": 47416, "num_steps_trained": 39392, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 78784, "last_target_update_ts": 23688, "num_target_updates": 201}, "done": false, "episodes_total": 1290, "training_iteration": 214, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-42", "timestamp": 1648816182, "time_this_iter_s": 0.30769944190979004, "time_total_s": 74.63646817207336, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82153b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82153b0>"}, "time_since_restore": 74.63646817207336, "timesteps_since_restore": 6848, "iterations_since_restore": 214, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.04, "episode_len_mean": 19.12, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -10.02, "policy1": -10.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 6.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20], "policy_policy0_reward": [-10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 3.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14953797219812073, "mean_inference_ms": 1.3483166434542073, "mean_action_processing_ms": 0.09303451709756519, "mean_env_wait_ms": 0.15674727838291827, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23822, "timesteps_this_iter": 32, "agent_timesteps_total": 47644, "timers": {"learn_time_ms": 6.144, "learn_throughput": 5207.93, "update_time_ms": 4.326}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23822, "num_agent_steps_sampled": 47644, "num_steps_trained": 39584, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 79168, "last_target_update_ts": 23802, "num_target_updates": 202}, "done": false, "episodes_total": 1296, "training_iteration": 215, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-42", "timestamp": 1648816182, "time_this_iter_s": 0.34931492805480957, "time_total_s": 74.98578310012817, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82157a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82157a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201e60>"}, "time_since_restore": 74.98578310012817, "timesteps_since_restore": 6880, "iterations_since_restore": 215, "perf": {"cpu_util_percent": 15.9, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.76, "episode_len_mean": 19.08, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.88, "policy1": -9.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14955848627197343, "mean_inference_ms": 1.348523252888242, "mean_action_processing_ms": 0.09305484945377401, "mean_env_wait_ms": 0.15677397788405145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23935, "timesteps_this_iter": 32, "agent_timesteps_total": 47870, "timers": {"learn_time_ms": 6.151, "learn_throughput": 5202.802, "update_time_ms": 4.033}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23935, "num_agent_steps_sampled": 47870, "num_steps_trained": 39776, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 79552, "last_target_update_ts": 23915, "num_target_updates": 203}, "done": false, "episodes_total": 1302, "training_iteration": 216, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-42", "timestamp": 1648816182, "time_this_iter_s": 0.3510630130767822, "time_total_s": 75.33684611320496, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82154d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82cadd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82154d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82cadd0>"}, "time_since_restore": 75.33684611320496, "timesteps_since_restore": 6912, "iterations_since_restore": 216, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.32, "episode_len_mean": 18.96, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.66, "policy1": -9.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0], "episode_lengths": [10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20], "policy_policy0_reward": [10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14958105631603036, "mean_inference_ms": 1.3487304220412648, "mean_action_processing_ms": 0.09307492590183497, "mean_env_wait_ms": 0.1568009639958676, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24043, "timesteps_this_iter": 32, "agent_timesteps_total": 48086, "timers": {"learn_time_ms": 6.079, "learn_throughput": 5263.956, "update_time_ms": 3.75}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24043, "num_agent_steps_sampled": 48086, "num_steps_trained": 39968, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 79936, "last_target_update_ts": 24023, "num_target_updates": 204}, "done": false, "episodes_total": 1308, "training_iteration": 217, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-43", "timestamp": 1648816183, "time_this_iter_s": 0.32909131050109863, "time_total_s": 75.66593742370605, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffdd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffdd0>"}, "time_since_restore": 75.66593742370605, "timesteps_since_restore": 6944, "iterations_since_restore": 217, "perf": {"cpu_util_percent": 16.2, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.32, "episode_len_mean": 18.76, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.66, "policy1": -9.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1496136497411788, "mean_inference_ms": 1.3490219491848148, "mean_action_processing_ms": 0.0931022439425349, "mean_env_wait_ms": 0.15684011601070794, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24153, "timesteps_this_iter": 32, "agent_timesteps_total": 48306, "timers": {"learn_time_ms": 6.524, "learn_throughput": 4904.991, "update_time_ms": 3.762}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24153, "num_agent_steps_sampled": 48306, "num_steps_trained": 40192, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 80384, "last_target_update_ts": 24127, "num_target_updates": 205}, "done": false, "episodes_total": 1315, "training_iteration": 218, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-43", "timestamp": 1648816183, "time_this_iter_s": 0.3938941955566406, "time_total_s": 76.0598316192627, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82035f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82035f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203710>"}, "time_since_restore": 76.0598316192627, "timesteps_since_restore": 6976, "iterations_since_restore": 218, "perf": {"cpu_util_percent": 16.4, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.52, "episode_len_mean": 18.56, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.26, "policy1": -9.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 34.0, -40.0, -20.0, 6.0, 12.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0], "episode_lengths": [20, 3, 20, 20, 17, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20], "policy_policy0_reward": [-10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0], "policy_policy1_reward": [-10.0, 17.0, -20.0, -10.0, 3.0, 6.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1496390302657599, "mean_inference_ms": 1.3492616396467954, "mean_action_processing_ms": 0.09312090321162682, "mean_env_wait_ms": 0.15687270140909795, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24253, "timesteps_this_iter": 32, "agent_timesteps_total": 48506, "timers": {"learn_time_ms": 6.551, "learn_throughput": 4884.446, "update_time_ms": 3.862}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24253, "num_agent_steps_sampled": 48506, "num_steps_trained": 40384, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 80768, "last_target_update_ts": 24233, "num_target_updates": 206}, "done": false, "episodes_total": 1321, "training_iteration": 219, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-44", "timestamp": 1648816184, "time_this_iter_s": 0.33130455017089844, "time_total_s": 76.3911361694336, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8046050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82157a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8046050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82157a0>"}, "time_since_restore": 76.3911361694336, "timesteps_since_restore": 7008, "iterations_since_restore": 219, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.68, "episode_len_mean": 18.54, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.34, "policy1": -9.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14966935139652718, "mean_inference_ms": 1.3495440427854044, "mean_action_processing_ms": 0.09314304297545896, "mean_env_wait_ms": 0.15691026984793688, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24365, "timesteps_this_iter": 32, "agent_timesteps_total": 48730, "timers": {"learn_time_ms": 6.307, "learn_throughput": 5073.838, "update_time_ms": 3.935}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24365, "num_agent_steps_sampled": 48730, "num_steps_trained": 40608, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 81216, "last_target_update_ts": 24345, "num_target_updates": 207}, "done": false, "episodes_total": 1328, "training_iteration": 220, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-44", "timestamp": 1648816184, "time_this_iter_s": 0.3681182861328125, "time_total_s": 76.7592544555664, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82155f0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82155f0>"}, "time_since_restore": 76.7592544555664, "timesteps_since_restore": 7040, "iterations_since_restore": 220, "perf": {"cpu_util_percent": 15.0, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.0, "episode_len_mean": 18.5, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.0, "policy1": -9.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14969171092458203, "mean_inference_ms": 1.3497510993163848, "mean_action_processing_ms": 0.09315977171775217, "mean_env_wait_ms": 0.1569379714615426, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24481, "timesteps_this_iter": 32, "agent_timesteps_total": 48962, "timers": {"learn_time_ms": 6.102, "learn_throughput": 5244.191, "update_time_ms": 3.713}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24481, "num_agent_steps_sampled": 48962, "num_steps_trained": 40800, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 81600, "last_target_update_ts": 24461, "num_target_updates": 208}, "done": false, "episodes_total": 1334, "training_iteration": 221, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-44", "timestamp": 1648816184, "time_this_iter_s": 0.34337544441223145, "time_total_s": 77.10262989997864, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8201e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ff950>"}, "time_since_restore": 77.10262989997864, "timesteps_since_restore": 7072, "iterations_since_restore": 221, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.78, "episode_len_mean": 18.49, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.89, "policy1": -8.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1497114499021487, "mean_inference_ms": 1.3499286040852458, "mean_action_processing_ms": 0.0931738291316432, "mean_env_wait_ms": 0.15696288632151073, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24600, "timesteps_this_iter": 32, "agent_timesteps_total": 49200, "timers": {"learn_time_ms": 6.054, "learn_throughput": 5285.328, "update_time_ms": 3.62}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24600, "num_agent_steps_sampled": 49200, "num_steps_trained": 40992, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 81984, "last_target_update_ts": 24580, "num_target_updates": 209}, "done": false, "episodes_total": 1340, "training_iteration": 222, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-45", "timestamp": 1648816185, "time_this_iter_s": 0.3528287410736084, "time_total_s": 77.45545864105225, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81fff80>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81fff80>"}, "time_since_restore": 77.45545864105225, "timesteps_since_restore": 7104, "iterations_since_restore": 222, "perf": {"cpu_util_percent": 16.4, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.0, "episode_len_mean": 18.4, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.0, "policy1": -9.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1497278824636335, "mean_inference_ms": 1.3500793587435675, "mean_action_processing_ms": 0.09318580724025673, "mean_env_wait_ms": 0.15698551458563614, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24706, "timesteps_this_iter": 32, "agent_timesteps_total": 49412, "timers": {"learn_time_ms": 5.997, "learn_throughput": 5335.883, "update_time_ms": 3.614}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24706, "num_agent_steps_sampled": 49412, "num_steps_trained": 41184, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 82368, "last_target_update_ts": 24686, "num_target_updates": 210}, "done": false, "episodes_total": 1346, "training_iteration": 223, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-45", "timestamp": 1648816185, "time_this_iter_s": 0.325237512588501, "time_total_s": 77.78069615364075, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215200>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215200>"}, "time_since_restore": 77.78069615364075, "timesteps_since_restore": 7136, "iterations_since_restore": 223, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.6, "episode_len_mean": 18.4, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.8, "policy1": -8.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14973940964372656, "mean_inference_ms": 1.3501864939974533, "mean_action_processing_ms": 0.09319474406234858, "mean_env_wait_ms": 0.1570022999616119, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24806, "timesteps_this_iter": 32, "agent_timesteps_total": 49612, "timers": {"learn_time_ms": 5.997, "learn_throughput": 5336.434, "update_time_ms": 3.598}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24806, "num_agent_steps_sampled": 49612, "num_steps_trained": 41344, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 82688, "last_target_update_ts": 24806, "num_target_updates": 211}, "done": false, "episodes_total": 1351, "training_iteration": 224, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-45", "timestamp": 1648816185, "time_this_iter_s": 0.29107165336608887, "time_total_s": 78.07176780700684, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203710>"}, "time_since_restore": 78.07176780700684, "timesteps_since_restore": 7168, "iterations_since_restore": 224, "perf": {"cpu_util_percent": 16.0, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.34, "episode_len_mean": 18.47, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.67, "policy1": -8.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14974593141241535, "mean_inference_ms": 1.3502285744639273, "mean_action_processing_ms": 0.0931994321934786, "mean_env_wait_ms": 0.15701086619358828, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24919, "timesteps_this_iter": 32, "agent_timesteps_total": 49838, "timers": {"learn_time_ms": 6.087, "learn_throughput": 5256.926, "update_time_ms": 3.71}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24919, "num_agent_steps_sampled": 49838, "num_steps_trained": 41536, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 83072, "last_target_update_ts": 24919, "num_target_updates": 212}, "done": false, "episodes_total": 1357, "training_iteration": 225, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-46", "timestamp": 1648816186, "time_this_iter_s": 0.34092235565185547, "time_total_s": 78.41269016265869, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82309e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82309e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203950>"}, "time_since_restore": 78.41269016265869, "timesteps_since_restore": 7200, "iterations_since_restore": 225, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.94, "episode_len_mean": 18.47, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.47, "policy1": -8.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, 26.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, 13.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14974649867641293, "mean_inference_ms": 1.350218358666624, "mean_action_processing_ms": 0.09319947535171855, "mean_env_wait_ms": 0.15701257653704143, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25019, "timesteps_this_iter": 32, "agent_timesteps_total": 50038, "timers": {"learn_time_ms": 6.138, "learn_throughput": 5213.23, "update_time_ms": 3.733}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25019, "num_agent_steps_sampled": 50038, "num_steps_trained": 41696, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 83392, "last_target_update_ts": 24919, "num_target_updates": 212}, "done": false, "episodes_total": 1362, "training_iteration": 226, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-46", "timestamp": 1648816186, "time_this_iter_s": 0.2921764850616455, "time_total_s": 78.70486664772034, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffdd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffdd0>"}, "time_since_restore": 78.70486664772034, "timesteps_since_restore": 7232, "iterations_since_restore": 226, "perf": {"cpu_util_percent": 15.9, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.16, "episode_len_mean": 18.48, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.58, "policy1": -8.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 13, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1497435311335581, "mean_inference_ms": 1.350173649165818, "mean_action_processing_ms": 0.09319752890288317, "mean_env_wait_ms": 0.15701123093977676, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25127, "timesteps_this_iter": 32, "agent_timesteps_total": 50254, "timers": {"learn_time_ms": 6.061, "learn_throughput": 5280.026, "update_time_ms": 3.598}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25127, "num_agent_steps_sampled": 50254, "num_steps_trained": 41888, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 83776, "last_target_update_ts": 25027, "num_target_updates": 213}, "done": false, "episodes_total": 1368, "training_iteration": 227, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-46", "timestamp": 1648816186, "time_this_iter_s": 0.32701873779296875, "time_total_s": 79.0318853855133, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8046050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8046050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203710>"}, "time_since_restore": 79.0318853855133, "timesteps_since_restore": 7264, "iterations_since_restore": 227, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.42, "episode_len_mean": 18.21, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.21, "policy1": -8.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0], "episode_lengths": [16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19], "policy_policy0_reward": [4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0], "policy_policy1_reward": [4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14975220108428064, "mean_inference_ms": 1.3502266645674859, "mean_action_processing_ms": 0.09320367107019858, "mean_env_wait_ms": 0.15702237100108368, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25233, "timesteps_this_iter": 32, "agent_timesteps_total": 50466, "timers": {"learn_time_ms": 6.895, "learn_throughput": 4641.0, "update_time_ms": 3.992}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25233, "num_agent_steps_sampled": 50466, "num_steps_trained": 42080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 84160, "last_target_update_ts": 25147, "num_target_updates": 214}, "done": false, "episodes_total": 1375, "training_iteration": 228, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-47", "timestamp": 1648816187, "time_this_iter_s": 0.41592955589294434, "time_total_s": 79.44781494140625, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffcb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffcb0>"}, "time_since_restore": 79.44781494140625, "timesteps_since_restore": 7296, "iterations_since_restore": 228, "perf": {"cpu_util_percent": 17.1, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.68, "episode_len_mean": 18.14, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.34, "policy1": -8.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14975553164797134, "mean_inference_ms": 1.3502372569655663, "mean_action_processing_ms": 0.09320598519718862, "mean_env_wait_ms": 0.15702570136834068, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25342, "timesteps_this_iter": 32, "agent_timesteps_total": 50684, "timers": {"learn_time_ms": 6.65, "learn_throughput": 4811.879, "update_time_ms": 3.882}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25342, "num_agent_steps_sampled": 50684, "num_steps_trained": 42272, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 84544, "last_target_update_ts": 25253, "num_target_updates": 215}, "done": false, "episodes_total": 1381, "training_iteration": 229, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-47", "timestamp": 1648816187, "time_this_iter_s": 0.3435800075531006, "time_total_s": 79.79139494895935, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201e60>"}, "time_since_restore": 79.79139494895935, "timesteps_since_restore": 7328, "iterations_since_restore": 229, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.56, "episode_len_mean": 18.08, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.28, "policy1": -8.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14975619527177952, "mean_inference_ms": 1.3502090206520623, "mean_action_processing_ms": 0.09320479103374633, "mean_env_wait_ms": 0.15702400408694112, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25456, "timesteps_this_iter": 32, "agent_timesteps_total": 50912, "timers": {"learn_time_ms": 6.24, "learn_throughput": 5128.471, "update_time_ms": 3.722}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25456, "num_agent_steps_sampled": 50912, "num_steps_trained": 42464, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 84928, "last_target_update_ts": 25362, "num_target_updates": 216}, "done": false, "episodes_total": 1387, "training_iteration": 230, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-48", "timestamp": 1648816188, "time_this_iter_s": 0.34398746490478516, "time_total_s": 80.13538241386414, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8208e60>"}, "time_since_restore": 80.13538241386414, "timesteps_since_restore": 7360, "iterations_since_restore": 230, "perf": {"cpu_util_percent": 17.3, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.26, "episode_len_mean": 17.83, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.63, "policy1": -7.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0], "episode_lengths": [20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14975887862931414, "mean_inference_ms": 1.350173987131172, "mean_action_processing_ms": 0.09320405326353541, "mean_env_wait_ms": 0.15702241099487346, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25565, "timesteps_this_iter": 32, "agent_timesteps_total": 51130, "timers": {"learn_time_ms": 6.191, "learn_throughput": 5168.741, "update_time_ms": 3.811}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25565, "num_agent_steps_sampled": 51130, "num_steps_trained": 42688, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 85376, "last_target_update_ts": 25468, "num_target_updates": 217}, "done": false, "episodes_total": 1394, "training_iteration": 231, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-48", "timestamp": 1648816188, "time_this_iter_s": 0.3566155433654785, "time_total_s": 80.49199795722961, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8046050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82309e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8046050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82309e0>"}, "time_since_restore": 80.49199795722961, "timesteps_since_restore": 7392, "iterations_since_restore": 231, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.04, "episode_len_mean": 17.82, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.52, "policy1": -7.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0], "episode_lengths": [20, 20, 20, 20, 8, 20, 20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14976313654865195, "mean_inference_ms": 1.3501670547130846, "mean_action_processing_ms": 0.09320522501011762, "mean_env_wait_ms": 0.15702445434417917, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25677, "timesteps_this_iter": 32, "agent_timesteps_total": 51354, "timers": {"learn_time_ms": 6.123, "learn_throughput": 5225.835, "update_time_ms": 3.833}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25677, "num_agent_steps_sampled": 51354, "num_steps_trained": 42880, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 85760, "last_target_update_ts": 25585, "num_target_updates": 218}, "done": false, "episodes_total": 1400, "training_iteration": 232, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-48", "timestamp": 1648816188, "time_this_iter_s": 0.3558766841888428, "time_total_s": 80.84787464141846, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82150e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffcb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82150e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffcb0>"}, "time_since_restore": 80.84787464141846, "timesteps_since_restore": 7424, "iterations_since_restore": 232, "perf": {"cpu_util_percent": 14.7, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.96, "episode_len_mean": 17.88, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.48, "policy1": -7.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0], "episode_lengths": [20, 20, 20, 4, 20, 20, 20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14976954759832478, "mean_inference_ms": 1.350189541084045, "mean_action_processing_ms": 0.0932088022719401, "mean_env_wait_ms": 0.1570307229867371, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25791, "timesteps_this_iter": 32, "agent_timesteps_total": 51582, "timers": {"learn_time_ms": 6.311, "learn_throughput": 5070.598, "update_time_ms": 3.853}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25791, "num_agent_steps_sampled": 51582, "num_steps_trained": 43072, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 86144, "last_target_update_ts": 25697, "num_target_updates": 219}, "done": false, "episodes_total": 1406, "training_iteration": 233, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-49", "timestamp": 1648816189, "time_this_iter_s": 0.3662142753601074, "time_total_s": 81.21408891677856, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8201e60>"}, "time_since_restore": 81.21408891677856, "timesteps_since_restore": 7456, "iterations_since_restore": 233, "perf": {"cpu_util_percent": 17.1, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.7, "episode_len_mean": 17.95, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.35, "policy1": -7.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 28.0, -40.0, 12.0, -20.0, -20.0, -20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 6, 20, 14, 20, 20, 20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, 14.0, -20.0, 6.0, -10.0, -10.0, -10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14977549739975451, "mean_inference_ms": 1.3502148062530113, "mean_action_processing_ms": 0.093212150798432, "mean_env_wait_ms": 0.15703596722262522, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25902, "timesteps_this_iter": 32, "agent_timesteps_total": 51804, "timers": {"learn_time_ms": 6.52, "learn_throughput": 4907.664, "update_time_ms": 3.901}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25902, "num_agent_steps_sampled": 51804, "num_steps_trained": 43264, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 86528, "last_target_update_ts": 25804, "num_target_updates": 220}, "done": false, "episodes_total": 1412, "training_iteration": 234, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-49", "timestamp": 1648816189, "time_this_iter_s": 0.36578822135925293, "time_total_s": 81.57987713813782, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cadd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cadd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232ef0>"}, "time_since_restore": 81.57987713813782, "timesteps_since_restore": 7488, "iterations_since_restore": 234, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.58, "episode_len_mean": 17.99, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.29, "policy1": -7.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 28.0, -40.0, 26.0, -20.0, -20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0], "episode_lengths": [20, 6, 20, 7, 20, 20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5], "policy_policy0_reward": [-10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0], "policy_policy1_reward": [-10.0, 14.0, -20.0, 13.0, -10.0, -10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14978058412115397, "mean_inference_ms": 1.3502374962117534, "mean_action_processing_ms": 0.09321487835324721, "mean_env_wait_ms": 0.15703870437112352, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26006, "timesteps_this_iter": 32, "agent_timesteps_total": 52012, "timers": {"learn_time_ms": 6.679, "learn_throughput": 4790.89, "update_time_ms": 4.119}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26006, "num_agent_steps_sampled": 52012, "num_steps_trained": 43456, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 86912, "last_target_update_ts": 25922, "num_target_updates": 221}, "done": false, "episodes_total": 1418, "training_iteration": 235, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-49", "timestamp": 1648816189, "time_this_iter_s": 0.3516712188720703, "time_total_s": 81.93154835700989, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82237a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82237a0>"}, "time_since_restore": 81.93154835700989, "timesteps_since_restore": 7520, "iterations_since_restore": 235, "perf": {"cpu_util_percent": 17.5, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.52, "episode_len_mean": 18.26, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.76, "policy1": -7.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 2.0, 28.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 19, 6, 20, 20, 20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, 1.0, 14.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1497883646600941, "mean_inference_ms": 1.35030520209345, "mean_action_processing_ms": 0.09322192102109032, "mean_env_wait_ms": 0.15704754225747267, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26106, "timesteps_this_iter": 32, "agent_timesteps_total": 52212, "timers": {"learn_time_ms": 6.936, "learn_throughput": 4613.371, "update_time_ms": 4.142}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26106, "num_agent_steps_sampled": 52212, "num_steps_trained": 43616, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 87232, "last_target_update_ts": 26026, "num_target_updates": 222}, "done": false, "episodes_total": 1423, "training_iteration": 236, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-50", "timestamp": 1648816190, "time_this_iter_s": 0.35509681701660156, "time_total_s": 82.28664517402649, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffcb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffcb0>"}, "time_since_restore": 82.28664517402649, "timesteps_since_restore": 7552, "iterations_since_restore": 236, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.42, "episode_len_mean": 18.41, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.21, "policy1": -8.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 0.0, -20.0, 8.0, -40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 16, 20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, 0.0, -10.0, 4.0, -20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14979819969826402, "mean_inference_ms": 1.3504039117900155, "mean_action_processing_ms": 0.09323213164490428, "mean_env_wait_ms": 0.15706126408058163, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26206, "timesteps_this_iter": 32, "agent_timesteps_total": 52412, "timers": {"learn_time_ms": 7.141, "learn_throughput": 4480.9, "update_time_ms": 4.033}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26206, "num_agent_steps_sampled": 52412, "num_steps_trained": 43776, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 87552, "last_target_update_ts": 26146, "num_target_updates": 223}, "done": false, "episodes_total": 1428, "training_iteration": 237, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-50", "timestamp": 1648816190, "time_this_iter_s": 0.3475954532623291, "time_total_s": 82.63424062728882, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8208e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223b90>"}, "time_since_restore": 82.63424062728882, "timesteps_since_restore": 7584, "iterations_since_restore": 237, "perf": {"cpu_util_percent": 16.5, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.1, "episode_len_mean": 18.45, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.55, "policy1": -8.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 19, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1498119863612889, "mean_inference_ms": 1.3505432742237653, "mean_action_processing_ms": 0.09324528406907227, "mean_env_wait_ms": 0.15708195000291464, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26306, "timesteps_this_iter": 32, "agent_timesteps_total": 52612, "timers": {"learn_time_ms": 6.834, "learn_throughput": 4682.466, "update_time_ms": 4.099}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26306, "num_agent_steps_sampled": 52612, "num_steps_trained": 43936, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 87872, "last_target_update_ts": 26266, "num_target_updates": 224}, "done": false, "episodes_total": 1433, "training_iteration": 238, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-51", "timestamp": 1648816191, "time_this_iter_s": 0.3285245895385742, "time_total_s": 82.96276521682739, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cadd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82150e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cadd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82150e0>"}, "time_since_restore": 82.96276521682739, "timesteps_since_restore": 7616, "iterations_since_restore": 238, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.26, "episode_len_mean": 18.23, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.13, "policy1": -8.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20], "policy_policy0_reward": [-10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1498366171396545, "mean_inference_ms": 1.3507628040866757, "mean_action_processing_ms": 0.09326556295546519, "mean_env_wait_ms": 0.15711350582726147, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26423, "timesteps_this_iter": 32, "agent_timesteps_total": 52846, "timers": {"learn_time_ms": 6.62, "learn_throughput": 4833.957, "update_time_ms": 3.987}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26423, "num_agent_steps_sampled": 52846, "num_steps_trained": 44160, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 88320, "last_target_update_ts": 26383, "num_target_updates": 225}, "done": false, "episodes_total": 1440, "training_iteration": 239, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-51", "timestamp": 1648816191, "time_this_iter_s": 0.3902931213378906, "time_total_s": 83.35305833816528, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82237a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82237a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223950>"}, "time_since_restore": 83.35305833816528, "timesteps_since_restore": 7648, "iterations_since_restore": 239, "perf": {"cpu_util_percent": 16.3, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.56, "episode_len_mean": 18.18, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.78, "policy1": -7.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14986437505810268, "mean_inference_ms": 1.350993867432046, "mean_action_processing_ms": 0.09328732013386073, "mean_env_wait_ms": 0.15714730867389162, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26524, "timesteps_this_iter": 32, "agent_timesteps_total": 53048, "timers": {"learn_time_ms": 6.544, "learn_throughput": 4890.034, "update_time_ms": 3.914}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26524, "num_agent_steps_sampled": 53048, "num_steps_trained": 44352, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 88704, "last_target_update_ts": 26484, "num_target_updates": 226}, "done": false, "episodes_total": 1446, "training_iteration": 240, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-51", "timestamp": 1648816191, "time_this_iter_s": 0.3493521213531494, "time_total_s": 83.70241045951843, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82230e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82239e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82230e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82239e0>"}, "time_since_restore": 83.70241045951843, "timesteps_since_restore": 7680, "iterations_since_restore": 240, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.16, "episode_len_mean": 18.08, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.58, "policy1": -7.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0], "episode_lengths": [20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14989807612906067, "mean_inference_ms": 1.3512770145455482, "mean_action_processing_ms": 0.09331407370714466, "mean_env_wait_ms": 0.15718782386116725, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26634, "timesteps_this_iter": 32, "agent_timesteps_total": 53268, "timers": {"learn_time_ms": 6.593, "learn_throughput": 4853.764, "update_time_ms": 3.952}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26634, "num_agent_steps_sampled": 53268, "num_steps_trained": 44544, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 89088, "last_target_update_ts": 26604, "num_target_updates": 227}, "done": false, "episodes_total": 1452, "training_iteration": 241, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-52", "timestamp": 1648816192, "time_this_iter_s": 0.372056245803833, "time_total_s": 84.07446670532227, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223440>"}, "time_since_restore": 84.07446670532227, "timesteps_since_restore": 7712, "iterations_since_restore": 241, "perf": {"cpu_util_percent": 17.5, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.3, "episode_len_mean": 17.95, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.15, "policy1": -7.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0], "episode_lengths": [20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14993434314847282, "mean_inference_ms": 1.351590827729457, "mean_action_processing_ms": 0.09334313505431684, "mean_env_wait_ms": 0.15723329384805163, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26734, "timesteps_this_iter": 32, "agent_timesteps_total": 53468, "timers": {"learn_time_ms": 6.601, "learn_throughput": 4847.803, "update_time_ms": 3.908}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26734, "num_agent_steps_sampled": 53468, "num_steps_trained": 44736, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 89472, "last_target_update_ts": 26724, "num_target_updates": 228}, "done": false, "episodes_total": 1458, "training_iteration": 242, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-52", "timestamp": 1648816192, "time_this_iter_s": 0.3362717628479004, "time_total_s": 84.41073846817017, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82239e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82230e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82239e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82230e0>"}, "time_since_restore": 84.41073846817017, "timesteps_since_restore": 7744, "iterations_since_restore": 242, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.94, "episode_len_mean": 18.07, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.47, "policy1": -7.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14997109751065818, "mean_inference_ms": 1.3519271020771644, "mean_action_processing_ms": 0.09337354631329617, "mean_env_wait_ms": 0.15728127592979319, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26834, "timesteps_this_iter": 32, "agent_timesteps_total": 53668, "timers": {"learn_time_ms": 6.751, "learn_throughput": 4740.013, "update_time_ms": 3.965}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26834, "num_agent_steps_sampled": 53668, "num_steps_trained": 44896, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 89792, "last_target_update_ts": 26834, "num_target_updates": 229}, "done": false, "episodes_total": 1463, "training_iteration": 243, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-53", "timestamp": 1648816193, "time_this_iter_s": 0.36102843284606934, "time_total_s": 84.77176690101624, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb90>"}, "time_since_restore": 84.77176690101624, "timesteps_since_restore": 7776, "iterations_since_restore": 243, "perf": {"cpu_util_percent": 16.1, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.64, "episode_len_mean": 17.92, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.32, "policy1": -7.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 34.0, -20.0, 32.0, -40.0, 2.0, -40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 3, 20, 4, 20, 19, 20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20], "policy_policy0_reward": [-10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, 17.0, -10.0, 16.0, -20.0, 1.0, -20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15001841347619352, "mean_inference_ms": 1.3523620729852175, "mean_action_processing_ms": 0.0934115214568494, "mean_env_wait_ms": 0.15734115281308397, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26939, "timesteps_this_iter": 32, "agent_timesteps_total": 53878, "timers": {"learn_time_ms": 6.952, "learn_throughput": 4603.292, "update_time_ms": 4.354}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26939, "num_agent_steps_sampled": 53878, "num_steps_trained": 45088, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 90176, "last_target_update_ts": 26939, "num_target_updates": 230}, "done": false, "episodes_total": 1469, "training_iteration": 244, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-53", "timestamp": 1648816193, "time_this_iter_s": 0.36832690238952637, "time_total_s": 85.14009380340576, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffc20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82230e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffc20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82230e0>"}, "time_since_restore": 85.14009380340576, "timesteps_since_restore": 7808, "iterations_since_restore": 244, "perf": {"cpu_util_percent": 15.9, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.48, "episode_len_mean": 18.14, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.74, "policy1": -7.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 22.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20], "policy_policy0_reward": [-20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 11.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15005715686069634, "mean_inference_ms": 1.3527296234471549, "mean_action_processing_ms": 0.09344466456956045, "mean_env_wait_ms": 0.15739289268349893, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27047, "timesteps_this_iter": 32, "agent_timesteps_total": 54094, "timers": {"learn_time_ms": 6.603, "learn_throughput": 4846.263, "update_time_ms": 4.418}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27047, "num_agent_steps_sampled": 54094, "num_steps_trained": 45280, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 90560, "last_target_update_ts": 27047, "num_target_updates": 231}, "done": false, "episodes_total": 1475, "training_iteration": 245, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-53", "timestamp": 1648816193, "time_this_iter_s": 0.3594059944152832, "time_total_s": 85.49949979782104, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82309e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82309e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223950>"}, "time_since_restore": 85.49949979782104, "timesteps_since_restore": 7840, "iterations_since_restore": 245, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.02, "episode_len_mean": 18.01, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.01, "policy1": -7.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 12.0, -20.0, -20.0, 16.0, -20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0], "episode_lengths": [20, 20, 14, 20, 20, 12, 20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18], "policy_policy0_reward": [-10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0], "policy_policy1_reward": [-10.0, -20.0, 6.0, -10.0, -10.0, 8.0, -10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15010183568313323, "mean_inference_ms": 1.3531598375047615, "mean_action_processing_ms": 0.09348253965013317, "mean_env_wait_ms": 0.1574529033103602, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27163, "timesteps_this_iter": 32, "agent_timesteps_total": 54326, "timers": {"learn_time_ms": 6.218, "learn_throughput": 5146.267, "update_time_ms": 3.849}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27163, "num_agent_steps_sampled": 54326, "num_steps_trained": 45504, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 91008, "last_target_update_ts": 27163, "num_target_updates": 232}, "done": false, "episodes_total": 1482, "training_iteration": 246, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-54", "timestamp": 1648816194, "time_this_iter_s": 0.37921571731567383, "time_total_s": 85.87871551513672, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffd40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffd40>"}, "time_since_restore": 85.87871551513672, "timesteps_since_restore": 7872, "iterations_since_restore": 246, "perf": {"cpu_util_percent": 17.8, "ram_util_percent": 49.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.64, "episode_len_mean": 18.12, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.32, "policy1": -7.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 32.0, 6.0, -20.0, 8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 4, 17, 20, 16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 16.0, 3.0, -10.0, 4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15013995140247727, "mean_inference_ms": 1.3535258563651837, "mean_action_processing_ms": 0.09351492875701581, "mean_env_wait_ms": 0.15750454217278023, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27280, "timesteps_this_iter": 32, "agent_timesteps_total": 54560, "timers": {"learn_time_ms": 6.025, "learn_throughput": 5310.905, "update_time_ms": 3.617}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27280, "num_agent_steps_sampled": 54560, "num_steps_trained": 45696, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 91392, "last_target_update_ts": 27280, "num_target_updates": 233}, "done": false, "episodes_total": 1488, "training_iteration": 247, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-54", "timestamp": 1648816194, "time_this_iter_s": 0.3472766876220703, "time_total_s": 86.22599220275879, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81fff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223440>"}, "time_since_restore": 86.22599220275879, "timesteps_since_restore": 7904, "iterations_since_restore": 247, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.02, "episode_len_mean": 18.31, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.01, "policy1": -8.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, -20.0, 12.0, -40.0, -20.0, -20.0, 4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [16, 20, 14, 20, 20, 20, 18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [4.0, -10.0, 6.0, -20.0, -10.0, -10.0, 2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1501698344371778, "mean_inference_ms": 1.353822422087918, "mean_action_processing_ms": 0.09354119122309924, "mean_env_wait_ms": 0.15754666089686628, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27380, "timesteps_this_iter": 32, "agent_timesteps_total": 54760, "timers": {"learn_time_ms": 6.037, "learn_throughput": 5300.816, "update_time_ms": 3.553}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27380, "num_agent_steps_sampled": 54760, "num_steps_trained": 45856, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 91712, "last_target_update_ts": 27280, "num_target_updates": 233}, "done": false, "episodes_total": 1493, "training_iteration": 248, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-54", "timestamp": 1648816194, "time_this_iter_s": 0.2926602363586426, "time_total_s": 86.51865243911743, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223170>"}, "time_since_restore": 86.51865243911743, "timesteps_since_restore": 7936, "iterations_since_restore": 248, "perf": {"cpu_util_percent": 14.6, "ram_util_percent": 49.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.14, "episode_len_mean": 18.27, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.07, "policy1": -8.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, -20.0, -40.0, 12.0, -20.0, -20.0, 0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0], "episode_lengths": [18, 20, 20, 14, 20, 20, 20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10], "policy_policy0_reward": [2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0], "policy_policy1_reward": [2.0, -10.0, -20.0, 6.0, -10.0, -10.0, 0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15020452609392357, "mean_inference_ms": 1.354161827809592, "mean_action_processing_ms": 0.09357145515171576, "mean_env_wait_ms": 0.157595835099616, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27486, "timesteps_this_iter": 32, "agent_timesteps_total": 54972, "timers": {"learn_time_ms": 6.213, "learn_throughput": 5150.71, "update_time_ms": 3.719}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27486, "num_agent_steps_sampled": 54972, "num_steps_trained": 46048, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 92096, "last_target_update_ts": 27400, "num_target_updates": 234}, "done": false, "episodes_total": 1499, "training_iteration": 249, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-55", "timestamp": 1648816195, "time_this_iter_s": 0.33473730087280273, "time_total_s": 86.85338973999023, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82233b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223f80>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82233b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223f80>"}, "time_since_restore": 86.85338973999023, "timesteps_since_restore": 7968, "iterations_since_restore": 249, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.02, "episode_len_mean": 18.21, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.01, "policy1": -8.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 14.0, 4.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0], "episode_lengths": [20, 13, 18, 20, 20, 20, 20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20], "policy_policy0_reward": [0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0], "policy_policy1_reward": [0.0, 7.0, 2.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15023938727757946, "mean_inference_ms": 1.3545012373120915, "mean_action_processing_ms": 0.09360135698241694, "mean_env_wait_ms": 0.15764576286516985, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27592, "timesteps_this_iter": 32, "agent_timesteps_total": 55184, "timers": {"learn_time_ms": 6.251, "learn_throughput": 5118.946, "update_time_ms": 3.905}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27592, "num_agent_steps_sampled": 55184, "num_steps_trained": 46240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 92480, "last_target_update_ts": 27506, "num_target_updates": 235}, "done": false, "episodes_total": 1505, "training_iteration": 250, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-55", "timestamp": 1648816195, "time_this_iter_s": 0.34870195388793945, "time_total_s": 87.20209169387817, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ff8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81ffb00>"}, "time_since_restore": 87.20209169387817, "timesteps_since_restore": 8000, "iterations_since_restore": 250, "perf": {"cpu_util_percent": 18.3, "ram_util_percent": 49.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.4, "episode_len_mean": 18.2, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.2, "policy1": -8.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -20.0, 2.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 19, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, 1.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15027280903474344, "mean_inference_ms": 1.354826267557184, "mean_action_processing_ms": 0.09363079477274784, "mean_env_wait_ms": 0.1576945388543235, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27702, "timesteps_this_iter": 32, "agent_timesteps_total": 55404, "timers": {"learn_time_ms": 6.326, "learn_throughput": 5058.578, "update_time_ms": 3.999}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27702, "num_agent_steps_sampled": 55404, "num_steps_trained": 46432, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 92864, "last_target_update_ts": 27612, "num_target_updates": 236}, "done": false, "episodes_total": 1511, "training_iteration": 251, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-56", "timestamp": 1648816196, "time_this_iter_s": 0.35697007179260254, "time_total_s": 87.55906176567078, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223440>"}, "time_since_restore": 87.55906176567078, "timesteps_since_restore": 8032, "iterations_since_restore": 251, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.78, "episode_len_mean": 18.09, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.89, "policy1": -7.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0], "episode_lengths": [5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20], "policy_policy0_reward": [15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0], "policy_policy1_reward": [15.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15030382077404675, "mean_inference_ms": 1.3551187696815288, "mean_action_processing_ms": 0.0936584390556461, "mean_env_wait_ms": 0.15774175065985502, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27810, "timesteps_this_iter": 32, "agent_timesteps_total": 55620, "timers": {"learn_time_ms": 6.25, "learn_throughput": 5119.629, "update_time_ms": 3.8}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27810, "num_agent_steps_sampled": 55620, "num_steps_trained": 46624, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 93248, "last_target_update_ts": 27722, "num_target_updates": 237}, "done": false, "episodes_total": 1517, "training_iteration": 252, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-56", "timestamp": 1648816196, "time_this_iter_s": 0.32975053787231445, "time_total_s": 87.88881230354309, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82238c0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb81ffd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82238c0>"}, "time_since_restore": 87.88881230354309, "timesteps_since_restore": 8064, "iterations_since_restore": 252, "perf": {"cpu_util_percent": 18.1, "ram_util_percent": 49.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.68, "episode_len_mean": 18.04, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.84, "policy1": -7.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1503298558101059, "mean_inference_ms": 1.3553453721503228, "mean_action_processing_ms": 0.09368013175688691, "mean_env_wait_ms": 0.15777967740989582, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27910, "timesteps_this_iter": 32, "agent_timesteps_total": 55820, "timers": {"learn_time_ms": 6.254, "learn_throughput": 5116.643, "update_time_ms": 3.639}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27910, "num_agent_steps_sampled": 55820, "num_steps_trained": 46816, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 93632, "last_target_update_ts": 27830, "num_target_updates": 238}, "done": false, "episodes_total": 1523, "training_iteration": 253, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-56", "timestamp": 1648816196, "time_this_iter_s": 0.3145906925201416, "time_total_s": 88.20340299606323, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82233b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223cb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82233b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223cb0>"}, "time_since_restore": 88.20340299606323, "timesteps_since_restore": 8096, "iterations_since_restore": 253, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.7, "episode_len_mean": 17.95, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.35, "policy1": -7.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, 30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, 15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15035271421738464, "mean_inference_ms": 1.355533129222254, "mean_action_processing_ms": 0.09369722489480797, "mean_env_wait_ms": 0.15781157423216224, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28021, "timesteps_this_iter": 32, "agent_timesteps_total": 56042, "timers": {"learn_time_ms": 6.508, "learn_throughput": 4917.139, "update_time_ms": 3.925}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28021, "num_agent_steps_sampled": 56042, "num_steps_trained": 47008, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 94016, "last_target_update_ts": 27941, "num_target_updates": 239}, "done": false, "episodes_total": 1529, "training_iteration": 254, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-57", "timestamp": 1648816197, "time_this_iter_s": 0.3641166687011719, "time_total_s": 88.5675196647644, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81f2d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb81f2d40>"}, "time_since_restore": 88.5675196647644, "timesteps_since_restore": 8128, "iterations_since_restore": 254, "perf": {"cpu_util_percent": 16.9, "ram_util_percent": 49.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.7, "episode_len_mean": 17.95, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.35, "policy1": -7.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, -20.0, 16.0, -20.0, -20.0, -40.0, 8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [5, 20, 12, 20, 20, 20, 16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [15.0, -10.0, 8.0, -10.0, -10.0, -20.0, 4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15036913870228696, "mean_inference_ms": 1.3556661275850257, "mean_action_processing_ms": 0.09370959498512604, "mean_env_wait_ms": 0.15783518851510528, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28121, "timesteps_this_iter": 32, "agent_timesteps_total": 56242, "timers": {"learn_time_ms": 6.609, "learn_throughput": 4841.892, "update_time_ms": 3.99}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28121, "num_agent_steps_sampled": 56242, "num_steps_trained": 47168, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 94336, "last_target_update_ts": 28061, "num_target_updates": 240}, "done": false, "episodes_total": 1534, "training_iteration": 255, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-57", "timestamp": 1648816197, "time_this_iter_s": 0.3078131675720215, "time_total_s": 88.87533283233643, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223440>"}, "time_since_restore": 88.87533283233643, "timesteps_since_restore": 8160, "iterations_since_restore": 255, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.16, "episode_len_mean": 17.98, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.58, "policy1": -7.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0], "episode_lengths": [16, 20, 5, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20], "policy_policy0_reward": [4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0], "policy_policy1_reward": [4.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1503864568539398, "mean_inference_ms": 1.3558112610322564, "mean_action_processing_ms": 0.09372351464437081, "mean_env_wait_ms": 0.15786161399509613, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28221, "timesteps_this_iter": 32, "agent_timesteps_total": 56442, "timers": {"learn_time_ms": 6.369, "learn_throughput": 5024.454, "update_time_ms": 3.823}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28221, "num_agent_steps_sampled": 56442, "num_steps_trained": 47360, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 94720, "last_target_update_ts": 28167, "num_target_updates": 241}, "done": false, "episodes_total": 1540, "training_iteration": 256, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-57", "timestamp": 1648816197, "time_this_iter_s": 0.3208446502685547, "time_total_s": 89.19617748260498, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82238c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82124d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82238c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82124d0>"}, "time_since_restore": 89.19617748260498, "timesteps_since_restore": 8192, "iterations_since_restore": 256, "perf": {"cpu_util_percent": 15.3, "ram_util_percent": 49.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.66, "episode_len_mean": 18.13, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.83, "policy1": -7.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, 20.0, -40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 10, 20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, 10.0, -20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15040024085717033, "mean_inference_ms": 1.3559496294952202, "mean_action_processing_ms": 0.09373588304903312, "mean_env_wait_ms": 0.1578863056557689, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28337, "timesteps_this_iter": 32, "agent_timesteps_total": 56674, "timers": {"learn_time_ms": 6.356, "learn_throughput": 5034.971, "update_time_ms": 3.94}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28337, "num_agent_steps_sampled": 56674, "num_steps_trained": 47552, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 95104, "last_target_update_ts": 28277, "num_target_updates": 242}, "done": false, "episodes_total": 1546, "training_iteration": 257, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-58", "timestamp": 1648816198, "time_this_iter_s": 0.3748903274536133, "time_total_s": 89.5710678100586, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223cb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223cb0>"}, "time_since_restore": 89.5710678100586, "timesteps_since_restore": 8224, "iterations_since_restore": 257, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.46, "episode_len_mean": 18.23, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.23, "policy1": -8.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 0.0, 8.0, -20.0, 12.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 16, 20, 14, 20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, 0.0, 4.0, -10.0, 6.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15040957743253766, "mean_inference_ms": 1.3560534822934887, "mean_action_processing_ms": 0.09374468749429657, "mean_env_wait_ms": 0.15790543875022547, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28437, "timesteps_this_iter": 32, "agent_timesteps_total": 56874, "timers": {"learn_time_ms": 6.497, "learn_throughput": 4925.729, "update_time_ms": 4.098}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28437, "num_agent_steps_sampled": 56874, "num_steps_trained": 47712, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 95424, "last_target_update_ts": 28397, "num_target_updates": 243}, "done": false, "episodes_total": 1551, "training_iteration": 258, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-58", "timestamp": 1648816198, "time_this_iter_s": 0.3343491554260254, "time_total_s": 89.90541696548462, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203f80>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203f80>"}, "time_since_restore": 89.90541696548462, "timesteps_since_restore": 8256, "iterations_since_restore": 258, "perf": {"cpu_util_percent": 16.2, "ram_util_percent": 49.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.06, "episode_len_mean": 18.33, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.53, "policy1": -8.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15041724322882546, "mean_inference_ms": 1.3561509054936176, "mean_action_processing_ms": 0.09375243968104757, "mean_env_wait_ms": 0.1579220070599076, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28537, "timesteps_this_iter": 32, "agent_timesteps_total": 57074, "timers": {"learn_time_ms": 6.589, "learn_throughput": 4856.908, "update_time_ms": 4.113}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28537, "num_agent_steps_sampled": 57074, "num_steps_trained": 47872, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 95744, "last_target_update_ts": 28517, "num_target_updates": 244}, "done": false, "episodes_total": 1556, "training_iteration": 259, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-58", "timestamp": 1648816198, "time_this_iter_s": 0.31279611587524414, "time_total_s": 90.21821308135986, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203c20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203c20>"}, "time_since_restore": 90.21821308135986, "timesteps_since_restore": 8288, "iterations_since_restore": 259, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.18, "episode_len_mean": 18.29, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.59, "policy1": -8.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0], "episode_lengths": [20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15042584482446042, "mean_inference_ms": 1.3562698218013833, "mean_action_processing_ms": 0.09376123477266678, "mean_env_wait_ms": 0.15794023329405016, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28643, "timesteps_this_iter": 32, "agent_timesteps_total": 57286, "timers": {"learn_time_ms": 6.698, "learn_throughput": 4777.571, "update_time_ms": 4.177}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28643, "num_agent_steps_sampled": 57286, "num_steps_trained": 48064, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 96128, "last_target_update_ts": 28623, "num_target_updates": 245}, "done": false, "episodes_total": 1562, "training_iteration": 260, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-59", "timestamp": 1648816199, "time_this_iter_s": 0.3813319206237793, "time_total_s": 90.59954500198364, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82238c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82238c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212b90>"}, "time_since_restore": 90.59954500198364, "timesteps_since_restore": 8320, "iterations_since_restore": 260, "perf": {"cpu_util_percent": 15.9, "ram_util_percent": 49.1}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.48, "episode_len_mean": 18.44, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.74, "policy1": -8.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 8, 20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15042831496080525, "mean_inference_ms": 1.3563266331905441, "mean_action_processing_ms": 0.09376582757078206, "mean_env_wait_ms": 0.15795195757163236, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28743, "timesteps_this_iter": 32, "agent_timesteps_total": 57486, "timers": {"learn_time_ms": 6.654, "learn_throughput": 4809.327, "update_time_ms": 3.962}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28743, "num_agent_steps_sampled": 57486, "num_steps_trained": 48224, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 96448, "last_target_update_ts": 28743, "num_target_updates": 246}, "done": false, "episodes_total": 1567, "training_iteration": 261, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-29-59", "timestamp": 1648816199, "time_this_iter_s": 0.31320977210998535, "time_total_s": 90.91275477409363, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8223830>"}, "time_since_restore": 90.91275477409363, "timesteps_since_restore": 8352, "iterations_since_restore": 261, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.72, "episode_len_mean": 18.56, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.86, "policy1": -8.86}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, 22.0, -20.0, 6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 9, 20, 17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, 11.0, -10.0, 3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15042918971739322, "mean_inference_ms": 1.356369492413931, "mean_action_processing_ms": 0.09376929228686155, "mean_env_wait_ms": 0.1579622520903414, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28843, "timesteps_this_iter": 32, "agent_timesteps_total": 57686, "timers": {"learn_time_ms": 6.358, "learn_throughput": 5033.328, "update_time_ms": 3.757}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28843, "num_agent_steps_sampled": 57686, "num_steps_trained": 48384, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 96768, "last_target_update_ts": 28743, "num_target_updates": 246}, "done": false, "episodes_total": 1572, "training_iteration": 262, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-30-00", "timestamp": 1648816200, "time_this_iter_s": 0.30433034896850586, "time_total_s": 91.21708512306213, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8212b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232440>"}, "time_since_restore": 91.21708512306213, "timesteps_since_restore": 8384, "iterations_since_restore": 262, "perf": {"cpu_util_percent": 16.7, "ram_util_percent": 49.1}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.7, "episode_len_mean": 18.65, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.85, "policy1": -8.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, -20.0, 16.0, 4.0, -20.0, -40.0, 6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0], "episode_lengths": [17, 20, 12, 18, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20], "policy_policy0_reward": [3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [3.0, -10.0, 8.0, 2.0, -10.0, -20.0, 3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15043005178145413, "mean_inference_ms": 1.3564266245945829, "mean_action_processing_ms": 0.09377344526621488, "mean_env_wait_ms": 0.15797371008555067, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28961, "timesteps_this_iter": 32, "agent_timesteps_total": 57922, "timers": {"learn_time_ms": 6.354, "learn_throughput": 5036.464, "update_time_ms": 3.804}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28961, "num_agent_steps_sampled": 57922, "num_steps_trained": 48576, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 97152, "last_target_update_ts": 28863, "num_target_updates": 247}, "done": false, "episodes_total": 1578, "training_iteration": 263, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-30-00", "timestamp": 1648816200, "time_this_iter_s": 0.37916111946105957, "time_total_s": 91.5962462425232, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8223f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8212b00>"}, "time_since_restore": 91.5962462425232, "timesteps_since_restore": 8416, "iterations_since_restore": 263, "perf": {"cpu_util_percent": 16.3, "ram_util_percent": 49.1}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.16, "episode_len_mean": 18.68, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.08, "policy1": -9.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -40.0], "episode_lengths": [17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20], "policy_policy0_reward": [3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0], "policy_policy1_reward": [3.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15043637447875446, "mean_inference_ms": 1.3565504221318287, "mean_action_processing_ms": 0.09378358837841334, "mean_env_wait_ms": 0.15799404024416755, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29071, "timesteps_this_iter": 32, "agent_timesteps_total": 58142, "timers": {"learn_time_ms": 6.742, "learn_throughput": 4746.382, "update_time_ms": 4.006}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29071, "num_agent_steps_sampled": 58142, "num_steps_trained": 48768, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 97536, "last_target_update_ts": 28981, "num_target_updates": 248}, "done": false, "episodes_total": 1584, "training_iteration": 264, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-30-00", "timestamp": 1648816200, "time_this_iter_s": 0.39406514167785645, "time_total_s": 91.99031138420105, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82238c0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82238c0>"}, "time_since_restore": 91.99031138420105, "timesteps_since_restore": 8448, "iterations_since_restore": 264, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.42, "episode_len_mean": 18.71, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.21, "policy1": -9.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15044282426033853, "mean_inference_ms": 1.356680346650348, "mean_action_processing_ms": 0.0937942846366592, "mean_env_wait_ms": 0.15801521587417866, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29171, "timesteps_this_iter": 32, "agent_timesteps_total": 58342, "timers": {"learn_time_ms": 6.576, "learn_throughput": 4866.223, "update_time_ms": 3.913}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29171, "num_agent_steps_sampled": 58342, "num_steps_trained": 48928, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 97856, "last_target_update_ts": 29091, "num_target_updates": 249}, "done": false, "episodes_total": 1589, "training_iteration": 265, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-30-01", "timestamp": 1648816201, "time_this_iter_s": 0.31955981254577637, "time_total_s": 92.30987119674683, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8203c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215e60>"}, "time_since_restore": 92.30987119674683, "timesteps_since_restore": 8480, "iterations_since_restore": 265, "perf": {"cpu_util_percent": 16.8, "ram_util_percent": 49.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.8, "episode_len_mean": 18.6, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.9, "policy1": -8.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 10, 20, 20, 20, 20, 6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15045791834337166, "mean_inference_ms": 1.3569069578137531, "mean_action_processing_ms": 0.09381246776165895, "mean_env_wait_ms": 0.15804776832825201, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29276, "timesteps_this_iter": 32, "agent_timesteps_total": 58552, "timers": {"learn_time_ms": 6.535, "learn_throughput": 4896.974, "update_time_ms": 4.085}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29276, "num_agent_steps_sampled": 58552, "num_steps_trained": 49120, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 98240, "last_target_update_ts": 29196, "num_target_updates": 250}, "done": false, "episodes_total": 1595, "training_iteration": 266, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-30-01", "timestamp": 1648816201, "time_this_iter_s": 0.3831181526184082, "time_total_s": 92.69298934936523, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82153b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82153b0>"}, "time_since_restore": 92.69298934936523, "timesteps_since_restore": 8512, "iterations_since_restore": 266, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.38, "episode_len_mean": 18.29, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.19, "policy1": -8.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, 20.0, 20.0, -20.0, -20.0], "episode_lengths": [6, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 13, 6, 20, 10, 10, 20, 20], "policy_policy0_reward": [14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0], "policy_policy1_reward": [14.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15048205490569735, "mean_inference_ms": 1.3572078891089923, "mean_action_processing_ms": 0.09383707120697198, "mean_env_wait_ms": 0.15809027253398242, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29395, "timesteps_this_iter": 32, "agent_timesteps_total": 58790, "timers": {"learn_time_ms": 6.185, "learn_throughput": 5174.121, "update_time_ms": 3.915}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29395, "num_agent_steps_sampled": 58790, "num_steps_trained": 49376, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 98752, "last_target_update_ts": 29309, "num_target_updates": 251}, "done": false, "episodes_total": 1603, "training_iteration": 267, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-30-02", "timestamp": 1648816202, "time_this_iter_s": 0.40818166732788086, "time_total_s": 93.10117101669312, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232440>"}, "time_since_restore": 93.10117101669312, "timesteps_since_restore": 8544, "iterations_since_restore": 267, "perf": {"cpu_util_percent": 18.4, "ram_util_percent": 49.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.46, "episode_len_mean": 18.53, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.73, "policy1": -8.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, 20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 13, 6, 20, 10, 10, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.150495246808562, "mean_inference_ms": 1.357375376531133, "mean_action_processing_ms": 0.09385068528470442, "mean_env_wait_ms": 0.1581134050591713, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29495, "timesteps_this_iter": 32, "agent_timesteps_total": 58990, "timers": {"learn_time_ms": 6.119, "learn_throughput": 5229.785, "update_time_ms": 3.819}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29495, "num_agent_steps_sampled": 58990, "num_steps_trained": 49536, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 99072, "last_target_update_ts": 29415, "num_target_updates": 252}, "done": false, "episodes_total": 1608, "training_iteration": 268, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-30-02", "timestamp": 1648816202, "time_this_iter_s": 0.2969810962677002, "time_total_s": 93.39815211296082, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82154d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb82154d0>"}, "time_since_restore": 93.39815211296082, "timesteps_since_restore": 8576, "iterations_since_restore": 268, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.02, "episode_len_mean": 18.41, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.51, "policy1": -8.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, 16.0, 24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, 20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 12, 8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 13, 6, 20, 10, 10, 20, 20, 20, 20, 20, 20, 20, 10, 6, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 8.0, 12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15051381463320718, "mean_inference_ms": 1.357604656495081, "mean_action_processing_ms": 0.09386864923654668, "mean_env_wait_ms": 0.1581463129818818, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29611, "timesteps_this_iter": 32, "agent_timesteps_total": 59222, "timers": {"learn_time_ms": 6.033, "learn_throughput": 5303.854, "update_time_ms": 3.773}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29611, "num_agent_steps_sampled": 59222, "num_steps_trained": 49760, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 99520, "last_target_update_ts": 29531, "num_target_updates": 253}, "done": false, "episodes_total": 1615, "training_iteration": 269, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-30-02", "timestamp": 1648816202, "time_this_iter_s": 0.37071990966796875, "time_total_s": 93.76887202262878, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215200>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82ca320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215200>"}, "time_since_restore": 93.76887202262878, "timesteps_since_restore": 8608, "iterations_since_restore": 269, "perf": {"cpu_util_percent": 16.4, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.64, "episode_len_mean": 18.32, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.32, "policy1": -8.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, 20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 34.0, -20.0], "episode_lengths": [8, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 13, 6, 20, 10, 10, 20, 20, 20, 20, 20, 20, 20, 10, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20], "policy_policy0_reward": [12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 17.0, -10.0], "policy_policy1_reward": [12.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 17.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1505316483405228, "mean_inference_ms": 1.3578247656976163, "mean_action_processing_ms": 0.09388566885566402, "mean_env_wait_ms": 0.1581779619264986, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29714, "timesteps_this_iter": 32, "agent_timesteps_total": 59428, "timers": {"learn_time_ms": 6.232, "learn_throughput": 5134.455, "update_time_ms": 3.812}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29714, "num_agent_steps_sampled": 59428, "num_steps_trained": 49920, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 99840, "last_target_update_ts": 29651, "num_target_updates": 254}, "done": false, "episodes_total": 1621, "training_iteration": 270, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-30-03", "timestamp": 1648816203, "time_this_iter_s": 0.3227815628051758, "time_total_s": 94.09165358543396, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82155f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232c20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82155f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232c20>"}, "time_since_restore": 94.09165358543396, "timesteps_since_restore": 8640, "iterations_since_restore": 270, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.98, "episode_len_mean": 18.39, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.49, "policy1": -8.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, 20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 13, 6, 20, 10, 10, 20, 20, 20, 20, 20, 20, 20, 10, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 6, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1505520449531589, "mean_inference_ms": 1.358079255637644, "mean_action_processing_ms": 0.0939069159284806, "mean_env_wait_ms": 0.15821515342110667, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29820, "timesteps_this_iter": 32, "agent_timesteps_total": 59640, "timers": {"learn_time_ms": 6.463, "learn_throughput": 4951.186, "update_time_ms": 4.058}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29820, "num_agent_steps_sampled": 59640, "num_steps_trained": 50112, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 100224, "last_target_update_ts": 29754, "num_target_updates": 255}, "done": false, "episodes_total": 1627, "training_iteration": 271, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-30-03", "timestamp": 1648816203, "time_this_iter_s": 0.3732469081878662, "time_total_s": 94.46490049362183, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232dd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8215b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8232dd0>"}, "time_since_restore": 94.46490049362183, "timesteps_since_restore": 8672, "iterations_since_restore": 271, "perf": {"cpu_util_percent": 17.1, "ram_util_percent": 49.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.08, "episode_len_mean": 18.24, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.04, "policy1": -8.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, 28.0, -40.0, 12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, 20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -20.0, -20.0, 16.0, 14.0, -20.0], "episode_lengths": [20, 20, 20, 6, 20, 14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 13, 6, 20, 10, 10, 20, 20, 20, 20, 20, 20, 20, 10, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 12, 13, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -10.0, -10.0, 8.0, 7.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, 14.0, -20.0, 6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -10.0, -10.0, 8.0, 7.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15057379943108054, "mean_inference_ms": 1.3583414092904604, "mean_action_processing_ms": 0.09392905400021506, "mean_env_wait_ms": 0.1582526882950953, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29925, "timesteps_this_iter": 32, "agent_timesteps_total": 59850, "timers": {"learn_time_ms": 6.577, "learn_throughput": 4865.376, "update_time_ms": 4.01}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29925, "num_agent_steps_sampled": 59850, "num_steps_trained": 50304, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 100608, "last_target_update_ts": 29860, "num_target_updates": 256}, "done": false, "episodes_total": 1633, "training_iteration": 272, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-30-03", "timestamp": 1648816203, "time_this_iter_s": 0.34717345237731934, "time_total_s": 94.81207394599915, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cacb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb82cacb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8203560>"}, "time_since_restore": 94.81207394599915, "timesteps_since_restore": 8704, "iterations_since_restore": 272, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.56, "episode_len_mean": 18.38, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.28, "policy1": -8.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, -40.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, 0.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 28.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, 20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -40.0, -20.0, -20.0, -20.0, 16.0, 14.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [14, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 13, 6, 20, 10, 10, 20, 20, 20, 20, 20, 20, 20, 10, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 12, 13, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -10.0, -10.0, 8.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [6.0, -20.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, 0.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 14.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, 10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -20.0, -10.0, -10.0, -10.0, 8.0, 7.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15059359527528768, "mean_inference_ms": 1.358584496657514, "mean_action_processing_ms": 0.09394933382694219, "mean_env_wait_ms": 0.15828800694451856, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 30025, "timesteps_this_iter": 32, "agent_timesteps_total": 60050, "timers": {"learn_time_ms": 6.62, "learn_throughput": 4833.975, "update_time_ms": 3.781}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 30025, "num_agent_steps_sampled": 60050, "num_steps_trained": 50464, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 100928, "last_target_update_ts": 29965, "num_target_updates": 257}, "done": true, "episodes_total": 1638, "training_iteration": 273, "trial_id": "30cc8_00000", "experiment_id": "987af3d6744e4009b4bc9d92518314c0", "date": "2022-04-01_05-30-04", "timestamp": 1648816204, "time_this_iter_s": 0.32519030570983887, "time_total_s": 95.13726425170898, "pid": 27071, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215200>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8232dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7feeb8215200>"}, "time_since_restore": 95.13726425170898, "timesteps_since_restore": 8736, "iterations_since_restore": 273, "perf": {"cpu_util_percent": 16.4, "ram_util_percent": 49.1}}
