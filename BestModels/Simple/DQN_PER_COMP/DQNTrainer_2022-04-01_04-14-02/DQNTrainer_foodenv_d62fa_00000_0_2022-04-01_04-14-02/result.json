{"episode_reward_max": 10.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.381818181818183, "episode_len_mean": 18.327272727272728, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -11.781818181818181, "policy1": -15.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -4.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, 8.0, -40.0, -30.0, 2.0, -30.0, -30.0, -30.0, -30.0, 10.0, 4.0, -30.0, -30.0, -30.0, -40.0, -40.0, -10.0, -30.0, -30.0, -30.0, -30.0, 8.0, -30.0, -40.0, -30.0, -18.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, 4.0, -30.0, -30.0], "episode_lengths": [20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 9, 20, 20, 20, 20, 5, 8, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 6, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, 4.0, -20.0, -10.0, -9.0, -10.0, -10.0, -10.0, -20.0, 5.0, 2.0, -10.0, -10.0, -10.0, -20.0, -20.0, -5.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -12.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, 5.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3293056790490808, "mean_inference_ms": 1.914461493137689, "mean_action_processing_ms": 0.12440275035362888, "mean_env_wait_ms": 0.07796665603743558, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1008, "timesteps_this_iter": 32, "agent_timesteps_total": 2016, "timers": {"load_time_ms": 0.502, "load_throughput": 63791.696, "learn_time_ms": 444.771, "learn_throughput": 71.947, "update_time_ms": 19.438}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -0.019079219549894333, "min_q": -0.7737859487533569, "max_q": 0.6095198392868042, "mean_td_error": 0.7333996295928955, "model": {}}, "td_error": [1.2235575914382935, 0.8087761402130127, 1.379067063331604, 0.8205089569091797, 1.6287649869918823, 1.317254900932312, 1.7199875116348267, 1.0379548072814941, 1.2725002765655518, 1.5347397327423096, 0.3802748918533325, 1.019531011581421, 1.5553252696990967, 1.7504558563232422, 0.7274568676948547, 1.0584391355514526, 0.7275639772415161, 1.640077829360962, 0.34665876626968384, 1.4763177633285522, 0.4348602294921875, 0.3715636134147644, 0.4872947931289673, 0.4723794162273407, 1.3155558109283447, 0.3730781078338623, 0.8807525634765625, 1.2700891494750977, 1.7307078838348389, 1.5737172365188599, -9.773785591125488, 0.9073611497879028], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 0.08035305142402649, "min_q": -0.7652958631515503, "max_q": 0.9888311624526978, "mean_td_error": 1.3298859596252441, "model": {}}, "td_error": [2.393556594848633, 1.5254671573638916, 0.9127755165100098, 1.0690319538116455, 1.3041046857833862, 1.5208911895751953, 1.6220424175262451, 1.3136179447174072, 1.619880199432373, 1.9989850521087646, 0.49582576751708984, 0.8133376240730286, 0.8357943296432495, 1.9135656356811523, 1.793244481086731, 0.47556644678115845, 0.9602017402648926, 0.26220786571502686, 0.9642002582550049, 2.2678382396698, 1.301567554473877, 1.3693935871124268, 1.867623209953308, 1.6220424175262451, 0.8769531846046448, 1.179097294807434, 0.9756516218185425, 0.8473614454269409, 1.4730647802352905, 1.0868903398513794, 2.3736801147460938, 1.5208914279937744], "custom_metrics": {}}}, "num_steps_sampled": 1008, "num_agent_steps_sampled": 2016, "num_steps_trained": 32, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64, "last_target_update_ts": 1008, "num_target_updates": 1}, "done": false, "episodes_total": 55, "training_iteration": 1, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-24", "timestamp": 1648811664, "time_this_iter_s": 3.564669370651245, "time_total_s": 3.564669370651245, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848a200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848a200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3.564669370651245, "timesteps_since_restore": 32, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 42.01666666666666, "ram_util_percent": 65.26666666666667}}
{"episode_reward_max": 10.0, "episode_reward_min": -40.0, "episode_reward_mean": -26.895522388059703, "episode_len_mean": 18.223880597014926, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -11.805970149253731, "policy1": -15.08955223880597}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -4.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, 8.0, -40.0, -30.0, 2.0, -30.0, -30.0, -30.0, -30.0, 10.0, 4.0, -30.0, -30.0, -30.0, -40.0, -40.0, -10.0, -30.0, -30.0, -30.0, -30.0, 8.0, -30.0, -40.0, -30.0, -18.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, 4.0, -30.0, -30.0, 4.0, -40.0, -14.0, -30.0, -30.0, 4.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0], "episode_lengths": [20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 9, 20, 20, 20, 20, 5, 8, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 6, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 8, 20, 17, 20, 20, 8, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, 4.0, -20.0, -10.0, -9.0, -10.0, -10.0, -10.0, -20.0, 5.0, 2.0, -10.0, -10.0, -10.0, -20.0, -20.0, -5.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 2.0, -20.0, -7.0, -20.0, -10.0, 2.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -12.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, 5.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 2.0, -20.0, -7.0, -10.0, -20.0, 2.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3292897329181602, "mean_inference_ms": 1.9107089196391467, "mean_action_processing_ms": 0.12447530262070848, "mean_env_wait_ms": 0.07793903690979206, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1221, "timesteps_this_iter": 32, "agent_timesteps_total": 2442, "timers": {"load_time_ms": 0.449, "load_throughput": 71237.051, "learn_time_ms": 7.673, "learn_throughput": 4170.584, "update_time_ms": 13.472}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -7.247448921203613, "min_q": -12.621794700622559, "max_q": -1.6563612222671509, "mean_td_error": -0.5981807112693787, "model": {}}, "td_error": [-3.5958175659179688, 4.747809410095215, 6.312087535858154, -2.7412009239196777, 1.3834810256958008, 0.7067489624023438, -10.767605781555176, 0.670170783996582, 2.633312702178955, -2.0813746452331543, -2.5825748443603516, -3.5879688262939453, -3.805577278137207, 1.9345064163208008, -5.650280952453613, -3.749915599822998, -2.4058666229248047, -2.3717422485351562, 5.1369218826293945, 4.477832794189453, 2.4263410568237305, -5.853911399841309, -3.4476194381713867, 4.680377960205078, 6.519820213317871, -2.4058666229248047, -12.187983512878418, -0.8020820617675781, 1.3834810256958008, 4.918666839599609, -1.4933652877807617, 2.457411289215088], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -6.542314529418945, "min_q": -11.671355247497559, "max_q": 2.345365047454834, "mean_td_error": 0.15964725613594055, "model": {}}, "td_error": [-2.3546853065490723, 2.0115227699279785, -1.7676854133605957, -6.016818046569824, 1.4354257583618164, 0.8756122589111328, 0.7031383514404297, -4.300836563110352, 2.857553482055664, -1.942990779876709, -1.183854579925537, -1.5519485473632812, -2.779855728149414, 9.562705039978027, 11.52672004699707, 0.5764651298522949, -0.5374693870544434, -3.4425907135009766, 2.3838934898376465, 1.3412036895751953, -6.717484951019287, 0.31122779846191406, 4.462273120880127, -0.5889968872070312, -5.311370849609375, -4.114243030548096, -3.37288236618042, 3.532559871673584, -0.942622184753418, 9.888442993164062, -1.1967449188232422, 1.7630481719970703], "custom_metrics": {}}}, "num_steps_sampled": 1221, "num_agent_steps_sampled": 2442, "num_steps_trained": 416, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 832, "last_target_update_ts": 1121, "num_target_updates": 2}, "done": false, "episodes_total": 67, "training_iteration": 2, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-25", "timestamp": 1648811665, "time_this_iter_s": 0.9918403625488281, "time_total_s": 4.556509733200073, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584aed40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584aed40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4.556509733200073, "timesteps_since_restore": 64, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 42.3, "ram_util_percent": 65.5}}
{"episode_reward_max": 10.0, "episode_reward_min": -40.0, "episode_reward_mean": -26.253164556962027, "episode_len_mean": 18.189873417721518, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -11.10126582278481, "policy1": -15.151898734177216}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -4.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, 8.0, -40.0, -30.0, 2.0, -30.0, -30.0, -30.0, -30.0, 10.0, 4.0, -30.0, -30.0, -30.0, -40.0, -40.0, -10.0, -30.0, -30.0, -30.0, -30.0, 8.0, -30.0, -40.0, -30.0, -18.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, 4.0, -30.0, -30.0, 4.0, -40.0, -14.0, -30.0, -30.0, 4.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, -4.0, -14.0, -30.0, -30.0, -30.0, -6.0, -30.0], "episode_lengths": [20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 9, 20, 20, 20, 20, 5, 8, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 6, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 8, 20, 17, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 17, 20, 20, 20, 13, 20], "policy_policy0_reward": [-10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, 4.0, -20.0, -10.0, -9.0, -10.0, -10.0, -10.0, -20.0, 5.0, 2.0, -10.0, -10.0, -10.0, -20.0, -20.0, -5.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 2.0, -20.0, -7.0, -20.0, -10.0, 2.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, -10.0, 8.0, -7.0, -10.0, -20.0, -10.0, -3.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -12.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, 5.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 2.0, -20.0, -7.0, -10.0, -20.0, 2.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -14.0, -20.0, -20.0, -20.0, -20.0, -12.0, -7.0, -20.0, -10.0, -20.0, -3.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3293954300193504, "mean_inference_ms": 1.9074872211118175, "mean_action_processing_ms": 0.12464677260905994, "mean_env_wait_ms": 0.07787481058084329, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1437, "timesteps_this_iter": 32, "agent_timesteps_total": 2874, "timers": {"load_time_ms": 0.469, "load_throughput": 68182.742, "learn_time_ms": 8.181, "learn_throughput": 3911.696, "update_time_ms": 9.07}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -5.22242546081543, "min_q": -8.507981300354004, "max_q": -1.9899171590805054, "mean_td_error": -0.3126997947692871, "model": {}}, "td_error": [1.2473607063293457, 0.6049232482910156, 0.6191291809082031, -1.4968018531799316, -0.11039304733276367, 2.741661787033081, -1.8171026706695557, -3.380408763885498, 1.6625783443450928, 0.3386096954345703, 2.1929733753204346, 1.1548700332641602, -0.8604698181152344, -0.22801423072814941, 4.022059917449951, -1.3752617835998535, 0.055260419845581055, 0.9108796119689941, -2.1606664657592773, 0.34469377994537354, 1.8581457138061523, -4.366189479827881, 0.21438884735107422, 0.6207146644592285, 0.32256555557250977, 0.7096099853515625, -0.36609649658203125, -4.775339126586914, -8.840221405029297, 1.7979812622070312, -0.6611232757568359, -0.9867110252380371], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.431020736694336, "min_q": -11.490201950073242, "max_q": -4.178196907043457, "mean_td_error": 0.32214754819869995, "model": {}}, "td_error": [0.2588081359863281, 0.2588081359863281, -0.3026728630065918, 3.201627731323242, 2.2955636978149414, -0.10408401489257812, 0.8381900787353516, 1.1986684799194336, 0.5623612403869629, 0.2711935043334961, 0.1367177963256836, 0.8994588851928711, 0.9284963607788086, 0.9407844543457031, -1.2616472244262695, 1.774923324584961, 3.2731728553771973, 0.517829418182373, 1.5828838348388672, 0.9698386192321777, 0.6420717239379883, 0.06628036499023438, 0.9361433982849121, -9.587850570678711, -1.06898832321167, -2.413790702819824, 0.6011877059936523, 2.837787628173828, 0.48184728622436523, 1.675018310546875, -1.0186729431152344, -1.0832347869873047], "custom_metrics": {}}}, "num_steps_sampled": 1437, "num_agent_steps_sampled": 2874, "num_steps_trained": 800, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 1600, "last_target_update_ts": 1344, "num_target_updates": 4}, "done": false, "episodes_total": 79, "training_iteration": 3, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-26", "timestamp": 1648811666, "time_this_iter_s": 0.9856326580047607, "time_total_s": 5.542142391204834, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848def0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848def0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5.542142391204834, "timesteps_since_restore": 96, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 40.400000000000006, "ram_util_percent": 65.55}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.118279569892472, "episode_len_mean": 17.774193548387096, "episode_media": {}, "episodes_this_iter": 14, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -10.35483870967742, "policy1": -14.763440860215054}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -4.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, 8.0, -40.0, -30.0, 2.0, -30.0, -30.0, -30.0, -30.0, 10.0, 4.0, -30.0, -30.0, -30.0, -40.0, -40.0, -10.0, -30.0, -30.0, -30.0, -30.0, 8.0, -30.0, -40.0, -30.0, -18.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, 4.0, -30.0, -30.0, 4.0, -40.0, -14.0, -30.0, -30.0, 4.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, -4.0, -14.0, -30.0, -30.0, -30.0, -6.0, -30.0, -30.0, -40.0, -40.0, -4.0, 2.0, -30.0, 12.0, -40.0, 12.0, -30.0, -2.0, -30.0, -12.0, -30.0], "episode_lengths": [20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 9, 20, 20, 20, 20, 5, 8, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 6, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 8, 20, 17, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 17, 20, 20, 20, 13, 20, 20, 20, 20, 12, 9, 20, 4, 20, 4, 20, 11, 20, 16, 20], "policy_policy0_reward": [-10.0, -10.0, 8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, 4.0, -20.0, -10.0, -9.0, -10.0, -10.0, -10.0, -20.0, 5.0, 2.0, -10.0, -10.0, -10.0, -20.0, -20.0, -5.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 2.0, -20.0, -7.0, -20.0, -10.0, 2.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, -10.0, 8.0, -7.0, -10.0, -20.0, -10.0, -3.0, -10.0, -10.0, -20.0, -20.0, 8.0, 1.0, -10.0, 6.0, -20.0, 6.0, -10.0, 9.0, -20.0, 4.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -12.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, 5.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 2.0, -20.0, -7.0, -10.0, -20.0, 2.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -14.0, -20.0, -20.0, -20.0, -20.0, -12.0, -7.0, -20.0, -10.0, -20.0, -3.0, -20.0, -20.0, -20.0, -20.0, -12.0, 1.0, -20.0, 6.0, -20.0, 6.0, -20.0, -11.0, -10.0, -16.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3314061081002478, "mean_inference_ms": 1.9110279185844303, "mean_action_processing_ms": 0.12534376307807646, "mean_env_wait_ms": 0.07817259145678102, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1653, "timesteps_this_iter": 32, "agent_timesteps_total": 3306, "timers": {"load_time_ms": 0.538, "load_throughput": 59530.617, "learn_time_ms": 10.217, "learn_throughput": 3131.962, "update_time_ms": 7.752}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -5.877834320068359, "min_q": -7.6773223876953125, "max_q": -2.307121515274048, "mean_td_error": -1.7474021911621094, "model": {}}, "td_error": [-3.5334315299987793, 0.48969173431396484, 0.33335304260253906, 0.214630126953125, -9.418207168579102, -0.25502538681030273, 0.023906707763671875, 0.214630126953125, -6.6773223876953125, 0.4379091262817383, -13.16775131225586, 0.3623385429382324, -0.8787617683410645, -5.246376037597656, -0.6536908149719238, 1.1410455703735352, 2.0359840393066406, 0.3510427474975586, -0.5982527732849121, -11.649081230163574, -6.456544399261475, -0.1001439094543457, -1.3909187316894531, 1.1362438201904297, 1.0611176490783691, 1.3554692268371582, -0.010901451110839844, 3.1154778003692627, 0.023906707763671875, -0.03325700759887695, -3.6388750076293945, -4.505076885223389], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.395007133483887, "min_q": -12.90609359741211, "max_q": -6.197009563446045, "mean_td_error": -0.8923975825309753, "model": {}}, "td_error": [0.9661960601806641, 0.8395571708679199, -3.423534870147705, -0.06214332580566406, -0.16314077377319336, -0.5026955604553223, -0.2993144989013672, -0.17438030242919922, -0.1777944564819336, -0.051016807556152344, -1.3459539413452148, -3.087484359741211, -0.23031139373779297, -0.24613666534423828, -0.2012157440185547, 0.01936054229736328, -0.8246092796325684, -7.5927534103393555, 0.21949481964111328, -0.2738971710205078, -0.12784099578857422, -0.9071264266967773, -0.22601604461669922, -0.1775655746459961, 1.1619758605957031, 0.3243684768676758, -0.10136985778808594, -0.10600662231445312, 0.9541654586791992, -11.567902565002441, 0.1392688751220703, -1.310898780822754], "custom_metrics": {}}}, "num_steps_sampled": 1653, "num_agent_steps_sampled": 3306, "num_steps_trained": 1248, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 2496, "last_target_update_ts": 1562, "num_target_updates": 6}, "done": false, "episodes_total": 93, "training_iteration": 4, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-27", "timestamp": 1648811667, "time_this_iter_s": 1.1792595386505127, "time_total_s": 6.721401929855347, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bcef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bcef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6.721401929855347, "timesteps_since_restore": 128, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 37.2, "ram_util_percent": 58.7}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.62, "episode_len_mean": 18.01, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -10.71, "policy1": -14.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, 8.0, -40.0, -30.0, 2.0, -30.0, -30.0, -30.0, -30.0, 10.0, 4.0, -30.0, -30.0, -30.0, -40.0, -40.0, -10.0, -30.0, -30.0, -30.0, -30.0, 8.0, -30.0, -40.0, -30.0, -18.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, 4.0, -30.0, -30.0, 4.0, -40.0, -14.0, -30.0, -30.0, 4.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, -4.0, -14.0, -30.0, -30.0, -30.0, -6.0, -30.0, -30.0, -40.0, -40.0, -4.0, 2.0, -30.0, 12.0, -40.0, 12.0, -30.0, -2.0, -30.0, -12.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -20.0, -30.0, -30.0, -30.0, -40.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 9, 20, 20, 20, 20, 5, 8, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 6, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 8, 20, 17, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 17, 20, 20, 20, 13, 20, 20, 20, 20, 12, 9, 20, 4, 20, 4, 20, 11, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, 4.0, -20.0, -10.0, -9.0, -10.0, -10.0, -10.0, -20.0, 5.0, 2.0, -10.0, -10.0, -10.0, -20.0, -20.0, -5.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 2.0, -20.0, -7.0, -20.0, -10.0, 2.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, -10.0, 8.0, -7.0, -10.0, -20.0, -10.0, -3.0, -10.0, -10.0, -20.0, -20.0, 8.0, 1.0, -10.0, 6.0, -20.0, 6.0, -10.0, 9.0, -20.0, 4.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 4.0, -20.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, 5.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 2.0, -20.0, -7.0, -10.0, -20.0, 2.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -14.0, -20.0, -20.0, -20.0, -20.0, -12.0, -7.0, -20.0, -10.0, -20.0, -3.0, -20.0, -20.0, -20.0, -20.0, -12.0, 1.0, -20.0, 6.0, -20.0, 6.0, -20.0, -11.0, -10.0, -16.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33344074204080504, "mean_inference_ms": 1.913484359928139, "mean_action_processing_ms": 0.12607907944112295, "mean_env_wait_ms": 0.07847142092566398, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1953, "timesteps_this_iter": 32, "agent_timesteps_total": 3906, "timers": {"load_time_ms": 0.481, "load_throughput": 66543.246, "learn_time_ms": 8.147, "learn_throughput": 3927.711, "update_time_ms": 6.398}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.391827583312988, "min_q": -10.047473907470703, "max_q": -6.071625232696533, "mean_td_error": -1.009295105934143, "model": {}}, "td_error": [-0.4765462875366211, 0.06740856170654297, -0.004368782043457031, 0.49622440338134766, 0.5280623435974121, 0.7305307388305664, -1.4739370346069336, 0.2478342056274414, 0.34249210357666016, 0.16060638427734375, 0.4027252197265625, -0.4765462875366211, -1.8616433143615723, -0.03574371337890625, -0.3587503433227539, 0.40378808975219727, 0.6162128448486328, 0.440859317779541, -6.93316650390625, 0.5548896789550781, -0.08636188507080078, -0.73162841796875, 0.25000667572021484, -0.4264521598815918, 0.08675765991210938, -8.065793991088867, -0.7740001678466797, -5.1573944091796875, -11.835226058959961, 0.051987648010253906, 0.4178133010864258, 0.6019172668457031], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.942862510681152, "min_q": -12.442625999450684, "max_q": 1.0262646675109863, "mean_td_error": -1.99196457862854, "model": {}}, "td_error": [-0.5238304138183594, 1.1919755935668945, -1.2403888702392578, -0.11085033416748047, -0.2885704040527344, 0.2667503356933594, 1.5434389114379883, -1.2289304733276367, -0.47318077087402344, -11.30848217010498, 0.09776878356933594, -0.804232120513916, -10.139901161193848, -0.3226766586303711, -0.9588093757629395, -9.859989166259766, 1.1919755935668945, -10.495774269104004, 0.17392635345458984, 0.23467636108398438, 2.130967617034912, -10.239015579223633, -1.4511826038360596, -10.915445327758789, -1.3506345748901367, -3.008995532989502, -1.275376319885254, 0.06559371948242188, 3.7031192779541016, 0.14960479736328125, 1.020218849182129, 0.4833841323852539], "custom_metrics": {}}}, "num_steps_sampled": 1953, "num_agent_steps_sampled": 3906, "num_steps_trained": 1728, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 3456, "last_target_update_ts": 1913, "num_target_updates": 9}, "done": false, "episodes_total": 108, "training_iteration": 5, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-29", "timestamp": 1648811669, "time_this_iter_s": 1.2897584438323975, "time_total_s": 8.011160373687744, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584aee60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584aee60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 8.011160373687744, "timesteps_since_restore": 160, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 30.35, "ram_util_percent": 58.8}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.58, "episode_len_mean": 17.79, "episode_media": {}, "episodes_this_iter": 13, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -9.89, "policy1": -14.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, -30.0, -30.0, -30.0, -30.0, 10.0, 4.0, -30.0, -30.0, -30.0, -40.0, -40.0, -10.0, -30.0, -30.0, -30.0, -30.0, 8.0, -30.0, -40.0, -30.0, -18.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, 4.0, -30.0, -30.0, 4.0, -40.0, -14.0, -30.0, -30.0, 4.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, -4.0, -14.0, -30.0, -30.0, -30.0, -6.0, -30.0, -30.0, -40.0, -40.0, -4.0, 2.0, -30.0, 12.0, -40.0, 12.0, -30.0, -2.0, -30.0, -12.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -20.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, 12.0, 0.0, -40.0, -30.0, -20.0, 0.0, -30.0, -40.0, -30.0, -30.0], "episode_lengths": [9, 20, 20, 20, 20, 5, 8, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 6, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 8, 20, 17, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 17, 20, 20, 20, 13, 20, 20, 20, 20, 12, 9, 20, 4, 20, 4, 20, 11, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 10, 20, 20, 20, 10, 20, 20, 20, 20], "policy_policy0_reward": [-9.0, -10.0, -10.0, -10.0, -20.0, 5.0, 2.0, -10.0, -10.0, -10.0, -20.0, -20.0, -5.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 2.0, -20.0, -7.0, -20.0, -10.0, 2.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, -10.0, 8.0, -7.0, -10.0, -20.0, -10.0, -3.0, -10.0, -10.0, -20.0, -20.0, 8.0, 1.0, -10.0, 6.0, -20.0, 6.0, -10.0, 9.0, -20.0, 4.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, 10.0, -20.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [11.0, -20.0, -20.0, -20.0, -10.0, 5.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 2.0, -20.0, -7.0, -10.0, -20.0, 2.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -14.0, -20.0, -20.0, -20.0, -20.0, -12.0, -7.0, -20.0, -10.0, -20.0, -3.0, -20.0, -20.0, -20.0, -20.0, -12.0, 1.0, -20.0, 6.0, -20.0, 6.0, -20.0, -11.0, -10.0, -16.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33579484756912636, "mean_inference_ms": 1.9173196788936002, "mean_action_processing_ms": 0.12699726732701166, "mean_env_wait_ms": 0.07883416747793819, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2177, "timesteps_this_iter": 32, "agent_timesteps_total": 4354, "timers": {"load_time_ms": 0.495, "load_throughput": 64620.957, "learn_time_ms": 8.07, "learn_throughput": 3965.167, "update_time_ms": 6.336}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.144460678100586, "min_q": -11.741578102111816, "max_q": -4.749629974365234, "mean_td_error": -1.0613231658935547, "model": {}}, "td_error": [2.351858615875244, -0.5320634841918945, -0.5604705810546875, -0.6657371520996094, -0.5815515518188477, -0.8488683700561523, -0.6836671829223633, -0.6645183563232422, -0.45864391326904297, -1.6291584968566895, -2.413106918334961, -0.599370002746582, -0.583104133605957, -0.9239044189453125, -1.0665388107299805, -0.3425331115722656, -0.2927722930908203, -4.723797798156738, -0.4370126724243164, -1.0658531188964844, -0.29763126373291016, -0.43583250045776367, -1.7028989791870117, -0.2952232360839844, 1.5512566566467285, -8.56026554107666, -0.6639232635498047, -0.20543193817138672, -2.5607833862304688, 0.03883552551269531, -3.8125405311584473, -0.2970905303955078], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.30706787109375, "min_q": -15.50329303741455, "max_q": 0.8977267742156982, "mean_td_error": -2.9103803634643555, "model": {}}, "td_error": [-2.033658981323242, -1.8833694458007812, -0.30643558502197266, 0.0986170768737793, 2.0525999069213867, -0.041554778814315796, -1.4582228660583496, -0.12372016906738281, -12.212667465209961, -0.9147024154663086, -2.0086781978607178, -13.941006660461426, -0.38245487213134766, -0.7603287696838379, -12.193867683410645, -13.752026557922363, -2.0896692276000977, -0.9476470947265625, -13.722942352294922, -0.4278421401977539, -0.4061717987060547, -0.8747310638427734, -0.8937935829162598, -0.5378885269165039, -0.0222625732421875, -0.6597223281860352, -0.9959583282470703, -5.444454193115234, -3.6020078659057617, -0.9463138580322266, -1.5751457214355469, -0.12413883209228516], "custom_metrics": {}}}, "num_steps_sampled": 2177, "num_agent_steps_sampled": 4354, "num_steps_trained": 2144, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 4288, "last_target_update_ts": 2137, "num_target_updates": 11}, "done": false, "episodes_total": 121, "training_iteration": 6, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-30", "timestamp": 1648811670, "time_this_iter_s": 1.0698895454406738, "time_total_s": 9.081049919128418, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58526c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58526c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 9.081049919128418, "timesteps_since_restore": 192, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 33.599999999999994, "ram_util_percent": 58.55}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.08, "episode_len_mean": 17.89, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 6.0}, "policy_reward_mean": {"policy0": -10.09, "policy1": -14.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.0, -30.0, -30.0, -30.0, -30.0, 8.0, -30.0, -40.0, -30.0, -18.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, 4.0, -30.0, -30.0, 4.0, -40.0, -14.0, -30.0, -30.0, 4.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, -4.0, -14.0, -30.0, -30.0, -30.0, -6.0, -30.0, -30.0, -40.0, -40.0, -4.0, 2.0, -30.0, 12.0, -40.0, 12.0, -30.0, -2.0, -30.0, -12.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -20.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, 12.0, 0.0, -40.0, -30.0, -20.0, 0.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, 6.0, -30.0, -30.0, 10.0, -30.0, -40.0], "episode_lengths": [15, 20, 20, 20, 20, 6, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 8, 20, 17, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 17, 20, 20, 20, 13, 20, 20, 20, 20, 12, 9, 20, 4, 20, 4, 20, 11, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 10, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 5, 20, 20], "policy_policy0_reward": [-5.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -20.0, -9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 2.0, -20.0, -7.0, -20.0, -10.0, 2.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, -10.0, 8.0, -7.0, -10.0, -20.0, -10.0, -3.0, -10.0, -10.0, -20.0, -20.0, 8.0, 1.0, -10.0, 6.0, -20.0, 6.0, -10.0, 9.0, -20.0, 4.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, 10.0, -20.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 3.0, -10.0, -10.0, 5.0, -20.0, -20.0], "policy_policy1_reward": [-5.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 2.0, -20.0, -7.0, -10.0, -20.0, 2.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -14.0, -20.0, -20.0, -20.0, -20.0, -12.0, -7.0, -20.0, -10.0, -20.0, -3.0, -20.0, -20.0, -20.0, -20.0, -12.0, 1.0, -20.0, 6.0, -20.0, 6.0, -20.0, -11.0, -10.0, -16.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, 5.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3376877742937166, "mean_inference_ms": 1.9189641558426576, "mean_action_processing_ms": 0.12774978509098797, "mean_env_wait_ms": 0.07913595274057901, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2389, "timesteps_this_iter": 32, "agent_timesteps_total": 4778, "timers": {"load_time_ms": 0.43, "load_throughput": 74334.143, "learn_time_ms": 7.515, "learn_throughput": 4258.109, "update_time_ms": 6.017}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.173198699951172, "min_q": -12.497425079345703, "max_q": -7.247704982757568, "mean_td_error": -1.0460535287857056, "model": {}}, "td_error": [1.000990867614746, 0.3788175582885742, 0.6465959548950195, 0.5941629409790039, 0.33786964416503906, 1.11773681640625, 0.9076108932495117, 0.7868289947509766, 0.18289756774902344, -19.678874969482422, -0.7815179824829102, 0.03730010986328125, 1.9614315032958984, 0.6468687057495117, 0.10662460327148438, 0.3989849090576172, -0.284423828125, 0.10304450988769531, 0.19674968719482422, -8.265604972839355, 0.7179746627807617, 1.397939682006836, 0.03730010986328125, 1.706282615661621, 0.5693931579589844, 0.760589599609375, -1.390493392944336, -12.023591041564941, 0.7261228561401367, 0.7888326644897461, -8.006101608276367, 0.8479433059692383], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.064434051513672, "min_q": -15.272172927856445, "max_q": -0.39501839876174927, "mean_td_error": -2.674739122390747, "model": {}}, "td_error": [0.06507587432861328, 0.7222442626953125, -0.3480968475341797, 0.19157791137695312, 1.4087514877319336, 0.1984405517578125, -9.111499786376953, 0.015332221984863281, -0.32644081115722656, -0.6131162643432617, -10.622456550598145, -3.0757036209106445, -3.065549850463867, 1.027130126953125, -2.7179784774780273, 0.05337047576904297, -0.2335948944091797, -4.09066104888916, -13.915291786193848, 0.4671640396118164, 0.4966259002685547, -9.129867553710938, 0.4177073836326599, -0.4323558807373047, 0.8030004501342773, -1.3125314712524414, 0.07187461853027344, 0.8897228240966797, 1.5737786293029785, -23.4855899810791, 0.16429877281188965, -11.677011489868164], "custom_metrics": {}}}, "num_steps_sampled": 2389, "num_agent_steps_sampled": 4778, "num_steps_trained": 2528, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 5056, "last_target_update_ts": 2369, "num_target_updates": 13}, "done": false, "episodes_total": 133, "training_iteration": 7, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-31", "timestamp": 1648811671, "time_this_iter_s": 1.0171055793762207, "time_total_s": 10.098155498504639, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 10.098155498504639, "timesteps_since_restore": 224, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 30.4, "ram_util_percent": 58.3}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.12, "episode_len_mean": 17.76, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 10.0, "policy1": 6.0}, "policy_reward_mean": {"policy0": -9.96, "policy1": -15.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, 4.0, -30.0, -30.0, 4.0, -40.0, -14.0, -30.0, -30.0, 4.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, -4.0, -14.0, -30.0, -30.0, -30.0, -6.0, -30.0, -30.0, -40.0, -40.0, -4.0, 2.0, -30.0, 12.0, -40.0, 12.0, -30.0, -2.0, -30.0, -12.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -20.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, 12.0, 0.0, -40.0, -30.0, -20.0, 0.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, 6.0, -30.0, -30.0, 10.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, 10.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -4.0, 0.0, -30.0, -30.0], "episode_lengths": [20, 20, 8, 20, 20, 8, 20, 17, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 12, 17, 20, 20, 20, 13, 20, 20, 20, 20, 12, 9, 20, 4, 20, 4, 20, 11, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 10, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 5, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 12, 10, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 2.0, -10.0, -10.0, 2.0, -20.0, -7.0, -20.0, -10.0, 2.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, -10.0, 8.0, -7.0, -10.0, -20.0, -10.0, -3.0, -10.0, -10.0, -20.0, -20.0, 8.0, 1.0, -10.0, 6.0, -20.0, 6.0, -10.0, 9.0, -20.0, 4.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, 10.0, -20.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 3.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, 8.0, 10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, 2.0, -20.0, -20.0, 2.0, -20.0, -7.0, -10.0, -20.0, 2.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -14.0, -20.0, -20.0, -20.0, -20.0, -12.0, -7.0, -20.0, -10.0, -20.0, -3.0, -20.0, -20.0, -20.0, -20.0, -12.0, 1.0, -20.0, 6.0, -20.0, 6.0, -20.0, -11.0, -10.0, -16.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, 5.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -12.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33971918155598596, "mean_inference_ms": 1.917267889358813, "mean_action_processing_ms": 0.12861441034981902, "mean_env_wait_ms": 0.07946690810253271, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2696, "timesteps_this_iter": 32, "agent_timesteps_total": 5392, "timers": {"load_time_ms": 0.431, "load_throughput": 74214.945, "learn_time_ms": 7.308, "learn_throughput": 4378.888, "update_time_ms": 6.156}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.363431930541992, "min_q": -13.016195297241211, "max_q": -8.079879760742188, "mean_td_error": -2.1587748527526855, "model": {}}, "td_error": [0.9889087677001953, 0.7590808868408203, 0.5673866271972656, 1.1908159255981445, -10.828792572021484, 0.7649602890014648, 0.7208099365234375, -1.5949549674987793, 0.5439338684082031, -8.384613990783691, 1.020883560180664, 1.125004768371582, -11.564550399780273, -11.232871055603027, 1.0473289489746094, 1.3061504364013672, 0.7014932632446289, 1.457047462463379, -10.47067642211914, 0.8199119567871094, 0.8671884536743164, -21.229808807373047, 1.0655221939086914, 1.0228681564331055, 1.8412561416625977, 1.4328269958496094, 0.9005203247070312, 2.704853057861328, 0.8139257431030273, -10.960577964782715, 0.8985986709594727, -7.375223159790039], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -12.489094734191895, "min_q": -16.049095153808594, "max_q": 1.188703179359436, "mean_td_error": -2.980311632156372, "model": {}}, "td_error": [-0.32506370544433594, -2.859896659851074, -14.868465423583984, 1.7209405899047852, -0.34887027740478516, -13.94223690032959, 0.48860740661621094, -0.39905834197998047, -6.138598442077637, -0.0674600601196289, -0.002899169921875, 0.5125331878662109, -0.1457204818725586, -0.7085723876953125, -15.049095153808594, 3.2725706100463867, -14.296979904174805, 0.3619871139526367, 2.390915870666504, -0.518957257270813, 1.8262968063354492, 0.20786094665527344, -0.2991781234741211, 0.1585521697998047, -13.325398445129395, 2.822464942932129, 0.20786094665527344, 1.374006986618042, -0.19355010986328125, -12.685888290405273, -14.896859169006348, 0.35817718505859375], "custom_metrics": {}}}, "num_steps_sampled": 2696, "num_agent_steps_sampled": 5392, "num_steps_trained": 3072, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 6144, "last_target_update_ts": 2696, "num_target_updates": 16}, "done": false, "episodes_total": 150, "training_iteration": 8, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-32", "timestamp": 1648811672, "time_this_iter_s": 1.2209043502807617, "time_total_s": 11.3190598487854, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 11.3190598487854, "timesteps_since_restore": 256, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 30.75, "ram_util_percent": 58.3}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.86, "episode_len_mean": 17.68, "episode_media": {}, "episodes_this_iter": 14, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 10.0, "policy1": 6.0}, "policy_reward_mean": {"policy0": -9.88, "policy1": -14.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, -4.0, -14.0, -30.0, -30.0, -30.0, -6.0, -30.0, -30.0, -40.0, -40.0, -4.0, 2.0, -30.0, 12.0, -40.0, 12.0, -30.0, -2.0, -30.0, -12.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -20.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, 12.0, 0.0, -40.0, -30.0, -20.0, 0.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, 6.0, -30.0, -30.0, 10.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, 10.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -4.0, 0.0, -30.0, -30.0, -2.0, -18.0, 4.0, -40.0, -30.0, -30.0, -30.0, 12.0, -40.0, -30.0, -2.0, -30.0, -40.0, -30.0], "episode_lengths": [20, 20, 20, 14, 20, 20, 20, 20, 12, 17, 20, 20, 20, 13, 20, 20, 20, 20, 12, 9, 20, 4, 20, 4, 20, 11, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 10, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 5, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 12, 10, 20, 20, 11, 19, 8, 20, 20, 20, 20, 4, 20, 20, 11, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, -10.0, 8.0, -7.0, -10.0, -20.0, -10.0, -3.0, -10.0, -10.0, -20.0, -20.0, 8.0, 1.0, -10.0, 6.0, -20.0, 6.0, -10.0, 9.0, -20.0, 4.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, 10.0, -20.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 3.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, 8.0, 10.0, -10.0, -10.0, -1.0, -9.0, 2.0, -20.0, -10.0, -20.0, -10.0, 6.0, -20.0, -10.0, -1.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -14.0, -20.0, -20.0, -20.0, -20.0, -12.0, -7.0, -20.0, -10.0, -20.0, -3.0, -20.0, -20.0, -20.0, -20.0, -12.0, 1.0, -20.0, 6.0, -20.0, 6.0, -20.0, -11.0, -10.0, -16.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, 5.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -12.0, -10.0, -20.0, -20.0, -1.0, -9.0, 2.0, -20.0, -20.0, -10.0, -20.0, 6.0, -20.0, -20.0, -1.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34105579026685773, "mean_inference_ms": 1.915417761276587, "mean_action_processing_ms": 0.12920134601705052, "mean_env_wait_ms": 0.07968553012080158, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2929, "timesteps_this_iter": 32, "agent_timesteps_total": 5858, "timers": {"load_time_ms": 0.487, "load_throughput": 65722.127, "learn_time_ms": 7.897, "learn_throughput": 4051.942, "update_time_ms": 6.514}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -12.25348949432373, "min_q": -14.05331039428711, "max_q": -5.616970062255859, "mean_td_error": -4.056751728057861, "model": {}}, "td_error": [-8.623384475708008, 0.30065250396728516, 0.8008832931518555, -0.2732276916503906, -11.396535873413086, 0.03695106506347656, -12.25283145904541, 0.7411746978759766, -20.833953857421875, -0.07403182983398438, 0.1346578598022461, -2.7445449829101562, 0.49153614044189453, -11.138251304626465, 0.8010149002075195, 0.3483247756958008, -0.8127727508544922, 0.77520751953125, -12.402524948120117, 0.6753473281860352, -9.67986011505127, -1.1701507568359375, -10.186386108398438, -0.3212308883666992, -21.168373107910156, 0.31873321533203125, -1.0650835037231445, 0.34815216064453125, -0.4881105422973633, -12.356765747070312, 0.6779518127441406, 0.7213802337646484], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.207853317260742, "min_q": -14.668989181518555, "max_q": -1.1237170696258545, "mean_td_error": -1.2264081239700317, "model": {}}, "td_error": [-1.0478088855743408, -0.3439750671386719, -9.556259155273438, 0.7561235427856445, -11.9539155960083, -0.7855901718139648, -9.765045166015625, -0.16257286071777344, 0.30422306060791016, 0.39513397216796875, 0.6529340744018555, 1.2147941589355469, 0.10663986206054688, 0.30683135986328125, -13.598037719726562, 0.9166464805603027, 0.4923410415649414, 0.4836406707763672, -0.5946945548057556, -0.36746788024902344, 0.3647317886352539, 0.03885078430175781, 0.32302093505859375, 0.4094061851501465, -0.8576126098632812, 0.7976045608520508, 0.22155380249023438, 0.4757671356201172, 0.2748079299926758, -0.18024230003356934, 0.37931370735168457, 1.0537967681884766], "custom_metrics": {}}}, "num_steps_sampled": 2929, "num_agent_steps_sampled": 5858, "num_steps_trained": 3520, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 7040, "last_target_update_ts": 2929, "num_target_updates": 18}, "done": false, "episodes_total": 164, "training_iteration": 9, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-33", "timestamp": 1648811673, "time_this_iter_s": 0.9731624126434326, "time_total_s": 12.292222261428833, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584ae8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584ae8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 12.292222261428833, "timesteps_since_restore": 288, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 31.55, "ram_util_percent": 58.349999999999994}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.76, "episode_len_mean": 17.28, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 10.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -9.68, "policy1": -14.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, 12.0, -40.0, 12.0, -30.0, -2.0, -30.0, -12.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -20.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, 12.0, 0.0, -40.0, -30.0, -20.0, 0.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, 6.0, -30.0, -30.0, 10.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, 10.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -4.0, 0.0, -30.0, -30.0, -2.0, -18.0, 4.0, -40.0, -30.0, -30.0, -30.0, 12.0, -40.0, -30.0, -2.0, -30.0, -40.0, -30.0, 10.0, -30.0, -30.0, 2.0, -40.0, 2.0, -30.0, 14.0, -14.0, -30.0, -30.0, 8.0, -30.0, -30.0, -14.0, -10.0, -12.0, -30.0, -30.0, -40.0], "episode_lengths": [20, 4, 20, 4, 20, 11, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 10, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 5, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 12, 10, 20, 20, 11, 19, 8, 20, 20, 20, 20, 4, 20, 20, 11, 20, 20, 20, 5, 20, 20, 9, 20, 9, 20, 3, 17, 20, 20, 6, 20, 20, 17, 15, 16, 20, 20, 20], "policy_policy0_reward": [-10.0, 6.0, -20.0, 6.0, -10.0, 9.0, -20.0, 4.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, 10.0, -20.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 3.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, 8.0, 10.0, -10.0, -10.0, -1.0, -9.0, 2.0, -20.0, -10.0, -20.0, -10.0, 6.0, -20.0, -10.0, -1.0, -10.0, -20.0, -10.0, 5.0, -20.0, -20.0, 1.0, -20.0, 1.0, -10.0, 7.0, 3.0, -10.0, -10.0, 4.0, -10.0, -10.0, -7.0, -5.0, -16.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, 6.0, -20.0, 6.0, -20.0, -11.0, -10.0, -16.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, 5.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -12.0, -10.0, -20.0, -20.0, -1.0, -9.0, 2.0, -20.0, -20.0, -10.0, -20.0, 6.0, -20.0, -20.0, -1.0, -20.0, -20.0, -20.0, 5.0, -10.0, -10.0, 1.0, -20.0, 1.0, -20.0, 7.0, -17.0, -20.0, -20.0, 4.0, -20.0, -20.0, -7.0, -5.0, 4.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3419723418602957, "mean_inference_ms": 1.9103968552976784, "mean_action_processing_ms": 0.1294957818772698, "mean_env_wait_ms": 0.07987127216218819, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3246, "timesteps_this_iter": 32, "agent_timesteps_total": 6492, "timers": {"load_time_ms": 0.441, "load_throughput": 72538.36, "learn_time_ms": 8.087, "learn_throughput": 3957.101, "update_time_ms": 6.247}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.012757301330566, "min_q": -14.747806549072266, "max_q": -11.453003883361816, "mean_td_error": -4.7590436935424805, "model": {}}, "td_error": [-0.26389217376708984, -0.10158443450927734, -2.0269079208374023, 1.2310686111450195, 0.3457183837890625, -10.87320613861084, -12.27692985534668, -3.3141965866088867, -4.896604537963867, -12.02198600769043, -20.97736167907715, -0.8702058792114258, 0.9111099243164062, -21.094852447509766, -0.18583202362060547, -13.206036567687988, 0.20181941986083984, 0.6738948822021484, -5.848177433013916, 0.5786733627319336, 0.821629524230957, 0.5070724487304688, -9.685867309570312, 0.2701864242553711, -21.53986358642578, 0.2795877456665039, 0.051792144775390625, -7.225183486938477, 1.129044532775879, -12.93967342376709, 0.05179023742675781, 0.005580902099609375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -9.97639274597168, "min_q": -16.44593048095703, "max_q": 1.8977153301239014, "mean_td_error": -2.495312452316284, "model": {}}, "td_error": [1.559164047241211, -0.25586986541748047, -1.6760683059692383, -7.1022844314575195, 0.20442771911621094, -13.712368965148926, 2.128756523132324, 0.18539607524871826, 0.6034736633300781, 0.5369739532470703, -13.630575180053711, 1.3827199935913086, 1.4003620147705078, -0.01849079132080078, 1.639021873474121, -8.569479942321777, -13.890039443969727, 4.329636573791504, 1.357828140258789, -0.19314956665039062, -14.986831665039062, 1.3219518661499023, -11.397984504699707, 4.612260818481445, -3.264204978942871, 0.6301689147949219, 3.4170103073120117, -1.1538124084472656, -7.367247581481934, -9.796735763549805, 0.9485416412353516, 0.9074532985687256], "custom_metrics": {}}}, "num_steps_sampled": 3246, "num_agent_steps_sampled": 6492, "num_steps_trained": 4128, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 8256, "last_target_update_ts": 3246, "num_target_updates": 21}, "done": false, "episodes_total": 184, "training_iteration": 10, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-34", "timestamp": 1648811674, "time_this_iter_s": 1.3528437614440918, "time_total_s": 13.645066022872925, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 13.645066022872925, "timesteps_since_restore": 320, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 30.6, "ram_util_percent": 58.4}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.42, "episode_len_mean": 17.11, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -9.41, "policy1": -14.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, 12.0, 0.0, -40.0, -30.0, -20.0, 0.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, 6.0, -30.0, -30.0, 10.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, 10.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -4.0, 0.0, -30.0, -30.0, -2.0, -18.0, 4.0, -40.0, -30.0, -30.0, -30.0, 12.0, -40.0, -30.0, -2.0, -30.0, -40.0, -30.0, 10.0, -30.0, -30.0, 2.0, -40.0, 2.0, -30.0, 14.0, -14.0, -30.0, -30.0, 8.0, -30.0, -30.0, -14.0, -10.0, -12.0, -30.0, -30.0, -40.0, -30.0, -40.0, -6.0, -30.0, -30.0, -40.0, -30.0, -30.0, -16.0, 12.0, -30.0, -40.0, 2.0, -30.0, 4.0, -12.0, 0.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 4, 10, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 5, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 12, 10, 20, 20, 11, 19, 8, 20, 20, 20, 20, 4, 20, 20, 11, 20, 20, 20, 5, 20, 20, 9, 20, 9, 20, 3, 17, 20, 20, 6, 20, 20, 17, 15, 16, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 18, 4, 20, 20, 9, 20, 8, 16, 10, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, 10.0, -20.0, -10.0, -10.0, 10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 3.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, 8.0, 10.0, -10.0, -10.0, -1.0, -9.0, 2.0, -20.0, -10.0, -20.0, -10.0, 6.0, -20.0, -10.0, -1.0, -10.0, -20.0, -10.0, 5.0, -20.0, -20.0, 1.0, -20.0, 1.0, -10.0, 7.0, 3.0, -10.0, -10.0, 4.0, -10.0, -10.0, -7.0, -5.0, -16.0, -10.0, -10.0, -20.0, -10.0, -20.0, -13.0, -20.0, -10.0, -20.0, -10.0, -10.0, 2.0, 6.0, -10.0, -20.0, 1.0, -10.0, 12.0, -6.0, 10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, 5.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -12.0, -10.0, -20.0, -20.0, -1.0, -9.0, 2.0, -20.0, -20.0, -10.0, -20.0, 6.0, -20.0, -20.0, -1.0, -20.0, -20.0, -20.0, 5.0, -10.0, -10.0, 1.0, -20.0, 1.0, -20.0, 7.0, -17.0, -20.0, -20.0, 4.0, -20.0, -20.0, -7.0, -5.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 7.0, -10.0, -20.0, -20.0, -20.0, -20.0, -18.0, 6.0, -20.0, -20.0, 1.0, -20.0, -8.0, -6.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3405425266490799, "mean_inference_ms": 1.8966138867726312, "mean_action_processing_ms": 0.12895279689776745, "mean_env_wait_ms": 0.07957570966347868, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3564, "timesteps_this_iter": 32, "agent_timesteps_total": 7128, "timers": {"load_time_ms": 0.432, "load_throughput": 74038.906, "learn_time_ms": 8.051, "learn_throughput": 3974.643, "update_time_ms": 5.713}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -12.012995719909668, "min_q": -14.825644493103027, "max_q": -2.088296890258789, "mean_td_error": -3.5402965545654297, "model": {}}, "td_error": [1.009139060974121, -0.4919242858886719, 0.17667293548583984, -13.588800430297852, -0.8579034805297852, -21.14846420288086, 0.1215372085571289, 1.2043390274047852, -13.082289695739746, 0.4074068069458008, -20.488040924072266, 0.20755577087402344, 1.1546878814697266, 0.37899112701416016, -4.8325395584106445, 0.03017711639404297, -9.88116455078125, -0.22732973098754883, 0.25026702880859375, 1.068678855895996, -20.948272705078125, 1.3321876525878906, 0.6810035705566406, -0.059157371520996094, 0.9155282974243164, -9.335869789123535, 1.5864009857177734, 0.7324399948120117, 0.774165153503418, 1.4224958419799805, -13.388334274291992, 1.5869293212890625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.490852355957031, "min_q": -16.225418090820312, "max_q": 1.320138931274414, "mean_td_error": -0.6221177577972412, "model": {}}, "td_error": [1.4094009399414062, -13.95556354522705, 2.7150745391845703, 5.839390754699707, -0.552506685256958, 2.5422706604003906, 1.368058204650879, -13.799642562866211, 0.6269493103027344, -1.369088888168335, -0.32024669647216797, 1.4398603439331055, 1.6915693283081055, 1.1986579895019531, 0.5040464401245117, 0.1649484634399414, 2.068596839904785, 1.1362686157226562, 2.592494010925293, 0.5590112209320068, -10.701897621154785, 0.7253458499908447, 1.0480899810791016, -9.224584579467773, 0.7581729888916016, 4.8447418212890625, 1.6728286743164062, 1.2371598482131958, -12.608922004699707, 3.3898515701293945, 1.8945131301879883, 1.197382926940918], "custom_metrics": {}}}, "num_steps_sampled": 3564, "num_agent_steps_sampled": 7128, "num_steps_trained": 4736, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 9472, "last_target_update_ts": 3564, "num_target_updates": 24}, "done": false, "episodes_total": 203, "training_iteration": 11, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-36", "timestamp": 1648811676, "time_this_iter_s": 1.2946619987487793, "time_total_s": 14.939728021621704, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 14.939728021621704, "timesteps_since_restore": 352, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 29.45, "ram_util_percent": 58.4}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -22.86, "episode_len_mean": 16.98, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -9.48, "policy1": -13.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -40.0, -30.0, -40.0, -40.0, 6.0, -30.0, -30.0, 10.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, 10.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -4.0, 0.0, -30.0, -30.0, -2.0, -18.0, 4.0, -40.0, -30.0, -30.0, -30.0, 12.0, -40.0, -30.0, -2.0, -30.0, -40.0, -30.0, 10.0, -30.0, -30.0, 2.0, -40.0, 2.0, -30.0, 14.0, -14.0, -30.0, -30.0, 8.0, -30.0, -30.0, -14.0, -10.0, -12.0, -30.0, -30.0, -40.0, -30.0, -40.0, -6.0, -30.0, -30.0, -40.0, -30.0, -30.0, -16.0, 12.0, -30.0, -40.0, 2.0, -30.0, 4.0, -12.0, 0.0, -30.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, 2.0, -30.0, -40.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, -30.0, -4.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 7, 20, 20, 5, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 12, 10, 20, 20, 11, 19, 8, 20, 20, 20, 20, 4, 20, 20, 11, 20, 20, 20, 5, 20, 20, 9, 20, 9, 20, 3, 17, 20, 20, 6, 20, 20, 17, 15, 16, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 18, 4, 20, 20, 9, 20, 8, 16, 10, 20, 20, 20, 20, 20, 8, 20, 9, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 12, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -20.0, 3.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, 8.0, 10.0, -10.0, -10.0, -1.0, -9.0, 2.0, -20.0, -10.0, -20.0, -10.0, 6.0, -20.0, -10.0, -1.0, -10.0, -20.0, -10.0, 5.0, -20.0, -20.0, 1.0, -20.0, 1.0, -10.0, 7.0, 3.0, -10.0, -10.0, 4.0, -10.0, -10.0, -7.0, -5.0, -16.0, -10.0, -10.0, -20.0, -10.0, -20.0, -13.0, -20.0, -10.0, -20.0, -10.0, -10.0, 2.0, 6.0, -10.0, -20.0, 1.0, -10.0, 12.0, -6.0, 10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, -10.0, 1.0, -10.0, -20.0, -10.0, -14.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -2.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, 5.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -12.0, -10.0, -20.0, -20.0, -1.0, -9.0, 2.0, -20.0, -20.0, -10.0, -20.0, 6.0, -20.0, -20.0, -1.0, -20.0, -20.0, -20.0, 5.0, -10.0, -10.0, 1.0, -20.0, 1.0, -20.0, 7.0, -17.0, -20.0, -20.0, 4.0, -20.0, -20.0, -7.0, -5.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 7.0, -10.0, -20.0, -20.0, -20.0, -20.0, -18.0, 6.0, -20.0, -20.0, 1.0, -20.0, -8.0, -6.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -8.0, -20.0, 1.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -10.0, -20.0, -2.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3382685025998071, "mean_inference_ms": 1.8787532900679285, "mean_action_processing_ms": 0.1280014883973209, "mean_env_wait_ms": 0.0791114350685061, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3895, "timesteps_this_iter": 32, "agent_timesteps_total": 7790, "timers": {"load_time_ms": 0.463, "load_throughput": 69120.264, "learn_time_ms": 8.343, "learn_throughput": 3835.428, "update_time_ms": 4.842}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.391525268554688, "min_q": -15.774666786193848, "max_q": -2.606724500656128, "mean_td_error": -2.248404026031494, "model": {}}, "td_error": [1.8797712326049805, -12.205535888671875, -2.880232334136963, -2.207061529159546, 2.5281248092651367, -10.960796356201172, -10.625275611877441, 2.7999584674835205, 4.088303565979004, 1.1749887466430664, -21.195281982421875, -2.836667060852051, 3.2241668701171875, -5.514050483703613, 2.163792610168457, 0.9437780380249023, -8.631120681762695, 1.3093328475952148, -0.39229679107666016, 0.8140573501586914, 3.960394859313965, -11.937750816345215, 3.5575246810913086, 8.463728904724121, -13.624068260192871, -0.5287818908691406, -0.4554023742675781, 1.160003662109375, 0.9633903503417969, 1.768341064453125, -8.352641105651855, -0.40162086486816406], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.567941665649414, "min_q": -17.297380447387695, "max_q": 1.4823806285858154, "mean_td_error": -2.163395881652832, "model": {}}, "td_error": [1.600750207901001, -0.19439125061035156, 1.400376319885254, 0.5491447448730469, 2.0260772705078125, -0.47719287872314453, -0.07065773010253906, -0.3837852478027344, -7.282312393188477, -9.917402267456055, -5.787919998168945, 4.062867164611816, -0.6053380966186523, -1.2282047271728516, -11.286319732666016, -0.015877723693847656, 0.9035511016845703, -1.4925870895385742, -12.771193504333496, 6.994382858276367, -14.495542526245117, -2.543961524963379, -5.355062007904053, -16.297380447387695, -0.3484373092651367, 0.6510038375854492, 2.6027164459228516, 2.446016311645508, 1.386795997619629, 0.7582473754882812, -4.915413856506348, 0.8583793640136719], "custom_metrics": {}}}, "num_steps_sampled": 3895, "num_agent_steps_sampled": 7790, "num_steps_trained": 5344, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 10688, "last_target_update_ts": 3795, "num_target_updates": 26}, "done": false, "episodes_total": 222, "training_iteration": 12, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-37", "timestamp": 1648811677, "time_this_iter_s": 1.3310720920562744, "time_total_s": 16.27080011367798, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 16.27080011367798, "timesteps_since_restore": 384, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 29.15, "ram_util_percent": 58.4}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.0, "episode_len_mean": 16.65, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -8.25, "policy1": -12.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -40.0, -40.0, -30.0, -4.0, 0.0, -30.0, -30.0, -2.0, -18.0, 4.0, -40.0, -30.0, -30.0, -30.0, 12.0, -40.0, -30.0, -2.0, -30.0, -40.0, -30.0, 10.0, -30.0, -30.0, 2.0, -40.0, 2.0, -30.0, 14.0, -14.0, -30.0, -30.0, 8.0, -30.0, -30.0, -14.0, -10.0, -12.0, -30.0, -30.0, -40.0, -30.0, -40.0, -6.0, -30.0, -30.0, -40.0, -30.0, -30.0, -16.0, 12.0, -30.0, -40.0, 2.0, -30.0, 4.0, -12.0, 0.0, -30.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, 2.0, -30.0, -40.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, -30.0, -4.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, 4.0, -2.0, -12.0, -30.0, -40.0, -30.0, -10.0, -30.0, -4.0, -30.0, -30.0, 6.0, -30.0, 10.0, -30.0], "episode_lengths": [20, 20, 20, 20, 12, 10, 20, 20, 11, 19, 8, 20, 20, 20, 20, 4, 20, 20, 11, 20, 20, 20, 5, 20, 20, 9, 20, 9, 20, 3, 17, 20, 20, 6, 20, 20, 17, 15, 16, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 18, 4, 20, 20, 9, 20, 8, 16, 10, 20, 20, 20, 20, 20, 8, 20, 9, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 12, 20, 10, 20, 20, 20, 20, 8, 11, 16, 20, 20, 20, 15, 20, 12, 20, 20, 7, 20, 5, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -10.0, 8.0, 10.0, -10.0, -10.0, -1.0, -9.0, 2.0, -20.0, -10.0, -20.0, -10.0, 6.0, -20.0, -10.0, -1.0, -10.0, -20.0, -10.0, 5.0, -20.0, -20.0, 1.0, -20.0, 1.0, -10.0, 7.0, 3.0, -10.0, -10.0, 4.0, -10.0, -10.0, -7.0, -5.0, -16.0, -10.0, -10.0, -20.0, -10.0, -20.0, -13.0, -20.0, -10.0, -20.0, -10.0, -10.0, 2.0, 6.0, -10.0, -20.0, 1.0, -10.0, 12.0, -6.0, 10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, -10.0, 1.0, -10.0, -20.0, -10.0, -14.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -2.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -1.0, -6.0, -10.0, -20.0, -10.0, -5.0, -10.0, -2.0, -10.0, -20.0, 3.0, -10.0, 5.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -20.0, -12.0, -10.0, -20.0, -20.0, -1.0, -9.0, 2.0, -20.0, -20.0, -10.0, -20.0, 6.0, -20.0, -20.0, -1.0, -20.0, -20.0, -20.0, 5.0, -10.0, -10.0, 1.0, -20.0, 1.0, -20.0, 7.0, -17.0, -20.0, -20.0, 4.0, -20.0, -20.0, -7.0, -5.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 7.0, -10.0, -20.0, -20.0, -20.0, -20.0, -18.0, 6.0, -20.0, -20.0, 1.0, -20.0, -8.0, -6.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -8.0, -20.0, 1.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -10.0, -20.0, -2.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -8.0, -1.0, -6.0, -20.0, -20.0, -20.0, -5.0, -20.0, -2.0, -20.0, -10.0, 3.0, -20.0, 5.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.336224646797266, "mean_inference_ms": 1.8625412970931239, "mean_action_processing_ms": 0.1270502989399337, "mean_env_wait_ms": 0.07864306803637469, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4219, "timesteps_this_iter": 32, "agent_timesteps_total": 8438, "timers": {"load_time_ms": 0.519, "load_throughput": 61601.674, "learn_time_ms": 8.07, "learn_throughput": 3965.202, "update_time_ms": 4.761}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.958402633666992, "min_q": -16.103471755981445, "max_q": -2.816196918487549, "mean_td_error": -2.0039029121398926, "model": {}}, "td_error": [-0.8310561180114746, -12.441620826721191, -0.4464550018310547, -0.9049949645996094, 2.776595115661621, 1.6145811080932617, -8.333603858947754, -4.408325672149658, 0.1408100128173828, -0.6091165542602539, 0.3538827896118164, 1.081319808959961, -6.2039995193481445, -1.9357352256774902, 0.32493019104003906, -18.477863311767578, -14.556681632995605, -1.9357352256774902, -0.02058124542236328, 0.5415163040161133, 1.7836189270019531, -0.6906042098999023, -3.1749162673950195, 1.8079900741577148, 2.4874677658081055, -0.7554950714111328, 1.0343217849731445, 2.1452598571777344, 3.234262466430664, -13.014347076416016, 2.5548391342163086, 2.7348432540893555], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.96419906616211, "min_q": -17.409435272216797, "max_q": 2.8298563957214355, "mean_td_error": -3.595172166824341, "model": {}}, "td_error": [0.21131134033203125, 0.46204185485839844, 1.6605415344238281, -5.333436489105225, -14.095734596252441, -0.3249478340148926, -1.089223861694336, -1.0959997177124023, 1.730240821838379, -24.0269718170166, 2.3841371536254883, -15.326471328735352, 2.181234836578369, -6.06120491027832, -9.301900863647461, 1.992666244506836, -14.845335960388184, 1.0598907470703125, 2.3576717376708984, 4.096495628356934, -0.9980132579803467, -1.9891760349273682, 1.8842644691467285, -2.143080711364746, 2.883903980255127, -13.988130569458008, 0.9057340621948242, 2.400233745574951, 0.5947787165641785, -14.23392105102539, -16.409435272216797, -0.5876703262329102], "custom_metrics": {}}}, "num_steps_sampled": 4219, "num_agent_steps_sampled": 8438, "num_steps_trained": 5984, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 11968, "last_target_update_ts": 4127, "num_target_updates": 29}, "done": false, "episodes_total": 242, "training_iteration": 13, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-39", "timestamp": 1648811679, "time_this_iter_s": 1.352494716644287, "time_total_s": 17.623294830322266, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584ae200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584ae200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 17.623294830322266, "timesteps_since_restore": 416, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 30.4, "ram_util_percent": 58.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.44, "episode_len_mean": 16.57, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -7.67, "policy1": -12.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -40.0, -30.0, 10.0, -30.0, -30.0, 2.0, -40.0, 2.0, -30.0, 14.0, -14.0, -30.0, -30.0, 8.0, -30.0, -30.0, -14.0, -10.0, -12.0, -30.0, -30.0, -40.0, -30.0, -40.0, -6.0, -30.0, -30.0, -40.0, -30.0, -30.0, -16.0, 12.0, -30.0, -40.0, 2.0, -30.0, 4.0, -12.0, 0.0, -30.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, 2.0, -30.0, -40.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, -30.0, -4.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, 4.0, -2.0, -12.0, -30.0, -40.0, -30.0, -10.0, -30.0, -4.0, -30.0, -30.0, 6.0, -30.0, 10.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, 8.0, 0.0, -18.0, 4.0, -30.0, -8.0, 8.0, -12.0, -20.0], "episode_lengths": [20, 20, 20, 5, 20, 20, 9, 20, 9, 20, 3, 17, 20, 20, 6, 20, 20, 17, 15, 16, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 18, 4, 20, 20, 9, 20, 8, 16, 10, 20, 20, 20, 20, 20, 8, 20, 9, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 12, 20, 10, 20, 20, 20, 20, 8, 11, 16, 20, 20, 20, 15, 20, 12, 20, 20, 7, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 6, 10, 19, 8, 20, 14, 6, 16, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, 5.0, -20.0, -20.0, 1.0, -20.0, 1.0, -10.0, 7.0, 3.0, -10.0, -10.0, 4.0, -10.0, -10.0, -7.0, -5.0, -16.0, -10.0, -10.0, -20.0, -10.0, -20.0, -13.0, -20.0, -10.0, -20.0, -10.0, -10.0, 2.0, 6.0, -10.0, -20.0, 1.0, -10.0, 12.0, -6.0, 10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, -10.0, 1.0, -10.0, -20.0, -10.0, -14.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -2.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -1.0, -6.0, -10.0, -20.0, -10.0, -5.0, -10.0, -2.0, -10.0, -20.0, 3.0, -10.0, 5.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, 4.0, 10.0, -9.0, 2.0, -10.0, 6.0, 4.0, 4.0, 0.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, 5.0, -10.0, -10.0, 1.0, -20.0, 1.0, -20.0, 7.0, -17.0, -20.0, -20.0, 4.0, -20.0, -20.0, -7.0, -5.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 7.0, -10.0, -20.0, -20.0, -20.0, -20.0, -18.0, 6.0, -20.0, -20.0, 1.0, -20.0, -8.0, -6.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -8.0, -20.0, 1.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -10.0, -20.0, -2.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -8.0, -1.0, -6.0, -20.0, -20.0, -20.0, -5.0, -20.0, -2.0, -20.0, -10.0, 3.0, -20.0, 5.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -8.0, -20.0, 4.0, -10.0, -9.0, 2.0, -20.0, -14.0, 4.0, -16.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33502216164252574, "mean_inference_ms": 1.8520337126211261, "mean_action_processing_ms": 0.12635599516884422, "mean_env_wait_ms": 0.07835807727223316, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4526, "timesteps_this_iter": 32, "agent_timesteps_total": 9052, "timers": {"load_time_ms": 0.46, "load_throughput": 69615.004, "learn_time_ms": 7.963, "learn_throughput": 4018.531, "update_time_ms": 4.751}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.711896896362305, "min_q": -15.49123477935791, "max_q": -4.7704997062683105, "mean_td_error": -1.4563543796539307, "model": {}}, "td_error": [1.229318618774414, -3.8059844970703125, -1.7892999649047852, 1.340113639831543, -0.21285247802734375, -1.9606332778930664, -6.574150085449219, 4.509307384490967, -11.06537914276123, -0.28718090057373047, -0.015042304992675781, -0.46123218536376953, -12.899561882019043, -1.2381172180175781, -0.8713035583496094, 6.5241475105285645, 1.1105012893676758, 0.1681222915649414, -0.0019054412841796875, 0.4710216522216797, 0.065460205078125, -0.4874906539916992, -1.7784690856933594, -0.6007709503173828, -2.754333972930908, 1.0335931777954102, 0.5052890777587891, -0.2555961608886719, -4.83426570892334, 1.4222841262817383, -14.169638633728027, 1.0807085037231445], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.068682670593262, "min_q": -18.471529006958008, "max_q": -1.9509196281433105, "mean_td_error": -1.3883318901062012, "model": {}}, "td_error": [-0.769622802734375, -2.560655117034912, 11.221549034118652, 1.0341644287109375, -0.41367077827453613, -0.6888847351074219, 0.8217740058898926, 0.3014397621154785, -3.8556556701660156, -5.317956924438477, 0.2961273193359375, -14.314950942993164, -16.605945587158203, -2.645383834838867, 0.037813425064086914, -2.7590646743774414, 0.34303855895996094, -1.8383874893188477, -6.30340576171875, -0.6932506561279297, 8.857168197631836, -0.7883977890014648, -1.9053411483764648, 3.186664581298828, -2.145514488220215, -2.6128902435302734, -3.944930076599121, 0.46382713317871094, -4.827122688293457, 1.1651337146759033, 0.8956928253173828, 1.940019130706787], "custom_metrics": {}}}, "num_steps_sampled": 4526, "num_agent_steps_sampled": 9052, "num_steps_trained": 6592, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 13184, "last_target_update_ts": 4470, "num_target_updates": 32}, "done": false, "episodes_total": 261, "training_iteration": 14, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-40", "timestamp": 1648811680, "time_this_iter_s": 1.3556652069091797, "time_total_s": 18.978960037231445, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 18.978960037231445, "timesteps_since_restore": 448, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 31.0, "ram_util_percent": 58.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.94, "episode_len_mean": 16.42, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -7.22, "policy1": -12.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -40.0, -30.0, -40.0, -6.0, -30.0, -30.0, -40.0, -30.0, -30.0, -16.0, 12.0, -30.0, -40.0, 2.0, -30.0, 4.0, -12.0, 0.0, -30.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, 2.0, -30.0, -40.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, -30.0, -4.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, 4.0, -2.0, -12.0, -30.0, -40.0, -30.0, -10.0, -30.0, -4.0, -30.0, -30.0, 6.0, -30.0, 10.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, 8.0, 0.0, -18.0, 4.0, -30.0, -8.0, 8.0, -12.0, -20.0, -30.0, -8.0, 0.0, -30.0, 14.0, -4.0, -30.0, 10.0, -30.0, -6.0, 6.0, -6.0, -30.0, -30.0, -40.0, -30.0, -30.0, -8.0, -30.0, -30.0, -2.0], "episode_lengths": [20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 18, 4, 20, 20, 9, 20, 8, 16, 10, 20, 20, 20, 20, 20, 8, 20, 9, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 12, 20, 10, 20, 20, 20, 20, 8, 11, 16, 20, 20, 20, 15, 20, 12, 20, 20, 7, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 6, 10, 19, 8, 20, 14, 6, 16, 20, 20, 14, 10, 20, 3, 12, 20, 5, 20, 13, 7, 13, 20, 20, 20, 20, 20, 14, 20, 20, 11], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -13.0, -20.0, -10.0, -20.0, -10.0, -10.0, 2.0, 6.0, -10.0, -20.0, 1.0, -10.0, 12.0, -6.0, 10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, -10.0, 1.0, -10.0, -20.0, -10.0, -14.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -2.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -1.0, -6.0, -10.0, -20.0, -10.0, -5.0, -10.0, -2.0, -10.0, -20.0, 3.0, -10.0, 5.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, 4.0, 10.0, -9.0, 2.0, -10.0, 6.0, 4.0, 4.0, 0.0, -10.0, 6.0, 0.0, -10.0, 7.0, 8.0, -20.0, 5.0, -10.0, -3.0, -7.0, 7.0, -10.0, -20.0, -20.0, -10.0, -10.0, -4.0, -10.0, -10.0, -1.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, 7.0, -10.0, -20.0, -20.0, -20.0, -20.0, -18.0, 6.0, -20.0, -20.0, 1.0, -20.0, -8.0, -6.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -8.0, -20.0, 1.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -10.0, -20.0, -2.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -8.0, -1.0, -6.0, -20.0, -20.0, -20.0, -5.0, -20.0, -2.0, -20.0, -10.0, 3.0, -20.0, 5.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -8.0, -20.0, 4.0, -10.0, -9.0, 2.0, -20.0, -14.0, 4.0, -16.0, -20.0, -20.0, -14.0, 0.0, -20.0, 7.0, -12.0, -10.0, 5.0, -20.0, -3.0, 13.0, -13.0, -20.0, -10.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33405245811619055, "mean_inference_ms": 1.8430788730048022, "mean_action_processing_ms": 0.12573529977091716, "mean_env_wait_ms": 0.07813377905885223, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4848, "timesteps_this_iter": 32, "agent_timesteps_total": 9696, "timers": {"load_time_ms": 0.435, "load_throughput": 73479.54, "learn_time_ms": 7.799, "learn_throughput": 4102.899, "update_time_ms": 4.861}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.778362274169922, "min_q": -13.867064476013184, "max_q": -0.7707481384277344, "mean_td_error": -2.125359535217285, "model": {}}, "td_error": [1.8275947570800781, -1.9333219528198242, 0.8132505416870117, -1.982750415802002, -1.111954689025879, -2.9556541442871094, -7.6513261795043945, -1.2313528060913086, -11.774080276489258, -3.9142065048217773, -0.6236305236816406, 0.8906650543212891, -8.906155586242676, -2.7732677459716797, -3.079965114593506, -0.5673189163208008, -3.830883741378784, 1.2350521087646484, 0.5847902297973633, -1.0236587524414062, -2.9556541442871094, -5.601595401763916, -7.986608505249023, 0.20501232147216797, 0.9655952453613281, -0.11724996566772461, -0.14260005950927734, 1.0498981475830078, -0.7247600555419922, 4.439939498901367, -12.028635025024414, 2.8933229446411133], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -7.3536577224731445, "min_q": -17.87749671936035, "max_q": -0.8729990124702454, "mean_td_error": -0.08190777897834778, "model": {}}, "td_error": [-3.2589664459228516, -15.99753189086914, 1.2748699188232422, -5.7965922355651855, 0.571932315826416, 4.188918113708496, -3.313868522644043, -2.8679115772247314, 1.4011507034301758, -5.887866497039795, 2.421389579772949, 2.12506103515625, 0.7413622736930847, -3.3714308738708496, 11.423683166503906, 1.0630903244018555, 0.8292531967163086, 1.3348088264465332, 1.6832175254821777, 1.6843161582946777, 0.563774585723877, 0.022362709045410156, -2.640178680419922, -0.0026216506958007812, -1.6823570728302002, 1.6473703384399414, 0.8718881607055664, 4.173986434936523, 0.5842194557189941, 0.7765102386474609, 0.295745849609375, 2.5193681716918945], "custom_metrics": {}}}, "num_steps_sampled": 4848, "num_agent_steps_sampled": 9696, "num_steps_trained": 7232, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 14464, "last_target_update_ts": 4817, "num_target_updates": 35}, "done": false, "episodes_total": 282, "training_iteration": 15, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-41", "timestamp": 1648811681, "time_this_iter_s": 1.3590478897094727, "time_total_s": 20.338007926940918, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848def0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848def0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 20.338007926940918, "timesteps_since_restore": 480, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 30.4, "ram_util_percent": 58.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.94, "episode_len_mean": 16.47, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -7.07, "policy1": -12.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -30.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, 2.0, -30.0, -40.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, -30.0, -4.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, 4.0, -2.0, -12.0, -30.0, -40.0, -30.0, -10.0, -30.0, -4.0, -30.0, -30.0, 6.0, -30.0, 10.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, 8.0, 0.0, -18.0, 4.0, -30.0, -8.0, 8.0, -12.0, -20.0, -30.0, -8.0, 0.0, -30.0, 14.0, -4.0, -30.0, 10.0, -30.0, -6.0, 6.0, -6.0, -30.0, -30.0, -40.0, -30.0, -30.0, -8.0, -30.0, -30.0, -2.0, 8.0, 6.0, -30.0, -30.0, -30.0, 6.0, -40.0, -30.0, -30.0, -30.0, -40.0, -20.0, -30.0, -8.0, -40.0, -30.0, -18.0, -30.0], "episode_lengths": [10, 20, 20, 20, 20, 20, 8, 20, 9, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 12, 20, 10, 20, 20, 20, 20, 8, 11, 16, 20, 20, 20, 15, 20, 12, 20, 20, 7, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 6, 10, 19, 8, 20, 14, 6, 16, 20, 20, 14, 10, 20, 3, 12, 20, 5, 20, 13, 7, 13, 20, 20, 20, 20, 20, 14, 20, 20, 11, 6, 7, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 19, 20], "policy_policy0_reward": [10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, -10.0, 1.0, -10.0, -20.0, -10.0, -14.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -2.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -1.0, -6.0, -10.0, -20.0, -10.0, -5.0, -10.0, -2.0, -10.0, -20.0, 3.0, -10.0, 5.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, 4.0, 10.0, -9.0, 2.0, -10.0, 6.0, 4.0, 4.0, 0.0, -10.0, 6.0, 0.0, -10.0, 7.0, 8.0, -20.0, 5.0, -10.0, -3.0, -7.0, 7.0, -10.0, -20.0, -20.0, -10.0, -10.0, -4.0, -10.0, -10.0, -1.0, 14.0, 3.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, 0.0, -20.0, 6.0, -20.0, -10.0, -9.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -8.0, -20.0, 1.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -10.0, -20.0, -2.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -8.0, -1.0, -6.0, -20.0, -20.0, -20.0, -5.0, -20.0, -2.0, -20.0, -10.0, 3.0, -20.0, 5.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -8.0, -20.0, 4.0, -10.0, -9.0, 2.0, -20.0, -14.0, 4.0, -16.0, -20.0, -20.0, -14.0, 0.0, -20.0, 7.0, -12.0, -10.0, 5.0, -20.0, -3.0, 13.0, -13.0, -20.0, -10.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -1.0, -6.0, 3.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -14.0, -20.0, -20.0, -9.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33327763929019505, "mean_inference_ms": 1.8366832926606889, "mean_action_processing_ms": 0.1252786778748832, "mean_env_wait_ms": 0.07798907874165315, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5161, "timesteps_this_iter": 32, "agent_timesteps_total": 10322, "timers": {"load_time_ms": 0.447, "load_throughput": 71640.1, "learn_time_ms": 7.805, "learn_throughput": 4099.966, "update_time_ms": 4.914}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -6.939400672912598, "min_q": -13.1576566696167, "max_q": 3.198801279067993, "mean_td_error": -1.4646410942077637, "model": {}}, "td_error": [1.5886178016662598, -2.061197280883789, 4.851489067077637, 4.080604553222656, 0.8066205978393555, -0.5859074592590332, -1.9884734153747559, -7.456673622131348, -1.9222698211669922, -1.5459537506103516, 4.198801040649414, -1.2773146629333496, -8.036922454833984, 1.3025908470153809, -0.08547210693359375, -1.7151942253112793, -1.7763912677764893, -8.654623985290527, -2.812558650970459, 0.5002045631408691, 1.473123550415039, -1.5278377532958984, 0.593778133392334, 1.840097188949585, 0.48804378509521484, 0.5503997802734375, -5.522217750549316, -2.340118885040283, -1.5665521621704102, -9.470815658569336, -9.425883293151855, 0.6294937133789062], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.08133316040039, "min_q": -15.827768325805664, "max_q": -4.129013538360596, "mean_td_error": -0.1525827795267105, "model": {}}, "td_error": [6.099138259887695, 0.45192718505859375, 1.0374479293823242, 0.6236476898193359, 1.075296401977539, 1.4536972045898438, -0.6584815979003906, -13.129013061523438, 1.4528379440307617, 0.5950717926025391, -5.464931488037109, 0.1877269744873047, -0.9645299911499023, 2.1056947708129883, 0.8361682891845703, 1.773669719696045, 0.3546285629272461, 0.8184976577758789, 0.2956399917602539, 5.166864395141602, -0.9645299911499023, 0.4163646697998047, -4.783115863800049, -2.1210432052612305, 5.028779029846191, 0.42494964599609375, 0.655217170715332, -11.506485939025879, 0.40437936782836914, -0.2868499755859375, 1.4030847549438477, 2.335601806640625], "custom_metrics": {}}}, "num_steps_sampled": 5161, "num_agent_steps_sampled": 10322, "num_steps_trained": 7808, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 15616, "last_target_update_ts": 5141, "num_target_updates": 38}, "done": false, "episodes_total": 300, "training_iteration": 16, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-43", "timestamp": 1648811683, "time_this_iter_s": 1.226076364517212, "time_total_s": 21.56408429145813, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 21.56408429145813, "timesteps_since_restore": 512, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 30.1, "ram_util_percent": 58.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.14, "episode_len_mean": 16.12, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -6.52, "policy1": -12.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, 0.0, -30.0, -30.0, -30.0, -30.0, 4.0, -2.0, -12.0, -30.0, -40.0, -30.0, -10.0, -30.0, -4.0, -30.0, -30.0, 6.0, -30.0, 10.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, 8.0, 0.0, -18.0, 4.0, -30.0, -8.0, 8.0, -12.0, -20.0, -30.0, -8.0, 0.0, -30.0, 14.0, -4.0, -30.0, 10.0, -30.0, -6.0, 6.0, -6.0, -30.0, -30.0, -40.0, -30.0, -30.0, -8.0, -30.0, -30.0, -2.0, 8.0, 6.0, -30.0, -30.0, -30.0, 6.0, -40.0, -30.0, -30.0, -30.0, -40.0, -20.0, -30.0, -8.0, -40.0, -30.0, -18.0, -30.0, -8.0, -30.0, -8.0, -30.0, -30.0, 12.0, 0.0, -40.0, 12.0, 10.0, -30.0, -30.0, -40.0, -30.0, -30.0, 0.0, -40.0, 4.0, -30.0, -14.0, -40.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 8, 11, 16, 20, 20, 20, 15, 20, 12, 20, 20, 7, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 6, 10, 19, 8, 20, 14, 6, 16, 20, 20, 14, 10, 20, 3, 12, 20, 5, 20, 13, 7, 13, 20, 20, 20, 20, 20, 14, 20, 20, 11, 6, 7, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 19, 20, 14, 20, 14, 20, 20, 4, 10, 20, 4, 5, 20, 20, 20, 20, 20, 10, 20, 8, 20, 17, 20], "policy_policy0_reward": [-10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -1.0, -6.0, -10.0, -20.0, -10.0, -5.0, -10.0, -2.0, -10.0, -20.0, 3.0, -10.0, 5.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, 4.0, 10.0, -9.0, 2.0, -10.0, 6.0, 4.0, 4.0, 0.0, -10.0, 6.0, 0.0, -10.0, 7.0, 8.0, -20.0, 5.0, -10.0, -3.0, -7.0, 7.0, -10.0, -20.0, -20.0, -10.0, -10.0, -4.0, -10.0, -10.0, -1.0, 14.0, 3.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, 0.0, -20.0, 6.0, -20.0, -10.0, -9.0, -20.0, 6.0, -20.0, 6.0, -10.0, -10.0, 6.0, 0.0, -20.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -20.0, 12.0, -10.0, -7.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -8.0, -1.0, -6.0, -20.0, -20.0, -20.0, -5.0, -20.0, -2.0, -20.0, -10.0, 3.0, -20.0, 5.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -8.0, -20.0, 4.0, -10.0, -9.0, 2.0, -20.0, -14.0, 4.0, -16.0, -20.0, -20.0, -14.0, 0.0, -20.0, 7.0, -12.0, -10.0, 5.0, -20.0, -3.0, 13.0, -13.0, -20.0, -10.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -1.0, -6.0, 3.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -14.0, -20.0, -20.0, -9.0, -10.0, -14.0, -10.0, -14.0, -20.0, -20.0, 6.0, 0.0, -20.0, 6.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -8.0, -20.0, -7.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33245059309522135, "mean_inference_ms": 1.8300995675230087, "mean_action_processing_ms": 0.12478391623673722, "mean_env_wait_ms": 0.07784676341114961, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5487, "timesteps_this_iter": 32, "agent_timesteps_total": 10974, "timers": {"load_time_ms": 0.436, "load_throughput": 73467.474, "learn_time_ms": 8.413, "learn_throughput": 3803.818, "update_time_ms": 5.312}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.189148426055908, "min_q": -9.582462310791016, "max_q": 21.391996383666992, "mean_td_error": -1.9233393669128418, "model": {}}, "td_error": [13.813623428344727, -0.42307090759277344, -8.582462310791016, -0.8149428367614746, -2.897303342819214, 10.12416934967041, -7.316885948181152, -1.0392658710479736, -1.4026539325714111, -0.2366166114807129, -12.660039901733398, 2.4602560997009277, -7.888304710388184, 0.5343704223632812, -29.21057891845703, -5.221595287322998, 1.0764541625976562, -8.582462310791016, 0.14725661277770996, -0.9149484634399414, 1.7111185789108276, 1.3019899129867554, -0.26659107208251953, -1.8696832656860352, 0.5469422340393066, 3.4437255859375, 1.490461826324463, 1.002308964729309, -2.517096519470215, 4.162139892578125, -7.955143451690674, -3.5620341300964355], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.398415565490723, "min_q": -14.39590072631836, "max_q": -6.983165264129639, "mean_td_error": -1.9430177211761475, "model": {}}, "td_error": [2.105311393737793, -16.435523986816406, 0.7218647003173828, 1.836838722229004, -8.936294555664062, 0.9461193084716797, -7.201821327209473, 0.3011503219604492, 0.20139646530151367, 0.5443625450134277, -10.892387390136719, 0.13568973541259766, -6.900335311889648, -8.350492477416992, 1.8898344039916992, 1.421976089477539, 2.093120574951172, 1.177922248840332, -0.2067546844482422, -2.02256441116333, 2.2066078186035156, 0.6838846206665039, -0.02035808563232422, -8.517096519470215, -0.0020112991333007812, 0.8431401252746582, 0.12364864349365234, -0.198883056640625, 0.7641372680664062, -10.260001182556152, 0.1327657699584961, -0.3618154525756836], "custom_metrics": {}}}, "num_steps_sampled": 5487, "num_agent_steps_sampled": 10974, "num_steps_trained": 8480, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 16960, "last_target_update_ts": 5467, "num_target_updates": 41}, "done": false, "episodes_total": 321, "training_iteration": 17, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-44", "timestamp": 1648811684, "time_this_iter_s": 1.3709018230438232, "time_total_s": 22.934986114501953, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847ff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847ff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 22.934986114501953, "timesteps_since_restore": 544, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 31.05, "ram_util_percent": 58.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.6, "episode_len_mean": 16.3, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -6.7, "policy1": -12.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, 10.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, 8.0, 0.0, -18.0, 4.0, -30.0, -8.0, 8.0, -12.0, -20.0, -30.0, -8.0, 0.0, -30.0, 14.0, -4.0, -30.0, 10.0, -30.0, -6.0, 6.0, -6.0, -30.0, -30.0, -40.0, -30.0, -30.0, -8.0, -30.0, -30.0, -2.0, 8.0, 6.0, -30.0, -30.0, -30.0, 6.0, -40.0, -30.0, -30.0, -30.0, -40.0, -20.0, -30.0, -8.0, -40.0, -30.0, -18.0, -30.0, -8.0, -30.0, -8.0, -30.0, -30.0, 12.0, 0.0, -40.0, 12.0, 10.0, -30.0, -30.0, -40.0, -30.0, -30.0, 0.0, -40.0, 4.0, -30.0, -14.0, -40.0, 6.0, -30.0, -30.0, -8.0, -30.0, -30.0, 0.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, -12.0, -30.0, -20.0, -30.0, -40.0], "episode_lengths": [20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 6, 10, 19, 8, 20, 14, 6, 16, 20, 20, 14, 10, 20, 3, 12, 20, 5, 20, 13, 7, 13, 20, 20, 20, 20, 20, 14, 20, 20, 11, 6, 7, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 19, 20, 14, 20, 14, 20, 20, 4, 10, 20, 4, 5, 20, 20, 20, 20, 20, 10, 20, 8, 20, 17, 20, 7, 20, 20, 14, 20, 20, 10, 20, 10, 20, 20, 20, 20, 16, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 5.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, 4.0, 10.0, -9.0, 2.0, -10.0, 6.0, 4.0, 4.0, 0.0, -10.0, 6.0, 0.0, -10.0, 7.0, 8.0, -20.0, 5.0, -10.0, -3.0, -7.0, 7.0, -10.0, -20.0, -20.0, -10.0, -10.0, -4.0, -10.0, -10.0, -1.0, 14.0, 3.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, 0.0, -20.0, 6.0, -20.0, -10.0, -9.0, -20.0, 6.0, -20.0, 6.0, -10.0, -10.0, 6.0, 0.0, -20.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -20.0, 12.0, -10.0, -7.0, -20.0, 3.0, -10.0, -10.0, 6.0, -10.0, -20.0, 0.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, -6.0, -10.0, 0.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, 5.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -8.0, -20.0, 4.0, -10.0, -9.0, 2.0, -20.0, -14.0, 4.0, -16.0, -20.0, -20.0, -14.0, 0.0, -20.0, 7.0, -12.0, -10.0, 5.0, -20.0, -3.0, 13.0, -13.0, -20.0, -10.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -1.0, -6.0, 3.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -14.0, -20.0, -20.0, -9.0, -10.0, -14.0, -10.0, -14.0, -20.0, -20.0, 6.0, 0.0, -20.0, 6.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -8.0, -20.0, -7.0, -20.0, 3.0, -20.0, -20.0, -14.0, -20.0, -10.0, 0.0, -20.0, 0.0, -20.0, -20.0, -10.0, -20.0, -6.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33189797248423775, "mean_inference_ms": 1.8261077125559506, "mean_action_processing_ms": 0.12448539477470033, "mean_env_wait_ms": 0.07777226322354634, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5804, "timesteps_this_iter": 32, "agent_timesteps_total": 11608, "timers": {"load_time_ms": 0.461, "load_throughput": 69467.278, "learn_time_ms": 8.089, "learn_throughput": 3956.016, "update_time_ms": 4.917}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -0.880443811416626, "min_q": -8.67131519317627, "max_q": 19.623886108398438, "mean_td_error": -0.44915327429771423, "model": {}}, "td_error": [-1.9484853744506836, -2.4883012771606445, 1.259053349494934, -5.644161701202393, 0.08765792846679688, -3.093428134918213, 1.4417250156402588, 0.1780974268913269, -2.203082323074341, -5.628997802734375, 0.13275855779647827, 0.5030496120452881, 3.1167569160461426, 0.7382328510284424, -2.2278594970703125, -0.05514848232269287, 1.5438616275787354, 0.6165336966514587, 0.4287344217300415, -4.642570972442627, 2.2745447158813477, -0.22008860111236572, -10.891457557678223, 17.157346725463867, -6.1868815422058105, -0.09575977921485901, 0.2995647192001343, -1.5704405307769775, 1.5907330513000488, 0.19083678722381592, 0.25887584686279297, 0.7053942680358887], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.075849533081055, "min_q": -15.506381034851074, "max_q": -8.302745819091797, "mean_td_error": -1.5835011005401611, "model": {}}, "td_error": [-0.212188720703125, 0.7479801177978516, 1.3459358215332031, -0.5719547271728516, 0.40879058837890625, 0.8309402465820312, -1.6138067245483398, 0.4149923324584961, 1.455474853515625, 0.5592832565307617, -3.272538185119629, -0.5327787399291992, -14.506381034851074, -0.04730701446533203, 2.2966060638427734, -0.4500560760498047, -0.752171516418457, 1.4638042449951172, 0.6629018783569336, -1.0433435440063477, -1.0606355667114258, 0.3357067108154297, -7.906449317932129, -0.2996988296508789, 1.260849952697754, -10.360698699951172, -0.13469219207763672, -11.465398788452148, 2.027799606323242, -10.895078659057617, 2.094546318054199, -1.4524669647216797], "custom_metrics": {}}}, "num_steps_sampled": 5804, "num_agent_steps_sampled": 11608, "num_steps_trained": 9056, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 18112, "last_target_update_ts": 5804, "num_target_updates": 44}, "done": false, "episodes_total": 339, "training_iteration": 18, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-45", "timestamp": 1648811685, "time_this_iter_s": 1.3111393451690674, "time_total_s": 24.24612545967102, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 24.24612545967102, "timesteps_since_restore": 576, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 30.15, "ram_util_percent": 58.55}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.48, "episode_len_mean": 16.29, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -6.69, "policy1": -12.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, -12.0, -20.0, -30.0, -8.0, 0.0, -30.0, 14.0, -4.0, -30.0, 10.0, -30.0, -6.0, 6.0, -6.0, -30.0, -30.0, -40.0, -30.0, -30.0, -8.0, -30.0, -30.0, -2.0, 8.0, 6.0, -30.0, -30.0, -30.0, 6.0, -40.0, -30.0, -30.0, -30.0, -40.0, -20.0, -30.0, -8.0, -40.0, -30.0, -18.0, -30.0, -8.0, -30.0, -8.0, -30.0, -30.0, 12.0, 0.0, -40.0, 12.0, 10.0, -30.0, -30.0, -40.0, -30.0, -30.0, 0.0, -40.0, 4.0, -30.0, -14.0, -40.0, 6.0, -30.0, -30.0, -8.0, -30.0, -30.0, 0.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, -12.0, -30.0, -20.0, -30.0, -40.0, 4.0, -30.0, -40.0, 14.0, -30.0, -20.0, 0.0, -30.0, 0.0, -30.0, -6.0, -30.0, -30.0, -30.0, -6.0, -40.0, -4.0, -40.0, -20.0], "episode_lengths": [6, 16, 20, 20, 14, 10, 20, 3, 12, 20, 5, 20, 13, 7, 13, 20, 20, 20, 20, 20, 14, 20, 20, 11, 6, 7, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 19, 20, 14, 20, 14, 20, 20, 4, 10, 20, 4, 5, 20, 20, 20, 20, 20, 10, 20, 8, 20, 17, 20, 7, 20, 20, 14, 20, 20, 10, 20, 10, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 3, 20, 20, 10, 20, 10, 20, 13, 20, 20, 20, 13, 20, 12, 20, 20], "policy_policy0_reward": [4.0, 4.0, 0.0, -10.0, 6.0, 0.0, -10.0, 7.0, 8.0, -20.0, 5.0, -10.0, -3.0, -7.0, 7.0, -10.0, -20.0, -20.0, -10.0, -10.0, -4.0, -10.0, -10.0, -1.0, 14.0, 3.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, 0.0, -20.0, 6.0, -20.0, -10.0, -9.0, -20.0, 6.0, -20.0, 6.0, -10.0, -10.0, 6.0, 0.0, -20.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -20.0, 12.0, -10.0, -7.0, -20.0, 3.0, -10.0, -10.0, 6.0, -10.0, -20.0, 0.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, -6.0, -10.0, 0.0, -10.0, -20.0, 12.0, -10.0, -20.0, 7.0, -10.0, 0.0, 0.0, -20.0, 0.0, -10.0, -3.0, -10.0, -10.0, -10.0, 7.0, -20.0, -2.0, -20.0, -10.0], "policy_policy1_reward": [4.0, -16.0, -20.0, -20.0, -14.0, 0.0, -20.0, 7.0, -12.0, -10.0, 5.0, -20.0, -3.0, 13.0, -13.0, -20.0, -10.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -1.0, -6.0, 3.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -14.0, -20.0, -20.0, -9.0, -10.0, -14.0, -10.0, -14.0, -20.0, -20.0, 6.0, 0.0, -20.0, 6.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -8.0, -20.0, -7.0, -20.0, 3.0, -20.0, -20.0, -14.0, -20.0, -10.0, 0.0, -20.0, 0.0, -20.0, -20.0, -10.0, -20.0, -6.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, -20.0, 7.0, -20.0, -20.0, 0.0, -10.0, 0.0, -20.0, -3.0, -20.0, -20.0, -20.0, -13.0, -20.0, -2.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33113832782894065, "mean_inference_ms": 1.820017855694796, "mean_action_processing_ms": 0.12406072292500403, "mean_env_wait_ms": 0.07760564863163659, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6113, "timesteps_this_iter": 32, "agent_timesteps_total": 12226, "timers": {"load_time_ms": 0.477, "load_throughput": 67061.921, "learn_time_ms": 8.051, "learn_throughput": 3974.631, "update_time_ms": 4.84}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.877062439918518, "min_q": -9.103653907775879, "max_q": 5.036538124084473, "mean_td_error": 0.18366290628910065, "model": {}}, "td_error": [-1.9225225448608398, 0.876378059387207, -0.05887734889984131, -2.0224294662475586, 1.9870963096618652, -1.8249176740646362, 0.6678681373596191, 2.05410099029541, 0.9170284271240234, 1.2211359739303589, -0.16357803344726562, -0.5226590037345886, 2.4035630226135254, 0.6100561618804932, 2.6558151245117188, 2.04646635055542, -1.9335637092590332, -2.1717662811279297, -0.30278539657592773, -0.2850964069366455, -0.7409299612045288, -1.7526018619537354, -0.26043224334716797, -1.1580810546875, 1.3222930431365967, 0.18903779983520508, 2.9230403900146484, 0.9863853454589844, 0.2467484474182129, -1.933487892150879, 0.7350006103515625, 1.0889275074005127], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -12.048240661621094, "min_q": -14.711668014526367, "max_q": -9.938582420349121, "mean_td_error": -3.6289501190185547, "model": {}}, "td_error": [-10.975648880004883, 0.8962888717651367, 0.08837604522705078, 0.4820280075073242, -0.3544607162475586, -0.8075828552246094, -0.43630027770996094, 0.14375877380371094, -0.07946014404296875, -0.011043548583984375, -11.099411010742188, 1.0118627548217773, -19.229406356811523, -1.0473012924194336, -9.623655319213867, -8.938582420349121, 0.8958187103271484, -1.173356056213379, 0.47162723541259766, 0.4530925750732422, -19.226747512817383, -0.8791131973266602, -0.7033252716064453, -0.23188018798828125, -13.1510648727417, 0.24088287353515625, -1.3759031295776367, -0.08845806121826172, 0.7128314971923828, -10.10380744934082, 0.4017610549926758, -12.388216018676758], "custom_metrics": {}}}, "num_steps_sampled": 6113, "num_agent_steps_sampled": 12226, "num_steps_trained": 9632, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 19264, "last_target_update_ts": 6113, "num_target_updates": 47}, "done": false, "episodes_total": 358, "training_iteration": 19, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-47", "timestamp": 1648811687, "time_this_iter_s": 1.2335960865020752, "time_total_s": 25.479721546173096, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 25.479721546173096, "timesteps_since_restore": 608, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 31.4, "ram_util_percent": 58.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.94, "episode_len_mean": 16.47, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -7.17, "policy1": -12.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.0, -30.0, -30.0, -2.0, 8.0, 6.0, -30.0, -30.0, -30.0, 6.0, -40.0, -30.0, -30.0, -30.0, -40.0, -20.0, -30.0, -8.0, -40.0, -30.0, -18.0, -30.0, -8.0, -30.0, -8.0, -30.0, -30.0, 12.0, 0.0, -40.0, 12.0, 10.0, -30.0, -30.0, -40.0, -30.0, -30.0, 0.0, -40.0, 4.0, -30.0, -14.0, -40.0, 6.0, -30.0, -30.0, -8.0, -30.0, -30.0, 0.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, -12.0, -30.0, -20.0, -30.0, -40.0, 4.0, -30.0, -40.0, 14.0, -30.0, -20.0, 0.0, -30.0, 0.0, -30.0, -6.0, -30.0, -30.0, -30.0, -6.0, -40.0, -4.0, -40.0, -20.0, 8.0, -8.0, -10.0, -30.0, -30.0, -4.0, -12.0, -30.0, 12.0, -40.0, -40.0, -16.0, 4.0, -8.0, -30.0, -30.0, -4.0, -30.0, -30.0, -16.0], "episode_lengths": [14, 20, 20, 11, 6, 7, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 19, 20, 14, 20, 14, 20, 20, 4, 10, 20, 4, 5, 20, 20, 20, 20, 20, 10, 20, 8, 20, 17, 20, 7, 20, 20, 14, 20, 20, 10, 20, 10, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 3, 20, 20, 10, 20, 10, 20, 13, 20, 20, 20, 13, 20, 12, 20, 20, 6, 14, 15, 20, 20, 12, 16, 20, 4, 20, 20, 18, 8, 14, 20, 20, 12, 20, 20, 18], "policy_policy0_reward": [-4.0, -10.0, -10.0, -1.0, 14.0, 3.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, -10.0, -20.0, 0.0, -20.0, 6.0, -20.0, -10.0, -9.0, -20.0, 6.0, -20.0, 6.0, -10.0, -10.0, 6.0, 0.0, -20.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -20.0, 12.0, -10.0, -7.0, -20.0, 3.0, -10.0, -10.0, 6.0, -10.0, -20.0, 0.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, -6.0, -10.0, 0.0, -10.0, -20.0, 12.0, -10.0, -20.0, 7.0, -10.0, 0.0, 0.0, -20.0, 0.0, -10.0, -3.0, -10.0, -10.0, -10.0, 7.0, -20.0, -2.0, -20.0, -10.0, 14.0, -4.0, -15.0, -10.0, -10.0, -2.0, 4.0, -10.0, 6.0, -20.0, -20.0, -18.0, 2.0, -4.0, -10.0, -10.0, -2.0, -10.0, -10.0, -8.0], "policy_policy1_reward": [-4.0, -20.0, -20.0, -1.0, -6.0, 3.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -14.0, -20.0, -20.0, -9.0, -10.0, -14.0, -10.0, -14.0, -20.0, -20.0, 6.0, 0.0, -20.0, 6.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -8.0, -20.0, -7.0, -20.0, 3.0, -20.0, -20.0, -14.0, -20.0, -10.0, 0.0, -20.0, 0.0, -20.0, -20.0, -10.0, -20.0, -6.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, -20.0, 7.0, -20.0, -20.0, 0.0, -10.0, 0.0, -20.0, -3.0, -20.0, -20.0, -20.0, -13.0, -20.0, -2.0, -20.0, -10.0, -6.0, -4.0, 5.0, -20.0, -20.0, -2.0, -16.0, -20.0, 6.0, -20.0, -20.0, 2.0, 2.0, -4.0, -20.0, -20.0, -2.0, -20.0, -20.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.330196096654665, "mean_inference_ms": 1.8131101707524784, "mean_action_processing_ms": 0.12358480659134685, "mean_env_wait_ms": 0.07737048159202148, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6430, "timesteps_this_iter": 32, "agent_timesteps_total": 12860, "timers": {"load_time_ms": 0.418, "load_throughput": 76555.857, "learn_time_ms": 7.928, "learn_throughput": 4036.381, "update_time_ms": 4.733}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.378882646560669, "min_q": -11.812134742736816, "max_q": 9.915343284606934, "mean_td_error": -0.2534526586532593, "model": {}}, "td_error": [4.958060264587402, -0.5999813079833984, 0.07700777053833008, -0.06820058822631836, -0.4216189384460449, -9.80838394165039, -0.42973804473876953, -9.617359161376953, 3.4673118591308594, -0.8115272521972656, 3.2773232460021973, 0.7609100341796875, 1.7621335983276367, -1.1906577348709106, 0.2069540023803711, -4.887711048126221, 2.0381569862365723, -0.27738189697265625, 0.8096280097961426, -0.14802026748657227, -2.6305313110351562, 0.48450613021850586, 1.0012059211730957, 0.23095035552978516, -2.3288486003875732, -1.6652913093566895, -1.1880407333374023, 1.6223143339157104, 0.9633762836456299, 4.123029708862305, 2.3152241706848145, -0.1352863311767578], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.517389297485352, "min_q": -13.832181930541992, "max_q": -7.939947128295898, "mean_td_error": -2.1215426921844482, "model": {}}, "td_error": [-17.961742401123047, -0.5232105255126953, 0.8301362991333008, 0.8273687362670898, 0.5454959869384766, 0.6952705383300781, 0.5081024169921875, -10.936372756958008, -6.939947128295898, 0.49712562561035156, -8.728240013122559, 0.9409589767456055, 0.5308675765991211, 0.9452934265136719, 0.7207393646240234, 0.5037651062011719, 1.045278549194336, 0.8184566497802734, 1.223341941833496, 0.8397903442382812, 0.6239223480224609, 0.43136119842529297, 0.44274044036865234, -17.038911819458008, -0.4333992004394531, -11.756362915039062, 1.3133001327514648, 0.815373420715332, 0.6910552978515625, -9.478204727172852, 0.709050178527832, -0.5917739868164062], "custom_metrics": {}}}, "num_steps_sampled": 6430, "num_agent_steps_sampled": 12860, "num_steps_trained": 10272, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 20544, "last_target_update_ts": 6430, "num_target_updates": 50}, "done": false, "episodes_total": 378, "training_iteration": 20, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-48", "timestamp": 1648811688, "time_this_iter_s": 1.2998883724212646, "time_total_s": 26.77960991859436, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847fb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847fb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 26.77960991859436, "timesteps_since_restore": 640, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 30.35, "ram_util_percent": 58.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.34, "episode_len_mean": 16.42, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -6.92, "policy1": -12.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-18.0, -30.0, -8.0, -30.0, -8.0, -30.0, -30.0, 12.0, 0.0, -40.0, 12.0, 10.0, -30.0, -30.0, -40.0, -30.0, -30.0, 0.0, -40.0, 4.0, -30.0, -14.0, -40.0, 6.0, -30.0, -30.0, -8.0, -30.0, -30.0, 0.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, -12.0, -30.0, -20.0, -30.0, -40.0, 4.0, -30.0, -40.0, 14.0, -30.0, -20.0, 0.0, -30.0, 0.0, -30.0, -6.0, -30.0, -30.0, -30.0, -6.0, -40.0, -4.0, -40.0, -20.0, 8.0, -8.0, -10.0, -30.0, -30.0, -4.0, -12.0, -30.0, 12.0, -40.0, -40.0, -16.0, 4.0, -8.0, -30.0, -30.0, -4.0, -30.0, -30.0, -16.0, -30.0, -6.0, -40.0, -4.0, -30.0, -8.0, -20.0, -12.0, 2.0, -16.0, -30.0, -30.0, -14.0, -30.0, -30.0, -4.0, 14.0, -30.0, -30.0, -30.0], "episode_lengths": [19, 20, 14, 20, 14, 20, 20, 4, 10, 20, 4, 5, 20, 20, 20, 20, 20, 10, 20, 8, 20, 17, 20, 7, 20, 20, 14, 20, 20, 10, 20, 10, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 3, 20, 20, 10, 20, 10, 20, 13, 20, 20, 20, 13, 20, 12, 20, 20, 6, 14, 15, 20, 20, 12, 16, 20, 4, 20, 20, 18, 8, 14, 20, 20, 12, 20, 20, 18, 20, 13, 20, 12, 20, 14, 20, 16, 9, 18, 20, 20, 17, 20, 20, 12, 3, 20, 20, 20], "policy_policy0_reward": [-9.0, -20.0, 6.0, -20.0, 6.0, -10.0, -10.0, 6.0, 0.0, -20.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -20.0, 12.0, -10.0, -7.0, -20.0, 3.0, -10.0, -10.0, 6.0, -10.0, -20.0, 0.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, -6.0, -10.0, 0.0, -10.0, -20.0, 12.0, -10.0, -20.0, 7.0, -10.0, 0.0, 0.0, -20.0, 0.0, -10.0, -3.0, -10.0, -10.0, -10.0, 7.0, -20.0, -2.0, -20.0, -10.0, 14.0, -4.0, -15.0, -10.0, -10.0, -2.0, 4.0, -10.0, 6.0, -20.0, -20.0, -18.0, 2.0, -4.0, -10.0, -10.0, -2.0, -10.0, -10.0, -8.0, -10.0, -3.0, -20.0, 8.0, -10.0, 6.0, 0.0, -6.0, -9.0, -8.0, -10.0, -10.0, -7.0, -10.0, -20.0, 8.0, 7.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-9.0, -10.0, -14.0, -10.0, -14.0, -20.0, -20.0, 6.0, 0.0, -20.0, 6.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -8.0, -20.0, -7.0, -20.0, 3.0, -20.0, -20.0, -14.0, -20.0, -10.0, 0.0, -20.0, 0.0, -20.0, -20.0, -10.0, -20.0, -6.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, -20.0, 7.0, -20.0, -20.0, 0.0, -10.0, 0.0, -20.0, -3.0, -20.0, -20.0, -20.0, -13.0, -20.0, -2.0, -20.0, -10.0, -6.0, -4.0, 5.0, -20.0, -20.0, -2.0, -16.0, -20.0, 6.0, -20.0, -20.0, 2.0, 2.0, -4.0, -20.0, -20.0, -2.0, -20.0, -20.0, -8.0, -20.0, -3.0, -20.0, -12.0, -20.0, -14.0, -20.0, -6.0, 11.0, -8.0, -20.0, -20.0, -7.0, -20.0, -10.0, -12.0, 7.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3294170924271745, "mean_inference_ms": 1.807219806563432, "mean_action_processing_ms": 0.1231930981825899, "mean_env_wait_ms": 0.07718051376507985, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6764, "timesteps_this_iter": 32, "agent_timesteps_total": 13528, "timers": {"load_time_ms": 0.426, "load_throughput": 75183.581, "learn_time_ms": 7.736, "learn_throughput": 4136.445, "update_time_ms": 4.594}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.630447864532471, "min_q": -12.651935577392578, "max_q": 6.5078043937683105, "mean_td_error": -2.016714334487915, "model": {}}, "td_error": [0.44444918632507324, -11.158815383911133, -0.4321122169494629, 0.44367504119873047, -0.9051423072814941, 0.5778770446777344, -1.7942852973937988, -1.4459846019744873, 0.5462551116943359, -4.300655364990234, -10.558774948120117, -9.791360855102539, -1.6324939727783203, -1.6366429328918457, -2.9868199825286865, -4.9495697021484375, 0.5662918090820312, 1.2200922966003418, -0.06334495544433594, 2.3210670948028564, 0.1284046173095703, 0.09650421142578125, 0.288238525390625, -4.617265701293945, -0.08985137939453125, -11.50259780883789, -0.8274393081665039, -0.16223669052124023, 0.49319887161254883, -3.8154428005218506, 0.7141985893249512, 0.2957274913787842], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.81941032409668, "min_q": -14.23366928100586, "max_q": -8.15861988067627, "mean_td_error": -1.2212493419647217, "model": {}}, "td_error": [0.2777576446533203, 0.5447320938110352, 0.4976787567138672, 1.5048236846923828, -1.0599050521850586, 0.21747112274169922, 0.131500244140625, 0.5113449096679688, -0.4273500442504883, -9.054465293884277, 0.23187828063964844, -0.5655031204223633, -0.33773231506347656, -0.8168401718139648, -0.234100341796875, 0.45160770416259766, -0.5668020248413086, -0.33818721771240234, 0.29522705078125, 0.5183477401733398, 0.9975099563598633, -0.766016960144043, 0.10906124114990234, -10.620185852050781, -11.76986026763916, 0.2389678955078125, -10.08471965789795, 0.2419118881225586, -0.018268585205078125, 0.8211297988891602, 1.0622358322143555, -1.073225975036621], "custom_metrics": {}}}, "num_steps_sampled": 6764, "num_agent_steps_sampled": 13528, "num_steps_trained": 10880, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 21760, "last_target_update_ts": 6669, "num_target_updates": 52}, "done": false, "episodes_total": 398, "training_iteration": 21, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-50", "timestamp": 1648811690, "time_this_iter_s": 1.3364460468292236, "time_total_s": 28.116055965423584, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 28.116055965423584, "timesteps_since_restore": 672, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 31.200000000000003, "ram_util_percent": 58.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.06, "episode_len_mean": 16.43, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -6.23, "policy1": -12.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -14.0, -40.0, 6.0, -30.0, -30.0, -8.0, -30.0, -30.0, 0.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, -12.0, -30.0, -20.0, -30.0, -40.0, 4.0, -30.0, -40.0, 14.0, -30.0, -20.0, 0.0, -30.0, 0.0, -30.0, -6.0, -30.0, -30.0, -30.0, -6.0, -40.0, -4.0, -40.0, -20.0, 8.0, -8.0, -10.0, -30.0, -30.0, -4.0, -12.0, -30.0, 12.0, -40.0, -40.0, -16.0, 4.0, -8.0, -30.0, -30.0, -4.0, -30.0, -30.0, -16.0, -30.0, -6.0, -40.0, -4.0, -30.0, -8.0, -20.0, -12.0, 2.0, -16.0, -30.0, -30.0, -14.0, -30.0, -30.0, -4.0, 14.0, -30.0, -30.0, -30.0, 8.0, -40.0, 4.0, -30.0, -2.0, -30.0, -10.0, -30.0, -30.0, -30.0, -14.0, 4.0, -30.0, -8.0, -30.0, 4.0, -30.0, 4.0, -30.0, -8.0], "episode_lengths": [20, 17, 20, 7, 20, 20, 14, 20, 20, 10, 20, 10, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 3, 20, 20, 10, 20, 10, 20, 13, 20, 20, 20, 13, 20, 12, 20, 20, 6, 14, 15, 20, 20, 12, 16, 20, 4, 20, 20, 18, 8, 14, 20, 20, 12, 20, 20, 18, 20, 13, 20, 12, 20, 14, 20, 16, 9, 18, 20, 20, 17, 20, 20, 12, 3, 20, 20, 20, 6, 20, 8, 20, 11, 20, 15, 20, 20, 20, 17, 8, 20, 14, 20, 8, 20, 8, 20, 14], "policy_policy0_reward": [-10.0, -7.0, -20.0, 3.0, -10.0, -10.0, 6.0, -10.0, -20.0, 0.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, -6.0, -10.0, 0.0, -10.0, -20.0, 12.0, -10.0, -20.0, 7.0, -10.0, 0.0, 0.0, -20.0, 0.0, -10.0, -3.0, -10.0, -10.0, -10.0, 7.0, -20.0, -2.0, -20.0, -10.0, 14.0, -4.0, -15.0, -10.0, -10.0, -2.0, 4.0, -10.0, 6.0, -20.0, -20.0, -18.0, 2.0, -4.0, -10.0, -10.0, -2.0, -10.0, -10.0, -8.0, -10.0, -3.0, -20.0, 8.0, -10.0, 6.0, 0.0, -6.0, -9.0, -8.0, -10.0, -10.0, -7.0, -10.0, -20.0, 8.0, 7.0, -10.0, -10.0, -10.0, 14.0, -20.0, 2.0, -10.0, 9.0, -10.0, -5.0, -10.0, -10.0, -10.0, 3.0, 12.0, -10.0, 6.0, -10.0, 12.0, -10.0, 12.0, -10.0, -4.0], "policy_policy1_reward": [-20.0, -7.0, -20.0, 3.0, -20.0, -20.0, -14.0, -20.0, -10.0, 0.0, -20.0, 0.0, -20.0, -20.0, -10.0, -20.0, -6.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, -20.0, 7.0, -20.0, -20.0, 0.0, -10.0, 0.0, -20.0, -3.0, -20.0, -20.0, -20.0, -13.0, -20.0, -2.0, -20.0, -10.0, -6.0, -4.0, 5.0, -20.0, -20.0, -2.0, -16.0, -20.0, 6.0, -20.0, -20.0, 2.0, 2.0, -4.0, -20.0, -20.0, -2.0, -20.0, -20.0, -8.0, -20.0, -3.0, -20.0, -12.0, -20.0, -14.0, -20.0, -6.0, 11.0, -8.0, -20.0, -20.0, -7.0, -20.0, -10.0, -12.0, 7.0, -20.0, -20.0, -20.0, -6.0, -20.0, 2.0, -20.0, -11.0, -20.0, -5.0, -20.0, -20.0, -20.0, -17.0, -8.0, -20.0, -14.0, -20.0, -8.0, -20.0, -8.0, -20.0, -4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.328846557384545, "mean_inference_ms": 1.802207391045349, "mean_action_processing_ms": 0.12286425853568182, "mean_env_wait_ms": 0.07700809875914656, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7073, "timesteps_this_iter": 32, "agent_timesteps_total": 14146, "timers": {"load_time_ms": 0.466, "load_throughput": 68628.996, "learn_time_ms": 7.636, "learn_throughput": 4190.781, "update_time_ms": 4.482}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.1191091537475586, "min_q": -13.860486030578613, "max_q": 6.468288898468018, "mean_td_error": -1.5271625518798828, "model": {}}, "td_error": [-17.042537689208984, -0.2937312126159668, 0.20489025115966797, 1.620570182800293, -0.6949055194854736, -4.169715881347656, -2.5597915649414062, -2.660224676132202, 0.47055768966674805, -2.4246578216552734, -17.042537689208984, -1.316338300704956, 0.7308676242828369, -2.5317111015319824, 0.29857444763183594, 0.9460301399230957, 1.1932268142700195, 0.37799072265625, 0.025942325592041016, -1.8230501413345337, 1.1276521682739258, 0.4776492118835449, 0.11541199684143066, -3.852879047393799, 0.13662290573120117, -1.056023120880127, -0.7064089775085449, 0.3816366195678711, 0.21467089653015137, -0.6638374328613281, 0.09936046600341797, 1.5474915504455566], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.610255241394043, "min_q": -14.14937973022461, "max_q": -7.505003929138184, "mean_td_error": -3.298905849456787, "model": {}}, "td_error": [0.5379848480224609, 0.6992120742797852, 0.5379848480224609, 1.3555221557617188, 1.0367584228515625, 0.5919427871704102, -1.236577033996582, -8.790682792663574, 1.1282539367675781, -0.04888343811035156, -0.31676578521728516, -16.5050048828125, -12.672550201416016, -8.3910551071167, 0.9750127792358398, -0.9790468215942383, 0.39643192291259766, 1.074610710144043, 0.7600679397583008, 1.003875732421875, -0.538823127746582, -10.955345153808594, 0.47646141052246094, 0.3517417907714844, -17.42562484741211, 0.32689762115478516, -10.72140884399414, -11.972036361694336, 0.7136526107788086, 0.11995697021484375, -8.612808227539062, -8.484739303588867], "custom_metrics": {}}}, "num_steps_sampled": 7073, "num_agent_steps_sampled": 14146, "num_steps_trained": 11520, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 23040, "last_target_update_ts": 7003, "num_target_updates": 55}, "done": false, "episodes_total": 418, "training_iteration": 22, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-51", "timestamp": 1648811691, "time_this_iter_s": 1.282369613647461, "time_total_s": 29.398425579071045, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584ae9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584ae9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 29.398425579071045, "timesteps_since_restore": 704, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 30.5, "ram_util_percent": 58.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.7, "episode_len_mean": 16.3, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -5.6, "policy1": -13.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -40.0, 4.0, -30.0, -40.0, 14.0, -30.0, -20.0, 0.0, -30.0, 0.0, -30.0, -6.0, -30.0, -30.0, -30.0, -6.0, -40.0, -4.0, -40.0, -20.0, 8.0, -8.0, -10.0, -30.0, -30.0, -4.0, -12.0, -30.0, 12.0, -40.0, -40.0, -16.0, 4.0, -8.0, -30.0, -30.0, -4.0, -30.0, -30.0, -16.0, -30.0, -6.0, -40.0, -4.0, -30.0, -8.0, -20.0, -12.0, 2.0, -16.0, -30.0, -30.0, -14.0, -30.0, -30.0, -4.0, 14.0, -30.0, -30.0, -30.0, 8.0, -40.0, 4.0, -30.0, -2.0, -30.0, -10.0, -30.0, -30.0, -30.0, -14.0, 4.0, -30.0, -8.0, -30.0, 4.0, -30.0, 4.0, -30.0, -8.0, -40.0, -30.0, 2.0, -4.0, -30.0, 8.0, -40.0, -16.0, -8.0, -30.0, -6.0, -30.0, -18.0, -16.0, -30.0, -4.0, -30.0, -30.0, -30.0], "episode_lengths": [20, 20, 8, 20, 20, 3, 20, 20, 10, 20, 10, 20, 13, 20, 20, 20, 13, 20, 12, 20, 20, 6, 14, 15, 20, 20, 12, 16, 20, 4, 20, 20, 18, 8, 14, 20, 20, 12, 20, 20, 18, 20, 13, 20, 12, 20, 14, 20, 16, 9, 18, 20, 20, 17, 20, 20, 12, 3, 20, 20, 20, 6, 20, 8, 20, 11, 20, 15, 20, 20, 20, 17, 8, 20, 14, 20, 8, 20, 8, 20, 14, 20, 20, 9, 12, 20, 6, 20, 18, 14, 20, 13, 20, 19, 18, 20, 12, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, 12.0, -10.0, -20.0, 7.0, -10.0, 0.0, 0.0, -20.0, 0.0, -10.0, -3.0, -10.0, -10.0, -10.0, 7.0, -20.0, -2.0, -20.0, -10.0, 14.0, -4.0, -15.0, -10.0, -10.0, -2.0, 4.0, -10.0, 6.0, -20.0, -20.0, -18.0, 2.0, -4.0, -10.0, -10.0, -2.0, -10.0, -10.0, -8.0, -10.0, -3.0, -20.0, 8.0, -10.0, 6.0, 0.0, -6.0, -9.0, -8.0, -10.0, -10.0, -7.0, -10.0, -20.0, 8.0, 7.0, -10.0, -10.0, -10.0, 14.0, -20.0, 2.0, -10.0, 9.0, -10.0, -5.0, -10.0, -10.0, -10.0, 3.0, 12.0, -10.0, 6.0, -10.0, 12.0, -10.0, 12.0, -10.0, -4.0, -20.0, -10.0, 1.0, -2.0, -10.0, 14.0, -20.0, 2.0, 6.0, -10.0, 7.0, -10.0, 1.0, 2.0, -20.0, 8.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -8.0, -20.0, -20.0, 7.0, -20.0, -20.0, 0.0, -10.0, 0.0, -20.0, -3.0, -20.0, -20.0, -20.0, -13.0, -20.0, -2.0, -20.0, -10.0, -6.0, -4.0, 5.0, -20.0, -20.0, -2.0, -16.0, -20.0, 6.0, -20.0, -20.0, 2.0, 2.0, -4.0, -20.0, -20.0, -2.0, -20.0, -20.0, -8.0, -20.0, -3.0, -20.0, -12.0, -20.0, -14.0, -20.0, -6.0, 11.0, -8.0, -20.0, -20.0, -7.0, -20.0, -10.0, -12.0, 7.0, -20.0, -20.0, -20.0, -6.0, -20.0, 2.0, -20.0, -11.0, -20.0, -5.0, -20.0, -20.0, -20.0, -17.0, -8.0, -20.0, -14.0, -20.0, -8.0, -20.0, -8.0, -20.0, -4.0, -20.0, -20.0, 1.0, -2.0, -20.0, -6.0, -20.0, -18.0, -14.0, -20.0, -13.0, -20.0, -19.0, -18.0, -10.0, -12.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3286158379449248, "mean_inference_ms": 1.7990807574045657, "mean_action_processing_ms": 0.12270306304414748, "mean_env_wait_ms": 0.07690225563231597, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7394, "timesteps_this_iter": 32, "agent_timesteps_total": 14788, "timers": {"load_time_ms": 0.51, "load_throughput": 62803.672, "learn_time_ms": 8.783, "learn_throughput": 3643.221, "update_time_ms": 5.373}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -0.48589980602264404, "min_q": -14.907798767089844, "max_q": 7.222278118133545, "mean_td_error": -0.2959213852882385, "model": {}}, "td_error": [0.17270183563232422, -2.4120547771453857, -0.789858341217041, -2.365569591522217, 1.1655263900756836, -1.0788331031799316, 0.4214286804199219, 2.429783821105957, -7.090412616729736, 0.208404541015625, -1.005134105682373, -1.5711004734039307, 3.8320765495300293, 0.7216435670852661, 0.43308281898498535, -0.2223949432373047, 2.3633666038513184, 0.4056377410888672, -1.7757904529571533, 1.1662678718566895, -0.05407071113586426, -1.8206415176391602, -1.3956079483032227, -0.32777929306030273, 0.6952147483825684, 1.0787923336029053, -0.09679841995239258, -0.7219996452331543, -0.39606189727783203, 1.2468796968460083, 0.4955310821533203, -3.1817147731781006], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.616264343261719, "min_q": -16.47386360168457, "max_q": -10.059550285339355, "mean_td_error": -2.7779159545898438, "model": {}}, "td_error": [0.13410663604736328, -0.3821077346801758, 0.8934402465820312, 0.04256629943847656, -9.949128150939941, -0.3468036651611328, 0.018088340759277344, -2.972808837890625, -11.804954528808594, 0.10117149353027344, -0.0039539337158203125, -10.337955474853516, 0.737396240234375, -19.72348403930664, -0.2633190155029297, -0.6295356750488281, 0.21767139434814453, 0.019359588623046875, -9.724632263183594, 0.26630687713623047, -0.013471603393554688, -11.117024421691895, 0.042972564697265625, 0.9716272354125977, -11.868135452270508, -0.4294261932373047, -0.01597309112548828, -1.4619388580322266, 0.15019989013671875, -1.036355972290039, 0.0826873779296875, -0.4898967742919922], "custom_metrics": {}}}, "num_steps_sampled": 7394, "num_agent_steps_sampled": 14788, "num_steps_trained": 12128, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 24256, "last_target_update_ts": 7334, "num_target_updates": 58}, "done": false, "episodes_total": 437, "training_iteration": 23, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-52", "timestamp": 1648811692, "time_this_iter_s": 1.434422492980957, "time_total_s": 30.832848072052002, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 30.832848072052002, "timesteps_since_restore": 736, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 33.0, "ram_util_percent": 58.7}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.96, "episode_len_mean": 16.08, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -5.08, "policy1": -12.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -6.0, -40.0, -4.0, -40.0, -20.0, 8.0, -8.0, -10.0, -30.0, -30.0, -4.0, -12.0, -30.0, 12.0, -40.0, -40.0, -16.0, 4.0, -8.0, -30.0, -30.0, -4.0, -30.0, -30.0, -16.0, -30.0, -6.0, -40.0, -4.0, -30.0, -8.0, -20.0, -12.0, 2.0, -16.0, -30.0, -30.0, -14.0, -30.0, -30.0, -4.0, 14.0, -30.0, -30.0, -30.0, 8.0, -40.0, 4.0, -30.0, -2.0, -30.0, -10.0, -30.0, -30.0, -30.0, -14.0, 4.0, -30.0, -8.0, -30.0, 4.0, -30.0, 4.0, -30.0, -8.0, -40.0, -30.0, 2.0, -4.0, -30.0, 8.0, -40.0, -16.0, -8.0, -30.0, -6.0, -30.0, -18.0, -16.0, -30.0, -4.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -6.0, -30.0, -4.0, -40.0, 8.0, -30.0, 4.0, 8.0, -18.0, 12.0, -8.0], "episode_lengths": [20, 13, 20, 12, 20, 20, 6, 14, 15, 20, 20, 12, 16, 20, 4, 20, 20, 18, 8, 14, 20, 20, 12, 20, 20, 18, 20, 13, 20, 12, 20, 14, 20, 16, 9, 18, 20, 20, 17, 20, 20, 12, 3, 20, 20, 20, 6, 20, 8, 20, 11, 20, 15, 20, 20, 20, 17, 8, 20, 14, 20, 8, 20, 8, 20, 14, 20, 20, 9, 12, 20, 6, 20, 18, 14, 20, 13, 20, 19, 18, 20, 12, 20, 20, 20, 20, 20, 20, 20, 13, 20, 12, 20, 6, 20, 8, 6, 19, 4, 14], "policy_policy0_reward": [-10.0, 7.0, -20.0, -2.0, -20.0, -10.0, 14.0, -4.0, -15.0, -10.0, -10.0, -2.0, 4.0, -10.0, 6.0, -20.0, -20.0, -18.0, 2.0, -4.0, -10.0, -10.0, -2.0, -10.0, -10.0, -8.0, -10.0, -3.0, -20.0, 8.0, -10.0, 6.0, 0.0, -6.0, -9.0, -8.0, -10.0, -10.0, -7.0, -10.0, -20.0, 8.0, 7.0, -10.0, -10.0, -10.0, 14.0, -20.0, 2.0, -10.0, 9.0, -10.0, -5.0, -10.0, -10.0, -10.0, 3.0, 12.0, -10.0, 6.0, -10.0, 12.0, -10.0, 12.0, -10.0, -4.0, -20.0, -10.0, 1.0, -2.0, -10.0, 14.0, -20.0, 2.0, 6.0, -10.0, 7.0, -10.0, 1.0, 2.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -3.0, -20.0, 8.0, -20.0, 14.0, -10.0, 2.0, 14.0, 1.0, 6.0, 6.0], "policy_policy1_reward": [-20.0, -13.0, -20.0, -2.0, -20.0, -10.0, -6.0, -4.0, 5.0, -20.0, -20.0, -2.0, -16.0, -20.0, 6.0, -20.0, -20.0, 2.0, 2.0, -4.0, -20.0, -20.0, -2.0, -20.0, -20.0, -8.0, -20.0, -3.0, -20.0, -12.0, -20.0, -14.0, -20.0, -6.0, 11.0, -8.0, -20.0, -20.0, -7.0, -20.0, -10.0, -12.0, 7.0, -20.0, -20.0, -20.0, -6.0, -20.0, 2.0, -20.0, -11.0, -20.0, -5.0, -20.0, -20.0, -20.0, -17.0, -8.0, -20.0, -14.0, -20.0, -8.0, -20.0, -8.0, -20.0, -4.0, -20.0, -20.0, 1.0, -2.0, -20.0, -6.0, -20.0, -18.0, -14.0, -20.0, -13.0, -20.0, -19.0, -18.0, -10.0, -12.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -3.0, -10.0, -12.0, -20.0, -6.0, -20.0, 2.0, -6.0, -19.0, 6.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3286219614245443, "mean_inference_ms": 1.7979460496893802, "mean_action_processing_ms": 0.12266984498663519, "mean_env_wait_ms": 0.07685503870365962, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7616, "timesteps_this_iter": 32, "agent_timesteps_total": 15232, "timers": {"load_time_ms": 0.453, "load_throughput": 70614.893, "learn_time_ms": 8.006, "learn_throughput": 3997.216, "update_time_ms": 4.84}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 1.5422022342681885, "min_q": -11.561629295349121, "max_q": 10.310538291931152, "mean_td_error": -0.11844396591186523, "model": {}}, "td_error": [6.276525974273682, -4.910219669342041, 7.534388542175293, 1.0822911262512207, -0.051136016845703125, -2.4078173637390137, -10.561629295349121, 1.0325546264648438, 1.0670394897460938, -0.14447736740112305, -8.459251403808594, -2.488955497741699, 2.3286190032958984, 7.109304428100586, -1.3559167385101318, -3.5674781799316406, 0.6821117401123047, 0.999361515045166, -3.6753268241882324, 0.3737623691558838, 5.123378276824951, 1.6363906860351562, 1.7826519012451172, 1.286229133605957, 1.3144721984863281, 3.212200164794922, -3.3057620525360107, 2.124608039855957, -8.55373477935791, 3.3460280895233154, -1.2067712545394897, -1.4136483669281006], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.60082721710205, "min_q": -16.61857795715332, "max_q": -9.466691017150879, "mean_td_error": -3.938610076904297, "model": {}}, "td_error": [0.24649810791015625, 0.4611167907714844, -1.2362241744995117, 1.0474176406860352, -19.662073135375977, -21.3298397064209, -11.0831937789917, 0.8257112503051758, 0.7238273620605469, 0.3033638000488281, 0.6698122024536133, -15.309871673583984, -11.41238021850586, 0.12166500091552734, -0.09581947326660156, 1.4750251770019531, 0.22593116760253906, -10.87990665435791, 2.053926467895508, 0.09967613220214844, -0.4477834701538086, 0.6981754302978516, -19.662073135375977, 0.1876544952392578, 2.295966148376465, -10.0807523727417, 0.22326087951660156, -0.16456890106201172, 0.3261585235595703, -15.309871673583984, 0.7744407653808594, -2.1207923889160156], "custom_metrics": {}}}, "num_steps_sampled": 7616, "num_agent_steps_sampled": 15232, "num_steps_trained": 12608, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 25216, "last_target_update_ts": 7565, "num_target_updates": 60}, "done": false, "episodes_total": 452, "training_iteration": 24, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-53", "timestamp": 1648811693, "time_this_iter_s": 1.0215485095977783, "time_total_s": 31.85439658164978, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 31.85439658164978, "timesteps_since_restore": 768, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 47.15, "ram_util_percent": 59.75}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.82, "episode_len_mean": 16.06, "episode_media": {}, "episodes_this_iter": 14, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -4.46, "policy1": -13.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, -40.0, -40.0, -16.0, 4.0, -8.0, -30.0, -30.0, -4.0, -30.0, -30.0, -16.0, -30.0, -6.0, -40.0, -4.0, -30.0, -8.0, -20.0, -12.0, 2.0, -16.0, -30.0, -30.0, -14.0, -30.0, -30.0, -4.0, 14.0, -30.0, -30.0, -30.0, 8.0, -40.0, 4.0, -30.0, -2.0, -30.0, -10.0, -30.0, -30.0, -30.0, -14.0, 4.0, -30.0, -8.0, -30.0, 4.0, -30.0, 4.0, -30.0, -8.0, -40.0, -30.0, 2.0, -4.0, -30.0, 8.0, -40.0, -16.0, -8.0, -30.0, -6.0, -30.0, -18.0, -16.0, -30.0, -4.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -6.0, -30.0, -4.0, -40.0, 8.0, -30.0, 4.0, 8.0, -18.0, 12.0, -8.0, -40.0, -16.0, -12.0, -30.0, 8.0, 8.0, -4.0, -30.0, -16.0, -8.0, -12.0, -30.0, -30.0, -30.0], "episode_lengths": [4, 20, 20, 18, 8, 14, 20, 20, 12, 20, 20, 18, 20, 13, 20, 12, 20, 14, 20, 16, 9, 18, 20, 20, 17, 20, 20, 12, 3, 20, 20, 20, 6, 20, 8, 20, 11, 20, 15, 20, 20, 20, 17, 8, 20, 14, 20, 8, 20, 8, 20, 14, 20, 20, 9, 12, 20, 6, 20, 18, 14, 20, 13, 20, 19, 18, 20, 12, 20, 20, 20, 20, 20, 20, 20, 13, 20, 12, 20, 6, 20, 8, 6, 19, 4, 14, 20, 18, 16, 20, 6, 6, 12, 20, 18, 14, 16, 20, 20, 20], "policy_policy0_reward": [6.0, -20.0, -20.0, -18.0, 2.0, -4.0, -10.0, -10.0, -2.0, -10.0, -10.0, -8.0, -10.0, -3.0, -20.0, 8.0, -10.0, 6.0, 0.0, -6.0, -9.0, -8.0, -10.0, -10.0, -7.0, -10.0, -20.0, 8.0, 7.0, -10.0, -10.0, -10.0, 14.0, -20.0, 2.0, -10.0, 9.0, -10.0, -5.0, -10.0, -10.0, -10.0, 3.0, 12.0, -10.0, 6.0, -10.0, 12.0, -10.0, 12.0, -10.0, -4.0, -20.0, -10.0, 1.0, -2.0, -10.0, 14.0, -20.0, 2.0, 6.0, -10.0, 7.0, -10.0, 1.0, 2.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -3.0, -20.0, 8.0, -20.0, 14.0, -10.0, 2.0, 14.0, 1.0, 6.0, 6.0, -20.0, 2.0, 4.0, -10.0, 14.0, 14.0, 8.0, -10.0, 2.0, 6.0, -6.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [6.0, -20.0, -20.0, 2.0, 2.0, -4.0, -20.0, -20.0, -2.0, -20.0, -20.0, -8.0, -20.0, -3.0, -20.0, -12.0, -20.0, -14.0, -20.0, -6.0, 11.0, -8.0, -20.0, -20.0, -7.0, -20.0, -10.0, -12.0, 7.0, -20.0, -20.0, -20.0, -6.0, -20.0, 2.0, -20.0, -11.0, -20.0, -5.0, -20.0, -20.0, -20.0, -17.0, -8.0, -20.0, -14.0, -20.0, -8.0, -20.0, -8.0, -20.0, -4.0, -20.0, -20.0, 1.0, -2.0, -20.0, -6.0, -20.0, -18.0, -14.0, -20.0, -13.0, -20.0, -19.0, -18.0, -10.0, -12.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -3.0, -10.0, -12.0, -20.0, -6.0, -20.0, 2.0, -6.0, -19.0, 6.0, -14.0, -20.0, -18.0, -16.0, -20.0, -6.0, -6.0, -12.0, -20.0, -18.0, -14.0, -6.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3287121187997618, "mean_inference_ms": 1.7973940489833178, "mean_action_processing_ms": 0.12268345751852312, "mean_env_wait_ms": 0.07683788658867882, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7842, "timesteps_this_iter": 32, "agent_timesteps_total": 15684, "timers": {"load_time_ms": 0.478, "load_throughput": 66878.134, "learn_time_ms": 7.974, "learn_throughput": 4013.16, "update_time_ms": 5.026}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.090234279632568, "min_q": -6.756082534790039, "max_q": 14.6937255859375, "mean_td_error": -0.08209625631570816, "model": {}}, "td_error": [0.08547019958496094, 1.4780960083007812, -0.012909889221191406, 0.11624526977539062, 3.2271180152893066, 3.083658456802368, 0.3490791320800781, -3.0094926357269287, 1.6188151836395264, 1.0325558185577393, 2.0951590538024902, -3.1342344284057617, -1.0849332809448242, -2.0987446308135986, 0.11492633819580078, -1.6140012741088867, -0.5032358169555664, -0.2235959768295288, -0.9470405578613281, -1.8126707077026367, 0.8281688690185547, 3.047732353210449, 0.3434476852416992, 0.015610337257385254, 1.5965924263000488, 0.18220043182373047, -2.0149173736572266, -1.5393133163452148, -2.1555347442626953, -1.2017724514007568, 0.13601446151733398, -0.625572681427002], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.713125228881836, "min_q": -17.572784423828125, "max_q": -9.841280937194824, "mean_td_error": -4.598964691162109, "model": {}}, "td_error": [-21.070613861083984, -12.615036964416504, 0.37428855895996094, 0.10863876342773438, -13.923155784606934, -18.84128189086914, -0.4851999282836914, 1.4007225036621094, 1.0085210800170898, -21.070613861083984, -12.454401969909668, 0.3352184295654297, -15.157878875732422, -1.0601673126220703, 0.19381141662597656, 0.724365234375, 1.882523536682129, 0.3229331970214844, -0.48062610626220703, -0.061751365661621094, -0.9601011276245117, -1.055150032043457, -0.005047798156738281, -15.04513931274414, 1.1296806335449219, -0.19244003295898438, 0.3888072967529297, 0.9447298049926758, 0.46902942657470703, 0.8712120056152344, -23.300498962402344, 0.4577655792236328], "custom_metrics": {}}}, "num_steps_sampled": 7842, "num_agent_steps_sampled": 15684, "num_steps_trained": 13056, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 26112, "last_target_update_ts": 7782, "num_target_updates": 62}, "done": false, "episodes_total": 466, "training_iteration": 25, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-55", "timestamp": 1648811695, "time_this_iter_s": 0.9620780944824219, "time_total_s": 32.8164746761322, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584ae170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584ae170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 32.8164746761322, "timesteps_since_restore": 800, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 38.9, "ram_util_percent": 60.3}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.94, "episode_len_mean": 16.52, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -4.72, "policy1": -14.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.0, -20.0, -12.0, 2.0, -16.0, -30.0, -30.0, -14.0, -30.0, -30.0, -4.0, 14.0, -30.0, -30.0, -30.0, 8.0, -40.0, 4.0, -30.0, -2.0, -30.0, -10.0, -30.0, -30.0, -30.0, -14.0, 4.0, -30.0, -8.0, -30.0, 4.0, -30.0, 4.0, -30.0, -8.0, -40.0, -30.0, 2.0, -4.0, -30.0, 8.0, -40.0, -16.0, -8.0, -30.0, -6.0, -30.0, -18.0, -16.0, -30.0, -4.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -6.0, -30.0, -4.0, -40.0, 8.0, -30.0, 4.0, 8.0, -18.0, 12.0, -8.0, -40.0, -16.0, -12.0, -30.0, 8.0, 8.0, -4.0, -30.0, -16.0, -8.0, -12.0, -30.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -14.0, -30.0, -30.0, -30.0, -30.0, -30.0, -20.0, -12.0, -40.0, -16.0, -30.0, -30.0], "episode_lengths": [14, 20, 16, 9, 18, 20, 20, 17, 20, 20, 12, 3, 20, 20, 20, 6, 20, 8, 20, 11, 20, 15, 20, 20, 20, 17, 8, 20, 14, 20, 8, 20, 8, 20, 14, 20, 20, 9, 12, 20, 6, 20, 18, 14, 20, 13, 20, 19, 18, 20, 12, 20, 20, 20, 20, 20, 20, 20, 13, 20, 12, 20, 6, 20, 8, 6, 19, 4, 14, 20, 18, 16, 20, 6, 6, 12, 20, 18, 14, 16, 20, 20, 20, 20, 20, 14, 20, 20, 17, 20, 20, 20, 20, 20, 20, 16, 20, 18, 20, 20], "policy_policy0_reward": [6.0, 0.0, -6.0, -9.0, -8.0, -10.0, -10.0, -7.0, -10.0, -20.0, 8.0, 7.0, -10.0, -10.0, -10.0, 14.0, -20.0, 2.0, -10.0, 9.0, -10.0, -5.0, -10.0, -10.0, -10.0, 3.0, 12.0, -10.0, 6.0, -10.0, 12.0, -10.0, 12.0, -10.0, -4.0, -20.0, -10.0, 1.0, -2.0, -10.0, 14.0, -20.0, 2.0, 6.0, -10.0, 7.0, -10.0, 1.0, 2.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -3.0, -20.0, 8.0, -20.0, 14.0, -10.0, 2.0, 14.0, 1.0, 6.0, 6.0, -20.0, 2.0, 4.0, -10.0, 14.0, 14.0, 8.0, -10.0, 2.0, 6.0, -6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -4.0, -10.0, -20.0, -7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, -8.0, -10.0, -10.0], "policy_policy1_reward": [-14.0, -20.0, -6.0, 11.0, -8.0, -20.0, -20.0, -7.0, -20.0, -10.0, -12.0, 7.0, -20.0, -20.0, -20.0, -6.0, -20.0, 2.0, -20.0, -11.0, -20.0, -5.0, -20.0, -20.0, -20.0, -17.0, -8.0, -20.0, -14.0, -20.0, -8.0, -20.0, -8.0, -20.0, -4.0, -20.0, -20.0, 1.0, -2.0, -20.0, -6.0, -20.0, -18.0, -14.0, -20.0, -13.0, -20.0, -19.0, -18.0, -10.0, -12.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -3.0, -10.0, -12.0, -20.0, -6.0, -20.0, 2.0, -6.0, -19.0, 6.0, -14.0, -20.0, -18.0, -16.0, -20.0, -6.0, -6.0, -12.0, -20.0, -18.0, -14.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -16.0, -20.0, -8.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32897988534857225, "mean_inference_ms": 1.797587616640604, "mean_action_processing_ms": 0.12278889615356085, "mean_env_wait_ms": 0.07684830175300411, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8167, "timesteps_this_iter": 32, "agent_timesteps_total": 16334, "timers": {"load_time_ms": 0.496, "load_throughput": 64518.448, "learn_time_ms": 8.347, "learn_throughput": 3833.763, "update_time_ms": 5.08}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.1226766109466553, "min_q": -3.9522128105163574, "max_q": 13.972813606262207, "mean_td_error": 0.6014860272407532, "model": {}}, "td_error": [1.5365787744522095, 2.7839202880859375, -1.7860805988311768, -0.5969648361206055, 0.8212218284606934, 0.6913925409317017, -0.11582064628601074, 8.699031829833984, 0.8672597408294678, 0.8040399551391602, 0.25493478775024414, -1.2204785346984863, 0.8314642906188965, -0.5963757038116455, 2.2255210876464844, 0.23524004220962524, -5.776681423187256, 1.2929577827453613, 2.081312417984009, 1.4155733585357666, -0.7507460117340088, 0.8009061813354492, 0.7831401824951172, 0.7618341445922852, -2.5678200721740723, 1.5133085250854492, 0.9095735549926758, 0.1343621015548706, 1.5314979553222656, -0.06279540061950684, 0.8939595222473145, 0.8522853851318359], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.919929504394531, "min_q": -18.5150146484375, "max_q": -8.475940704345703, "mean_td_error": -4.388665199279785, "model": {}}, "td_error": [1.181386947631836, -13.948142051696777, -20.73870086669922, 1.1858062744140625, 0.5983219146728516, -18.081905364990234, 0.5475006103515625, -0.2004871368408203, 0.41147708892822266, 3.31793212890625, 3.794902801513672, 0.08178329467773438, -20.73870086669922, 0.04063606262207031, -12.155845642089844, 0.6186819076538086, -11.165600776672363, 1.3992156982421875, 1.1224489212036133, 0.5547275543212891, -17.475940704345703, 0.5530433654785156, -13.999604225158691, -12.429057121276855, -0.4617643356323242, -15.915531158447266, 0.37598228454589844, 0.01964569091796875, -0.4969043731689453, -1.1055221557617188, 2.0843076705932617, 0.5886192321777344], "custom_metrics": {}}}, "num_steps_sampled": 8167, "num_agent_steps_sampled": 16334, "num_steps_trained": 13600, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 27200, "last_target_update_ts": 8127, "num_target_updates": 65}, "done": false, "episodes_total": 483, "training_iteration": 26, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-56", "timestamp": 1648811696, "time_this_iter_s": 1.3472785949707031, "time_total_s": 34.163753271102905, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848def0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848def0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 34.163753271102905, "timesteps_since_restore": 832, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 39.25, "ram_util_percent": 60.85}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.18, "episode_len_mean": 16.64, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -5.04, "policy1": -14.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.0, -30.0, -10.0, -30.0, -30.0, -30.0, -14.0, 4.0, -30.0, -8.0, -30.0, 4.0, -30.0, 4.0, -30.0, -8.0, -40.0, -30.0, 2.0, -4.0, -30.0, 8.0, -40.0, -16.0, -8.0, -30.0, -6.0, -30.0, -18.0, -16.0, -30.0, -4.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -6.0, -30.0, -4.0, -40.0, 8.0, -30.0, 4.0, 8.0, -18.0, 12.0, -8.0, -40.0, -16.0, -12.0, -30.0, 8.0, 8.0, -4.0, -30.0, -16.0, -8.0, -12.0, -30.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -14.0, -30.0, -30.0, -30.0, -30.0, -30.0, -20.0, -12.0, -40.0, -16.0, -30.0, -30.0, -30.0, -30.0, -16.0, 2.0, -30.0, -30.0, -4.0, -30.0, -14.0, 8.0, -30.0, -30.0, 0.0, -16.0, 4.0, -30.0, -30.0, -30.0, -14.0], "episode_lengths": [11, 20, 15, 20, 20, 20, 17, 8, 20, 14, 20, 8, 20, 8, 20, 14, 20, 20, 9, 12, 20, 6, 20, 18, 14, 20, 13, 20, 19, 18, 20, 12, 20, 20, 20, 20, 20, 20, 20, 13, 20, 12, 20, 6, 20, 8, 6, 19, 4, 14, 20, 18, 16, 20, 6, 6, 12, 20, 18, 14, 16, 20, 20, 20, 20, 20, 14, 20, 20, 17, 20, 20, 20, 20, 20, 20, 16, 20, 18, 20, 20, 20, 20, 18, 9, 20, 20, 12, 20, 17, 6, 20, 20, 10, 18, 8, 20, 20, 20, 17], "policy_policy0_reward": [9.0, -10.0, -5.0, -10.0, -10.0, -10.0, 3.0, 12.0, -10.0, 6.0, -10.0, 12.0, -10.0, 12.0, -10.0, -4.0, -20.0, -10.0, 1.0, -2.0, -10.0, 14.0, -20.0, 2.0, 6.0, -10.0, 7.0, -10.0, 1.0, 2.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -3.0, -20.0, 8.0, -20.0, 14.0, -10.0, 2.0, 14.0, 1.0, 6.0, 6.0, -20.0, 2.0, 4.0, -10.0, 14.0, 14.0, 8.0, -10.0, 2.0, 6.0, -6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -4.0, -10.0, -20.0, -7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, -8.0, -10.0, -10.0, -20.0, -10.0, -8.0, -9.0, -10.0, -10.0, -2.0, -10.0, 3.0, 14.0, -10.0, -10.0, -10.0, 2.0, 2.0, -10.0, -10.0, -20.0, -7.0], "policy_policy1_reward": [-11.0, -20.0, -5.0, -20.0, -20.0, -20.0, -17.0, -8.0, -20.0, -14.0, -20.0, -8.0, -20.0, -8.0, -20.0, -4.0, -20.0, -20.0, 1.0, -2.0, -20.0, -6.0, -20.0, -18.0, -14.0, -20.0, -13.0, -20.0, -19.0, -18.0, -10.0, -12.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -3.0, -10.0, -12.0, -20.0, -6.0, -20.0, 2.0, -6.0, -19.0, 6.0, -14.0, -20.0, -18.0, -16.0, -20.0, -6.0, -6.0, -12.0, -20.0, -18.0, -14.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -16.0, -20.0, -8.0, -20.0, -20.0, -10.0, -20.0, -8.0, 11.0, -20.0, -20.0, -2.0, -20.0, -17.0, -6.0, -20.0, -20.0, 10.0, -18.0, 2.0, -20.0, -20.0, -10.0, -7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32928538229601456, "mean_inference_ms": 1.7982112716717489, "mean_action_processing_ms": 0.1229319829709318, "mean_env_wait_ms": 0.07686892719560678, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8482, "timesteps_this_iter": 32, "agent_timesteps_total": 16964, "timers": {"load_time_ms": 0.428, "load_throughput": 74789.774, "learn_time_ms": 7.885, "learn_throughput": 4058.128, "update_time_ms": 5.051}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 1.5381922721862793, "min_q": -2.718409776687622, "max_q": 9.2322416305542, "mean_td_error": 0.32721686363220215, "model": {}}, "td_error": [0.6407493352890015, 2.8485636711120605, 1.041734218597412, 0.9528088569641113, 0.9738050699234009, 1.0854227542877197, 1.3843835592269897, 2.1568655967712402, 0.09506630897521973, 1.3243921995162964, 0.12405872344970703, -1.0521478652954102, 1.1515555381774902, -0.02915811538696289, -0.5549945831298828, 4.0217604637146, 1.8786132335662842, 0.10447216033935547, -0.9069194793701172, 0.44540727138519287, 1.6757559776306152, -0.7333805561065674, 0.7158984541893005, 0.13970661163330078, 0.3314347267150879, 0.34003210067749023, -0.16730737686157227, -9.096576690673828, -0.8703632354736328, 0.7577190399169922, 0.4039020538330078, -0.7123205661773682], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.682059288024902, "min_q": -17.204910278320312, "max_q": -2.813507080078125, "mean_td_error": -3.6195313930511475, "model": {}}, "td_error": [-1.7427349090576172, 0.5224704742431641, 0.4006671905517578, 1.0269384384155273, 0.7121553421020508, -0.1781787872314453, -0.3066844940185547, -13.189665794372559, 1.4731550216674805, -0.5840473175048828, -14.037627220153809, 0.7573680877685547, -11.813507080078125, -4.801403045654297, -0.08566761016845703, -0.31750011444091797, -2.2592759132385254, -1.2736244201660156, 1.051443099975586, 0.98876953125, 1.185598373413086, 0.8474769592285156, 0.9988250732421875, -15.372535705566406, 0.7430276870727539, -13.795931816101074, -15.519021987915039, 3.589951992034912, -0.4390554428100586, -2.0550575256347656, -16.146427154541016, -16.204910278320312], "custom_metrics": {}}}, "num_steps_sampled": 8482, "num_agent_steps_sampled": 16964, "num_steps_trained": 14208, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 28416, "last_target_update_ts": 8465, "num_target_updates": 68}, "done": false, "episodes_total": 502, "training_iteration": 27, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-57", "timestamp": 1648811697, "time_this_iter_s": 1.318742275238037, "time_total_s": 35.48249554634094, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 35.48249554634094, "timesteps_since_restore": 864, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 38.85, "ram_util_percent": 61.4}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.58, "episode_len_mean": 16.64, "episode_media": {}, "episodes_this_iter": 14, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -5.64, "policy1": -13.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -8.0, -40.0, -30.0, 2.0, -4.0, -30.0, 8.0, -40.0, -16.0, -8.0, -30.0, -6.0, -30.0, -18.0, -16.0, -30.0, -4.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -6.0, -30.0, -4.0, -40.0, 8.0, -30.0, 4.0, 8.0, -18.0, 12.0, -8.0, -40.0, -16.0, -12.0, -30.0, 8.0, 8.0, -4.0, -30.0, -16.0, -8.0, -12.0, -30.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -14.0, -30.0, -30.0, -30.0, -30.0, -30.0, -20.0, -12.0, -40.0, -16.0, -30.0, -30.0, -30.0, -30.0, -16.0, 2.0, -30.0, -30.0, -4.0, -30.0, -14.0, 8.0, -30.0, -30.0, 0.0, -16.0, 4.0, -30.0, -30.0, -30.0, -14.0, 4.0, -4.0, -16.0, -30.0, -30.0, -40.0, 4.0, -30.0, 6.0, -30.0, -40.0, 4.0, -40.0, -30.0], "episode_lengths": [20, 14, 20, 20, 9, 12, 20, 6, 20, 18, 14, 20, 13, 20, 19, 18, 20, 12, 20, 20, 20, 20, 20, 20, 20, 13, 20, 12, 20, 6, 20, 8, 6, 19, 4, 14, 20, 18, 16, 20, 6, 6, 12, 20, 18, 14, 16, 20, 20, 20, 20, 20, 14, 20, 20, 17, 20, 20, 20, 20, 20, 20, 16, 20, 18, 20, 20, 20, 20, 18, 9, 20, 20, 12, 20, 17, 6, 20, 20, 10, 18, 8, 20, 20, 20, 17, 8, 12, 18, 20, 20, 20, 8, 20, 7, 20, 20, 8, 20, 20], "policy_policy0_reward": [-10.0, -4.0, -20.0, -10.0, 1.0, -2.0, -10.0, 14.0, -20.0, 2.0, 6.0, -10.0, 7.0, -10.0, 1.0, 2.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -3.0, -20.0, 8.0, -20.0, 14.0, -10.0, 2.0, 14.0, 1.0, 6.0, 6.0, -20.0, 2.0, 4.0, -10.0, 14.0, 14.0, 8.0, -10.0, 2.0, 6.0, -6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -4.0, -10.0, -20.0, -7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, -8.0, -10.0, -10.0, -20.0, -10.0, -8.0, -9.0, -10.0, -10.0, -2.0, -10.0, 3.0, 14.0, -10.0, -10.0, -10.0, 2.0, 2.0, -10.0, -10.0, -20.0, -7.0, 12.0, 8.0, -8.0, -10.0, -10.0, -20.0, 12.0, -10.0, 3.0, -10.0, -20.0, 12.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -4.0, -20.0, -20.0, 1.0, -2.0, -20.0, -6.0, -20.0, -18.0, -14.0, -20.0, -13.0, -20.0, -19.0, -18.0, -10.0, -12.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -3.0, -10.0, -12.0, -20.0, -6.0, -20.0, 2.0, -6.0, -19.0, 6.0, -14.0, -20.0, -18.0, -16.0, -20.0, -6.0, -6.0, -12.0, -20.0, -18.0, -14.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -16.0, -20.0, -8.0, -20.0, -20.0, -10.0, -20.0, -8.0, 11.0, -20.0, -20.0, -2.0, -20.0, -17.0, -6.0, -20.0, -20.0, 10.0, -18.0, 2.0, -20.0, -20.0, -10.0, -7.0, -8.0, -12.0, -8.0, -20.0, -20.0, -20.0, -8.0, -20.0, 3.0, -20.0, -20.0, -8.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3295560687597519, "mean_inference_ms": 1.7993677984555092, "mean_action_processing_ms": 0.12310052985922944, "mean_env_wait_ms": 0.07690628013495565, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8703, "timesteps_this_iter": 32, "agent_timesteps_total": 17406, "timers": {"load_time_ms": 0.438, "load_throughput": 73047.637, "learn_time_ms": 8.716, "learn_throughput": 3671.475, "update_time_ms": 5.222}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 0.09797531366348267, "min_q": -4.315211296081543, "max_q": 7.520429611206055, "mean_td_error": 0.3521652817726135, "model": {}}, "td_error": [2.074289560317993, -1.8897416591644287, 1.1232510805130005, 1.0254755020141602, 0.014095783233642578, 0.4215857982635498, -0.4941434860229492, 0.18923139572143555, -2.3299400806427, 0.4790792465209961, 0.5428752899169922, 1.800753116607666, 3.0285797119140625, -0.4484386444091797, 0.15838027000427246, 3.907857656478882, 0.0520017147064209, 0.4812138080596924, 0.2439265251159668, 0.016965866088867188, 4.6456756591796875, -1.0883569717407227, -0.5552921295166016, 0.09642243385314941, 2.2426486015319824, -1.4348869323730469, 1.0351850986480713, -2.82525897026062, 0.6074151992797852, 0.014095783233642578, -3.315211296081543, 1.4495540857315063], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.962774276733398, "min_q": -17.982147216796875, "max_q": -1.0716876983642578, "mean_td_error": -2.3154208660125732, "model": {}}, "td_error": [0.9449138641357422, -1.0578205585479736, -1.5319230556488037, 0.4521923065185547, 0.5579624176025391, -1.4034032821655273, 0.6921577453613281, -16.219257354736328, 2.3897619247436523, -15.978497505187988, -7.084502220153809, 0.4825401306152344, 0.3522300720214844, 1.2905397415161133, 0.47832679748535156, -7.2210283279418945, 0.34392738342285156, 0.1289520263671875, 0.2984771728515625, -14.977437019348145, -5.903841972351074, 1.3291015625, 0.26036834716796875, -1.1758427619934082, 0.8177814483642578, 0.27173614501953125, -0.04696464538574219, -15.183263778686523, 1.5797691345214844, 0.5631027221679688, -0.07168769836425781, 0.5281600952148438], "custom_metrics": {}}}, "num_steps_sampled": 8703, "num_agent_steps_sampled": 17406, "num_steps_trained": 14656, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 29312, "last_target_update_ts": 8683, "num_target_updates": 70}, "done": false, "episodes_total": 516, "training_iteration": 28, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-58", "timestamp": 1648811698, "time_this_iter_s": 0.9831264019012451, "time_total_s": 36.46562194824219, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 36.46562194824219, "timesteps_since_restore": 896, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 39.0, "ram_util_percent": 62.099999999999994}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.84, "episode_len_mean": 16.42, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -5.42, "policy1": -13.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-16.0, -30.0, -4.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -6.0, -30.0, -4.0, -40.0, 8.0, -30.0, 4.0, 8.0, -18.0, 12.0, -8.0, -40.0, -16.0, -12.0, -30.0, 8.0, 8.0, -4.0, -30.0, -16.0, -8.0, -12.0, -30.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -14.0, -30.0, -30.0, -30.0, -30.0, -30.0, -20.0, -12.0, -40.0, -16.0, -30.0, -30.0, -30.0, -30.0, -16.0, 2.0, -30.0, -30.0, -4.0, -30.0, -14.0, 8.0, -30.0, -30.0, 0.0, -16.0, 4.0, -30.0, -30.0, -30.0, -14.0, 4.0, -4.0, -16.0, -30.0, -30.0, -40.0, 4.0, -30.0, 6.0, -30.0, -40.0, 4.0, -40.0, -30.0, -30.0, 0.0, -30.0, 8.0, 10.0, -30.0, -6.0, -12.0, -30.0, 4.0, -12.0, -12.0, -6.0, -30.0, -30.0], "episode_lengths": [18, 20, 12, 20, 20, 20, 20, 20, 20, 20, 13, 20, 12, 20, 6, 20, 8, 6, 19, 4, 14, 20, 18, 16, 20, 6, 6, 12, 20, 18, 14, 16, 20, 20, 20, 20, 20, 14, 20, 20, 17, 20, 20, 20, 20, 20, 20, 16, 20, 18, 20, 20, 20, 20, 18, 9, 20, 20, 12, 20, 17, 6, 20, 20, 10, 18, 8, 20, 20, 20, 17, 8, 12, 18, 20, 20, 20, 8, 20, 7, 20, 20, 8, 20, 20, 20, 10, 20, 6, 5, 20, 13, 16, 20, 8, 16, 16, 13, 20, 20], "policy_policy0_reward": [2.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -3.0, -20.0, 8.0, -20.0, 14.0, -10.0, 2.0, 14.0, 1.0, 6.0, 6.0, -20.0, 2.0, 4.0, -10.0, 14.0, 14.0, 8.0, -10.0, 2.0, 6.0, -6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -4.0, -10.0, -20.0, -7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, -8.0, -10.0, -10.0, -20.0, -10.0, -8.0, -9.0, -10.0, -10.0, -2.0, -10.0, 3.0, 14.0, -10.0, -10.0, -10.0, 2.0, 2.0, -10.0, -10.0, -20.0, -7.0, 12.0, 8.0, -8.0, -10.0, -10.0, -20.0, 12.0, -10.0, 3.0, -10.0, -20.0, 12.0, -20.0, -20.0, -10.0, 10.0, -20.0, 14.0, 5.0, -10.0, -3.0, 4.0, -10.0, 12.0, -6.0, 4.0, -13.0, -10.0, -10.0], "policy_policy1_reward": [-18.0, -10.0, -12.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -3.0, -10.0, -12.0, -20.0, -6.0, -20.0, 2.0, -6.0, -19.0, 6.0, -14.0, -20.0, -18.0, -16.0, -20.0, -6.0, -6.0, -12.0, -20.0, -18.0, -14.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -16.0, -20.0, -8.0, -20.0, -20.0, -10.0, -20.0, -8.0, 11.0, -20.0, -20.0, -2.0, -20.0, -17.0, -6.0, -20.0, -20.0, 10.0, -18.0, 2.0, -20.0, -20.0, -10.0, -7.0, -8.0, -12.0, -8.0, -20.0, -20.0, -20.0, -8.0, -20.0, 3.0, -20.0, -20.0, -8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -6.0, 5.0, -20.0, -3.0, -16.0, -20.0, -8.0, -6.0, -16.0, 7.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32971759903388764, "mean_inference_ms": 1.7997436805444806, "mean_action_processing_ms": 0.12318835551086035, "mean_env_wait_ms": 0.07691128204477488, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8926, "timesteps_this_iter": 32, "agent_timesteps_total": 17852, "timers": {"load_time_ms": 0.445, "load_throughput": 71943.465, "learn_time_ms": 8.042, "learn_throughput": 3979.038, "update_time_ms": 5.18}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.340314269065857, "min_q": -5.324206829071045, "max_q": 4.345372200012207, "mean_td_error": 0.10555072128772736, "model": {}}, "td_error": [-0.8908145427703857, 0.9588994979858398, 0.6544613838195801, -3.1798152923583984, 0.7782220840454102, 0.4989051818847656, 1.3442168235778809, -4.265129089355469, -0.06525939702987671, 1.270479679107666, 0.2594609260559082, 0.29308176040649414, 1.0415925979614258, 0.9611282348632812, 0.22690248489379883, -1.5773301124572754, 0.6687042713165283, 0.9493308067321777, -0.1598813533782959, 0.8103780746459961, 1.3603544235229492, -0.6079797744750977, -0.9061059951782227, 2.050534248352051, -0.4009590148925781, 1.490898609161377, -0.4565896987915039, -1.2731037139892578, 0.7802953720092773, -0.9061059951782227, 0.6984333992004395, 0.9704170227050781], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.826017379760742, "min_q": -19.602890014648438, "max_q": 10.58775520324707, "mean_td_error": -0.8507897853851318, "model": {}}, "td_error": [2.0988588333129883, 2.8563761711120605, -6.777305603027344, 1.1325092315673828, 0.02475738525390625, -7.385540008544922, 0.7647838592529297, -14.624251365661621, -3.3084144592285156, 2.774376392364502, -2.136155128479004, 1.876636028289795, 0.8691596984863281, -24.59635353088379, -0.033537864685058594, -0.7282638549804688, 0.6755123138427734, 4.063852310180664, 2.85660457611084, 0.07793998718261719, 0.46826171875, -9.44148063659668, 1.9397411346435547, 0.9865493774414062, 0.9385089874267578, 3.2236061096191406, 1.0307846069335938, 2.8656005859375, 5.470150947570801, 2.4653587341308594, 0.7583465576171875, 1.5877552032470703], "custom_metrics": {}}}, "num_steps_sampled": 8926, "num_agent_steps_sampled": 17852, "num_steps_trained": 15136, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 30272, "last_target_update_ts": 8886, "num_target_updates": 72}, "done": false, "episodes_total": 531, "training_iteration": 29, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-14-59", "timestamp": 1648811699, "time_this_iter_s": 0.9911623001098633, "time_total_s": 37.45678424835205, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 37.45678424835205, "timesteps_since_restore": 928, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 39.2, "ram_util_percent": 62.7}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.14, "episode_len_mean": 15.57, "episode_media": {}, "episodes_this_iter": 25, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -4.07, "policy1": -12.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, -4.0, -30.0, -16.0, -8.0, -12.0, -30.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -14.0, -30.0, -30.0, -30.0, -30.0, -30.0, -20.0, -12.0, -40.0, -16.0, -30.0, -30.0, -30.0, -30.0, -16.0, 2.0, -30.0, -30.0, -4.0, -30.0, -14.0, 8.0, -30.0, -30.0, 0.0, -16.0, 4.0, -30.0, -30.0, -30.0, -14.0, 4.0, -4.0, -16.0, -30.0, -30.0, -40.0, 4.0, -30.0, 6.0, -30.0, -40.0, 4.0, -40.0, -30.0, -30.0, 0.0, -30.0, 8.0, 10.0, -30.0, -6.0, -12.0, -30.0, 4.0, -12.0, -12.0, -6.0, -30.0, -30.0, 14.0, -30.0, 0.0, 14.0, -4.0, -6.0, -30.0, -8.0, -4.0, -30.0, -30.0, 4.0, 0.0, -12.0, -12.0, -30.0, -8.0, -4.0, -8.0, -2.0, 8.0, 0.0, -6.0, -2.0, -6.0], "episode_lengths": [6, 6, 12, 20, 18, 14, 16, 20, 20, 20, 20, 20, 14, 20, 20, 17, 20, 20, 20, 20, 20, 20, 16, 20, 18, 20, 20, 20, 20, 18, 9, 20, 20, 12, 20, 17, 6, 20, 20, 10, 18, 8, 20, 20, 20, 17, 8, 12, 18, 20, 20, 20, 8, 20, 7, 20, 20, 8, 20, 20, 20, 10, 20, 6, 5, 20, 13, 16, 20, 8, 16, 16, 13, 20, 20, 3, 20, 10, 3, 12, 13, 20, 14, 12, 20, 20, 8, 10, 16, 16, 20, 14, 12, 14, 11, 6, 10, 13, 11, 13], "policy_policy0_reward": [14.0, 14.0, 8.0, -10.0, 2.0, 6.0, -6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -4.0, -10.0, -20.0, -7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, -8.0, -10.0, -10.0, -20.0, -10.0, -8.0, -9.0, -10.0, -10.0, -2.0, -10.0, 3.0, 14.0, -10.0, -10.0, -10.0, 2.0, 2.0, -10.0, -10.0, -20.0, -7.0, 12.0, 8.0, -8.0, -10.0, -10.0, -20.0, 12.0, -10.0, 3.0, -10.0, -20.0, 12.0, -20.0, -20.0, -10.0, 10.0, -20.0, 14.0, 5.0, -10.0, -3.0, 4.0, -10.0, 12.0, -6.0, 4.0, -13.0, -10.0, -10.0, 7.0, -10.0, 10.0, 7.0, 8.0, -13.0, -10.0, 6.0, 8.0, -10.0, -10.0, 12.0, 10.0, 4.0, 4.0, -20.0, 6.0, 8.0, 6.0, -11.0, 14.0, 10.0, -3.0, -11.0, -3.0], "policy_policy1_reward": [-6.0, -6.0, -12.0, -20.0, -18.0, -14.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -16.0, -20.0, -8.0, -20.0, -20.0, -10.0, -20.0, -8.0, 11.0, -20.0, -20.0, -2.0, -20.0, -17.0, -6.0, -20.0, -20.0, 10.0, -18.0, 2.0, -20.0, -20.0, -10.0, -7.0, -8.0, -12.0, -8.0, -20.0, -20.0, -20.0, -8.0, -20.0, 3.0, -20.0, -20.0, -8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -6.0, 5.0, -20.0, -3.0, -16.0, -20.0, -8.0, -6.0, -16.0, 7.0, -20.0, -20.0, 7.0, -20.0, -10.0, 7.0, -12.0, 7.0, -20.0, -14.0, -12.0, -20.0, -20.0, -8.0, -10.0, -16.0, -16.0, -10.0, -14.0, -12.0, -14.0, 9.0, -6.0, -10.0, -3.0, 9.0, -3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32991803621210464, "mean_inference_ms": 1.799311272627267, "mean_action_processing_ms": 0.1232361487299827, "mean_env_wait_ms": 0.07688835957181986, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9247, "timesteps_this_iter": 32, "agent_timesteps_total": 18494, "timers": {"load_time_ms": 0.467, "load_throughput": 68478.433, "learn_time_ms": 7.944, "learn_throughput": 4028.349, "update_time_ms": 4.91}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.744378685951233, "min_q": -6.7112932205200195, "max_q": 4.145143985748291, "mean_td_error": -0.3273075520992279, "model": {}}, "td_error": [-0.9166827201843262, 2.0117666721343994, -0.9876837730407715, 1.8176052570343018, 0.9544034004211426, -1.5031323432922363, 0.628739595413208, 0.23546981811523438, -0.24607181549072266, -0.6253175735473633, 0.7052819728851318, 2.0553152561187744, 1.4273905754089355, -0.7353286743164062, 0.6118307113647461, 1.6505231857299805, 0.9599289894104004, -1.9490656852722168, 0.7048492431640625, -1.0128241777420044, -0.16868042945861816, 1.3735737800598145, 0.41068124771118164, -0.0243682861328125, -1.7661328315734863, -2.034066915512085, -2.7399988174438477, -0.48111391067504883, -7.451587677001953, 0.4734978675842285, -3.2314648628234863, -0.6211788654327393], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.601571083068848, "min_q": -20.19626808166504, "max_q": 8.560547828674316, "mean_td_error": -0.8028520941734314, "model": {}}, "td_error": [5.040828227996826, -0.033428192138671875, 3.589061737060547, 1.192300796508789, -6.3078203201293945, 2.1220970153808594, 1.4390678405761719, -7.1472673416137695, 1.4725589752197266, 3.476088523864746, 1.6255519390106201, 0.37897491455078125, 1.749673843383789, 1.4643678665161133, -16.993675231933594, 0.38925743103027344, 0.929595947265625, 1.6820068359375, 0.37252044677734375, 0.9338893890380859, -19.19626808166504, 3.2125988006591797, -6.449713706970215, -0.14635848999023438, -0.6067647933959961, -6.037923812866211, 3.2125988006591797, -0.48954200744628906, 1.1054439544677734, 2.107855796813965, 0.6039257049560547, -0.3827705383300781], "custom_metrics": {}}}, "num_steps_sampled": 9247, "num_agent_steps_sampled": 18494, "num_steps_trained": 15872, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 31744, "last_target_update_ts": 9194, "num_target_updates": 75}, "done": false, "episodes_total": 556, "training_iteration": 30, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-01", "timestamp": 1648811701, "time_this_iter_s": 1.449282169342041, "time_total_s": 38.90606641769409, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 38.90606641769409, "timesteps_since_restore": 960, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 38.4, "ram_util_percent": 63.15}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.48, "episode_len_mean": 14.99, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -3.59, "policy1": -10.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -30.0, -30.0, -30.0, -20.0, -12.0, -40.0, -16.0, -30.0, -30.0, -30.0, -30.0, -16.0, 2.0, -30.0, -30.0, -4.0, -30.0, -14.0, 8.0, -30.0, -30.0, 0.0, -16.0, 4.0, -30.0, -30.0, -30.0, -14.0, 4.0, -4.0, -16.0, -30.0, -30.0, -40.0, 4.0, -30.0, 6.0, -30.0, -40.0, 4.0, -40.0, -30.0, -30.0, 0.0, -30.0, 8.0, 10.0, -30.0, -6.0, -12.0, -30.0, 4.0, -12.0, -12.0, -6.0, -30.0, -30.0, 14.0, -30.0, 0.0, 14.0, -4.0, -6.0, -30.0, -8.0, -4.0, -30.0, -30.0, 4.0, 0.0, -12.0, -12.0, -30.0, -8.0, -4.0, -8.0, -2.0, 8.0, 0.0, -6.0, -2.0, -6.0, -30.0, -8.0, 2.0, 2.0, -12.0, 8.0, -6.0, -6.0, 4.0, 6.0, -4.0, -30.0, 4.0, 0.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 16, 20, 18, 20, 20, 20, 20, 18, 9, 20, 20, 12, 20, 17, 6, 20, 20, 10, 18, 8, 20, 20, 20, 17, 8, 12, 18, 20, 20, 20, 8, 20, 7, 20, 20, 8, 20, 20, 20, 10, 20, 6, 5, 20, 13, 16, 20, 8, 16, 16, 13, 20, 20, 3, 20, 10, 3, 12, 13, 20, 14, 12, 20, 20, 8, 10, 16, 16, 20, 14, 12, 14, 11, 6, 10, 13, 11, 13, 20, 14, 9, 9, 16, 6, 13, 13, 8, 7, 12, 20, 8, 10, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, -8.0, -10.0, -10.0, -20.0, -10.0, -8.0, -9.0, -10.0, -10.0, -2.0, -10.0, 3.0, 14.0, -10.0, -10.0, -10.0, 2.0, 2.0, -10.0, -10.0, -20.0, -7.0, 12.0, 8.0, -8.0, -10.0, -10.0, -20.0, 12.0, -10.0, 3.0, -10.0, -20.0, 12.0, -20.0, -20.0, -10.0, 10.0, -20.0, 14.0, 5.0, -10.0, -3.0, 4.0, -10.0, 12.0, -6.0, 4.0, -13.0, -10.0, -10.0, 7.0, -10.0, 10.0, 7.0, 8.0, -13.0, -10.0, 6.0, 8.0, -10.0, -10.0, 12.0, 10.0, 4.0, 4.0, -20.0, 6.0, 8.0, 6.0, -11.0, 14.0, 10.0, -3.0, -11.0, -3.0, -10.0, 6.0, 1.0, 1.0, 4.0, 14.0, -3.0, -13.0, 12.0, 3.0, 8.0, -20.0, 2.0, 0.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -16.0, -20.0, -8.0, -20.0, -20.0, -10.0, -20.0, -8.0, 11.0, -20.0, -20.0, -2.0, -20.0, -17.0, -6.0, -20.0, -20.0, 10.0, -18.0, 2.0, -20.0, -20.0, -10.0, -7.0, -8.0, -12.0, -8.0, -20.0, -20.0, -20.0, -8.0, -20.0, 3.0, -20.0, -20.0, -8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -6.0, 5.0, -20.0, -3.0, -16.0, -20.0, -8.0, -6.0, -16.0, 7.0, -20.0, -20.0, 7.0, -20.0, -10.0, 7.0, -12.0, 7.0, -20.0, -14.0, -12.0, -20.0, -20.0, -8.0, -10.0, -16.0, -16.0, -10.0, -14.0, -12.0, -14.0, 9.0, -6.0, -10.0, -3.0, 9.0, -3.0, -20.0, -14.0, 1.0, 1.0, -16.0, -6.0, -3.0, 7.0, -8.0, 3.0, -12.0, -10.0, 2.0, 0.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33005943685573913, "mean_inference_ms": 1.7990838508655314, "mean_action_processing_ms": 0.12325393096667007, "mean_env_wait_ms": 0.07687874476452375, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9452, "timesteps_this_iter": 32, "agent_timesteps_total": 18904, "timers": {"load_time_ms": 0.44, "load_throughput": 72770.401, "learn_time_ms": 8.218, "learn_throughput": 3894.116, "update_time_ms": 5.041}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.2056043148040771, "min_q": -7.1235032081604, "max_q": 7.587764263153076, "mean_td_error": -1.1309864521026611, "model": {}}, "td_error": [0.5111846923828125, 0.674415111541748, -0.7328119277954102, -0.7000980377197266, -0.9604682922363281, 0.9262717962265015, -2.4298312664031982, -4.293023586273193, -1.552368402481079, 0.47992849349975586, -10.593255043029785, -1.694822072982788, 1.602948546409607, -1.2599165439605713, 0.31573915481567383, -3.929049491882324, -2.8570713996887207, 0.312669038772583, -1.4122357368469238, -0.1775212287902832, 1.4057378768920898, 0.4927363395690918, -0.9760525226593018, -0.07892727851867676, -4.949637413024902, -1.0706243515014648, -0.9760146141052246, -2.4372167587280273, -2.0640668869018555, 1.0292329788208008, 0.5264139175415039, 0.6761689186096191], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.646804809570312, "min_q": -20.698410034179688, "max_q": 6.747182846069336, "mean_td_error": -0.2559394836425781, "model": {}}, "td_error": [0.0888969898223877, 2.774043560028076, 3.36358642578125, 3.0553107261657715, -12.48337173461914, 3.2380027770996094, 5.7045135498046875, 3.6658706665039062, 2.6830101013183594, -1.092172622680664, 1.6585350036621094, -0.33926916122436523, 0.25975608825683594, -14.793038368225098, 3.6216678619384766, 2.765247344970703, 3.237394332885742, -0.5833663940429688, -0.027587890625, -18.3828125, 0.3473472595214844, -0.07864189147949219, -4.284276008605957, -0.14205336570739746, -2.695263624191284, 0.8492698669433594, 2.928741931915283, 0.7296047210693359, 1.9833202362060547, -0.9654636383056641, 3.6216659545898438, 1.1014690399169922], "custom_metrics": {}}}, "num_steps_sampled": 9452, "num_agent_steps_sampled": 18904, "num_steps_trained": 16384, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 32768, "last_target_update_ts": 9402, "num_target_updates": 77}, "done": false, "episodes_total": 572, "training_iteration": 31, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-02", "timestamp": 1648811702, "time_this_iter_s": 0.9784755706787109, "time_total_s": 39.8845419883728, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847fdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847fdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 39.8845419883728, "timesteps_since_restore": 992, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 39.2, "ram_util_percent": 63.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -10.58, "episode_len_mean": 13.49, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 10.0}, "policy_reward_mean": {"policy0": -1.59, "policy1": -8.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, -30.0, -30.0, 0.0, -16.0, 4.0, -30.0, -30.0, -30.0, -14.0, 4.0, -4.0, -16.0, -30.0, -30.0, -40.0, 4.0, -30.0, 6.0, -30.0, -40.0, 4.0, -40.0, -30.0, -30.0, 0.0, -30.0, 8.0, 10.0, -30.0, -6.0, -12.0, -30.0, 4.0, -12.0, -12.0, -6.0, -30.0, -30.0, 14.0, -30.0, 0.0, 14.0, -4.0, -6.0, -30.0, -8.0, -4.0, -30.0, -30.0, 4.0, 0.0, -12.0, -12.0, -30.0, -8.0, -4.0, -8.0, -2.0, 8.0, 0.0, -6.0, -2.0, -6.0, -30.0, -8.0, 2.0, 2.0, -12.0, 8.0, -6.0, -6.0, 4.0, 6.0, -4.0, -30.0, 4.0, 0.0, -30.0, -30.0, -14.0, 8.0, 8.0, -8.0, 8.0, -12.0, -30.0, 8.0, 0.0, -12.0, 14.0, 4.0, 0.0, -6.0, -2.0, 6.0, 6.0, 12.0, -40.0, -40.0], "episode_lengths": [6, 20, 20, 10, 18, 8, 20, 20, 20, 17, 8, 12, 18, 20, 20, 20, 8, 20, 7, 20, 20, 8, 20, 20, 20, 10, 20, 6, 5, 20, 13, 16, 20, 8, 16, 16, 13, 20, 20, 3, 20, 10, 3, 12, 13, 20, 14, 12, 20, 20, 8, 10, 16, 16, 20, 14, 12, 14, 11, 6, 10, 13, 11, 13, 20, 14, 9, 9, 16, 6, 13, 13, 8, 7, 12, 20, 8, 10, 20, 20, 17, 6, 6, 14, 6, 16, 20, 6, 10, 16, 3, 8, 10, 13, 11, 7, 7, 4, 20, 20], "policy_policy0_reward": [14.0, -10.0, -10.0, -10.0, 2.0, 2.0, -10.0, -10.0, -20.0, -7.0, 12.0, 8.0, -8.0, -10.0, -10.0, -20.0, 12.0, -10.0, 3.0, -10.0, -20.0, 12.0, -20.0, -20.0, -10.0, 10.0, -20.0, 14.0, 5.0, -10.0, -3.0, 4.0, -10.0, 12.0, -6.0, 4.0, -13.0, -10.0, -10.0, 7.0, -10.0, 10.0, 7.0, 8.0, -13.0, -10.0, 6.0, 8.0, -10.0, -10.0, 12.0, 10.0, 4.0, 4.0, -20.0, 6.0, 8.0, 6.0, -11.0, 14.0, 10.0, -3.0, -11.0, -3.0, -10.0, 6.0, 1.0, 1.0, 4.0, 14.0, -3.0, -13.0, 12.0, 3.0, 8.0, -20.0, 2.0, 0.0, -10.0, -10.0, -7.0, 14.0, 14.0, 6.0, 4.0, 4.0, -20.0, 4.0, 10.0, 4.0, 7.0, 2.0, 10.0, -3.0, -1.0, 3.0, 3.0, 6.0, -20.0, -20.0], "policy_policy1_reward": [-6.0, -20.0, -20.0, 10.0, -18.0, 2.0, -20.0, -20.0, -10.0, -7.0, -8.0, -12.0, -8.0, -20.0, -20.0, -20.0, -8.0, -20.0, 3.0, -20.0, -20.0, -8.0, -20.0, -10.0, -20.0, -10.0, -10.0, -6.0, 5.0, -20.0, -3.0, -16.0, -20.0, -8.0, -6.0, -16.0, 7.0, -20.0, -20.0, 7.0, -20.0, -10.0, 7.0, -12.0, 7.0, -20.0, -14.0, -12.0, -20.0, -20.0, -8.0, -10.0, -16.0, -16.0, -10.0, -14.0, -12.0, -14.0, 9.0, -6.0, -10.0, -3.0, 9.0, -3.0, -20.0, -14.0, 1.0, 1.0, -16.0, -6.0, -3.0, 7.0, -8.0, 3.0, -12.0, -10.0, 2.0, 0.0, -20.0, -20.0, -7.0, -6.0, -6.0, -14.0, 4.0, -16.0, -10.0, 4.0, -10.0, -16.0, 7.0, 2.0, -10.0, -3.0, -1.0, 3.0, 3.0, 6.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33027113155663995, "mean_inference_ms": 1.7988132330370776, "mean_action_processing_ms": 0.12324010763026579, "mean_env_wait_ms": 0.07685912880026907, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9672, "timesteps_this_iter": 32, "agent_timesteps_total": 19344, "timers": {"load_time_ms": 0.455, "load_throughput": 70374.228, "learn_time_ms": 9.46, "learn_throughput": 3382.691, "update_time_ms": 5.26}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 1.5416189432144165, "min_q": -4.855092525482178, "max_q": 6.805508613586426, "mean_td_error": -0.9384433627128601, "model": {}}, "td_error": [-6.216038703918457, -0.30046844482421875, -2.382481575012207, -2.097099781036377, -0.566041111946106, -1.8343106508255005, -1.1376895904541016, -0.6161632537841797, -3.9138107299804688, -1.0467411279678345, -0.09504973888397217, -2.0627760887145996, 0.05156755447387695, -2.4157185554504395, -1.3761563301086426, 0.9131343364715576, -3.1146087646484375, 0.20643389225006104, -1.4095356464385986, 3.5680134296417236, 0.6450947523117065, -1.0031487941741943, -3.5610461235046387, 0.10972929000854492, 7.410679817199707, -0.12834882736206055, -10.917099952697754, 1.5194759368896484, -0.2094559669494629, 0.577460765838623, 0.37981748580932617, 0.9921941757202148], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.865955352783203, "min_q": -19.911592483520508, "max_q": 0.5191211104393005, "mean_td_error": -2.2992496490478516, "model": {}}, "td_error": [-3.3552188873291016, -14.22442626953125, 0.3662681579589844, 0.020051956176757812, 2.2445764541625977, 0.24884796142578125, -5.347846031188965, -0.9671840667724609, -1.743406057357788, 0.7934637069702148, 2.0757083892822266, -0.8146800994873047, -18.911592483520508, 0.6353788375854492, -8.295409202575684, 1.2895517349243164, 0.0037078857421875, 1.3597469329833984, 0.6423892974853516, -0.10672569274902344, -2.0571846961975098, -0.3065338134765625, 0.13538551330566406, -1.0867938995361328, 0.2610645294189453, -2.049417495727539, -7.384264945983887, 0.3753509521484375, -0.000217437744140625, -0.08585929870605469, 0.12940406799316406, -17.420129776000977], "custom_metrics": {}}}, "num_steps_sampled": 9672, "num_agent_steps_sampled": 19344, "num_steps_trained": 16992, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 33984, "last_target_update_ts": 9621, "num_target_updates": 79}, "done": false, "episodes_total": 592, "training_iteration": 32, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-03", "timestamp": 1648811703, "time_this_iter_s": 1.1225786209106445, "time_total_s": 41.00712060928345, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 41.00712060928345, "timesteps_since_restore": 1024, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 40.15, "ram_util_percent": 63.75}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -8.44, "episode_len_mean": 12.77, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 9.0}, "policy_reward_mean": {"policy0": -0.47, "policy1": -7.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, 0.0, -30.0, 8.0, 10.0, -30.0, -6.0, -12.0, -30.0, 4.0, -12.0, -12.0, -6.0, -30.0, -30.0, 14.0, -30.0, 0.0, 14.0, -4.0, -6.0, -30.0, -8.0, -4.0, -30.0, -30.0, 4.0, 0.0, -12.0, -12.0, -30.0, -8.0, -4.0, -8.0, -2.0, 8.0, 0.0, -6.0, -2.0, -6.0, -30.0, -8.0, 2.0, 2.0, -12.0, 8.0, -6.0, -6.0, 4.0, 6.0, -4.0, -30.0, 4.0, 0.0, -30.0, -30.0, -14.0, 8.0, 8.0, -8.0, 8.0, -12.0, -30.0, 8.0, 0.0, -12.0, 14.0, 4.0, 0.0, -6.0, -2.0, 6.0, 6.0, 12.0, -40.0, -40.0, 14.0, 10.0, 0.0, -16.0, -12.0, 0.0, -30.0, -30.0, -16.0, -30.0, 8.0, -30.0, -40.0, 8.0, -8.0, 0.0, -4.0, 14.0, -12.0, -30.0, 2.0, 4.0, 12.0, -40.0], "episode_lengths": [20, 10, 20, 6, 5, 20, 13, 16, 20, 8, 16, 16, 13, 20, 20, 3, 20, 10, 3, 12, 13, 20, 14, 12, 20, 20, 8, 10, 16, 16, 20, 14, 12, 14, 11, 6, 10, 13, 11, 13, 20, 14, 9, 9, 16, 6, 13, 13, 8, 7, 12, 20, 8, 10, 20, 20, 17, 6, 6, 14, 6, 16, 20, 6, 10, 16, 3, 8, 10, 13, 11, 7, 7, 4, 20, 20, 3, 5, 10, 18, 16, 10, 20, 20, 18, 20, 6, 20, 20, 6, 14, 10, 12, 3, 16, 20, 9, 8, 4, 20], "policy_policy0_reward": [-10.0, 10.0, -20.0, 14.0, 5.0, -10.0, -3.0, 4.0, -10.0, 12.0, -6.0, 4.0, -13.0, -10.0, -10.0, 7.0, -10.0, 10.0, 7.0, 8.0, -13.0, -10.0, 6.0, 8.0, -10.0, -10.0, 12.0, 10.0, 4.0, 4.0, -20.0, 6.0, 8.0, 6.0, -11.0, 14.0, 10.0, -3.0, -11.0, -3.0, -10.0, 6.0, 1.0, 1.0, 4.0, 14.0, -3.0, -13.0, 12.0, 3.0, 8.0, -20.0, 2.0, 0.0, -10.0, -10.0, -7.0, 14.0, 14.0, 6.0, 4.0, 4.0, -20.0, 4.0, 10.0, 4.0, 7.0, 2.0, 10.0, -3.0, -1.0, 3.0, 3.0, 6.0, -20.0, -20.0, 7.0, 5.0, 10.0, -8.0, 4.0, 0.0, -10.0, -10.0, 2.0, -10.0, 4.0, -20.0, -20.0, 4.0, 6.0, 10.0, 8.0, 7.0, 4.0, -10.0, 1.0, 2.0, 6.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -6.0, 5.0, -20.0, -3.0, -16.0, -20.0, -8.0, -6.0, -16.0, 7.0, -20.0, -20.0, 7.0, -20.0, -10.0, 7.0, -12.0, 7.0, -20.0, -14.0, -12.0, -20.0, -20.0, -8.0, -10.0, -16.0, -16.0, -10.0, -14.0, -12.0, -14.0, 9.0, -6.0, -10.0, -3.0, 9.0, -3.0, -20.0, -14.0, 1.0, 1.0, -16.0, -6.0, -3.0, 7.0, -8.0, 3.0, -12.0, -10.0, 2.0, 0.0, -20.0, -20.0, -7.0, -6.0, -6.0, -14.0, 4.0, -16.0, -10.0, 4.0, -10.0, -16.0, 7.0, 2.0, -10.0, -3.0, -1.0, 3.0, 3.0, 6.0, -20.0, -20.0, 7.0, 5.0, -10.0, -8.0, -16.0, 0.0, -20.0, -20.0, -18.0, -20.0, 4.0, -10.0, -20.0, 4.0, -14.0, -10.0, -12.0, 7.0, -16.0, -20.0, 1.0, 2.0, 6.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3306321536692795, "mean_inference_ms": 1.7982729988316317, "mean_action_processing_ms": 0.12319417963846568, "mean_env_wait_ms": 0.07684399598831478, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9980, "timesteps_this_iter": 32, "agent_timesteps_total": 19960, "timers": {"load_time_ms": 0.434, "load_throughput": 73677.185, "learn_time_ms": 8.149, "learn_throughput": 3926.722, "update_time_ms": 5.669}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.0894525051116943, "min_q": -3.7893056869506836, "max_q": 9.884658813476562, "mean_td_error": -0.42864271998405457, "model": {}}, "td_error": [-0.11791622638702393, -1.2434587478637695, -4.6802287101745605, -0.6861878037452698, 1.4930593967437744, -3.171027183532715, -2.4453206062316895, -0.33699893951416016, 0.8941993713378906, -1.4528214931488037, 1.4378864765167236, -0.4197530746459961, -1.2810897827148438, 0.9767602682113647, -0.009754657745361328, -1.8373656272888184, 4.09713077545166, -0.2035846710205078, -0.46915626525878906, 1.0543742179870605, 1.0181398391723633, -2.803750514984131, 0.022247791290283203, 0.2691974639892578, 1.20016610622406, -2.602457046508789, 1.7306132316589355, -0.8909033536911011, 1.0529688596725464, -0.8363056182861328, 0.3147869110107422, -3.7900185585021973], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.868809700012207, "min_q": -21.438003540039062, "max_q": 6.943925380706787, "mean_td_error": -0.982059895992279, "model": {}}, "td_error": [-13.869828224182129, 1.2750539779663086, 0.05708122253417969, -0.30058741569519043, -1.6622562408447266, 0.5961284637451172, -0.8448085784912109, -1.778726577758789, 2.8785457611083984, 2.035885810852051, -2.5629420280456543, -4.122206687927246, 1.0577716827392578, 1.8185482025146484, 5.414740085601807, 0.06898689270019531, -0.14026260375976562, -0.6337032318115234, -1.0480384826660156, -0.24211502075195312, 0.8436908721923828, 1.28167724609375, 0.1799297332763672, -7.518362045288086, 2.8358545303344727, 0.03910255432128906, 1.7993450164794922, -0.26990318298339844, -0.3581123352050781, -0.259674072265625, -18.662601470947266, 0.6658707857131958], "custom_metrics": {}}}, "num_steps_sampled": 9980, "num_agent_steps_sampled": 19960, "num_steps_trained": 17696, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 35392, "last_target_update_ts": 9939, "num_target_updates": 82}, "done": false, "episodes_total": 616, "training_iteration": 33, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-05", "timestamp": 1648811705, "time_this_iter_s": 1.4089241027832031, "time_total_s": 42.41604471206665, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 42.41604471206665, "timesteps_since_restore": 1056, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 38.15, "ram_util_percent": 64.05}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -7.64, "episode_len_mean": 12.57, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 9.0}, "policy_reward_mean": {"policy0": 0.23, "policy1": -7.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 14.0, -4.0, -6.0, -30.0, -8.0, -4.0, -30.0, -30.0, 4.0, 0.0, -12.0, -12.0, -30.0, -8.0, -4.0, -8.0, -2.0, 8.0, 0.0, -6.0, -2.0, -6.0, -30.0, -8.0, 2.0, 2.0, -12.0, 8.0, -6.0, -6.0, 4.0, 6.0, -4.0, -30.0, 4.0, 0.0, -30.0, -30.0, -14.0, 8.0, 8.0, -8.0, 8.0, -12.0, -30.0, 8.0, 0.0, -12.0, 14.0, 4.0, 0.0, -6.0, -2.0, 6.0, 6.0, 12.0, -40.0, -40.0, 14.0, 10.0, 0.0, -16.0, -12.0, 0.0, -30.0, -30.0, -16.0, -30.0, 8.0, -30.0, -40.0, 8.0, -8.0, 0.0, -4.0, 14.0, -12.0, -30.0, 2.0, 4.0, 12.0, -40.0, 0.0, -30.0, -20.0, 8.0, 8.0, -12.0, 0.0, 10.0, -30.0, -12.0, 8.0, -12.0, -10.0, -30.0, -2.0, -10.0, -8.0], "episode_lengths": [10, 3, 12, 13, 20, 14, 12, 20, 20, 8, 10, 16, 16, 20, 14, 12, 14, 11, 6, 10, 13, 11, 13, 20, 14, 9, 9, 16, 6, 13, 13, 8, 7, 12, 20, 8, 10, 20, 20, 17, 6, 6, 14, 6, 16, 20, 6, 10, 16, 3, 8, 10, 13, 11, 7, 7, 4, 20, 20, 3, 5, 10, 18, 16, 10, 20, 20, 18, 20, 6, 20, 20, 6, 14, 10, 12, 3, 16, 20, 9, 8, 4, 20, 10, 20, 20, 6, 6, 16, 10, 5, 20, 16, 6, 16, 15, 20, 11, 15, 14], "policy_policy0_reward": [10.0, 7.0, 8.0, -13.0, -10.0, 6.0, 8.0, -10.0, -10.0, 12.0, 10.0, 4.0, 4.0, -20.0, 6.0, 8.0, 6.0, -11.0, 14.0, 10.0, -3.0, -11.0, -3.0, -10.0, 6.0, 1.0, 1.0, 4.0, 14.0, -3.0, -13.0, 12.0, 3.0, 8.0, -20.0, 2.0, 0.0, -10.0, -10.0, -7.0, 14.0, 14.0, 6.0, 4.0, 4.0, -20.0, 4.0, 10.0, 4.0, 7.0, 2.0, 10.0, -3.0, -1.0, 3.0, 3.0, 6.0, -20.0, -20.0, 7.0, 5.0, 10.0, -8.0, 4.0, 0.0, -10.0, -10.0, 2.0, -10.0, 4.0, -20.0, -20.0, 4.0, 6.0, 10.0, 8.0, 7.0, 4.0, -10.0, 1.0, 2.0, 6.0, -20.0, 10.0, -20.0, 0.0, 14.0, 14.0, 4.0, 10.0, 5.0, -10.0, 4.0, 14.0, 4.0, 5.0, -10.0, -1.0, -5.0, -14.0], "policy_policy1_reward": [-10.0, 7.0, -12.0, 7.0, -20.0, -14.0, -12.0, -20.0, -20.0, -8.0, -10.0, -16.0, -16.0, -10.0, -14.0, -12.0, -14.0, 9.0, -6.0, -10.0, -3.0, 9.0, -3.0, -20.0, -14.0, 1.0, 1.0, -16.0, -6.0, -3.0, 7.0, -8.0, 3.0, -12.0, -10.0, 2.0, 0.0, -20.0, -20.0, -7.0, -6.0, -6.0, -14.0, 4.0, -16.0, -10.0, 4.0, -10.0, -16.0, 7.0, 2.0, -10.0, -3.0, -1.0, 3.0, 3.0, 6.0, -20.0, -20.0, 7.0, 5.0, -10.0, -8.0, -16.0, 0.0, -20.0, -20.0, -18.0, -20.0, 4.0, -10.0, -20.0, 4.0, -14.0, -10.0, -12.0, 7.0, -16.0, -20.0, 1.0, 2.0, 6.0, -20.0, -10.0, -10.0, -20.0, -6.0, -6.0, -16.0, -10.0, 5.0, -20.0, -16.0, -6.0, -16.0, -15.0, -20.0, -1.0, -5.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3308436208439214, "mean_inference_ms": 1.7975192097900055, "mean_action_processing_ms": 0.12311836492824928, "mean_env_wait_ms": 0.07681616263384385, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10206, "timesteps_this_iter": 32, "agent_timesteps_total": 20412, "timers": {"load_time_ms": 0.431, "load_throughput": 74284.773, "learn_time_ms": 8.029, "learn_throughput": 3985.489, "update_time_ms": 4.948}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.5517098903656006, "min_q": -4.41363000869751, "max_q": 11.428659439086914, "mean_td_error": -0.7341670393943787, "model": {}}, "td_error": [-3.0171568393707275, -2.054513692855835, -0.7266337871551514, -1.7179031372070312, -1.3597736358642578, -1.1086710691452026, 0.18748295307159424, -2.3155226707458496, -0.4596443176269531, 2.8027572631835938, -0.04679536819458008, 1.215569257736206, 0.05052065849304199, -0.6688261032104492, -0.1297910213470459, -1.5750517845153809, -0.6895914077758789, -0.8707566261291504, -4.237794876098633, 1.0545759201049805, -3.082509994506836, -2.132294178009033, 1.85636568069458, -4.109649658203125, 1.190587043762207, 0.5655560493469238, -2.6070847511291504, -1.4094834327697754, -2.1071505546569824, 2.918065071105957, -0.8260335922241211, 1.9178061485290527], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -12.875060081481934, "min_q": -21.421716690063477, "max_q": 5.835583686828613, "mean_td_error": -3.4190547466278076, "model": {}}, "td_error": [0.7862815856933594, -13.407753944396973, -1.1202583312988281, -12.789021492004395, -1.9006881713867188, -13.399696350097656, -0.4044761657714844, 1.6028146743774414, -1.5754475593566895, -0.5549106597900391, 2.540865898132324, 0.8149499893188477, 3.207160234451294, -20.421716690063477, 0.85821533203125, 1.3617219924926758, 0.7862815856933594, -0.5703144073486328, -0.6999988555908203, -0.46437835693359375, 0.5118780136108398, -0.4069366455078125, 1.2078840732574463, -17.19866180419922, -14.321968078613281, -15.313831329345703, 0.5272026062011719, 2.25655460357666, -13.641947746276855, -0.6662788391113281, 3.355767250061035, -0.36904430389404297], "custom_metrics": {}}}, "num_steps_sampled": 10206, "num_agent_steps_sampled": 20412, "num_steps_trained": 18240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 36480, "last_target_update_ts": 10146, "num_target_updates": 84}, "done": false, "episodes_total": 633, "training_iteration": 34, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-06", "timestamp": 1648811706, "time_this_iter_s": 1.0219602584838867, "time_total_s": 43.43800497055054, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 43.43800497055054, "timesteps_since_restore": 1088, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 39.3, "ram_util_percent": 64.2}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -8.0, "episode_len_mean": 12.65, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 9.0}, "policy_reward_mean": {"policy0": -0.05, "policy1": -7.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.0, -8.0, -2.0, 8.0, 0.0, -6.0, -2.0, -6.0, -30.0, -8.0, 2.0, 2.0, -12.0, 8.0, -6.0, -6.0, 4.0, 6.0, -4.0, -30.0, 4.0, 0.0, -30.0, -30.0, -14.0, 8.0, 8.0, -8.0, 8.0, -12.0, -30.0, 8.0, 0.0, -12.0, 14.0, 4.0, 0.0, -6.0, -2.0, 6.0, 6.0, 12.0, -40.0, -40.0, 14.0, 10.0, 0.0, -16.0, -12.0, 0.0, -30.0, -30.0, -16.0, -30.0, 8.0, -30.0, -40.0, 8.0, -8.0, 0.0, -4.0, 14.0, -12.0, -30.0, 2.0, 4.0, 12.0, -40.0, 0.0, -30.0, -20.0, 8.0, 8.0, -12.0, 0.0, 10.0, -30.0, -12.0, 8.0, -12.0, -10.0, -30.0, -2.0, -10.0, -8.0, -4.0, -30.0, -30.0, 0.0, -4.0, -30.0, -30.0, 8.0, -14.0, -4.0, 4.0, -40.0, -14.0, 8.0, -12.0], "episode_lengths": [12, 14, 11, 6, 10, 13, 11, 13, 20, 14, 9, 9, 16, 6, 13, 13, 8, 7, 12, 20, 8, 10, 20, 20, 17, 6, 6, 14, 6, 16, 20, 6, 10, 16, 3, 8, 10, 13, 11, 7, 7, 4, 20, 20, 3, 5, 10, 18, 16, 10, 20, 20, 18, 20, 6, 20, 20, 6, 14, 10, 12, 3, 16, 20, 9, 8, 4, 20, 10, 20, 20, 6, 6, 16, 10, 5, 20, 16, 6, 16, 15, 20, 11, 15, 14, 12, 20, 20, 10, 12, 20, 20, 6, 17, 12, 8, 20, 17, 6, 16], "policy_policy0_reward": [8.0, 6.0, -11.0, 14.0, 10.0, -3.0, -11.0, -3.0, -10.0, 6.0, 1.0, 1.0, 4.0, 14.0, -3.0, -13.0, 12.0, 3.0, 8.0, -20.0, 2.0, 0.0, -10.0, -10.0, -7.0, 14.0, 14.0, 6.0, 4.0, 4.0, -20.0, 4.0, 10.0, 4.0, 7.0, 2.0, 10.0, -3.0, -1.0, 3.0, 3.0, 6.0, -20.0, -20.0, 7.0, 5.0, 10.0, -8.0, 4.0, 0.0, -10.0, -10.0, 2.0, -10.0, 4.0, -20.0, -20.0, 4.0, 6.0, 10.0, 8.0, 7.0, 4.0, -10.0, 1.0, 2.0, 6.0, -20.0, 10.0, -20.0, 0.0, 14.0, 14.0, 4.0, 10.0, 5.0, -10.0, 4.0, 14.0, 4.0, 5.0, -10.0, -1.0, -5.0, -14.0, 8.0, -10.0, -10.0, 10.0, 8.0, -10.0, -10.0, 4.0, 3.0, -2.0, 2.0, -20.0, -7.0, 14.0, 4.0], "policy_policy1_reward": [-12.0, -14.0, 9.0, -6.0, -10.0, -3.0, 9.0, -3.0, -20.0, -14.0, 1.0, 1.0, -16.0, -6.0, -3.0, 7.0, -8.0, 3.0, -12.0, -10.0, 2.0, 0.0, -20.0, -20.0, -7.0, -6.0, -6.0, -14.0, 4.0, -16.0, -10.0, 4.0, -10.0, -16.0, 7.0, 2.0, -10.0, -3.0, -1.0, 3.0, 3.0, 6.0, -20.0, -20.0, 7.0, 5.0, -10.0, -8.0, -16.0, 0.0, -20.0, -20.0, -18.0, -20.0, 4.0, -10.0, -20.0, 4.0, -14.0, -10.0, -12.0, 7.0, -16.0, -20.0, 1.0, 2.0, 6.0, -20.0, -10.0, -10.0, -20.0, -6.0, -6.0, -16.0, -10.0, 5.0, -20.0, -16.0, -6.0, -16.0, -15.0, -20.0, -1.0, -5.0, 6.0, -12.0, -20.0, -20.0, -10.0, -12.0, -20.0, -20.0, 4.0, -17.0, -2.0, 2.0, -20.0, -7.0, -6.0, -16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33100727292166526, "mean_inference_ms": 1.7970943051799635, "mean_action_processing_ms": 0.12307590677944784, "mean_env_wait_ms": 0.07680303679683344, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10422, "timesteps_this_iter": 32, "agent_timesteps_total": 20844, "timers": {"load_time_ms": 0.46, "load_throughput": 69499.652, "learn_time_ms": 8.063, "learn_throughput": 3968.59, "update_time_ms": 4.816}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.644256114959717, "min_q": -3.0343708992004395, "max_q": 13.6643648147583, "mean_td_error": -0.2844637632369995, "model": {}}, "td_error": [-1.560434341430664, 0.336239218711853, 0.5702191591262817, 4.447147369384766, -1.7240076065063477, -0.8886356353759766, 1.3217105865478516, 0.22834491729736328, 0.8982148170471191, 1.1580934524536133, -0.530768632888794, -5.644923686981201, 1.7459516525268555, 0.9561082124710083, -2.0255017280578613, -1.9235639572143555, -3.178828239440918, -0.8107404708862305, 1.988980770111084, 0.8327946662902832, -0.8968974947929382, -0.925959587097168, -0.7965679168701172, -0.15014410018920898, 0.45142966508865356, -2.0343708992004395, -0.726377010345459, -0.013831615447998047, 0.24923324584960938, -0.03334474563598633, -0.2265033721923828, -0.1959075927734375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.978675842285156, "min_q": -20.630773544311523, "max_q": 6.918377876281738, "mean_td_error": -1.586958885192871, "model": {}}, "td_error": [-0.1674175262451172, -14.873026847839355, 2.4359540939331055, 0.36391639709472656, 1.2697086334228516, 0.5206203460693359, 2.795029640197754, 1.1497211456298828, 0.5070552825927734, -2.0816221237182617, 0.18697261810302734, 1.4012908935546875, 2.050473213195801, -0.11723518371582031, -0.5432796478271484, 0.4927253723144531, -14.385562896728516, 0.5421047210693359, -12.688251495361328, -3.9231085777282715, 0.561827540397644, -14.44677448272705, 1.9800920486450195, -2.145322799682617, -1.3855462074279785, -3.0494446754455566, 1.1615318059921265, 0.22887229919433594, 2.852389097213745, 1.05609130859375, -3.4843053817749023, 0.9518371820449829], "custom_metrics": {}}}, "num_steps_sampled": 10422, "num_agent_steps_sampled": 20844, "num_steps_trained": 18720, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 37440, "last_target_update_ts": 10363, "num_target_updates": 86}, "done": false, "episodes_total": 648, "training_iteration": 35, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-07", "timestamp": 1648811707, "time_this_iter_s": 0.9692556858062744, "time_total_s": 44.40726065635681, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 44.40726065635681, "timesteps_since_restore": 1120, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 39.05, "ram_util_percent": 64.3}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -8.88, "episode_len_mean": 12.94, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -0.54, "policy1": -8.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.0, 4.0, 6.0, -4.0, -30.0, 4.0, 0.0, -30.0, -30.0, -14.0, 8.0, 8.0, -8.0, 8.0, -12.0, -30.0, 8.0, 0.0, -12.0, 14.0, 4.0, 0.0, -6.0, -2.0, 6.0, 6.0, 12.0, -40.0, -40.0, 14.0, 10.0, 0.0, -16.0, -12.0, 0.0, -30.0, -30.0, -16.0, -30.0, 8.0, -30.0, -40.0, 8.0, -8.0, 0.0, -4.0, 14.0, -12.0, -30.0, 2.0, 4.0, 12.0, -40.0, 0.0, -30.0, -20.0, 8.0, 8.0, -12.0, 0.0, 10.0, -30.0, -12.0, 8.0, -12.0, -10.0, -30.0, -2.0, -10.0, -8.0, -4.0, -30.0, -30.0, 0.0, -4.0, -30.0, -30.0, 8.0, -14.0, -4.0, 4.0, -40.0, -14.0, 8.0, -12.0, -14.0, -4.0, -2.0, 4.0, -30.0, -4.0, -30.0, 0.0, 0.0, -30.0, 0.0, -18.0, 2.0, -30.0, 4.0], "episode_lengths": [13, 8, 7, 12, 20, 8, 10, 20, 20, 17, 6, 6, 14, 6, 16, 20, 6, 10, 16, 3, 8, 10, 13, 11, 7, 7, 4, 20, 20, 3, 5, 10, 18, 16, 10, 20, 20, 18, 20, 6, 20, 20, 6, 14, 10, 12, 3, 16, 20, 9, 8, 4, 20, 10, 20, 20, 6, 6, 16, 10, 5, 20, 16, 6, 16, 15, 20, 11, 15, 14, 12, 20, 20, 10, 12, 20, 20, 6, 17, 12, 8, 20, 17, 6, 16, 17, 12, 11, 8, 20, 12, 20, 10, 10, 20, 10, 19, 9, 20, 8], "policy_policy0_reward": [-13.0, 12.0, 3.0, 8.0, -20.0, 2.0, 0.0, -10.0, -10.0, -7.0, 14.0, 14.0, 6.0, 4.0, 4.0, -20.0, 4.0, 10.0, 4.0, 7.0, 2.0, 10.0, -3.0, -1.0, 3.0, 3.0, 6.0, -20.0, -20.0, 7.0, 5.0, 10.0, -8.0, 4.0, 0.0, -10.0, -10.0, 2.0, -10.0, 4.0, -20.0, -20.0, 4.0, 6.0, 10.0, 8.0, 7.0, 4.0, -10.0, 1.0, 2.0, 6.0, -20.0, 10.0, -20.0, 0.0, 14.0, 14.0, 4.0, 10.0, 5.0, -10.0, 4.0, 14.0, 4.0, 5.0, -10.0, -1.0, -5.0, -14.0, 8.0, -10.0, -10.0, 10.0, 8.0, -10.0, -10.0, 4.0, 3.0, -2.0, 2.0, -20.0, -7.0, 14.0, 4.0, 3.0, -2.0, -1.0, 12.0, -10.0, 8.0, -10.0, 10.0, 10.0, -20.0, 0.0, -9.0, -9.0, -20.0, 12.0], "policy_policy1_reward": [7.0, -8.0, 3.0, -12.0, -10.0, 2.0, 0.0, -20.0, -20.0, -7.0, -6.0, -6.0, -14.0, 4.0, -16.0, -10.0, 4.0, -10.0, -16.0, 7.0, 2.0, -10.0, -3.0, -1.0, 3.0, 3.0, 6.0, -20.0, -20.0, 7.0, 5.0, -10.0, -8.0, -16.0, 0.0, -20.0, -20.0, -18.0, -20.0, 4.0, -10.0, -20.0, 4.0, -14.0, -10.0, -12.0, 7.0, -16.0, -20.0, 1.0, 2.0, 6.0, -20.0, -10.0, -10.0, -20.0, -6.0, -6.0, -16.0, -10.0, 5.0, -20.0, -16.0, -6.0, -16.0, -15.0, -20.0, -1.0, -5.0, 6.0, -12.0, -20.0, -20.0, -10.0, -12.0, -20.0, -20.0, 4.0, -17.0, -2.0, 2.0, -20.0, -7.0, -6.0, -16.0, -17.0, -2.0, -1.0, -8.0, -20.0, -12.0, -20.0, -10.0, -10.0, -10.0, 0.0, -9.0, 11.0, -10.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.331214292634342, "mean_inference_ms": 1.7968943204911374, "mean_action_processing_ms": 0.12305282872269434, "mean_env_wait_ms": 0.0767921355971704, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10628, "timesteps_this_iter": 32, "agent_timesteps_total": 21256, "timers": {"load_time_ms": 0.494, "load_throughput": 64833.218, "learn_time_ms": 8.681, "learn_throughput": 3686.288, "update_time_ms": 5.379}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.02259635925293, "min_q": 0.32549726963043213, "max_q": 16.98454475402832, "mean_td_error": 1.348825216293335, "model": {}}, "td_error": [1.3573870658874512, 2.318368673324585, 2.22584867477417, 0.7847833633422852, 1.2165966033935547, 2.016597270965576, -2.3413491249084473, 2.136758327484131, 2.4447402954101562, -0.677060604095459, 1.9162079095840454, 1.3633546829223633, 0.5478448867797852, -0.19438600540161133, -0.7041168212890625, 0.5724396705627441, -0.16064929962158203, -1.2030243873596191, 2.08935546875, 0.6162469387054443, 9.078353881835938, 0.43461036682128906, 1.4296255111694336, 6.363473892211914, 3.108304977416992, 0.36803102493286133, 0.963254451751709, 0.5690302848815918, 2.0953426361083984, 1.405940055847168, 1.0909621715545654, -0.07046765089035034], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -12.420610427856445, "min_q": -19.36088752746582, "max_q": 13.864505767822266, "mean_td_error": -3.500994920730591, "model": {}}, "td_error": [0.24993228912353516, -22.36918830871582, 14.864505767822266, -3.3904833793640137, 1.3792219161987305, -0.7940908670425415, -0.17000770568847656, 0.9057741165161133, 0.40421199798583984, -11.85900592803955, -3.3249268531799316, -5.762029647827148, -22.930313110351562, -10.479562759399414, 1.0964431762695312, -1.3570423126220703, -0.7346210479736328, -6.091741561889648, -2.627767562866211, -1.6298131942749023, 0.14182859659194946, -11.82856273651123, 1.6279487609863281, -3.883016586303711, -2.2927169799804688, 0.14708900451660156, -0.13307476043701172, 0.49051856994628906, 1.5932235717773438, -13.602104187011719, -6.102560997009277, -3.5698957443237305], "custom_metrics": {}}}, "num_steps_sampled": 10628, "num_agent_steps_sampled": 21256, "num_steps_trained": 19200, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 38400, "last_target_update_ts": 10572, "num_target_updates": 88}, "done": false, "episodes_total": 663, "training_iteration": 36, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-08", "timestamp": 1648811708, "time_this_iter_s": 0.9926228523254395, "time_total_s": 45.39988350868225, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584767a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584767a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 45.39988350868225, "timesteps_since_restore": 1152, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 40.1, "ram_util_percent": 64.3}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -8.12, "episode_len_mean": 12.66, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -0.06, "policy1": -8.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, 4.0, 0.0, -6.0, -2.0, 6.0, 6.0, 12.0, -40.0, -40.0, 14.0, 10.0, 0.0, -16.0, -12.0, 0.0, -30.0, -30.0, -16.0, -30.0, 8.0, -30.0, -40.0, 8.0, -8.0, 0.0, -4.0, 14.0, -12.0, -30.0, 2.0, 4.0, 12.0, -40.0, 0.0, -30.0, -20.0, 8.0, 8.0, -12.0, 0.0, 10.0, -30.0, -12.0, 8.0, -12.0, -10.0, -30.0, -2.0, -10.0, -8.0, -4.0, -30.0, -30.0, 0.0, -4.0, -30.0, -30.0, 8.0, -14.0, -4.0, 4.0, -40.0, -14.0, 8.0, -12.0, -14.0, -4.0, -2.0, 4.0, -30.0, -4.0, -30.0, 0.0, 0.0, -30.0, 0.0, -18.0, 2.0, -30.0, 4.0, -4.0, -10.0, 8.0, 8.0, -2.0, -4.0, -4.0, -12.0, 8.0, 6.0, 14.0, -6.0, -8.0, -4.0, -2.0, -30.0, -30.0, 8.0, 10.0], "episode_lengths": [3, 8, 10, 13, 11, 7, 7, 4, 20, 20, 3, 5, 10, 18, 16, 10, 20, 20, 18, 20, 6, 20, 20, 6, 14, 10, 12, 3, 16, 20, 9, 8, 4, 20, 10, 20, 20, 6, 6, 16, 10, 5, 20, 16, 6, 16, 15, 20, 11, 15, 14, 12, 20, 20, 10, 12, 20, 20, 6, 17, 12, 8, 20, 17, 6, 16, 17, 12, 11, 8, 20, 12, 20, 10, 10, 20, 10, 19, 9, 20, 8, 12, 15, 6, 6, 11, 12, 12, 16, 6, 7, 3, 13, 14, 12, 11, 20, 20, 6, 5], "policy_policy0_reward": [7.0, 2.0, 10.0, -3.0, -1.0, 3.0, 3.0, 6.0, -20.0, -20.0, 7.0, 5.0, 10.0, -8.0, 4.0, 0.0, -10.0, -10.0, 2.0, -10.0, 4.0, -20.0, -20.0, 4.0, 6.0, 10.0, 8.0, 7.0, 4.0, -10.0, 1.0, 2.0, 6.0, -20.0, 10.0, -20.0, 0.0, 14.0, 14.0, 4.0, 10.0, 5.0, -10.0, 4.0, 14.0, 4.0, 5.0, -10.0, -1.0, -5.0, -14.0, 8.0, -10.0, -10.0, 10.0, 8.0, -10.0, -10.0, 4.0, 3.0, -2.0, 2.0, -20.0, -7.0, 14.0, 4.0, 3.0, -2.0, -1.0, 12.0, -10.0, 8.0, -10.0, 10.0, 10.0, -20.0, 0.0, -9.0, -9.0, -20.0, 12.0, -2.0, -5.0, 14.0, 14.0, -1.0, -2.0, 8.0, 4.0, 4.0, 3.0, 7.0, 7.0, 6.0, -12.0, 9.0, -10.0, -10.0, 14.0, 5.0], "policy_policy1_reward": [7.0, 2.0, -10.0, -3.0, -1.0, 3.0, 3.0, 6.0, -20.0, -20.0, 7.0, 5.0, -10.0, -8.0, -16.0, 0.0, -20.0, -20.0, -18.0, -20.0, 4.0, -10.0, -20.0, 4.0, -14.0, -10.0, -12.0, 7.0, -16.0, -20.0, 1.0, 2.0, 6.0, -20.0, -10.0, -10.0, -20.0, -6.0, -6.0, -16.0, -10.0, 5.0, -20.0, -16.0, -6.0, -16.0, -15.0, -20.0, -1.0, -5.0, 6.0, -12.0, -20.0, -20.0, -10.0, -12.0, -20.0, -20.0, 4.0, -17.0, -2.0, 2.0, -20.0, -7.0, -6.0, -16.0, -17.0, -2.0, -1.0, -8.0, -20.0, -12.0, -20.0, -10.0, -10.0, -10.0, 0.0, -9.0, 11.0, -10.0, -8.0, -2.0, -5.0, -6.0, -6.0, -1.0, -2.0, -12.0, -16.0, 4.0, 3.0, 7.0, -13.0, -14.0, 8.0, -11.0, -20.0, -20.0, -6.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33150428983860203, "mean_inference_ms": 1.796624732679369, "mean_action_processing_ms": 0.12303276936521737, "mean_env_wait_ms": 0.07677359654894685, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10835, "timesteps_this_iter": 32, "agent_timesteps_total": 21670, "timers": {"load_time_ms": 0.436, "load_throughput": 73379.109, "learn_time_ms": 7.839, "learn_throughput": 4082.147, "update_time_ms": 5.077}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.957836866378784, "min_q": -2.1381382942199707, "max_q": 12.938246726989746, "mean_td_error": -0.033063456416130066, "model": {}}, "td_error": [3.44865345954895, 0.4657207727432251, 0.5309195518493652, 0.2096569538116455, 0.17025303840637207, -0.34262943267822266, -0.0483856201171875, 0.061571598052978516, -1.4266319274902344, 1.9640626907348633, -0.8625764846801758, -0.323016881942749, 0.030632972717285156, 0.5236148834228516, -2.995272636413574, -0.16575980186462402, 0.022771477699279785, 0.6510167121887207, -1.7637760639190674, -2.2481937408447266, 1.4494953155517578, 4.098230838775635, -1.5715432167053223, 5.176912307739258, -1.1379530429840088, 0.43639373779296875, -0.20652008056640625, -0.1943526268005371, 0.0631948709487915, 0.35648441314697266, 1.918701171875, -9.349706649780273], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.206339836120605, "min_q": -18.565845489501953, "max_q": 5.766719341278076, "mean_td_error": -3.2089951038360596, "model": {}}, "td_error": [0.31616878509521484, -1.132786750793457, 1.414773941040039, -5.457795143127441, -14.929044723510742, 0.6581554412841797, -1.0490837097167969, 0.6692209243774414, -0.7625923156738281, 0.2816810607910156, -1.160055160522461, 0.18931299448013306, -1.1535720825195312, -11.218384742736816, 6.766719341278076, -4.135478973388672, -11.590448379516602, 2.7465314865112305, -13.515572547912598, -0.38019752502441406, -0.7336978912353516, 2.01253604888916, -3.250600814819336, -2.2304306030273438, 0.6802492141723633, -1.3162364959716797, -13.929805755615234, -12.490336418151855, -0.5492916107177734, -1.6206121444702148, -13.929805755615234, -1.8873662948608398], "custom_metrics": {}}}, "num_steps_sampled": 10835, "num_agent_steps_sampled": 21670, "num_steps_trained": 19776, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 39552, "last_target_update_ts": 10784, "num_target_updates": 90}, "done": false, "episodes_total": 682, "training_iteration": 37, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-09", "timestamp": 1648811709, "time_this_iter_s": 1.0497100353240967, "time_total_s": 46.44959354400635, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 46.44959354400635, "timesteps_since_restore": 1184, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 39.3, "ram_util_percent": 64.4}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -8.54, "episode_len_mean": 12.92, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": 0.08, "policy1": -8.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -16.0, -30.0, 8.0, -30.0, -40.0, 8.0, -8.0, 0.0, -4.0, 14.0, -12.0, -30.0, 2.0, 4.0, 12.0, -40.0, 0.0, -30.0, -20.0, 8.0, 8.0, -12.0, 0.0, 10.0, -30.0, -12.0, 8.0, -12.0, -10.0, -30.0, -2.0, -10.0, -8.0, -4.0, -30.0, -30.0, 0.0, -4.0, -30.0, -30.0, 8.0, -14.0, -4.0, 4.0, -40.0, -14.0, 8.0, -12.0, -14.0, -4.0, -2.0, 4.0, -30.0, -4.0, -30.0, 0.0, 0.0, -30.0, 0.0, -18.0, 2.0, -30.0, 4.0, -4.0, -10.0, 8.0, 8.0, -2.0, -4.0, -4.0, -12.0, 8.0, 6.0, 14.0, -6.0, -8.0, -4.0, -2.0, -30.0, -30.0, 8.0, 10.0, 4.0, 4.0, 4.0, -8.0, 0.0, 12.0, 0.0, 8.0, -20.0, 6.0, -8.0, -4.0, -30.0, -30.0, 0.0, -30.0, -30.0], "episode_lengths": [20, 18, 20, 6, 20, 20, 6, 14, 10, 12, 3, 16, 20, 9, 8, 4, 20, 10, 20, 20, 6, 6, 16, 10, 5, 20, 16, 6, 16, 15, 20, 11, 15, 14, 12, 20, 20, 10, 12, 20, 20, 6, 17, 12, 8, 20, 17, 6, 16, 17, 12, 11, 8, 20, 12, 20, 10, 10, 20, 10, 19, 9, 20, 8, 12, 15, 6, 6, 11, 12, 12, 16, 6, 7, 3, 13, 14, 12, 11, 20, 20, 6, 5, 8, 8, 8, 14, 10, 4, 10, 6, 20, 7, 14, 12, 20, 20, 10, 20, 20], "policy_policy0_reward": [-10.0, 2.0, -10.0, 4.0, -20.0, -20.0, 4.0, 6.0, 10.0, 8.0, 7.0, 4.0, -10.0, 1.0, 2.0, 6.0, -20.0, 10.0, -20.0, 0.0, 14.0, 14.0, 4.0, 10.0, 5.0, -10.0, 4.0, 14.0, 4.0, 5.0, -10.0, -1.0, -5.0, -14.0, 8.0, -10.0, -10.0, 10.0, 8.0, -10.0, -10.0, 4.0, 3.0, -2.0, 2.0, -20.0, -7.0, 14.0, 4.0, 3.0, -2.0, -1.0, 12.0, -10.0, 8.0, -10.0, 10.0, 10.0, -20.0, 0.0, -9.0, -9.0, -20.0, 12.0, -2.0, -5.0, 14.0, 14.0, -1.0, -2.0, 8.0, 4.0, 4.0, 3.0, 7.0, 7.0, 6.0, -12.0, 9.0, -10.0, -10.0, 14.0, 5.0, 12.0, 12.0, 12.0, -4.0, 0.0, 6.0, 0.0, 4.0, 0.0, 3.0, -4.0, 8.0, -10.0, -10.0, 10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -18.0, -20.0, 4.0, -10.0, -20.0, 4.0, -14.0, -10.0, -12.0, 7.0, -16.0, -20.0, 1.0, 2.0, 6.0, -20.0, -10.0, -10.0, -20.0, -6.0, -6.0, -16.0, -10.0, 5.0, -20.0, -16.0, -6.0, -16.0, -15.0, -20.0, -1.0, -5.0, 6.0, -12.0, -20.0, -20.0, -10.0, -12.0, -20.0, -20.0, 4.0, -17.0, -2.0, 2.0, -20.0, -7.0, -6.0, -16.0, -17.0, -2.0, -1.0, -8.0, -20.0, -12.0, -20.0, -10.0, -10.0, -10.0, 0.0, -9.0, 11.0, -10.0, -8.0, -2.0, -5.0, -6.0, -6.0, -1.0, -2.0, -12.0, -16.0, 4.0, 3.0, 7.0, -13.0, -14.0, 8.0, -11.0, -20.0, -20.0, -6.0, 5.0, -8.0, -8.0, -8.0, -4.0, 0.0, 6.0, 0.0, 4.0, -20.0, 3.0, -4.0, -12.0, -20.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33174753603984714, "mean_inference_ms": 1.796357622860515, "mean_action_processing_ms": 0.12302227506716833, "mean_env_wait_ms": 0.07676372538977738, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11046, "timesteps_this_iter": 32, "agent_timesteps_total": 22092, "timers": {"load_time_ms": 0.463, "load_throughput": 69081.13, "learn_time_ms": 7.921, "learn_throughput": 4039.758, "update_time_ms": 4.89}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.9243173599243164, "min_q": -3.2011280059814453, "max_q": 11.153585433959961, "mean_td_error": -0.04467421770095825, "model": {}}, "td_error": [0.40635812282562256, 0.7752809524536133, 1.8190364837646484, 1.6312732696533203, 0.6137853860855103, -0.16257473826408386, -2.9761269092559814, 2.3468775749206543, -0.6239824295043945, 0.6144230961799622, 2.898585557937622, -1.6286418437957764, -2.2011280059814453, -1.6501774787902832, -1.9893217086791992, 0.7641210556030273, -2.7979817390441895, 0.5533981323242188, -0.17027854919433594, -1.7105541229248047, 7.188358783721924, -1.0453720092773438, 2.087313652038574, -1.963364601135254, 1.4311885833740234, -1.0566046237945557, -3.2266159057617188, -1.0851383209228516, -1.0453720092773438, -1.1761481761932373, 1.9082250595092773, 0.041582345962524414], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.651434898376465, "min_q": -17.127710342407227, "max_q": 8.375269889831543, "mean_td_error": -2.1505661010742188, "model": {}}, "td_error": [-11.432140350341797, -1.7609443664550781, 1.8919296264648438, 0.9016208648681641, -10.454962730407715, -7.958488941192627, -1.198573112487793, 0.1655902862548828, 1.7359743118286133, -14.509906768798828, -13.504960060119629, 9.152297973632812, -2.31864070892334, 4.100730895996094, 3.2375898361206055, 2.548892021179199, 0.879058837890625, -4.636666297912598, -11.406003952026367, 0.6121387481689453, 3.2142934799194336, 3.925048828125, -6.102481365203857, 1.396951675415039, -0.10158348083496094, 2.1273727416992188, 1.0801353454589844, -18.542219161987305, 3.92464542388916, -7.893637657165527, 2.469212532043457, -0.36038875579833984], "custom_metrics": {}}}, "num_steps_sampled": 11046, "num_agent_steps_sampled": 22092, "num_steps_trained": 20320, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 40640, "last_target_update_ts": 10996, "num_target_updates": 92}, "done": false, "episodes_total": 699, "training_iteration": 38, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-10", "timestamp": 1648811710, "time_this_iter_s": 1.0130140781402588, "time_total_s": 47.462607622146606, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 47.462607622146606, "timesteps_since_restore": 1216, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 39.7, "ram_util_percent": 64.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -7.56, "episode_len_mean": 12.68, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": 0.62, "policy1": -8.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -30.0, -20.0, 8.0, 8.0, -12.0, 0.0, 10.0, -30.0, -12.0, 8.0, -12.0, -10.0, -30.0, -2.0, -10.0, -8.0, -4.0, -30.0, -30.0, 0.0, -4.0, -30.0, -30.0, 8.0, -14.0, -4.0, 4.0, -40.0, -14.0, 8.0, -12.0, -14.0, -4.0, -2.0, 4.0, -30.0, -4.0, -30.0, 0.0, 0.0, -30.0, 0.0, -18.0, 2.0, -30.0, 4.0, -4.0, -10.0, 8.0, 8.0, -2.0, -4.0, -4.0, -12.0, 8.0, 6.0, 14.0, -6.0, -8.0, -4.0, -2.0, -30.0, -30.0, 8.0, 10.0, 4.0, 4.0, 4.0, -8.0, 0.0, 12.0, 0.0, 8.0, -20.0, 6.0, -8.0, -4.0, -30.0, -30.0, 0.0, -30.0, -30.0, 0.0, 6.0, -4.0, 12.0, -30.0, 4.0, -18.0, -30.0, -30.0, 0.0, -12.0, 0.0, -8.0, 6.0, 0.0, 10.0, 0.0], "episode_lengths": [10, 20, 20, 6, 6, 16, 10, 5, 20, 16, 6, 16, 15, 20, 11, 15, 14, 12, 20, 20, 10, 12, 20, 20, 6, 17, 12, 8, 20, 17, 6, 16, 17, 12, 11, 8, 20, 12, 20, 10, 10, 20, 10, 19, 9, 20, 8, 12, 15, 6, 6, 11, 12, 12, 16, 6, 7, 3, 13, 14, 12, 11, 20, 20, 6, 5, 8, 8, 8, 14, 10, 4, 10, 6, 20, 7, 14, 12, 20, 20, 10, 20, 20, 10, 7, 12, 4, 20, 8, 19, 20, 20, 10, 16, 10, 14, 7, 10, 5, 10], "policy_policy0_reward": [10.0, -20.0, 0.0, 14.0, 14.0, 4.0, 10.0, 5.0, -10.0, 4.0, 14.0, 4.0, 5.0, -10.0, -1.0, -5.0, -14.0, 8.0, -10.0, -10.0, 10.0, 8.0, -10.0, -10.0, 4.0, 3.0, -2.0, 2.0, -20.0, -7.0, 14.0, 4.0, 3.0, -2.0, -1.0, 12.0, -10.0, 8.0, -10.0, 10.0, 10.0, -20.0, 0.0, -9.0, -9.0, -20.0, 12.0, -2.0, -5.0, 14.0, 14.0, -1.0, -2.0, 8.0, 4.0, 4.0, 3.0, 7.0, 7.0, 6.0, -12.0, 9.0, -10.0, -10.0, 14.0, 5.0, 12.0, 12.0, 12.0, -4.0, 0.0, 6.0, 0.0, 4.0, 0.0, 3.0, -4.0, 8.0, -10.0, -10.0, 10.0, -20.0, -10.0, 10.0, 3.0, -2.0, 6.0, -10.0, 12.0, -9.0, -10.0, -10.0, 10.0, 4.0, 0.0, -4.0, 3.0, 10.0, 5.0, 0.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -6.0, -6.0, -16.0, -10.0, 5.0, -20.0, -16.0, -6.0, -16.0, -15.0, -20.0, -1.0, -5.0, 6.0, -12.0, -20.0, -20.0, -10.0, -12.0, -20.0, -20.0, 4.0, -17.0, -2.0, 2.0, -20.0, -7.0, -6.0, -16.0, -17.0, -2.0, -1.0, -8.0, -20.0, -12.0, -20.0, -10.0, -10.0, -10.0, 0.0, -9.0, 11.0, -10.0, -8.0, -2.0, -5.0, -6.0, -6.0, -1.0, -2.0, -12.0, -16.0, 4.0, 3.0, 7.0, -13.0, -14.0, 8.0, -11.0, -20.0, -20.0, -6.0, 5.0, -8.0, -8.0, -8.0, -4.0, 0.0, 6.0, 0.0, 4.0, -20.0, 3.0, -4.0, -12.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 3.0, -2.0, 6.0, -20.0, -8.0, -9.0, -20.0, -20.0, -10.0, -16.0, 0.0, -4.0, 3.0, -10.0, 5.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33193659558149674, "mean_inference_ms": 1.795739790713852, "mean_action_processing_ms": 0.12298016586832997, "mean_env_wait_ms": 0.07673516961056595, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11248, "timesteps_this_iter": 32, "agent_timesteps_total": 22496, "timers": {"load_time_ms": 0.43, "load_throughput": 74362.972, "learn_time_ms": 7.699, "learn_throughput": 4156.287, "update_time_ms": 4.562}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.253153324127197, "min_q": -1.8358309268951416, "max_q": 12.290245056152344, "mean_td_error": 0.009494751691818237, "model": {}}, "td_error": [0.9436521530151367, 5.050853729248047, 0.5615673065185547, 0.9398866891860962, -2.9831299781799316, -2.143514633178711, -1.6331872940063477, 0.3243541717529297, -1.3589823246002197, -0.736814022064209, 0.7373208999633789, 0.972559928894043, -2.7642345428466797, 1.991166114807129, -0.6607027053833008, -1.5300722122192383, -0.11678647994995117, 2.096432685852051, 0.11608505249023438, 6.905029773712158, -2.063704490661621, -0.45114684104919434, 0.9051790237426758, -2.460632801055908, -4.698152542114258, 2.883941411972046, -0.44903564453125, 0.3209552764892578, 0.4254109859466553, 2.0476417541503906, 0.03481149673461914, -2.902919292449951], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -7.738080024719238, "min_q": -17.304101943969727, "max_q": 11.686690330505371, "mean_td_error": -3.0616707801818848, "model": {}}, "td_error": [0.9871826171875, -17.707538604736328, 3.4825870990753174, 1.1846580505371094, 0.7581424713134766, -11.849271774291992, -12.514579772949219, -0.31725597381591797, 5.729393005371094, -1.1349577903747559, -11.476733207702637, 4.695962905883789, -16.304101943969727, 0.2239837646484375, -3.039091110229492, 4.319968223571777, -3.9892935752868652, 1.8153810501098633, -23.768049240112305, 5.299397945404053, 1.1644668579101562, -11.692070960998535, 0.06170845031738281, 0.15297365188598633, 1.8334836959838867, 3.4405288696289062, -0.2507057189941406, -9.372676849365234, -16.254730224609375, 2.594618797302246, 1.2664604187011719, 2.686690330505371], "custom_metrics": {}}}, "num_steps_sampled": 11248, "num_agent_steps_sampled": 22496, "num_steps_trained": 20864, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 41728, "last_target_update_ts": 11202, "num_target_updates": 94}, "done": false, "episodes_total": 716, "training_iteration": 39, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-11", "timestamp": 1648811711, "time_this_iter_s": 0.9334573745727539, "time_total_s": 48.39606499671936, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848fdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848fdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 48.39606499671936, "timesteps_since_restore": 1248, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 36.9, "ram_util_percent": 61.349999999999994}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -6.12, "episode_len_mean": 11.96, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": 0.94, "policy1": -7.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.0, -30.0, -30.0, 8.0, -14.0, -4.0, 4.0, -40.0, -14.0, 8.0, -12.0, -14.0, -4.0, -2.0, 4.0, -30.0, -4.0, -30.0, 0.0, 0.0, -30.0, 0.0, -18.0, 2.0, -30.0, 4.0, -4.0, -10.0, 8.0, 8.0, -2.0, -4.0, -4.0, -12.0, 8.0, 6.0, 14.0, -6.0, -8.0, -4.0, -2.0, -30.0, -30.0, 8.0, 10.0, 4.0, 4.0, 4.0, -8.0, 0.0, 12.0, 0.0, 8.0, -20.0, 6.0, -8.0, -4.0, -30.0, -30.0, 0.0, -30.0, -30.0, 0.0, 6.0, -4.0, 12.0, -30.0, 4.0, -18.0, -30.0, -30.0, 0.0, -12.0, 0.0, -8.0, 6.0, 0.0, 10.0, 0.0, -30.0, 0.0, -8.0, 0.0, 0.0, 4.0, 14.0, -4.0, 0.0, 8.0, 8.0, 10.0, 10.0, 4.0, -30.0, 4.0, 8.0, 2.0, -40.0, 8.0, -30.0], "episode_lengths": [12, 20, 20, 6, 17, 12, 8, 20, 17, 6, 16, 17, 12, 11, 8, 20, 12, 20, 10, 10, 20, 10, 19, 9, 20, 8, 12, 15, 6, 6, 11, 12, 12, 16, 6, 7, 3, 13, 14, 12, 11, 20, 20, 6, 5, 8, 8, 8, 14, 10, 4, 10, 6, 20, 7, 14, 12, 20, 20, 10, 20, 20, 10, 7, 12, 4, 20, 8, 19, 20, 20, 10, 16, 10, 14, 7, 10, 5, 10, 20, 10, 14, 10, 10, 8, 3, 12, 10, 6, 6, 5, 5, 8, 20, 8, 6, 9, 20, 6, 20], "policy_policy0_reward": [8.0, -10.0, -10.0, 4.0, 3.0, -2.0, 2.0, -20.0, -7.0, 14.0, 4.0, 3.0, -2.0, -1.0, 12.0, -10.0, 8.0, -10.0, 10.0, 10.0, -20.0, 0.0, -9.0, -9.0, -20.0, 12.0, -2.0, -5.0, 14.0, 14.0, -1.0, -2.0, 8.0, 4.0, 4.0, 3.0, 7.0, 7.0, 6.0, -12.0, 9.0, -10.0, -10.0, 14.0, 5.0, 12.0, 12.0, 12.0, -4.0, 0.0, 6.0, 0.0, 4.0, 0.0, 3.0, -4.0, 8.0, -10.0, -10.0, 10.0, -20.0, -10.0, 10.0, 3.0, -2.0, 6.0, -10.0, 12.0, -9.0, -10.0, -10.0, 10.0, 4.0, 0.0, -4.0, 3.0, 10.0, 5.0, 0.0, -20.0, 10.0, -4.0, 0.0, 0.0, 12.0, 7.0, 8.0, 10.0, 14.0, 14.0, 5.0, 5.0, 2.0, -10.0, 12.0, 14.0, 1.0, -20.0, 4.0, -10.0], "policy_policy1_reward": [-12.0, -20.0, -20.0, 4.0, -17.0, -2.0, 2.0, -20.0, -7.0, -6.0, -16.0, -17.0, -2.0, -1.0, -8.0, -20.0, -12.0, -20.0, -10.0, -10.0, -10.0, 0.0, -9.0, 11.0, -10.0, -8.0, -2.0, -5.0, -6.0, -6.0, -1.0, -2.0, -12.0, -16.0, 4.0, 3.0, 7.0, -13.0, -14.0, 8.0, -11.0, -20.0, -20.0, -6.0, 5.0, -8.0, -8.0, -8.0, -4.0, 0.0, 6.0, 0.0, 4.0, -20.0, 3.0, -4.0, -12.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 3.0, -2.0, 6.0, -20.0, -8.0, -9.0, -20.0, -20.0, -10.0, -16.0, 0.0, -4.0, 3.0, -10.0, 5.0, 0.0, -10.0, -10.0, -4.0, 0.0, 0.0, -8.0, 7.0, -12.0, -10.0, -6.0, -6.0, 5.0, 5.0, 2.0, -20.0, -8.0, -6.0, 1.0, -20.0, 4.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.332126084293809, "mean_inference_ms": 1.7943216625935792, "mean_action_processing_ms": 0.1228847030925305, "mean_env_wait_ms": 0.0766939108932468, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11464, "timesteps_this_iter": 32, "agent_timesteps_total": 22928, "timers": {"load_time_ms": 0.445, "load_throughput": 71935.753, "learn_time_ms": 8.009, "learn_throughput": 3995.741, "update_time_ms": 5.381}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.314499378204346, "min_q": -2.0015265941619873, "max_q": 12.123461723327637, "mean_td_error": -0.062043070793151855, "model": {}}, "td_error": [6.601000785827637, 0.6426296234130859, -2.621096611022949, 1.244727611541748, -0.5633912086486816, 1.8120594024658203, -4.2899169921875, -0.4284987449645996, 0.7959585189819336, 0.9761056900024414, 2.3962364196777344, -1.8507835865020752, -5.014854431152344, -0.7694625854492188, 0.9822063446044922, -0.9974164962768555, -0.5865654945373535, 0.4741239547729492, -1.9129981994628906, -0.1724698543548584, -0.00870513916015625, 0.4837455749511719, 0.5662679672241211, 7.880655288696289, -0.6182198524475098, -1.16410493850708, -2.7639989852905273, 0.9867935180664062, -0.4142570495605469, -0.4893021583557129, -0.754723072052002, -2.4071226119995117], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -9.486103057861328, "min_q": -17.778152465820312, "max_q": 5.503299713134766, "mean_td_error": -3.334901809692383, "model": {}}, "td_error": [-0.05049562454223633, -0.00807332992553711, -1.2748184204101562, -1.002976417541504, -10.895173072814941, 3.161208152770996, -9.21236801147461, -3.6484603881835938, 1.428579568862915, -19.49448013305664, 0.6117000579833984, 0.5833520889282227, 0.07658028602600098, 0.2817268371582031, -3.817911148071289, -11.487363815307617, -14.928422927856445, -4.289019584655762, 0.33571434020996094, 2.0035390853881836, -10.158726692199707, 4.334735870361328, 2.069514274597168, 1.17625093460083, 2.894052505493164, 0.7274608612060547, -1.537740707397461, -11.116466522216797, -3.7923097610473633, -1.3607444763183594, -8.616031646728516, -9.709689140319824], "custom_metrics": {}}}, "num_steps_sampled": 11464, "num_agent_steps_sampled": 22928, "num_steps_trained": 21504, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 43008, "last_target_update_ts": 11418, "num_target_updates": 96}, "done": false, "episodes_total": 737, "training_iteration": 40, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-12", "timestamp": 1648811712, "time_this_iter_s": 1.0200414657592773, "time_total_s": 49.41610646247864, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 49.41610646247864, "timesteps_since_restore": 1280, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 30.3, "ram_util_percent": 58.1}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -5.32, "episode_len_mean": 11.71, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 8.0}, "policy_reward_mean": {"policy0": 1.89, "policy1": -7.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.0, -10.0, 8.0, 8.0, -2.0, -4.0, -4.0, -12.0, 8.0, 6.0, 14.0, -6.0, -8.0, -4.0, -2.0, -30.0, -30.0, 8.0, 10.0, 4.0, 4.0, 4.0, -8.0, 0.0, 12.0, 0.0, 8.0, -20.0, 6.0, -8.0, -4.0, -30.0, -30.0, 0.0, -30.0, -30.0, 0.0, 6.0, -4.0, 12.0, -30.0, 4.0, -18.0, -30.0, -30.0, 0.0, -12.0, 0.0, -8.0, 6.0, 0.0, 10.0, 0.0, -30.0, 0.0, -8.0, 0.0, 0.0, 4.0, 14.0, -4.0, 0.0, 8.0, 8.0, 10.0, 10.0, 4.0, -30.0, 4.0, 8.0, 2.0, -40.0, 8.0, -30.0, 4.0, 4.0, -8.0, 4.0, 4.0, -30.0, 8.0, 0.0, -2.0, 6.0, -20.0, -30.0, 8.0, -30.0, -4.0, -30.0, -30.0, -14.0, -16.0, 4.0, -8.0, -4.0, 4.0, 4.0, -4.0, -20.0], "episode_lengths": [12, 15, 6, 6, 11, 12, 12, 16, 6, 7, 3, 13, 14, 12, 11, 20, 20, 6, 5, 8, 8, 8, 14, 10, 4, 10, 6, 20, 7, 14, 12, 20, 20, 10, 20, 20, 10, 7, 12, 4, 20, 8, 19, 20, 20, 10, 16, 10, 14, 7, 10, 5, 10, 20, 10, 14, 10, 10, 8, 3, 12, 10, 6, 6, 5, 5, 8, 20, 8, 6, 9, 20, 6, 20, 8, 8, 14, 8, 8, 20, 6, 10, 11, 7, 20, 20, 6, 20, 12, 20, 20, 17, 18, 8, 14, 12, 8, 8, 12, 20], "policy_policy0_reward": [-2.0, -5.0, 14.0, 14.0, -1.0, -2.0, 8.0, 4.0, 4.0, 3.0, 7.0, 7.0, 6.0, -12.0, 9.0, -10.0, -10.0, 14.0, 5.0, 12.0, 12.0, 12.0, -4.0, 0.0, 6.0, 0.0, 4.0, 0.0, 3.0, -4.0, 8.0, -10.0, -10.0, 10.0, -20.0, -10.0, 10.0, 3.0, -2.0, 6.0, -10.0, 12.0, -9.0, -10.0, -10.0, 10.0, 4.0, 0.0, -4.0, 3.0, 10.0, 5.0, 0.0, -20.0, 10.0, -4.0, 0.0, 0.0, 12.0, 7.0, 8.0, 10.0, 14.0, 14.0, 5.0, 5.0, 2.0, -10.0, 12.0, 14.0, 1.0, -20.0, 4.0, -10.0, 12.0, 2.0, 6.0, 12.0, 2.0, -10.0, 4.0, 10.0, -1.0, 3.0, 0.0, -10.0, 14.0, -10.0, -2.0, -10.0, -10.0, 3.0, 2.0, 2.0, 6.0, 8.0, 12.0, 12.0, -2.0, 0.0], "policy_policy1_reward": [-2.0, -5.0, -6.0, -6.0, -1.0, -2.0, -12.0, -16.0, 4.0, 3.0, 7.0, -13.0, -14.0, 8.0, -11.0, -20.0, -20.0, -6.0, 5.0, -8.0, -8.0, -8.0, -4.0, 0.0, 6.0, 0.0, 4.0, -20.0, 3.0, -4.0, -12.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 3.0, -2.0, 6.0, -20.0, -8.0, -9.0, -20.0, -20.0, -10.0, -16.0, 0.0, -4.0, 3.0, -10.0, 5.0, 0.0, -10.0, -10.0, -4.0, 0.0, 0.0, -8.0, 7.0, -12.0, -10.0, -6.0, -6.0, 5.0, 5.0, 2.0, -20.0, -8.0, -6.0, 1.0, -20.0, 4.0, -20.0, -8.0, 2.0, -14.0, -8.0, 2.0, -20.0, 4.0, -10.0, -1.0, 3.0, -20.0, -20.0, -6.0, -20.0, -2.0, -20.0, -20.0, -17.0, -18.0, 2.0, -14.0, -12.0, -8.0, -8.0, -2.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33205358753202363, "mean_inference_ms": 1.7905330984326102, "mean_action_processing_ms": 0.12260874472734465, "mean_env_wait_ms": 0.07656406047113049, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11799, "timesteps_this_iter": 32, "agent_timesteps_total": 23598, "timers": {"load_time_ms": 0.403, "load_throughput": 79395.284, "learn_time_ms": 7.747, "learn_throughput": 4130.78, "update_time_ms": 4.534}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.289839744567871, "min_q": -1.6460721492767334, "max_q": 11.202927589416504, "mean_td_error": -0.29058775305747986, "model": {}}, "td_error": [0.34537816047668457, -1.4295101165771484, -0.8768067359924316, 5.012797832489014, -1.006845474243164, -0.372969388961792, -0.3480377197265625, 2.8064427375793457, -0.017724990844726562, -1.0179686546325684, -1.966660499572754, -0.3998450040817261, -2.137014389038086, 0.026140451431274414, -0.18507134914398193, -5.14082145690918, -0.47837066650390625, -2.3981614112854004, 1.1523914337158203, 1.6061713695526123, -1.3706035614013672, -0.08206522464752197, 2.5884597301483154, 2.7467079162597656, 0.7875635623931885, -1.504481554031372, 1.0449838638305664, 0.23772954940795898, 0.23666954040527344, -0.6054439544677734, -7.83791446685791, 1.2860713005065918], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -6.821073532104492, "min_q": -14.839147567749023, "max_q": 7.821258068084717, "mean_td_error": -0.2838138937950134, "model": {}}, "td_error": [2.54049015045166, 0.2557868957519531, 0.24039125442504883, 2.2486801147460938, 0.11083829402923584, 3.4208178520202637, 4.286886692047119, -2.77227783203125, 0.5515041351318359, -1.2285683155059814, -1.6648921966552734, 2.636411666870117, -9.88796615600586, 0.6014194488525391, 0.08617544174194336, -6.978636264801025, 3.1575136184692383, -0.7408971786499023, 0.5071649551391602, 1.5873603820800781, 1.003626823425293, -2.4528560638427734, 4.083498954772949, -2.4066591262817383, 0.4303731918334961, -7.931684494018555, 4.083498954772949, 0.523134708404541, 0.36996030807495117, -3.703442096710205, -2.584801197052002, 0.5451030731201172], "custom_metrics": {}}}, "num_steps_sampled": 11799, "num_agent_steps_sampled": 23598, "num_steps_trained": 22336, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 44672, "last_target_update_ts": 11751, "num_target_updates": 99}, "done": false, "episodes_total": 763, "training_iteration": 41, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-13", "timestamp": 1648811713, "time_this_iter_s": 1.4376120567321777, "time_total_s": 50.853718519210815, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 50.853718519210815, "timesteps_since_restore": 1312, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 30.9, "ram_util_percent": 58.1}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -5.62, "episode_len_mean": 11.86, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 2.04, "policy1": -7.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.0, 4.0, 4.0, 4.0, -8.0, 0.0, 12.0, 0.0, 8.0, -20.0, 6.0, -8.0, -4.0, -30.0, -30.0, 0.0, -30.0, -30.0, 0.0, 6.0, -4.0, 12.0, -30.0, 4.0, -18.0, -30.0, -30.0, 0.0, -12.0, 0.0, -8.0, 6.0, 0.0, 10.0, 0.0, -30.0, 0.0, -8.0, 0.0, 0.0, 4.0, 14.0, -4.0, 0.0, 8.0, 8.0, 10.0, 10.0, 4.0, -30.0, 4.0, 8.0, 2.0, -40.0, 8.0, -30.0, 4.0, 4.0, -8.0, 4.0, 4.0, -30.0, 8.0, 0.0, -2.0, 6.0, -20.0, -30.0, 8.0, -30.0, -4.0, -30.0, -30.0, -14.0, -16.0, 4.0, -8.0, -4.0, 4.0, 4.0, -4.0, -20.0, 4.0, -16.0, 8.0, -12.0, 0.0, -30.0, 8.0, -2.0, -18.0, -30.0, 4.0, -8.0, -10.0, 4.0, 8.0, -4.0, 4.0, -4.0], "episode_lengths": [5, 8, 8, 8, 14, 10, 4, 10, 6, 20, 7, 14, 12, 20, 20, 10, 20, 20, 10, 7, 12, 4, 20, 8, 19, 20, 20, 10, 16, 10, 14, 7, 10, 5, 10, 20, 10, 14, 10, 10, 8, 3, 12, 10, 6, 6, 5, 5, 8, 20, 8, 6, 9, 20, 6, 20, 8, 8, 14, 8, 8, 20, 6, 10, 11, 7, 20, 20, 6, 20, 12, 20, 20, 17, 18, 8, 14, 12, 8, 8, 12, 20, 8, 18, 6, 16, 10, 20, 6, 11, 19, 20, 8, 14, 15, 8, 6, 12, 8, 12], "policy_policy0_reward": [5.0, 12.0, 12.0, 12.0, -4.0, 0.0, 6.0, 0.0, 4.0, 0.0, 3.0, -4.0, 8.0, -10.0, -10.0, 10.0, -20.0, -10.0, 10.0, 3.0, -2.0, 6.0, -10.0, 12.0, -9.0, -10.0, -10.0, 10.0, 4.0, 0.0, -4.0, 3.0, 10.0, 5.0, 0.0, -20.0, 10.0, -4.0, 0.0, 0.0, 12.0, 7.0, 8.0, 10.0, 14.0, 14.0, 5.0, 5.0, 2.0, -10.0, 12.0, 14.0, 1.0, -20.0, 4.0, -10.0, 12.0, 2.0, 6.0, 12.0, 2.0, -10.0, 4.0, 10.0, -1.0, 3.0, 0.0, -10.0, 14.0, -10.0, -2.0, -10.0, -10.0, 3.0, 2.0, 2.0, 6.0, 8.0, 12.0, 12.0, -2.0, 0.0, 12.0, -8.0, 4.0, 4.0, 10.0, -10.0, 14.0, 9.0, -9.0, -10.0, 12.0, 6.0, 5.0, 2.0, 14.0, -2.0, 2.0, 8.0], "policy_policy1_reward": [5.0, -8.0, -8.0, -8.0, -4.0, 0.0, 6.0, 0.0, 4.0, -20.0, 3.0, -4.0, -12.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 3.0, -2.0, 6.0, -20.0, -8.0, -9.0, -20.0, -20.0, -10.0, -16.0, 0.0, -4.0, 3.0, -10.0, 5.0, 0.0, -10.0, -10.0, -4.0, 0.0, 0.0, -8.0, 7.0, -12.0, -10.0, -6.0, -6.0, 5.0, 5.0, 2.0, -20.0, -8.0, -6.0, 1.0, -20.0, 4.0, -20.0, -8.0, 2.0, -14.0, -8.0, 2.0, -20.0, 4.0, -10.0, -1.0, 3.0, -20.0, -20.0, -6.0, -20.0, -2.0, -20.0, -20.0, -17.0, -18.0, 2.0, -14.0, -12.0, -8.0, -8.0, -2.0, -20.0, -8.0, -8.0, 4.0, -16.0, -10.0, -20.0, -6.0, -11.0, -9.0, -20.0, -8.0, -14.0, -15.0, 2.0, -6.0, -2.0, 2.0, -12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3318141762313616, "mean_inference_ms": 1.7869688543189832, "mean_action_processing_ms": 0.1223482793590481, "mean_env_wait_ms": 0.07645930971342221, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12016, "timesteps_this_iter": 32, "agent_timesteps_total": 24032, "timers": {"load_time_ms": 0.431, "load_throughput": 74210.842, "learn_time_ms": 7.505, "learn_throughput": 4263.709, "update_time_ms": 4.453}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.955119609832764, "min_q": -1.611510992050171, "max_q": 12.791097640991211, "mean_td_error": -0.3719319701194763, "model": {}}, "td_error": [0.4441030025482178, -4.197005271911621, -0.08988070487976074, 0.029915809631347656, 1.1297597885131836, 0.24095535278320312, 0.1843414306640625, 0.9911403656005859, -0.2846717834472656, -0.6383724212646484, 0.993776798248291, 0.9119837284088135, 1.1188454627990723, -0.6115109920501709, -3.156278610229492, -0.8133392333984375, -0.3620576858520508, -1.0394930839538574, 0.24682831764221191, 0.07463741302490234, 0.35312747955322266, -0.3480212092399597, -1.0454301834106445, 1.1209373474121094, -1.246476411819458, -0.8523483276367188, -1.2821656465530396, -1.7260942459106445, -1.5031671524047852, -0.9446563720703125, -0.10693120956420898, 0.5057246685028076], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -7.7236738204956055, "min_q": -14.376019477844238, "max_q": 8.940923690795898, "mean_td_error": -0.7944296598434448, "model": {}}, "td_error": [-11.793636322021484, 4.97966194152832, 1.087930679321289, 1.5491743087768555, 4.377129554748535, 1.054549217224121, -0.05907630920410156, 1.6062684059143066, -2.8878231048583984, -0.4549293518066406, 0.20223522186279297, 0.2582857608795166, 1.492375373840332, -1.4977526664733887, 2.53914213180542, -0.7966060638427734, 0.6696748733520508, -5.582636833190918, -10.216821670532227, 0.5764980316162109, 4.473831653594971, 2.3990955352783203, -6.136666774749756, -0.010449767112731934, -0.5203170776367188, -2.4787187576293945, 1.7440671920776367, -0.10790157318115234, -2.555020809173584, -1.6556568145751953, -8.309248924255371, 0.631591796875], "custom_metrics": {}}}, "num_steps_sampled": 12016, "num_agent_steps_sampled": 24032, "num_steps_trained": 22912, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 45824, "last_target_update_ts": 11970, "num_target_updates": 101}, "done": false, "episodes_total": 781, "training_iteration": 42, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-14", "timestamp": 1648811714, "time_this_iter_s": 0.9552736282348633, "time_total_s": 51.80899214744568, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848a200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848a200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 51.80899214744568, "timesteps_since_restore": 1344, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 30.85, "ram_util_percent": 58.2}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -3.82, "episode_len_mean": 11.16, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 3.44, "policy1": -7.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-18.0, -30.0, -30.0, 0.0, -12.0, 0.0, -8.0, 6.0, 0.0, 10.0, 0.0, -30.0, 0.0, -8.0, 0.0, 0.0, 4.0, 14.0, -4.0, 0.0, 8.0, 8.0, 10.0, 10.0, 4.0, -30.0, 4.0, 8.0, 2.0, -40.0, 8.0, -30.0, 4.0, 4.0, -8.0, 4.0, 4.0, -30.0, 8.0, 0.0, -2.0, 6.0, -20.0, -30.0, 8.0, -30.0, -4.0, -30.0, -30.0, -14.0, -16.0, 4.0, -8.0, -4.0, 4.0, 4.0, -4.0, -20.0, 4.0, -16.0, 8.0, -12.0, 0.0, -30.0, 8.0, -2.0, -18.0, -30.0, 4.0, -8.0, -10.0, 4.0, 8.0, -4.0, 4.0, -4.0, 10.0, 8.0, 14.0, 12.0, 8.0, -30.0, -12.0, 8.0, 6.0, -12.0, 6.0, 10.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, -4.0, 4.0, 4.0, -8.0, -8.0, -4.0], "episode_lengths": [19, 20, 20, 10, 16, 10, 14, 7, 10, 5, 10, 20, 10, 14, 10, 10, 8, 3, 12, 10, 6, 6, 5, 5, 8, 20, 8, 6, 9, 20, 6, 20, 8, 8, 14, 8, 8, 20, 6, 10, 11, 7, 20, 20, 6, 20, 12, 20, 20, 17, 18, 8, 14, 12, 8, 8, 12, 20, 8, 18, 6, 16, 10, 20, 6, 11, 19, 20, 8, 14, 15, 8, 6, 12, 8, 12, 5, 6, 3, 4, 6, 20, 16, 6, 7, 16, 7, 5, 6, 8, 6, 6, 6, 6, 12, 8, 8, 14, 14, 12], "policy_policy0_reward": [-9.0, -10.0, -10.0, 10.0, 4.0, 0.0, -4.0, 3.0, 10.0, 5.0, 0.0, -20.0, 10.0, -4.0, 0.0, 0.0, 12.0, 7.0, 8.0, 10.0, 14.0, 14.0, 5.0, 5.0, 2.0, -10.0, 12.0, 14.0, 1.0, -20.0, 4.0, -10.0, 12.0, 2.0, 6.0, 12.0, 2.0, -10.0, 4.0, 10.0, -1.0, 3.0, 0.0, -10.0, 14.0, -10.0, -2.0, -10.0, -10.0, 3.0, 2.0, 2.0, 6.0, 8.0, 12.0, 12.0, -2.0, 0.0, 12.0, -8.0, 4.0, 4.0, 10.0, -10.0, 14.0, 9.0, -9.0, -10.0, 12.0, 6.0, 5.0, 2.0, 14.0, -2.0, 2.0, 8.0, 5.0, 4.0, 7.0, 6.0, 14.0, -10.0, 4.0, 4.0, 3.0, 4.0, 3.0, 5.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 8.0, 12.0, 12.0, 6.0, 6.0, -2.0], "policy_policy1_reward": [-9.0, -20.0, -20.0, -10.0, -16.0, 0.0, -4.0, 3.0, -10.0, 5.0, 0.0, -10.0, -10.0, -4.0, 0.0, 0.0, -8.0, 7.0, -12.0, -10.0, -6.0, -6.0, 5.0, 5.0, 2.0, -20.0, -8.0, -6.0, 1.0, -20.0, 4.0, -20.0, -8.0, 2.0, -14.0, -8.0, 2.0, -20.0, 4.0, -10.0, -1.0, 3.0, -20.0, -20.0, -6.0, -20.0, -2.0, -20.0, -20.0, -17.0, -18.0, 2.0, -14.0, -12.0, -8.0, -8.0, -2.0, -20.0, -8.0, -8.0, 4.0, -16.0, -10.0, -20.0, -6.0, -11.0, -9.0, -20.0, -8.0, -14.0, -15.0, 2.0, -6.0, -2.0, 2.0, -12.0, 5.0, 4.0, 7.0, 6.0, -6.0, -20.0, -16.0, 4.0, 3.0, -16.0, 3.0, 5.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -12.0, -8.0, -8.0, -14.0, -14.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3314955326424113, "mean_inference_ms": 1.7818257985352977, "mean_action_processing_ms": 0.12197384509246816, "mean_env_wait_ms": 0.07629412309169659, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12223, "timesteps_this_iter": 32, "agent_timesteps_total": 24446, "timers": {"load_time_ms": 0.439, "load_throughput": 72948.382, "learn_time_ms": 7.872, "learn_throughput": 4065.048, "update_time_ms": 4.638}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.278153419494629, "min_q": -2.265434503555298, "max_q": 13.703182220458984, "mean_td_error": 0.26468324661254883, "model": {}}, "td_error": [0.3055076599121094, -0.43656158447265625, 0.6769351959228516, 0.7524576187133789, 1.9211406707763672, -0.948542594909668, 3.7009243965148926, -0.4020546078681946, -1.1508064270019531, -1.9321608543395996, -1.1320538520812988, 0.18314862251281738, 0.6569955348968506, 0.4842100143432617, 0.13282203674316406, -0.8438518047332764, 0.4737980365753174, -0.25855201482772827, -1.0343847274780273, 0.8144495487213135, -0.13418197631835938, 0.7524576187133789, 1.1079673767089844, 0.7564153671264648, -1.1320538520812988, 0.6338412761688232, 2.4485666751861572, -0.27381086349487305, 0.43888747692108154, 1.663848638534546, -2.1903510093688965, 2.4348559379577637], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.848295211791992, "min_q": -13.826606750488281, "max_q": -1.1824798583984375, "mean_td_error": -1.5912858247756958, "model": {}}, "td_error": [1.3982458114624023, -0.23577308654785156, 0.9136800765991211, -13.372331619262695, -6.7693772315979, 3.9085607528686523, -7.102635383605957, 4.616891860961914, -1.9535398483276367, -0.6053533554077148, -6.913386821746826, -8.859938621520996, -0.2863607406616211, -7.164253234863281, 0.9408750534057617, 0.6805036067962646, -17.55187225341797, -2.481822967529297, 1.8899869918823242, -0.9667963981628418, 4.070569038391113, -0.21989822387695312, 2.0182833671569824, 1.026320219039917, 1.285262107849121, -0.11946868896484375, -5.3416266441345215, -1.7734079360961914, 0.32390880584716797, 4.193880081176758, 1.111182689666748, 2.4185428619384766], "custom_metrics": {}}}, "num_steps_sampled": 12223, "num_agent_steps_sampled": 24446, "num_steps_trained": 23648, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 47296, "last_target_update_ts": 12183, "num_target_updates": 103}, "done": false, "episodes_total": 805, "training_iteration": 43, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-16", "timestamp": 1648811716, "time_this_iter_s": 1.2712278366088867, "time_total_s": 53.080219984054565, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847fc20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847fc20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 53.080219984054565, "timesteps_since_restore": 1376, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 31.35, "ram_util_percent": 58.2}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -3.18, "episode_len_mean": 10.89, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 3.91, "policy1": -7.09}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 10.0, 10.0, 4.0, -30.0, 4.0, 8.0, 2.0, -40.0, 8.0, -30.0, 4.0, 4.0, -8.0, 4.0, 4.0, -30.0, 8.0, 0.0, -2.0, 6.0, -20.0, -30.0, 8.0, -30.0, -4.0, -30.0, -30.0, -14.0, -16.0, 4.0, -8.0, -4.0, 4.0, 4.0, -4.0, -20.0, 4.0, -16.0, 8.0, -12.0, 0.0, -30.0, 8.0, -2.0, -18.0, -30.0, 4.0, -8.0, -10.0, 4.0, 8.0, -4.0, 4.0, -4.0, 10.0, 8.0, 14.0, 12.0, 8.0, -30.0, -12.0, 8.0, 6.0, -12.0, 6.0, 10.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, -4.0, 4.0, 4.0, -8.0, -8.0, -4.0, 4.0, 0.0, -4.0, -4.0, 0.0, 0.0, -12.0, 10.0, 0.0, -14.0, 8.0, 0.0, 6.0, -10.0, -30.0, 4.0, -30.0, 6.0, 12.0, 12.0], "episode_lengths": [6, 6, 5, 5, 8, 20, 8, 6, 9, 20, 6, 20, 8, 8, 14, 8, 8, 20, 6, 10, 11, 7, 20, 20, 6, 20, 12, 20, 20, 17, 18, 8, 14, 12, 8, 8, 12, 20, 8, 18, 6, 16, 10, 20, 6, 11, 19, 20, 8, 14, 15, 8, 6, 12, 8, 12, 5, 6, 3, 4, 6, 20, 16, 6, 7, 16, 7, 5, 6, 8, 6, 6, 6, 6, 12, 8, 8, 14, 14, 12, 8, 10, 12, 12, 10, 10, 16, 5, 10, 17, 6, 10, 7, 15, 20, 8, 20, 7, 4, 4], "policy_policy0_reward": [14.0, 14.0, 5.0, 5.0, 2.0, -10.0, 12.0, 14.0, 1.0, -20.0, 4.0, -10.0, 12.0, 2.0, 6.0, 12.0, 2.0, -10.0, 4.0, 10.0, -1.0, 3.0, 0.0, -10.0, 14.0, -10.0, -2.0, -10.0, -10.0, 3.0, 2.0, 2.0, 6.0, 8.0, 12.0, 12.0, -2.0, 0.0, 12.0, -8.0, 4.0, 4.0, 10.0, -10.0, 14.0, 9.0, -9.0, -10.0, 12.0, 6.0, 5.0, 2.0, 14.0, -2.0, 2.0, 8.0, 5.0, 4.0, 7.0, 6.0, 14.0, -10.0, 4.0, 4.0, 3.0, 4.0, 3.0, 5.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 8.0, 12.0, 12.0, 6.0, 6.0, -2.0, 12.0, 10.0, -2.0, 8.0, 0.0, 10.0, -6.0, 5.0, 10.0, -7.0, 14.0, 10.0, 3.0, 5.0, -20.0, 12.0, -10.0, 3.0, 6.0, 6.0], "policy_policy1_reward": [-6.0, -6.0, 5.0, 5.0, 2.0, -20.0, -8.0, -6.0, 1.0, -20.0, 4.0, -20.0, -8.0, 2.0, -14.0, -8.0, 2.0, -20.0, 4.0, -10.0, -1.0, 3.0, -20.0, -20.0, -6.0, -20.0, -2.0, -20.0, -20.0, -17.0, -18.0, 2.0, -14.0, -12.0, -8.0, -8.0, -2.0, -20.0, -8.0, -8.0, 4.0, -16.0, -10.0, -20.0, -6.0, -11.0, -9.0, -20.0, -8.0, -14.0, -15.0, 2.0, -6.0, -2.0, 2.0, -12.0, 5.0, 4.0, 7.0, 6.0, -6.0, -20.0, -16.0, 4.0, 3.0, -16.0, 3.0, 5.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -12.0, -8.0, -8.0, -14.0, -14.0, -2.0, -8.0, -10.0, -2.0, -12.0, 0.0, -10.0, -6.0, 5.0, -10.0, -7.0, -6.0, -10.0, 3.0, -15.0, -10.0, -8.0, -20.0, 3.0, 6.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3312421562192766, "mean_inference_ms": 1.777720790990155, "mean_action_processing_ms": 0.12168429542260029, "mean_env_wait_ms": 0.07615430461843636, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12434, "timesteps_this_iter": 32, "agent_timesteps_total": 24868, "timers": {"load_time_ms": 0.424, "load_throughput": 75415.929, "learn_time_ms": 7.646, "learn_throughput": 4185.005, "update_time_ms": 4.688}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.740581512451172, "min_q": -3.2241411209106445, "max_q": 15.008199691772461, "mean_td_error": -0.025846168398857117, "model": {}}, "td_error": [-2.2241411209106445, -0.09525871276855469, -0.27294254302978516, -0.6017346382141113, 8.651948928833008, 1.5505867004394531, 0.15781760215759277, 1.924881935119629, -6.75602912902832, 0.8447003364562988, -3.7022552490234375, 1.1401557922363281, 3.087006092071533, -0.21037888526916504, -4.4974164962768555, 2.6555089950561523, 0.19652843475341797, 1.0038022994995117, -0.4411557912826538, -0.11719322204589844, -2.252427101135254, -0.5454826354980469, 0.26915836334228516, -0.059317588806152344, -0.7836172580718994, -2.26242733001709, -1.045419692993164, 0.09614753723144531, 1.6790199279785156, -0.5606544017791748, 1.978835105895996, 0.36467647552490234], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.573543548583984, "min_q": -14.425666809082031, "max_q": 3.4583091735839844, "mean_td_error": -2.3575525283813477, "model": {}}, "td_error": [0.8272914886474609, -0.35539913177490234, -1.9377803802490234, 2.256885528564453, -7.349652290344238, -1.2251110076904297, -4.268362045288086, 0.4605741500854492, -2.510669231414795, -1.1690235137939453, 1.3532028198242188, -7.9776611328125, -1.6238784790039062, -12.57478141784668, -9.673829078674316, -11.561614990234375, -1.376542091369629, -0.6435928344726562, -8.767114639282227, -8.7326078414917, 1.036362886428833, -0.6345458030700684, 2.930767059326172, -0.036673545837402344, 0.7085608243942261, 3.903989791870117, -1.5617380142211914, -1.6208992004394531, 0.6324758529663086, -1.1263866424560547, -1.0089731216430664, -1.8149499893188477], "custom_metrics": {}}}, "num_steps_sampled": 12434, "num_agent_steps_sampled": 24868, "num_steps_trained": 24288, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 48576, "last_target_update_ts": 12391, "num_target_updates": 105}, "done": false, "episodes_total": 825, "training_iteration": 44, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-17", "timestamp": 1648811717, "time_this_iter_s": 1.010270595550537, "time_total_s": 54.0904905796051, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 54.0904905796051, "timesteps_since_restore": 1408, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 30.8, "ram_util_percent": 58.2}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": -2.7, "episode_len_mean": 10.85, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 4.75, "policy1": -7.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, -20.0, -30.0, 8.0, -30.0, -4.0, -30.0, -30.0, -14.0, -16.0, 4.0, -8.0, -4.0, 4.0, 4.0, -4.0, -20.0, 4.0, -16.0, 8.0, -12.0, 0.0, -30.0, 8.0, -2.0, -18.0, -30.0, 4.0, -8.0, -10.0, 4.0, 8.0, -4.0, 4.0, -4.0, 10.0, 8.0, 14.0, 12.0, 8.0, -30.0, -12.0, 8.0, 6.0, -12.0, 6.0, 10.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, -4.0, 4.0, 4.0, -8.0, -8.0, -4.0, 4.0, 0.0, -4.0, -4.0, 0.0, 0.0, -12.0, 10.0, 0.0, -14.0, 8.0, 0.0, 6.0, -10.0, -30.0, 4.0, -30.0, 6.0, 12.0, 12.0, 0.0, 0.0, -8.0, 8.0, 4.0, 8.0, 8.0, 0.0, 12.0, -4.0, 4.0, -4.0, -20.0, 0.0, -30.0, 8.0, -4.0, -4.0, 0.0, 8.0, 8.0], "episode_lengths": [7, 20, 20, 6, 20, 12, 20, 20, 17, 18, 8, 14, 12, 8, 8, 12, 20, 8, 18, 6, 16, 10, 20, 6, 11, 19, 20, 8, 14, 15, 8, 6, 12, 8, 12, 5, 6, 3, 4, 6, 20, 16, 6, 7, 16, 7, 5, 6, 8, 6, 6, 6, 6, 12, 8, 8, 14, 14, 12, 8, 10, 12, 12, 10, 10, 16, 5, 10, 17, 6, 10, 7, 15, 20, 8, 20, 7, 4, 4, 10, 10, 14, 6, 8, 6, 6, 10, 4, 12, 8, 12, 20, 10, 20, 6, 12, 12, 10, 6, 6], "policy_policy0_reward": [3.0, 0.0, -10.0, 14.0, -10.0, -2.0, -10.0, -10.0, 3.0, 2.0, 2.0, 6.0, 8.0, 12.0, 12.0, -2.0, 0.0, 12.0, -8.0, 4.0, 4.0, 10.0, -10.0, 14.0, 9.0, -9.0, -10.0, 12.0, 6.0, 5.0, 2.0, 14.0, -2.0, 2.0, 8.0, 5.0, 4.0, 7.0, 6.0, 14.0, -10.0, 4.0, 4.0, 3.0, 4.0, 3.0, 5.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 8.0, 12.0, 12.0, 6.0, 6.0, -2.0, 12.0, 10.0, -2.0, 8.0, 0.0, 10.0, -6.0, 5.0, 10.0, -7.0, 14.0, 10.0, 3.0, 5.0, -20.0, 12.0, -10.0, 3.0, 6.0, 6.0, 10.0, 10.0, 6.0, 14.0, 2.0, 4.0, 4.0, 10.0, 6.0, 8.0, 12.0, 8.0, 0.0, 10.0, -10.0, 14.0, 8.0, -2.0, 10.0, 14.0, 14.0], "policy_policy1_reward": [3.0, -20.0, -20.0, -6.0, -20.0, -2.0, -20.0, -20.0, -17.0, -18.0, 2.0, -14.0, -12.0, -8.0, -8.0, -2.0, -20.0, -8.0, -8.0, 4.0, -16.0, -10.0, -20.0, -6.0, -11.0, -9.0, -20.0, -8.0, -14.0, -15.0, 2.0, -6.0, -2.0, 2.0, -12.0, 5.0, 4.0, 7.0, 6.0, -6.0, -20.0, -16.0, 4.0, 3.0, -16.0, 3.0, 5.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -12.0, -8.0, -8.0, -14.0, -14.0, -2.0, -8.0, -10.0, -2.0, -12.0, 0.0, -10.0, -6.0, 5.0, -10.0, -7.0, -6.0, -10.0, 3.0, -15.0, -10.0, -8.0, -20.0, 3.0, 6.0, 6.0, -10.0, -10.0, -14.0, -6.0, 2.0, 4.0, 4.0, -10.0, 6.0, -12.0, -8.0, -12.0, -20.0, -10.0, -20.0, -6.0, -12.0, -2.0, -10.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3310955144758994, "mean_inference_ms": 1.7740770648017923, "mean_action_processing_ms": 0.12142366636915458, "mean_env_wait_ms": 0.07602179983059108, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12642, "timesteps_this_iter": 32, "agent_timesteps_total": 25284, "timers": {"load_time_ms": 0.448, "load_throughput": 71384.814, "learn_time_ms": 7.804, "learn_throughput": 4100.605, "update_time_ms": 4.717}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.596955299377441, "min_q": -1.7763335704803467, "max_q": 13.561416625976562, "mean_td_error": 0.564035952091217, "model": {}}, "td_error": [-0.575624942779541, 3.4000096321105957, -1.0907478332519531, -0.07356250286102295, -0.3133225440979004, -1.23844575881958, -0.3583207130432129, 6.463547229766846, 0.7791318893432617, 3.8809871673583984, -0.4448666572570801, 0.5273456573486328, 1.7257404327392578, -0.3675050735473633, 1.0316944122314453, -0.025031566619873047, -0.9474802017211914, 4.92315149307251, 0.08629751205444336, -1.1567134857177734, -0.7936115264892578, -1.4946246147155762, -2.941690444946289, 4.846899509429932, 0.061028480529785156, -0.7810707092285156, -0.4214348793029785, -0.08864283561706543, 0.26798200607299805, 0.7383613586425781, 1.7690582275390625, 0.6606125831604004], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -7.848766803741455, "min_q": -13.369211196899414, "max_q": 4.9589524269104, "mean_td_error": -0.615705132484436, "model": {}}, "td_error": [-0.1313467025756836, 0.12108612060546875, 1.9100213050842285, -6.695964813232422, 1.4327120780944824, -5.613174915313721, 2.1291613578796387, 0.7321248054504395, 0.8460551500320435, 0.11920356750488281, 3.3414487838745117, -0.1673274040222168, 0.22863483428955078, -1.7849111557006836, -3.9703211784362793, -3.4283385276794434, 0.937159538269043, 2.6633429527282715, 1.506004810333252, -1.542902946472168, -0.01662158966064453, -2.4498987197875977, -12.369211196899414, 1.874354362487793, 1.0767946243286133, 0.7094554901123047, -0.23552227020263672, 0.6759271621704102, -5.574494361877441, 0.7875518798828125, -0.056868553161621094, 3.2433013916015625], "custom_metrics": {}}}, "num_steps_sampled": 12642, "num_agent_steps_sampled": 25284, "num_steps_trained": 24960, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 49920, "last_target_update_ts": 12596, "num_target_updates": 107}, "done": false, "episodes_total": 846, "training_iteration": 45, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-18", "timestamp": 1648811718, "time_this_iter_s": 1.0509259700775146, "time_total_s": 55.14141654968262, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 55.14141654968262, "timesteps_since_restore": 1440, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 29.85, "ram_util_percent": 58.3}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": -1.3, "episode_len_mean": 10.25, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 5.55, "policy1": -6.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.0, 0.0, -30.0, 8.0, -2.0, -18.0, -30.0, 4.0, -8.0, -10.0, 4.0, 8.0, -4.0, 4.0, -4.0, 10.0, 8.0, 14.0, 12.0, 8.0, -30.0, -12.0, 8.0, 6.0, -12.0, 6.0, 10.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, -4.0, 4.0, 4.0, -8.0, -8.0, -4.0, 4.0, 0.0, -4.0, -4.0, 0.0, 0.0, -12.0, 10.0, 0.0, -14.0, 8.0, 0.0, 6.0, -10.0, -30.0, 4.0, -30.0, 6.0, 12.0, 12.0, 0.0, 0.0, -8.0, 8.0, 4.0, 8.0, 8.0, 0.0, 12.0, -4.0, 4.0, -4.0, -20.0, 0.0, -30.0, 8.0, -4.0, -4.0, 0.0, 8.0, 8.0, 4.0, 0.0, 0.0, 2.0, -30.0, 12.0, 0.0, -30.0, 0.0, 10.0, 4.0, 8.0, 0.0, 12.0, 4.0, -16.0, -16.0, 8.0, 0.0, -20.0], "episode_lengths": [16, 10, 20, 6, 11, 19, 20, 8, 14, 15, 8, 6, 12, 8, 12, 5, 6, 3, 4, 6, 20, 16, 6, 7, 16, 7, 5, 6, 8, 6, 6, 6, 6, 12, 8, 8, 14, 14, 12, 8, 10, 12, 12, 10, 10, 16, 5, 10, 17, 6, 10, 7, 15, 20, 8, 20, 7, 4, 4, 10, 10, 14, 6, 8, 6, 6, 10, 4, 12, 8, 12, 20, 10, 20, 6, 12, 12, 10, 6, 6, 8, 10, 10, 9, 20, 4, 10, 20, 10, 5, 8, 6, 10, 4, 8, 18, 18, 6, 10, 20], "policy_policy0_reward": [4.0, 10.0, -10.0, 14.0, 9.0, -9.0, -10.0, 12.0, 6.0, 5.0, 2.0, 14.0, -2.0, 2.0, 8.0, 5.0, 4.0, 7.0, 6.0, 14.0, -10.0, 4.0, 4.0, 3.0, 4.0, 3.0, 5.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 8.0, 12.0, 12.0, 6.0, 6.0, -2.0, 12.0, 10.0, -2.0, 8.0, 0.0, 10.0, -6.0, 5.0, 10.0, -7.0, 14.0, 10.0, 3.0, 5.0, -20.0, 12.0, -10.0, 3.0, 6.0, 6.0, 10.0, 10.0, 6.0, 14.0, 2.0, 4.0, 4.0, 10.0, 6.0, 8.0, 12.0, 8.0, 0.0, 10.0, -10.0, 14.0, 8.0, -2.0, 10.0, 14.0, 14.0, 2.0, 0.0, 10.0, 11.0, -10.0, 6.0, 10.0, -10.0, 10.0, 5.0, 12.0, 4.0, 10.0, 6.0, 12.0, 2.0, 2.0, 14.0, 10.0, 0.0], "policy_policy1_reward": [-16.0, -10.0, -20.0, -6.0, -11.0, -9.0, -20.0, -8.0, -14.0, -15.0, 2.0, -6.0, -2.0, 2.0, -12.0, 5.0, 4.0, 7.0, 6.0, -6.0, -20.0, -16.0, 4.0, 3.0, -16.0, 3.0, 5.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -12.0, -8.0, -8.0, -14.0, -14.0, -2.0, -8.0, -10.0, -2.0, -12.0, 0.0, -10.0, -6.0, 5.0, -10.0, -7.0, -6.0, -10.0, 3.0, -15.0, -10.0, -8.0, -20.0, 3.0, 6.0, 6.0, -10.0, -10.0, -14.0, -6.0, 2.0, 4.0, 4.0, -10.0, 6.0, -12.0, -8.0, -12.0, -20.0, -10.0, -20.0, -6.0, -12.0, -2.0, -10.0, -6.0, -6.0, 2.0, 0.0, -10.0, -9.0, -20.0, 6.0, -10.0, -20.0, -10.0, 5.0, -8.0, 4.0, -10.0, 6.0, -8.0, -18.0, -18.0, -6.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33104303339592106, "mean_inference_ms": 1.771019634880267, "mean_action_processing_ms": 0.12120372058516192, "mean_env_wait_ms": 0.07592053018939313, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12856, "timesteps_this_iter": 32, "agent_timesteps_total": 25712, "timers": {"load_time_ms": 0.437, "load_throughput": 73242.962, "learn_time_ms": 7.729, "learn_throughput": 4140.056, "update_time_ms": 4.789}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.509095668792725, "min_q": -1.958402156829834, "max_q": 14.611434936523438, "mean_td_error": 0.11892261356115341, "model": {}}, "td_error": [-1.60536527633667, 4.942869663238525, -0.1963636875152588, 0.7284889221191406, -1.291910171508789, 0.17513704299926758, 0.32865047454833984, -1.1003851890563965, 0.8346786499023438, 0.5232982635498047, 0.5449142456054688, 0.7495999336242676, 0.019191741943359375, -0.26973390579223633, 2.0365467071533203, -1.414576530456543, -0.02959442138671875, 2.6093616485595703, -3.7574753761291504, -0.6473208665847778, -0.9102816581726074, -0.15755200386047363, 0.08799171447753906, -0.26973390579223633, -2.6513872146606445, -0.5332212448120117, 0.9306106567382812, -1.061676025390625, 6.072527885437012, -0.29497718811035156, 0.6847829818725586, -1.2715721130371094], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.836633682250977, "min_q": -12.60491943359375, "max_q": 3.2883243560791016, "mean_td_error": -1.6137442588806152, "model": {}}, "td_error": [0.2580451965332031, 1.0064382553100586, -1.0619020462036133, -7.241488456726074, -0.5695991516113281, 0.9696521759033203, -4.355937957763672, -18.294084548950195, -1.0998334884643555, -1.2827682495117188, -2.943930149078369, -0.17387104034423828, 1.8235793113708496, -0.9238014221191406, -3.25408935546875, 0.81536865234375, 2.2681198120117188, 0.7242527008056641, 1.1454658508300781, 1.723708152770996, -5.726127624511719, 1.1725130081176758, 0.2347555160522461, -6.47769832611084, -0.22467613220214844, -1.3071346282958984, 0.5689706802368164, -5.711675643920898, 0.8840131759643555, 0.6239490509033203, -6.631590843200684, 1.4215593338012695], "custom_metrics": {}}}, "num_steps_sampled": 12856, "num_agent_steps_sampled": 25712, "num_steps_trained": 25600, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 51200, "last_target_update_ts": 12802, "num_target_updates": 109}, "done": false, "episodes_total": 866, "training_iteration": 46, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-19", "timestamp": 1648811719, "time_this_iter_s": 1.0396568775177002, "time_total_s": 56.18107342720032, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 56.18107342720032, "timesteps_since_restore": 1472, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 32.4, "ram_util_percent": 58.3}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": -0.4, "episode_len_mean": 9.95, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 6.15, "policy1": -6.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 6.0, -12.0, 6.0, 10.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, -4.0, 4.0, 4.0, -8.0, -8.0, -4.0, 4.0, 0.0, -4.0, -4.0, 0.0, 0.0, -12.0, 10.0, 0.0, -14.0, 8.0, 0.0, 6.0, -10.0, -30.0, 4.0, -30.0, 6.0, 12.0, 12.0, 0.0, 0.0, -8.0, 8.0, 4.0, 8.0, 8.0, 0.0, 12.0, -4.0, 4.0, -4.0, -20.0, 0.0, -30.0, 8.0, -4.0, -4.0, 0.0, 8.0, 8.0, 4.0, 0.0, 0.0, 2.0, -30.0, 12.0, 0.0, -30.0, 0.0, 10.0, 4.0, 8.0, 0.0, 12.0, 4.0, -16.0, -16.0, 8.0, 0.0, -20.0, 12.0, 14.0, 8.0, 4.0, 10.0, -20.0, 0.0, 8.0, 4.0, 8.0, -16.0, 4.0, -4.0, 0.0, -16.0, 2.0, 4.0, 4.0, 4.0, 4.0, -16.0, -8.0], "episode_lengths": [6, 7, 16, 7, 5, 6, 8, 6, 6, 6, 6, 12, 8, 8, 14, 14, 12, 8, 10, 12, 12, 10, 10, 16, 5, 10, 17, 6, 10, 7, 15, 20, 8, 20, 7, 4, 4, 10, 10, 14, 6, 8, 6, 6, 10, 4, 12, 8, 12, 20, 10, 20, 6, 12, 12, 10, 6, 6, 8, 10, 10, 9, 20, 4, 10, 20, 10, 5, 8, 6, 10, 4, 8, 18, 18, 6, 10, 20, 4, 3, 6, 8, 5, 20, 10, 6, 8, 6, 18, 8, 12, 10, 18, 9, 8, 8, 8, 8, 18, 14], "policy_policy0_reward": [4.0, 3.0, 4.0, 3.0, 5.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 8.0, 12.0, 12.0, 6.0, 6.0, -2.0, 12.0, 10.0, -2.0, 8.0, 0.0, 10.0, -6.0, 5.0, 10.0, -7.0, 14.0, 10.0, 3.0, 5.0, -20.0, 12.0, -10.0, 3.0, 6.0, 6.0, 10.0, 10.0, 6.0, 14.0, 2.0, 4.0, 4.0, 10.0, 6.0, 8.0, 12.0, 8.0, 0.0, 10.0, -10.0, 14.0, 8.0, -2.0, 10.0, 14.0, 14.0, 2.0, 0.0, 10.0, 11.0, -10.0, 6.0, 10.0, -10.0, 10.0, 5.0, 12.0, 4.0, 10.0, 6.0, 12.0, 2.0, 2.0, 14.0, 10.0, 0.0, 6.0, 7.0, 14.0, 12.0, 5.0, 0.0, 10.0, 14.0, 2.0, 4.0, 2.0, 12.0, 8.0, 10.0, -8.0, 1.0, 12.0, 12.0, 12.0, 2.0, 2.0, 6.0], "policy_policy1_reward": [4.0, 3.0, -16.0, 3.0, 5.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -12.0, -8.0, -8.0, -14.0, -14.0, -2.0, -8.0, -10.0, -2.0, -12.0, 0.0, -10.0, -6.0, 5.0, -10.0, -7.0, -6.0, -10.0, 3.0, -15.0, -10.0, -8.0, -20.0, 3.0, 6.0, 6.0, -10.0, -10.0, -14.0, -6.0, 2.0, 4.0, 4.0, -10.0, 6.0, -12.0, -8.0, -12.0, -20.0, -10.0, -20.0, -6.0, -12.0, -2.0, -10.0, -6.0, -6.0, 2.0, 0.0, -10.0, -9.0, -20.0, 6.0, -10.0, -20.0, -10.0, 5.0, -8.0, 4.0, -10.0, 6.0, -8.0, -18.0, -18.0, -6.0, -10.0, -20.0, 6.0, 7.0, -6.0, -8.0, 5.0, -20.0, -10.0, -6.0, 2.0, 4.0, -18.0, -8.0, -12.0, -10.0, -8.0, 1.0, -8.0, -8.0, -8.0, 2.0, -18.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33104167559667674, "mean_inference_ms": 1.7682479376324332, "mean_action_processing_ms": 0.12099912943574029, "mean_env_wait_ms": 0.07582662781763301, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13071, "timesteps_this_iter": 32, "agent_timesteps_total": 26142, "timers": {"load_time_ms": 0.413, "load_throughput": 77434.794, "learn_time_ms": 7.684, "learn_throughput": 4164.502, "update_time_ms": 4.71}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.454716205596924, "min_q": -1.2768508195877075, "max_q": 16.180896759033203, "mean_td_error": 0.8796309232711792, "model": {}}, "td_error": [-1.8396720886230469, 2.167055130004883, 0.9448823928833008, 1.0353975296020508, -0.4085235595703125, 2.0502500534057617, 0.40738773345947266, 0.6581411361694336, 1.404383659362793, 1.6185417175292969, 1.1486825942993164, -4.363215446472168, -1.2947726249694824, 0.8126664161682129, 0.2211453914642334, 9.913976669311523, -0.08615684509277344, 1.6659317016601562, 1.0525312423706055, 2.3117690086364746, 1.6449861526489258, 3.299196243286133, 0.8164024353027344, 1.1135239601135254, 0.31579089164733887, 0.3636322021484375, 0.5652709007263184, 0.4097776412963867, -0.01647663116455078, -1.279537558555603, 0.23531866073608398, 1.2599029541015625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.39944076538086, "min_q": -12.724533081054688, "max_q": 6.085967063903809, "mean_td_error": -1.7241554260253906, "model": {}}, "td_error": [-9.633399963378906, -0.10344600677490234, 0.4401366710662842, -10.627448081970215, -4.0853705406188965, -0.751011848449707, -0.5680427551269531, 0.06801319122314453, -2.2091379165649414, 0.7550563812255859, 2.2213544845581055, 2.2213544845581055, 0.4922313690185547, -10.58697509765625, -4.67617130279541, 0.0070514678955078125, 1.873784065246582, 0.5846176147460938, -1.656144142150879, -0.36495113372802734, -0.7202491760253906, -6.753130912780762, 0.23606491088867188, -1.1770877838134766, -1.3499135971069336, 1.450261116027832, 0.8164825439453125, 0.0075626373291015625, -1.054366111755371, 0.5592684745788574, 0.8859742283821106, -11.475341796875], "custom_metrics": {}}}, "num_steps_sampled": 13071, "num_agent_steps_sampled": 26142, "num_steps_trained": 26272, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 52544, "last_target_update_ts": 13015, "num_target_updates": 111}, "done": false, "episodes_total": 888, "training_iteration": 47, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-20", "timestamp": 1648811720, "time_this_iter_s": 1.072328805923462, "time_total_s": 57.25340223312378, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58470cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58470cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 57.25340223312378, "timesteps_since_restore": 1504, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 30.3, "ram_util_percent": 58.3}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": -1.28, "episode_len_mean": 10.29, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 5.71, "policy1": -6.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.0, 0.0, 0.0, -12.0, 10.0, 0.0, -14.0, 8.0, 0.0, 6.0, -10.0, -30.0, 4.0, -30.0, 6.0, 12.0, 12.0, 0.0, 0.0, -8.0, 8.0, 4.0, 8.0, 8.0, 0.0, 12.0, -4.0, 4.0, -4.0, -20.0, 0.0, -30.0, 8.0, -4.0, -4.0, 0.0, 8.0, 8.0, 4.0, 0.0, 0.0, 2.0, -30.0, 12.0, 0.0, -30.0, 0.0, 10.0, 4.0, 8.0, 0.0, 12.0, 4.0, -16.0, -16.0, 8.0, 0.0, -20.0, 12.0, 14.0, 8.0, 4.0, 10.0, -20.0, 0.0, 8.0, 4.0, 8.0, -16.0, 4.0, -4.0, 0.0, -16.0, 2.0, 4.0, 4.0, 4.0, 4.0, -16.0, -8.0, -30.0, -8.0, 0.0, 14.0, 8.0, -30.0, 0.0, 4.0, -16.0, 8.0, 4.0, 4.0, -4.0, 4.0, -4.0, -16.0, 12.0, 4.0, 0.0, 4.0], "episode_lengths": [12, 10, 10, 16, 5, 10, 17, 6, 10, 7, 15, 20, 8, 20, 7, 4, 4, 10, 10, 14, 6, 8, 6, 6, 10, 4, 12, 8, 12, 20, 10, 20, 6, 12, 12, 10, 6, 6, 8, 10, 10, 9, 20, 4, 10, 20, 10, 5, 8, 6, 10, 4, 8, 18, 18, 6, 10, 20, 4, 3, 6, 8, 5, 20, 10, 6, 8, 6, 18, 8, 12, 10, 18, 9, 8, 8, 8, 8, 18, 14, 20, 14, 10, 3, 6, 20, 10, 8, 18, 6, 8, 8, 12, 8, 12, 18, 4, 8, 10, 8], "policy_policy0_reward": [8.0, 0.0, 10.0, -6.0, 5.0, 10.0, -7.0, 14.0, 10.0, 3.0, 5.0, -20.0, 12.0, -10.0, 3.0, 6.0, 6.0, 10.0, 10.0, 6.0, 14.0, 2.0, 4.0, 4.0, 10.0, 6.0, 8.0, 12.0, 8.0, 0.0, 10.0, -10.0, 14.0, 8.0, -2.0, 10.0, 14.0, 14.0, 2.0, 0.0, 10.0, 11.0, -10.0, 6.0, 10.0, -10.0, 10.0, 5.0, 12.0, 4.0, 10.0, 6.0, 12.0, 2.0, 2.0, 14.0, 10.0, 0.0, 6.0, 7.0, 14.0, 12.0, 5.0, 0.0, 10.0, 14.0, 2.0, 4.0, 2.0, 12.0, 8.0, 10.0, -8.0, 1.0, 12.0, 12.0, 12.0, 2.0, 2.0, 6.0, -20.0, 6.0, 10.0, 7.0, 14.0, -10.0, 0.0, 12.0, 2.0, 14.0, 12.0, 12.0, -2.0, 12.0, 8.0, 2.0, 6.0, 12.0, 10.0, 12.0], "policy_policy1_reward": [-12.0, 0.0, -10.0, -6.0, 5.0, -10.0, -7.0, -6.0, -10.0, 3.0, -15.0, -10.0, -8.0, -20.0, 3.0, 6.0, 6.0, -10.0, -10.0, -14.0, -6.0, 2.0, 4.0, 4.0, -10.0, 6.0, -12.0, -8.0, -12.0, -20.0, -10.0, -20.0, -6.0, -12.0, -2.0, -10.0, -6.0, -6.0, 2.0, 0.0, -10.0, -9.0, -20.0, 6.0, -10.0, -20.0, -10.0, 5.0, -8.0, 4.0, -10.0, 6.0, -8.0, -18.0, -18.0, -6.0, -10.0, -20.0, 6.0, 7.0, -6.0, -8.0, 5.0, -20.0, -10.0, -6.0, 2.0, 4.0, -18.0, -8.0, -12.0, -10.0, -8.0, 1.0, -8.0, -8.0, -8.0, 2.0, -18.0, -14.0, -10.0, -14.0, -10.0, 7.0, -6.0, -20.0, 0.0, -8.0, -18.0, -6.0, -8.0, -8.0, -2.0, -8.0, -12.0, -18.0, 6.0, -8.0, -10.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.330988804696289, "mean_inference_ms": 1.7657588931804873, "mean_action_processing_ms": 0.12081333591860681, "mean_env_wait_ms": 0.07573736273760065, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13282, "timesteps_this_iter": 32, "agent_timesteps_total": 26564, "timers": {"load_time_ms": 0.441, "load_throughput": 72628.641, "learn_time_ms": 7.77, "learn_throughput": 4118.612, "update_time_ms": 4.563}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.257755279541016, "min_q": -1.9589364528656006, "max_q": 15.757102966308594, "mean_td_error": 0.37123826146125793, "model": {}}, "td_error": [0.3913288116455078, -1.3733832836151123, -1.026564598083496, -0.07451868057250977, 0.814185619354248, -1.2486581802368164, 0.7201499938964844, 12.92361068725586, -0.5773344039916992, 0.8078031539916992, -0.417694091796875, 0.6199169158935547, -1.1299552917480469, 0.28008460998535156, 0.5690031051635742, -1.8361330032348633, -0.5652172565460205, 0.9762725830078125, -1.5455207824707031, 0.49576568603515625, -1.026564598083496, 5.574967861175537, -1.0318212509155273, -0.5093239545822144, 0.4740333557128906, -0.9613146781921387, -0.5964889526367188, 1.3381876945495605, 5.958640098571777, -4.307568550109863, -1.0156030654907227, -0.8206605911254883], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -9.17992115020752, "min_q": -13.537281036376953, "max_q": 8.766380310058594, "mean_td_error": -1.3185977935791016, "model": {}}, "td_error": [0.027360916137695312, 9.766380310058594, 1.145024299621582, 0.7370471954345703, -0.19655561447143555, 0.875152587890625, 0.4087944030761719, -13.937948226928711, 0.3926353454589844, 0.2306966781616211, 0.244049072265625, 0.4437370300292969, 1.4246039390563965, 2.542478561401367, -6.171948432922363, 2.703038215637207, 2.6552276611328125, -0.09988975524902344, 1.4681291580200195, -0.9339418411254883, -20.94147491455078, -0.09796428680419922, -6.842564105987549, -8.907814025878906, -2.5578765869140625, -1.995285987854004, -0.9441152215003967, 2.625124931335449, 2.297273635864258, 2.1342878341674805, -9.10946273803711, -1.5793342590332031], "custom_metrics": {}}}, "num_steps_sampled": 13282, "num_agent_steps_sampled": 26564, "num_steps_trained": 26880, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 53760, "last_target_update_ts": 13234, "num_target_updates": 113}, "done": false, "episodes_total": 908, "training_iteration": 48, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-21", "timestamp": 1648811721, "time_this_iter_s": 0.9914898872375488, "time_total_s": 58.24489212036133, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58470f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58470f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 58.24489212036133, "timesteps_since_restore": 1536, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 31.1, "ram_util_percent": 58.4}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": -0.66, "episode_len_mean": 10.03, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 6.57, "policy1": -7.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 0.0, 12.0, -4.0, 4.0, -4.0, -20.0, 0.0, -30.0, 8.0, -4.0, -4.0, 0.0, 8.0, 8.0, 4.0, 0.0, 0.0, 2.0, -30.0, 12.0, 0.0, -30.0, 0.0, 10.0, 4.0, 8.0, 0.0, 12.0, 4.0, -16.0, -16.0, 8.0, 0.0, -20.0, 12.0, 14.0, 8.0, 4.0, 10.0, -20.0, 0.0, 8.0, 4.0, 8.0, -16.0, 4.0, -4.0, 0.0, -16.0, 2.0, 4.0, 4.0, 4.0, 4.0, -16.0, -8.0, -30.0, -8.0, 0.0, 14.0, 8.0, -30.0, 0.0, 4.0, -16.0, 8.0, 4.0, 4.0, -4.0, 4.0, -4.0, -16.0, 12.0, 4.0, 0.0, 4.0, 8.0, 14.0, -8.0, 4.0, 0.0, -4.0, 4.0, 10.0, 0.0, 14.0, -30.0, 4.0, 8.0, 8.0, 0.0, 4.0, 8.0, 0.0, -12.0, 0.0, 4.0, -8.0, 4.0], "episode_lengths": [6, 10, 4, 12, 8, 12, 20, 10, 20, 6, 12, 12, 10, 6, 6, 8, 10, 10, 9, 20, 4, 10, 20, 10, 5, 8, 6, 10, 4, 8, 18, 18, 6, 10, 20, 4, 3, 6, 8, 5, 20, 10, 6, 8, 6, 18, 8, 12, 10, 18, 9, 8, 8, 8, 8, 18, 14, 20, 14, 10, 3, 6, 20, 10, 8, 18, 6, 8, 8, 12, 8, 12, 18, 4, 8, 10, 8, 6, 3, 14, 8, 10, 12, 8, 5, 10, 3, 20, 8, 6, 6, 10, 8, 6, 10, 16, 10, 8, 14, 8], "policy_policy0_reward": [4.0, 10.0, 6.0, 8.0, 12.0, 8.0, 0.0, 10.0, -10.0, 14.0, 8.0, -2.0, 10.0, 14.0, 14.0, 2.0, 0.0, 10.0, 11.0, -10.0, 6.0, 10.0, -10.0, 10.0, 5.0, 12.0, 4.0, 10.0, 6.0, 12.0, 2.0, 2.0, 14.0, 10.0, 0.0, 6.0, 7.0, 14.0, 12.0, 5.0, 0.0, 10.0, 14.0, 2.0, 4.0, 2.0, 12.0, 8.0, 10.0, -8.0, 1.0, 12.0, 12.0, 12.0, 2.0, 2.0, 6.0, -20.0, 6.0, 10.0, 7.0, 14.0, -10.0, 0.0, 12.0, 2.0, 14.0, 12.0, 12.0, -2.0, 12.0, 8.0, 2.0, 6.0, 12.0, 10.0, 12.0, 14.0, 7.0, -4.0, 12.0, 10.0, -2.0, 12.0, 5.0, 10.0, 7.0, -10.0, 12.0, 14.0, 14.0, 10.0, 12.0, 14.0, 10.0, -6.0, 10.0, 12.0, 6.0, 12.0], "policy_policy1_reward": [4.0, -10.0, 6.0, -12.0, -8.0, -12.0, -20.0, -10.0, -20.0, -6.0, -12.0, -2.0, -10.0, -6.0, -6.0, 2.0, 0.0, -10.0, -9.0, -20.0, 6.0, -10.0, -20.0, -10.0, 5.0, -8.0, 4.0, -10.0, 6.0, -8.0, -18.0, -18.0, -6.0, -10.0, -20.0, 6.0, 7.0, -6.0, -8.0, 5.0, -20.0, -10.0, -6.0, 2.0, 4.0, -18.0, -8.0, -12.0, -10.0, -8.0, 1.0, -8.0, -8.0, -8.0, 2.0, -18.0, -14.0, -10.0, -14.0, -10.0, 7.0, -6.0, -20.0, 0.0, -8.0, -18.0, -6.0, -8.0, -8.0, -2.0, -8.0, -12.0, -18.0, 6.0, -8.0, -10.0, -8.0, -6.0, 7.0, -4.0, -8.0, -10.0, -2.0, -8.0, 5.0, -10.0, 7.0, -20.0, -8.0, -6.0, -6.0, -10.0, -8.0, -6.0, -10.0, -6.0, -10.0, -8.0, -14.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3309436397395422, "mean_inference_ms": 1.7630205658067153, "mean_action_processing_ms": 0.12059760452750848, "mean_env_wait_ms": 0.0756432040020829, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13491, "timesteps_this_iter": 32, "agent_timesteps_total": 26982, "timers": {"load_time_ms": 0.447, "load_throughput": 71640.1, "learn_time_ms": 7.856, "learn_throughput": 4073.573, "update_time_ms": 4.582}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.5291643142700195, "min_q": 0.9634029269218445, "max_q": 15.178251266479492, "mean_td_error": 0.3439928889274597, "model": {}}, "td_error": [0.1270294189453125, 1.2209205627441406, 0.9984655380249023, -0.12236499786376953, 4.61029577255249, 1.3076691627502441, 0.5905303955078125, 0.9931354522705078, -0.3480954170227051, 0.8350379467010498, -0.5603322982788086, -0.0408167839050293, -0.5474843978881836, 0.1059267520904541, -0.6258753538131714, -1.3841190338134766, -0.6641397476196289, 0.4581618309020996, -0.980687141418457, -0.4040813446044922, -0.292952299118042, 1.274867057800293, 0.3821449279785156, 0.13677406311035156, 2.0420665740966797, 2.073854446411133, 1.5053887367248535, -1.3524599075317383, 1.9004826545715332, -0.4773688316345215, 0.591468334197998, -2.345669746398926], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.051011085510254, "min_q": -13.276844024658203, "max_q": 4.091487884521484, "mean_td_error": -2.267817974090576, "model": {}}, "td_error": [-1.1440412998199463, -10.590044021606445, -0.9277474880218506, 2.382110595703125, 2.9564218521118164, -3.943770408630371, -5.529306411743164, 2.382110595703125, -16.855350494384766, -2.1705856323242188, 0.7003035545349121, -4.908512115478516, 1.6682558059692383, -5.322109699249268, 2.008647918701172, 3.0088138580322266, 5.527435302734375, 0.41390323638916016, -2.650709629058838, -6.1083855628967285, 0.8233809471130371, 1.2271957397460938, -8.255675315856934, -1.294529914855957, 1.2271957397460938, 0.9286994934082031, -3.7742738723754883, -9.229362487792969, -7.312099456787109, 0.9633941650390625, 0.5015368461608887, -9.273077011108398], "custom_metrics": {}}}, "num_steps_sampled": 13491, "num_agent_steps_sampled": 26982, "num_steps_trained": 27552, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 55104, "last_target_update_ts": 13451, "num_target_updates": 115}, "done": false, "episodes_total": 931, "training_iteration": 49, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-22", "timestamp": 1648811722, "time_this_iter_s": 1.0272700786590576, "time_total_s": 59.272162199020386, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 59.272162199020386, "timesteps_since_restore": 1568, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 30.5, "ram_util_percent": 58.4}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": -0.42, "episode_len_mean": 9.96, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 5.94, "policy1": -6.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, 0.0, 10.0, 4.0, 8.0, 0.0, 12.0, 4.0, -16.0, -16.0, 8.0, 0.0, -20.0, 12.0, 14.0, 8.0, 4.0, 10.0, -20.0, 0.0, 8.0, 4.0, 8.0, -16.0, 4.0, -4.0, 0.0, -16.0, 2.0, 4.0, 4.0, 4.0, 4.0, -16.0, -8.0, -30.0, -8.0, 0.0, 14.0, 8.0, -30.0, 0.0, 4.0, -16.0, 8.0, 4.0, 4.0, -4.0, 4.0, -4.0, -16.0, 12.0, 4.0, 0.0, 4.0, 8.0, 14.0, -8.0, 4.0, 0.0, -4.0, 4.0, 10.0, 0.0, 14.0, -30.0, 4.0, 8.0, 8.0, 0.0, 4.0, 8.0, 0.0, -12.0, 0.0, 4.0, -8.0, 4.0, 0.0, 2.0, -30.0, 10.0, 6.0, 8.0, -16.0, 12.0, 0.0, 8.0, -20.0, 4.0, -4.0, -8.0, 4.0, -10.0, -8.0, 8.0, 10.0, 12.0, 2.0, 4.0], "episode_lengths": [20, 10, 5, 8, 6, 10, 4, 8, 18, 18, 6, 10, 20, 4, 3, 6, 8, 5, 20, 10, 6, 8, 6, 18, 8, 12, 10, 18, 9, 8, 8, 8, 8, 18, 14, 20, 14, 10, 3, 6, 20, 10, 8, 18, 6, 8, 8, 12, 8, 12, 18, 4, 8, 10, 8, 6, 3, 14, 8, 10, 12, 8, 5, 10, 3, 20, 8, 6, 6, 10, 8, 6, 10, 16, 10, 8, 14, 8, 10, 9, 20, 5, 7, 6, 18, 4, 10, 6, 20, 8, 12, 14, 8, 15, 14, 6, 5, 4, 9, 8], "policy_policy0_reward": [-10.0, 10.0, 5.0, 12.0, 4.0, 10.0, 6.0, 12.0, 2.0, 2.0, 14.0, 10.0, 0.0, 6.0, 7.0, 14.0, 12.0, 5.0, 0.0, 10.0, 14.0, 2.0, 4.0, 2.0, 12.0, 8.0, 10.0, -8.0, 1.0, 12.0, 12.0, 12.0, 2.0, 2.0, 6.0, -20.0, 6.0, 10.0, 7.0, 14.0, -10.0, 0.0, 12.0, 2.0, 14.0, 12.0, 12.0, -2.0, 12.0, 8.0, 2.0, 6.0, 12.0, 10.0, 12.0, 14.0, 7.0, -4.0, 12.0, 10.0, -2.0, 12.0, 5.0, 10.0, 7.0, -10.0, 12.0, 14.0, 14.0, 10.0, 12.0, 14.0, 10.0, -6.0, 10.0, 12.0, 6.0, 12.0, 10.0, 11.0, -20.0, 5.0, 3.0, 14.0, 2.0, 6.0, 0.0, 4.0, 0.0, 12.0, 8.0, -4.0, 2.0, -5.0, 6.0, 4.0, 5.0, 6.0, 1.0, 2.0], "policy_policy1_reward": [-20.0, -10.0, 5.0, -8.0, 4.0, -10.0, 6.0, -8.0, -18.0, -18.0, -6.0, -10.0, -20.0, 6.0, 7.0, -6.0, -8.0, 5.0, -20.0, -10.0, -6.0, 2.0, 4.0, -18.0, -8.0, -12.0, -10.0, -8.0, 1.0, -8.0, -8.0, -8.0, 2.0, -18.0, -14.0, -10.0, -14.0, -10.0, 7.0, -6.0, -20.0, 0.0, -8.0, -18.0, -6.0, -8.0, -8.0, -2.0, -8.0, -12.0, -18.0, 6.0, -8.0, -10.0, -8.0, -6.0, 7.0, -4.0, -8.0, -10.0, -2.0, -8.0, 5.0, -10.0, 7.0, -20.0, -8.0, -6.0, -6.0, -10.0, -8.0, -6.0, -10.0, -6.0, -10.0, -8.0, -14.0, -8.0, -10.0, -9.0, -10.0, 5.0, 3.0, -6.0, -18.0, 6.0, 0.0, 4.0, -20.0, -8.0, -12.0, -4.0, 2.0, -5.0, -14.0, 4.0, 5.0, 6.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3309691036834831, "mean_inference_ms": 1.7609051626235033, "mean_action_processing_ms": 0.12044153377324023, "mean_env_wait_ms": 0.07558442616746561, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13709, "timesteps_this_iter": 32, "agent_timesteps_total": 27418, "timers": {"load_time_ms": 0.483, "load_throughput": 66280.36, "learn_time_ms": 7.995, "learn_throughput": 4002.354, "update_time_ms": 4.608}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.284371376037598, "min_q": -1.2274658679962158, "max_q": 13.512868881225586, "mean_td_error": 1.2218512296676636, "model": {}}, "td_error": [1.237555980682373, 1.2313117980957031, -2.4333102703094482, 2.111845016479492, 1.9427430629730225, 0.7069168090820312, -0.7475051879882812, -1.5418591499328613, -1.013479232788086, 0.2079305648803711, 9.288822174072266, 2.4264373779296875, 0.7146539688110352, 1.2983436584472656, 0.31305694580078125, 5.026064872741699, -1.297558307647705, -0.6627635955810547, 1.0023384094238281, -0.7105550765991211, 0.13729095458984375, -1.6528115272521973, 2.8771092891693115, 9.499446868896484, 0.96331787109375, 1.656834602355957, -0.7258186340332031, 5.821436882019043, -0.23088407516479492, 0.23596978187561035, 0.9264907240867615, 0.4898664951324463], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -7.6794962882995605, "min_q": -13.986418724060059, "max_q": 5.233236312866211, "mean_td_error": -1.6814948320388794, "model": {}}, "td_error": [-1.1350126266479492, 1.6485891342163086, 0.15234375, -12.2533597946167, -11.571407318115234, -1.3711843490600586, 0.7086887359619141, 1.294215202331543, -13.250922203063965, 0.5671815872192383, -1.8700463771820068, 3.541757583618164, -3.512192726135254, 1.3128366470336914, 0.25978755950927734, -3.3085737228393555, -0.5200362205505371, 1.0487422943115234, 3.702928066253662, -0.6256985664367676, -1.0208168029785156, -6.569022178649902, 6.2959418296813965, 2.041454315185547, 3.0332765579223633, -10.278955459594727, -5.641125679016113, 1.8239717483520508, -6.026904582977295, 0.182847261428833, -0.3425474166870117, -2.124588966369629], "custom_metrics": {}}}, "num_steps_sampled": 13709, "num_agent_steps_sampled": 27418, "num_steps_trained": 28256, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 56512, "last_target_update_ts": 13677, "num_target_updates": 117}, "done": false, "episodes_total": 953, "training_iteration": 50, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-24", "timestamp": 1648811724, "time_this_iter_s": 1.1540000438690186, "time_total_s": 60.426162242889404, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584709e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584709e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 60.426162242889404, "timesteps_since_restore": 1600, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 31.65, "ram_util_percent": 58.4}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 1.08, "episode_len_mean": 9.21, "episode_media": {}, "episodes_this_iter": 28, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 5.49, "policy1": -4.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 4.0, 4.0, 4.0, 4.0, -16.0, -8.0, -30.0, -8.0, 0.0, 14.0, 8.0, -30.0, 0.0, 4.0, -16.0, 8.0, 4.0, 4.0, -4.0, 4.0, -4.0, -16.0, 12.0, 4.0, 0.0, 4.0, 8.0, 14.0, -8.0, 4.0, 0.0, -4.0, 4.0, 10.0, 0.0, 14.0, -30.0, 4.0, 8.0, 8.0, 0.0, 4.0, 8.0, 0.0, -12.0, 0.0, 4.0, -8.0, 4.0, 0.0, 2.0, -30.0, 10.0, 6.0, 8.0, -16.0, 12.0, 0.0, 8.0, -20.0, 4.0, -4.0, -8.0, 4.0, -10.0, -8.0, 8.0, 10.0, 12.0, 2.0, 4.0, 14.0, 14.0, 14.0, 8.0, 14.0, -4.0, 6.0, -30.0, -6.0, 2.0, 14.0, 0.0, -12.0, 4.0, 6.0, 4.0, 14.0, 14.0, -20.0, 4.0, 14.0, -4.0, 14.0, 4.0, 8.0, 14.0, 10.0, 10.0], "episode_lengths": [9, 8, 8, 8, 8, 18, 14, 20, 14, 10, 3, 6, 20, 10, 8, 18, 6, 8, 8, 12, 8, 12, 18, 4, 8, 10, 8, 6, 3, 14, 8, 10, 12, 8, 5, 10, 3, 20, 8, 6, 6, 10, 8, 6, 10, 16, 10, 8, 14, 8, 10, 9, 20, 5, 7, 6, 18, 4, 10, 6, 20, 8, 12, 14, 8, 15, 14, 6, 5, 4, 9, 8, 3, 3, 3, 6, 3, 12, 7, 20, 13, 9, 3, 10, 16, 8, 7, 8, 3, 3, 20, 8, 3, 12, 3, 8, 6, 3, 5, 5], "policy_policy0_reward": [1.0, 12.0, 12.0, 12.0, 2.0, 2.0, 6.0, -20.0, 6.0, 10.0, 7.0, 14.0, -10.0, 0.0, 12.0, 2.0, 14.0, 12.0, 12.0, -2.0, 12.0, 8.0, 2.0, 6.0, 12.0, 10.0, 12.0, 14.0, 7.0, -4.0, 12.0, 10.0, -2.0, 12.0, 5.0, 10.0, 7.0, -10.0, 12.0, 14.0, 14.0, 10.0, 12.0, 14.0, 10.0, -6.0, 10.0, 12.0, 6.0, 12.0, 10.0, 11.0, -20.0, 5.0, 3.0, 14.0, 2.0, 6.0, 0.0, 4.0, 0.0, 12.0, 8.0, -4.0, 2.0, -5.0, 6.0, 4.0, 5.0, 6.0, 1.0, 2.0, 7.0, 7.0, 7.0, 4.0, 7.0, -2.0, 3.0, -20.0, 7.0, 1.0, 7.0, 0.0, 4.0, 12.0, 3.0, 12.0, 7.0, 7.0, -10.0, 12.0, 7.0, 8.0, 7.0, 12.0, 4.0, 7.0, 5.0, 5.0], "policy_policy1_reward": [1.0, -8.0, -8.0, -8.0, 2.0, -18.0, -14.0, -10.0, -14.0, -10.0, 7.0, -6.0, -20.0, 0.0, -8.0, -18.0, -6.0, -8.0, -8.0, -2.0, -8.0, -12.0, -18.0, 6.0, -8.0, -10.0, -8.0, -6.0, 7.0, -4.0, -8.0, -10.0, -2.0, -8.0, 5.0, -10.0, 7.0, -20.0, -8.0, -6.0, -6.0, -10.0, -8.0, -6.0, -10.0, -6.0, -10.0, -8.0, -14.0, -8.0, -10.0, -9.0, -10.0, 5.0, 3.0, -6.0, -18.0, 6.0, 0.0, 4.0, -20.0, -8.0, -12.0, -4.0, 2.0, -5.0, -14.0, 4.0, 5.0, 6.0, 1.0, 2.0, 7.0, 7.0, 7.0, 4.0, 7.0, -2.0, 3.0, -10.0, -13.0, 1.0, 7.0, 0.0, -16.0, -8.0, 3.0, -8.0, 7.0, 7.0, -10.0, -8.0, 7.0, -12.0, 7.0, -8.0, 4.0, 7.0, 5.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33109214186605107, "mean_inference_ms": 1.7582467407445717, "mean_action_processing_ms": 0.12024161144339153, "mean_env_wait_ms": 0.07550176240532251, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13919, "timesteps_this_iter": 32, "agent_timesteps_total": 27838, "timers": {"load_time_ms": 0.435, "load_throughput": 73584.281, "learn_time_ms": 7.737, "learn_throughput": 4135.77, "update_time_ms": 4.707}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.7535481452941895, "min_q": -1.8302381038665771, "max_q": 14.432893753051758, "mean_td_error": 1.148768663406372, "model": {}}, "td_error": [-2.3554325103759766, 0.40812158584594727, 1.3891706466674805, 0.6234917640686035, -1.3150596618652344, 2.724864959716797, -1.9688444137573242, 2.9757795333862305, 0.1331615447998047, -1.1530356407165527, -0.5307683944702148, 11.180980682373047, -2.228445053100586, 1.6896324157714844, -0.5021018981933594, -0.45238637924194336, -0.3903970718383789, 4.0087432861328125, -1.0181159973144531, 7.142200469970703, 1.1277408599853516, -1.3676891326904297, -0.6400165557861328, 0.45583581924438477, 12.465518951416016, 5.493556022644043, 0.2555675506591797, -1.22308349609375, -0.5252323150634766, -1.2217578887939453, 0.8248262405395508, 0.7537698745727539], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -7.0518903732299805, "min_q": -15.26591682434082, "max_q": 7.229909896850586, "mean_td_error": -1.8178911209106445, "model": {}}, "td_error": [2.449540138244629, -0.6441144943237305, 2.2345476150512695, -0.6368446350097656, -0.5246543884277344, 4.125182628631592, -3.7415695190429688, -1.4078397750854492, -16.7607421875, -9.673799514770508, -0.17893409729003906, 0.8960247039794922, -12.014551162719727, 3.895359754562378, 2.2263879776000977, -1.1984527111053467, 2.6964664459228516, -6.528729438781738, 6.923908233642578, -8.335579872131348, -9.706870079040527, 3.2154006958007812, -2.8343429565429688, -0.6193857192993164, 0.7567062377929688, -2.1360697746276855, -12.242939949035645, 1.7758865356445312, -0.44091129302978516, 0.17182493209838867, 0.29121971130371094, -0.20463943481445312], "custom_metrics": {}}}, "num_steps_sampled": 13919, "num_agent_steps_sampled": 27838, "num_steps_trained": 28896, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 57792, "last_target_update_ts": 13889, "num_target_updates": 119}, "done": false, "episodes_total": 981, "training_iteration": 51, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-25", "timestamp": 1648811725, "time_this_iter_s": 1.0221281051635742, "time_total_s": 61.44829034805298, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 61.44829034805298, "timesteps_since_restore": 1632, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 29.9, "ram_util_percent": 58.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 0.92, "episode_len_mean": 9.29, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 5.51, "policy1": -4.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, -4.0, 4.0, -4.0, -16.0, 12.0, 4.0, 0.0, 4.0, 8.0, 14.0, -8.0, 4.0, 0.0, -4.0, 4.0, 10.0, 0.0, 14.0, -30.0, 4.0, 8.0, 8.0, 0.0, 4.0, 8.0, 0.0, -12.0, 0.0, 4.0, -8.0, 4.0, 0.0, 2.0, -30.0, 10.0, 6.0, 8.0, -16.0, 12.0, 0.0, 8.0, -20.0, 4.0, -4.0, -8.0, 4.0, -10.0, -8.0, 8.0, 10.0, 12.0, 2.0, 4.0, 14.0, 14.0, 14.0, 8.0, 14.0, -4.0, 6.0, -30.0, -6.0, 2.0, 14.0, 0.0, -12.0, 4.0, 6.0, 4.0, 14.0, 14.0, -20.0, 4.0, 14.0, -4.0, 14.0, 4.0, 8.0, 14.0, 10.0, 10.0, 2.0, 8.0, -14.0, 8.0, 4.0, -30.0, 0.0, -12.0, 0.0, -30.0, -16.0, 4.0, 4.0, 4.0, -12.0, 0.0, 4.0, 8.0], "episode_lengths": [8, 12, 8, 12, 18, 4, 8, 10, 8, 6, 3, 14, 8, 10, 12, 8, 5, 10, 3, 20, 8, 6, 6, 10, 8, 6, 10, 16, 10, 8, 14, 8, 10, 9, 20, 5, 7, 6, 18, 4, 10, 6, 20, 8, 12, 14, 8, 15, 14, 6, 5, 4, 9, 8, 3, 3, 3, 6, 3, 12, 7, 20, 13, 9, 3, 10, 16, 8, 7, 8, 3, 3, 20, 8, 3, 12, 3, 8, 6, 3, 5, 5, 9, 6, 17, 6, 8, 20, 10, 16, 10, 20, 18, 8, 8, 8, 16, 10, 8, 6], "policy_policy0_reward": [12.0, -2.0, 12.0, 8.0, 2.0, 6.0, 12.0, 10.0, 12.0, 14.0, 7.0, -4.0, 12.0, 10.0, -2.0, 12.0, 5.0, 10.0, 7.0, -10.0, 12.0, 14.0, 14.0, 10.0, 12.0, 14.0, 10.0, -6.0, 10.0, 12.0, 6.0, 12.0, 10.0, 11.0, -20.0, 5.0, 3.0, 14.0, 2.0, 6.0, 0.0, 4.0, 0.0, 12.0, 8.0, -4.0, 2.0, -5.0, 6.0, 4.0, 5.0, 6.0, 1.0, 2.0, 7.0, 7.0, 7.0, 4.0, 7.0, -2.0, 3.0, -20.0, 7.0, 1.0, 7.0, 0.0, 4.0, 12.0, 3.0, 12.0, 7.0, 7.0, -10.0, 12.0, 7.0, 8.0, 7.0, 12.0, 4.0, 7.0, 5.0, 5.0, 1.0, 4.0, 3.0, 4.0, 12.0, -10.0, 10.0, 4.0, 10.0, -20.0, 2.0, 12.0, 12.0, 12.0, 4.0, 10.0, 12.0, 14.0], "policy_policy1_reward": [-8.0, -2.0, -8.0, -12.0, -18.0, 6.0, -8.0, -10.0, -8.0, -6.0, 7.0, -4.0, -8.0, -10.0, -2.0, -8.0, 5.0, -10.0, 7.0, -20.0, -8.0, -6.0, -6.0, -10.0, -8.0, -6.0, -10.0, -6.0, -10.0, -8.0, -14.0, -8.0, -10.0, -9.0, -10.0, 5.0, 3.0, -6.0, -18.0, 6.0, 0.0, 4.0, -20.0, -8.0, -12.0, -4.0, 2.0, -5.0, -14.0, 4.0, 5.0, 6.0, 1.0, 2.0, 7.0, 7.0, 7.0, 4.0, 7.0, -2.0, 3.0, -10.0, -13.0, 1.0, 7.0, 0.0, -16.0, -8.0, 3.0, -8.0, 7.0, 7.0, -10.0, -8.0, 7.0, -12.0, 7.0, -8.0, 4.0, 7.0, 5.0, 5.0, 1.0, 4.0, -17.0, 4.0, -8.0, -20.0, -10.0, -16.0, -10.0, -10.0, -18.0, -8.0, -8.0, -8.0, -16.0, -10.0, -8.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33116147876283003, "mean_inference_ms": 1.7565273782813255, "mean_action_processing_ms": 0.12011397431213411, "mean_env_wait_ms": 0.07545150232300502, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14123, "timesteps_this_iter": 32, "agent_timesteps_total": 28246, "timers": {"load_time_ms": 0.455, "load_throughput": 70293.143, "learn_time_ms": 7.85, "learn_throughput": 4076.469, "update_time_ms": 4.743}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.31645393371582, "min_q": -2.70773983001709, "max_q": 12.17445182800293, "mean_td_error": 0.675859808921814, "model": {}}, "td_error": [0.8027591705322266, 1.0976581573486328, -0.9945392608642578, -0.31914615631103516, 4.287387371063232, -2.3086938858032227, -0.36744165420532227, 6.79958963394165, -0.1794748306274414, -0.8529272079467773, -0.6048765182495117, -1.0550894737243652, -2.7140398025512695, -2.016023635864258, 8.504032135009766, 2.5793275833129883, 5.578429222106934, 0.4013669490814209, -1.068404197692871, -0.28903770446777344, -1.7077398300170898, -1.170283317565918, 0.4943675994873047, 0.663724422454834, -0.10616302490234375, 0.5223903656005859, 0.6904239654541016, 0.6219353675842285, -1.8226513862609863, 0.08874893188476562, 6.424181938171387, -0.3522796630859375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -6.074626445770264, "min_q": -11.359795570373535, "max_q": 8.84091567993164, "mean_td_error": -0.9661130905151367, "model": {}}, "td_error": [-0.8992365598678589, 0.15961360931396484, -4.250922203063965, 2.154690742492676, 1.1893835067749023, -6.337198257446289, -1.653106689453125, -0.30550670623779297, 1.4663591384887695, 1.0825729370117188, -2.0229239463806152, -0.74855637550354, 0.6350054740905762, -0.23215007781982422, 1.6193246841430664, 0.7787446975708008, -0.28624629974365234, -0.9755258560180664, -2.6746418476104736, -13.987545013427734, -3.0696520805358887, 4.030735969543457, 2.2742085456848145, 6.03166389465332, -4.102313995361328, 0.937108039855957, 0.017220497131347656, -4.922031879425049, -3.6421470642089844, -1.5483722686767578, -1.705082893371582, 0.07090902328491211], "custom_metrics": {}}}, "num_steps_sampled": 14123, "num_agent_steps_sampled": 28246, "num_steps_trained": 29472, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 58944, "last_target_update_ts": 14099, "num_target_updates": 121}, "done": false, "episodes_total": 999, "training_iteration": 52, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-26", "timestamp": 1648811726, "time_this_iter_s": 0.9413297176361084, "time_total_s": 62.38962006568909, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa585268c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa585268c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 62.38962006568909, "timesteps_since_restore": 1664, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 29.8, "ram_util_percent": 58.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 0.12, "episode_len_mean": 9.64, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 5.26, "policy1": -5.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 0.0, 4.0, 8.0, 0.0, -12.0, 0.0, 4.0, -8.0, 4.0, 0.0, 2.0, -30.0, 10.0, 6.0, 8.0, -16.0, 12.0, 0.0, 8.0, -20.0, 4.0, -4.0, -8.0, 4.0, -10.0, -8.0, 8.0, 10.0, 12.0, 2.0, 4.0, 14.0, 14.0, 14.0, 8.0, 14.0, -4.0, 6.0, -30.0, -6.0, 2.0, 14.0, 0.0, -12.0, 4.0, 6.0, 4.0, 14.0, 14.0, -20.0, 4.0, 14.0, -4.0, 14.0, 4.0, 8.0, 14.0, 10.0, 10.0, 2.0, 8.0, -14.0, 8.0, 4.0, -30.0, 0.0, -12.0, 0.0, -30.0, -16.0, 4.0, 4.0, 4.0, -12.0, 0.0, 4.0, 8.0, -30.0, 0.0, 0.0, 0.0, 8.0, 4.0, 4.0, -16.0, 4.0, -20.0, 8.0, -4.0, -12.0, -30.0, 10.0, 14.0, -8.0, 14.0, 0.0, 4.0, -10.0], "episode_lengths": [6, 6, 10, 8, 6, 10, 16, 10, 8, 14, 8, 10, 9, 20, 5, 7, 6, 18, 4, 10, 6, 20, 8, 12, 14, 8, 15, 14, 6, 5, 4, 9, 8, 3, 3, 3, 6, 3, 12, 7, 20, 13, 9, 3, 10, 16, 8, 7, 8, 3, 3, 20, 8, 3, 12, 3, 8, 6, 3, 5, 5, 9, 6, 17, 6, 8, 20, 10, 16, 10, 20, 18, 8, 8, 8, 16, 10, 8, 6, 20, 10, 10, 10, 6, 8, 8, 18, 8, 20, 6, 12, 16, 20, 5, 3, 14, 3, 10, 8, 15], "policy_policy0_reward": [14.0, 14.0, 10.0, 12.0, 14.0, 10.0, -6.0, 10.0, 12.0, 6.0, 12.0, 10.0, 11.0, -20.0, 5.0, 3.0, 14.0, 2.0, 6.0, 0.0, 4.0, 0.0, 12.0, 8.0, -4.0, 2.0, -5.0, 6.0, 4.0, 5.0, 6.0, 1.0, 2.0, 7.0, 7.0, 7.0, 4.0, 7.0, -2.0, 3.0, -20.0, 7.0, 1.0, 7.0, 0.0, 4.0, 12.0, 3.0, 12.0, 7.0, 7.0, -10.0, 12.0, 7.0, 8.0, 7.0, 12.0, 4.0, 7.0, 5.0, 5.0, 1.0, 4.0, 3.0, 4.0, 12.0, -10.0, 10.0, 4.0, 10.0, -20.0, 2.0, 12.0, 12.0, 12.0, 4.0, 10.0, 12.0, 14.0, -10.0, 10.0, 10.0, 10.0, 14.0, 12.0, 12.0, 2.0, 12.0, 0.0, 14.0, 8.0, 4.0, -10.0, 5.0, 7.0, 6.0, 7.0, 10.0, 2.0, -5.0], "policy_policy1_reward": [-6.0, -6.0, -10.0, -8.0, -6.0, -10.0, -6.0, -10.0, -8.0, -14.0, -8.0, -10.0, -9.0, -10.0, 5.0, 3.0, -6.0, -18.0, 6.0, 0.0, 4.0, -20.0, -8.0, -12.0, -4.0, 2.0, -5.0, -14.0, 4.0, 5.0, 6.0, 1.0, 2.0, 7.0, 7.0, 7.0, 4.0, 7.0, -2.0, 3.0, -10.0, -13.0, 1.0, 7.0, 0.0, -16.0, -8.0, 3.0, -8.0, 7.0, 7.0, -10.0, -8.0, 7.0, -12.0, 7.0, -8.0, 4.0, 7.0, 5.0, 5.0, 1.0, 4.0, -17.0, 4.0, -8.0, -20.0, -10.0, -16.0, -10.0, -10.0, -18.0, -8.0, -8.0, -8.0, -16.0, -10.0, -8.0, -6.0, -20.0, -10.0, -10.0, -10.0, -6.0, -8.0, -8.0, -18.0, -8.0, -20.0, -6.0, -12.0, -16.0, -20.0, 5.0, 7.0, -14.0, 7.0, -10.0, 2.0, -5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33127028876153664, "mean_inference_ms": 1.7546958271418982, "mean_action_processing_ms": 0.11997754728437002, "mean_env_wait_ms": 0.07541223742160366, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14353, "timesteps_this_iter": 32, "agent_timesteps_total": 28706, "timers": {"load_time_ms": 0.434, "load_throughput": 73685.275, "learn_time_ms": 7.551, "learn_throughput": 4237.995, "update_time_ms": 4.621}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.26466178894043, "min_q": -0.8075684309005737, "max_q": 13.451305389404297, "mean_td_error": 0.24845728278160095, "model": {}}, "td_error": [-0.08364105224609375, -2.1074066162109375, -0.9490623474121094, -0.8863210678100586, -0.8220515251159668, -0.8255105018615723, 0.7611861228942871, 11.015209197998047, -2.6257615089416504, 0.2852058410644531, -1.020195484161377, -0.583531379699707, -2.116641044616699, -0.04822731018066406, -0.9334549903869629, -0.8362817764282227, -0.6368169784545898, -2.764789342880249, 0.3128833770751953, 6.823935031890869, 0.7087600231170654, -0.5780577659606934, 0.9134509563446045, -0.8337106704711914, 0.5603349208831787, 0.1212453842163086, -0.861670970916748, 4.451305389404297, 5.2658538818359375, -1.1032414436340332, 0.11146235466003418, -2.763824462890625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.9385364055633545, "min_q": -10.045741081237793, "max_q": 3.227013111114502, "mean_td_error": -2.1646981239318848, "model": {}}, "td_error": [2.7456207275390625, -0.6636810302734375, -0.9768075942993164, -0.7104244232177734, -13.514728546142578, -2.503772020339966, -1.4687585830688477, -3.903200149536133, 0.23577547073364258, -0.8713274002075195, 0.16438817977905273, -0.5401983261108398, -3.0007567405700684, 0.6913204193115234, -6.53702449798584, 2.195828437805176, -4.120495319366455, 0.16667425632476807, -0.9786171913146973, -4.223270416259766, -5.353628635406494, -2.0085487365722656, -3.271350860595703, -6.067319869995117, 3.0352704524993896, -3.0849804878234863, -4.223270416259766, -1.126457691192627, -4.528879165649414, 5.307221412658691, -6.611259460449219, -3.5236802101135254], "custom_metrics": {}}}, "num_steps_sampled": 14353, "num_agent_steps_sampled": 28706, "num_steps_trained": 30080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 60160, "last_target_update_ts": 14317, "num_target_updates": 123}, "done": false, "episodes_total": 1020, "training_iteration": 53, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-27", "timestamp": 1648811727, "time_this_iter_s": 1.0617096424102783, "time_total_s": 63.451329708099365, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 63.451329708099365, "timesteps_since_restore": 1696, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 31.3, "ram_util_percent": 58.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": -0.78, "episode_len_mean": 10.09, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 5.21, "policy1": -5.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-16.0, 12.0, 0.0, 8.0, -20.0, 4.0, -4.0, -8.0, 4.0, -10.0, -8.0, 8.0, 10.0, 12.0, 2.0, 4.0, 14.0, 14.0, 14.0, 8.0, 14.0, -4.0, 6.0, -30.0, -6.0, 2.0, 14.0, 0.0, -12.0, 4.0, 6.0, 4.0, 14.0, 14.0, -20.0, 4.0, 14.0, -4.0, 14.0, 4.0, 8.0, 14.0, 10.0, 10.0, 2.0, 8.0, -14.0, 8.0, 4.0, -30.0, 0.0, -12.0, 0.0, -30.0, -16.0, 4.0, 4.0, 4.0, -12.0, 0.0, 4.0, 8.0, -30.0, 0.0, 0.0, 0.0, 8.0, 4.0, 4.0, -16.0, 4.0, -20.0, 8.0, -4.0, -12.0, -30.0, 10.0, 14.0, -8.0, 14.0, 0.0, 4.0, -10.0, 4.0, 8.0, -30.0, -8.0, 8.0, -16.0, 0.0, -20.0, 8.0, 0.0, -16.0, 0.0, 2.0, 4.0, 4.0, -18.0, -8.0], "episode_lengths": [18, 4, 10, 6, 20, 8, 12, 14, 8, 15, 14, 6, 5, 4, 9, 8, 3, 3, 3, 6, 3, 12, 7, 20, 13, 9, 3, 10, 16, 8, 7, 8, 3, 3, 20, 8, 3, 12, 3, 8, 6, 3, 5, 5, 9, 6, 17, 6, 8, 20, 10, 16, 10, 20, 18, 8, 8, 8, 16, 10, 8, 6, 20, 10, 10, 10, 6, 8, 8, 18, 8, 20, 6, 12, 16, 20, 5, 3, 14, 3, 10, 8, 15, 8, 6, 20, 14, 6, 18, 10, 20, 6, 10, 18, 10, 9, 8, 8, 19, 14], "policy_policy0_reward": [2.0, 6.0, 0.0, 4.0, 0.0, 12.0, 8.0, -4.0, 2.0, -5.0, 6.0, 4.0, 5.0, 6.0, 1.0, 2.0, 7.0, 7.0, 7.0, 4.0, 7.0, -2.0, 3.0, -20.0, 7.0, 1.0, 7.0, 0.0, 4.0, 12.0, 3.0, 12.0, 7.0, 7.0, -10.0, 12.0, 7.0, 8.0, 7.0, 12.0, 4.0, 7.0, 5.0, 5.0, 1.0, 4.0, 3.0, 4.0, 12.0, -10.0, 10.0, 4.0, 10.0, -20.0, 2.0, 12.0, 12.0, 12.0, 4.0, 10.0, 12.0, 14.0, -10.0, 10.0, 10.0, 10.0, 14.0, 12.0, 12.0, 2.0, 12.0, 0.0, 14.0, 8.0, 4.0, -10.0, 5.0, 7.0, 6.0, 7.0, 10.0, 2.0, -5.0, 12.0, 14.0, -10.0, 6.0, 14.0, 2.0, 10.0, 0.0, 14.0, 10.0, 2.0, 10.0, 11.0, 12.0, 12.0, 1.0, 6.0], "policy_policy1_reward": [-18.0, 6.0, 0.0, 4.0, -20.0, -8.0, -12.0, -4.0, 2.0, -5.0, -14.0, 4.0, 5.0, 6.0, 1.0, 2.0, 7.0, 7.0, 7.0, 4.0, 7.0, -2.0, 3.0, -10.0, -13.0, 1.0, 7.0, 0.0, -16.0, -8.0, 3.0, -8.0, 7.0, 7.0, -10.0, -8.0, 7.0, -12.0, 7.0, -8.0, 4.0, 7.0, 5.0, 5.0, 1.0, 4.0, -17.0, 4.0, -8.0, -20.0, -10.0, -16.0, -10.0, -10.0, -18.0, -8.0, -8.0, -8.0, -16.0, -10.0, -8.0, -6.0, -20.0, -10.0, -10.0, -10.0, -6.0, -8.0, -8.0, -18.0, -8.0, -20.0, -6.0, -12.0, -16.0, -20.0, 5.0, 7.0, -14.0, 7.0, -10.0, 2.0, -5.0, -8.0, -6.0, -20.0, -14.0, -6.0, -18.0, -10.0, -20.0, -6.0, -10.0, -18.0, -10.0, -9.0, -8.0, -8.0, -19.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3313340577492724, "mean_inference_ms": 1.7533748344996034, "mean_action_processing_ms": 0.11987414463355844, "mean_env_wait_ms": 0.07538907403261019, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14557, "timesteps_this_iter": 32, "agent_timesteps_total": 29114, "timers": {"load_time_ms": 0.524, "load_throughput": 61030.251, "learn_time_ms": 8.154, "learn_throughput": 3924.644, "update_time_ms": 4.819}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.5388665199279785, "min_q": -1.331466555595398, "max_q": 14.14055347442627, "mean_td_error": 0.20391789078712463, "model": {}}, "td_error": [-1.504687786102295, -0.5662970542907715, 6.087552070617676, 0.7807555198669434, 0.4012875556945801, -0.4793415069580078, -0.9764714241027832, 0.1790637969970703, 1.2207088470458984, 0.5005707740783691, -2.62746000289917, -0.5492770671844482, -1.1657969951629639, -0.5799427032470703, 0.5136623382568359, 0.5338077545166016, -0.5849752426147461, 0.024053573608398438, 0.005301475524902344, 1.3314199447631836, 0.13861656188964844, -0.5664267539978027, -0.4515092372894287, 6.0060906410217285, 0.157391756772995, -0.8577718734741211, -0.6580700874328613, 1.5665926933288574, 0.1334400177001953, -0.21520423889160156, -0.9575309753417969, -0.3141803741455078], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.654634475708008, "min_q": -7.982483863830566, "max_q": 5.1391987800598145, "mean_td_error": -0.21128398180007935, "model": {}}, "td_error": [10.775260925292969, -1.2281970977783203, 4.0147385597229, -4.045473098754883, 10.131534576416016, 5.279867172241211, -1.151216983795166, 2.980781078338623, 0.4384285807609558, -4.092340469360352, -3.9043307304382324, -9.629178047180176, 0.15039682388305664, 1.1802520751953125, -3.8608012199401855, -1.9942359924316406, 0.016067981719970703, -0.812995433807373, 0.6991255283355713, -1.8875480890274048, -0.9123402833938599, 4.650346279144287, -15.128993034362793, -5.380939483642578, 2.003417491912842, 0.3373689651489258, 1.3882126808166504, 2.1260323524475098, 0.13777732849121094, -0.5555696487426758, 1.961435317993164, -0.44797277450561523], "custom_metrics": {}}}, "num_steps_sampled": 14557, "num_agent_steps_sampled": 29114, "num_steps_trained": 30624, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 61248, "last_target_update_ts": 14543, "num_target_updates": 125}, "done": false, "episodes_total": 1037, "training_iteration": 54, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-28", "timestamp": 1648811728, "time_this_iter_s": 0.9711275100708008, "time_total_s": 64.42245721817017, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 64.42245721817017, "timesteps_since_restore": 1728, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 30.049999999999997, "ram_util_percent": 58.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": -0.58, "episode_len_mean": 9.99, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 6.11, "policy1": -6.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.0, 2.0, 14.0, 0.0, -12.0, 4.0, 6.0, 4.0, 14.0, 14.0, -20.0, 4.0, 14.0, -4.0, 14.0, 4.0, 8.0, 14.0, 10.0, 10.0, 2.0, 8.0, -14.0, 8.0, 4.0, -30.0, 0.0, -12.0, 0.0, -30.0, -16.0, 4.0, 4.0, 4.0, -12.0, 0.0, 4.0, 8.0, -30.0, 0.0, 0.0, 0.0, 8.0, 4.0, 4.0, -16.0, 4.0, -20.0, 8.0, -4.0, -12.0, -30.0, 10.0, 14.0, -8.0, 14.0, 0.0, 4.0, -10.0, 4.0, 8.0, -30.0, -8.0, 8.0, -16.0, 0.0, -20.0, 8.0, 0.0, -16.0, 0.0, 2.0, 4.0, 4.0, -18.0, -8.0, 8.0, -30.0, 4.0, -4.0, 8.0, 12.0, 14.0, 6.0, 4.0, -14.0, 14.0, 0.0, 10.0, -6.0, 8.0, 4.0, 10.0, -8.0, 0.0, 4.0, 4.0, 4.0, -8.0, 10.0], "episode_lengths": [13, 9, 3, 10, 16, 8, 7, 8, 3, 3, 20, 8, 3, 12, 3, 8, 6, 3, 5, 5, 9, 6, 17, 6, 8, 20, 10, 16, 10, 20, 18, 8, 8, 8, 16, 10, 8, 6, 20, 10, 10, 10, 6, 8, 8, 18, 8, 20, 6, 12, 16, 20, 5, 3, 14, 3, 10, 8, 15, 8, 6, 20, 14, 6, 18, 10, 20, 6, 10, 18, 10, 9, 8, 8, 19, 14, 6, 20, 8, 12, 6, 4, 3, 7, 8, 17, 3, 10, 5, 13, 6, 8, 5, 14, 10, 8, 8, 8, 14, 5], "policy_policy0_reward": [7.0, 1.0, 7.0, 0.0, 4.0, 12.0, 3.0, 12.0, 7.0, 7.0, -10.0, 12.0, 7.0, 8.0, 7.0, 12.0, 4.0, 7.0, 5.0, 5.0, 1.0, 4.0, 3.0, 4.0, 12.0, -10.0, 10.0, 4.0, 10.0, -20.0, 2.0, 12.0, 12.0, 12.0, 4.0, 10.0, 12.0, 14.0, -10.0, 10.0, 10.0, 10.0, 14.0, 12.0, 12.0, 2.0, 12.0, 0.0, 14.0, 8.0, 4.0, -10.0, 5.0, 7.0, 6.0, 7.0, 10.0, 2.0, -5.0, 12.0, 14.0, -10.0, 6.0, 14.0, 2.0, 10.0, 0.0, 14.0, 10.0, 2.0, 10.0, 11.0, 12.0, 12.0, 1.0, 6.0, 14.0, -20.0, 12.0, 8.0, 14.0, 6.0, 7.0, 3.0, 12.0, 3.0, 7.0, 0.0, 5.0, -3.0, 4.0, 12.0, 5.0, 6.0, 10.0, 12.0, 12.0, 12.0, 6.0, 5.0], "policy_policy1_reward": [-13.0, 1.0, 7.0, 0.0, -16.0, -8.0, 3.0, -8.0, 7.0, 7.0, -10.0, -8.0, 7.0, -12.0, 7.0, -8.0, 4.0, 7.0, 5.0, 5.0, 1.0, 4.0, -17.0, 4.0, -8.0, -20.0, -10.0, -16.0, -10.0, -10.0, -18.0, -8.0, -8.0, -8.0, -16.0, -10.0, -8.0, -6.0, -20.0, -10.0, -10.0, -10.0, -6.0, -8.0, -8.0, -18.0, -8.0, -20.0, -6.0, -12.0, -16.0, -20.0, 5.0, 7.0, -14.0, 7.0, -10.0, 2.0, -5.0, -8.0, -6.0, -20.0, -14.0, -6.0, -18.0, -10.0, -20.0, -6.0, -10.0, -18.0, -10.0, -9.0, -8.0, -8.0, -19.0, -14.0, -6.0, -10.0, -8.0, -12.0, -6.0, 6.0, 7.0, 3.0, -8.0, -17.0, 7.0, 0.0, 5.0, -3.0, 4.0, -8.0, 5.0, -14.0, -10.0, -8.0, -8.0, -8.0, -14.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33143744644017287, "mean_inference_ms": 1.751922821293606, "mean_action_processing_ms": 0.11975285972428418, "mean_env_wait_ms": 0.07536645494493244, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14765, "timesteps_this_iter": 32, "agent_timesteps_total": 29530, "timers": {"load_time_ms": 0.42, "load_throughput": 76229.754, "learn_time_ms": 7.923, "learn_throughput": 4038.664, "update_time_ms": 4.857}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.535630226135254, "min_q": -1.3753023147583008, "max_q": 13.685543060302734, "mean_td_error": 0.8909091949462891, "model": {}}, "td_error": [-0.09786033630371094, -0.7353057861328125, -0.1412191390991211, 5.356428146362305, -0.4499082565307617, 0.5708370208740234, 1.428201675415039, 0.7575349807739258, 0.32483720779418945, -0.15955686569213867, 3.8455448150634766, 0.1857445240020752, -0.5105712413787842, -0.9859304428100586, 1.6364526748657227, 0.5220139026641846, -0.6518516540527344, -0.5672359466552734, -0.07272768020629883, 0.3306010961532593, -0.21584463119506836, 1.7518171072006226, -0.23105573654174805, 10.303390502929688, 4.629121780395508, -0.1701192855834961, 6.041361331939697, -0.1701192855834961, 0.8159970045089722, -1.0242557525634766, -2.8415794372558594, -0.9656476974487305], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.741023302078247, "min_q": -9.368083953857422, "max_q": 5.768223285675049, "mean_td_error": -0.4983959197998047, "model": {}}, "td_error": [2.1133174896240234, 4.643594741821289, -0.2989468574523926, 2.6443920135498047, -13.942261695861816, -3.5686988830566406, 2.0639123916625977, -1.7157971858978271, 0.9745583534240723, 2.7951416969299316, 2.4279675483703613, -0.21184015274047852, 2.4670729637145996, -1.9268429279327393, -0.1038656234741211, -0.2863945960998535, -3.231776714324951, 2.135378122329712, 3.8413844108581543, 7.538482666015625, -2.4474058151245117, 2.7951416969299316, 2.769012928009033, 0.2727358341217041, -13.942261695861816, 0.589972734451294, 0.5209932327270508, -0.7579774856567383, 1.31052827835083, -16.404325485229492, -0.16025209426879883, 1.146390438079834], "custom_metrics": {}}}, "num_steps_sampled": 14765, "num_agent_steps_sampled": 29530, "num_steps_trained": 31328, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 62656, "last_target_update_ts": 14760, "num_target_updates": 127}, "done": false, "episodes_total": 1061, "training_iteration": 55, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-29", "timestamp": 1648811729, "time_this_iter_s": 1.1465449333190918, "time_total_s": 65.56900215148926, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 65.56900215148926, "timesteps_since_restore": 1760, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 31.75, "ram_util_percent": 58.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": -0.8, "episode_len_mean": 10.1, "episode_media": {}, "episodes_this_iter": 25, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 7.1, "policy1": -7.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, 0.0, -12.0, 0.0, -30.0, -16.0, 4.0, 4.0, 4.0, -12.0, 0.0, 4.0, 8.0, -30.0, 0.0, 0.0, 0.0, 8.0, 4.0, 4.0, -16.0, 4.0, -20.0, 8.0, -4.0, -12.0, -30.0, 10.0, 14.0, -8.0, 14.0, 0.0, 4.0, -10.0, 4.0, 8.0, -30.0, -8.0, 8.0, -16.0, 0.0, -20.0, 8.0, 0.0, -16.0, 0.0, 2.0, 4.0, 4.0, -18.0, -8.0, 8.0, -30.0, 4.0, -4.0, 8.0, 12.0, 14.0, 6.0, 4.0, -14.0, 14.0, 0.0, 10.0, -6.0, 8.0, 4.0, 10.0, -8.0, 0.0, 4.0, 4.0, 4.0, -8.0, 10.0, 8.0, 4.0, 0.0, 8.0, 8.0, -14.0, 4.0, 4.0, 0.0, 4.0, 10.0, 10.0, 14.0, 8.0, 0.0, 4.0, 4.0, 4.0, 0.0, -4.0, -16.0, -4.0, 8.0, 8.0, 8.0], "episode_lengths": [20, 10, 16, 10, 20, 18, 8, 8, 8, 16, 10, 8, 6, 20, 10, 10, 10, 6, 8, 8, 18, 8, 20, 6, 12, 16, 20, 5, 3, 14, 3, 10, 8, 15, 8, 6, 20, 14, 6, 18, 10, 20, 6, 10, 18, 10, 9, 8, 8, 19, 14, 6, 20, 8, 12, 6, 4, 3, 7, 8, 17, 3, 10, 5, 13, 6, 8, 5, 14, 10, 8, 8, 8, 14, 5, 6, 8, 10, 6, 6, 17, 8, 8, 10, 8, 5, 5, 3, 6, 10, 8, 8, 8, 10, 12, 18, 12, 6, 6, 6], "policy_policy0_reward": [-10.0, 10.0, 4.0, 10.0, -20.0, 2.0, 12.0, 12.0, 12.0, 4.0, 10.0, 12.0, 14.0, -10.0, 10.0, 10.0, 10.0, 14.0, 12.0, 12.0, 2.0, 12.0, 0.0, 14.0, 8.0, 4.0, -10.0, 5.0, 7.0, 6.0, 7.0, 10.0, 2.0, -5.0, 12.0, 14.0, -10.0, 6.0, 14.0, 2.0, 10.0, 0.0, 14.0, 10.0, 2.0, 10.0, 11.0, 12.0, 12.0, 1.0, 6.0, 14.0, -20.0, 12.0, 8.0, 14.0, 6.0, 7.0, 3.0, 12.0, 3.0, 7.0, 0.0, 5.0, -3.0, 4.0, 12.0, 5.0, 6.0, 10.0, 12.0, 12.0, 12.0, 6.0, 5.0, 14.0, 12.0, 0.0, 14.0, 14.0, 3.0, 12.0, 12.0, 10.0, 12.0, 5.0, 5.0, 7.0, 14.0, 10.0, 12.0, 12.0, 2.0, 10.0, 8.0, 2.0, 8.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-20.0, -10.0, -16.0, -10.0, -10.0, -18.0, -8.0, -8.0, -8.0, -16.0, -10.0, -8.0, -6.0, -20.0, -10.0, -10.0, -10.0, -6.0, -8.0, -8.0, -18.0, -8.0, -20.0, -6.0, -12.0, -16.0, -20.0, 5.0, 7.0, -14.0, 7.0, -10.0, 2.0, -5.0, -8.0, -6.0, -20.0, -14.0, -6.0, -18.0, -10.0, -20.0, -6.0, -10.0, -18.0, -10.0, -9.0, -8.0, -8.0, -19.0, -14.0, -6.0, -10.0, -8.0, -12.0, -6.0, 6.0, 7.0, 3.0, -8.0, -17.0, 7.0, 0.0, 5.0, -3.0, 4.0, -8.0, 5.0, -14.0, -10.0, -8.0, -8.0, -8.0, -14.0, 5.0, -6.0, -8.0, 0.0, -6.0, -6.0, -17.0, -8.0, -8.0, -10.0, -8.0, 5.0, 5.0, 7.0, -6.0, -10.0, -8.0, -8.0, 2.0, -10.0, -12.0, -18.0, -12.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3316515683472227, "mean_inference_ms": 1.7507173072012807, "mean_action_processing_ms": 0.1196512727144243, "mean_env_wait_ms": 0.07536734454129232, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14975, "timesteps_this_iter": 32, "agent_timesteps_total": 29950, "timers": {"load_time_ms": 0.453, "load_throughput": 70592.609, "learn_time_ms": 7.773, "learn_throughput": 4116.856, "update_time_ms": 4.925}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.8009748458862305, "min_q": -0.36685919761657715, "max_q": 13.337352752685547, "mean_td_error": 0.7368068099021912, "model": {}}, "td_error": [0.203200101852417, 4.276483535766602, 0.14914798736572266, 7.763835430145264, -0.20978641510009766, 2.1180500984191895, -2.3036346435546875, 6.204075813293457, -0.7479844093322754, -0.6872758865356445, -1.0688223838806152, 0.9979205131530762, 0.3211245536804199, -0.603114128112793, -0.603114128112793, 0.2720808982849121, -1.4579839706420898, -0.8346893787384033, -2.567455291748047, 0.022182464599609375, -0.026288986206054688, -0.5089712142944336, -0.21958017349243164, 0.9752063155174255, 6.592074871063232, 4.688035011291504, -0.45243406295776367, 0.05268096923828125, -1.394139051437378, -0.12195342779159546, 4.339923858642578, -1.590977668762207], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.330746650695801, "min_q": -7.792840480804443, "max_q": 4.005911827087402, "mean_td_error": -0.2034379541873932, "model": {}}, "td_error": [-4.1648430824279785, 1.470977783203125, 0.8378419876098633, 4.9751811027526855, 2.112299919128418, 0.6177031397819519, 1.5689406394958496, -1.467270851135254, -0.16045475006103516, -0.9115848541259766, -0.672473669052124, -3.5605363845825195, 1.0796866416931152, 3.336291790008545, 0.8097043037414551, -3.9856762886047363, 1.4736123085021973, 0.6664557456970215, 3.161149740219116, 0.7256131172180176, -0.754737377166748, -0.8979384899139404, -0.9484424591064453, -0.19766974449157715, -2.6224727630615234, -4.103310585021973, 2.683595895767212, -0.1393136978149414, -5.391824722290039, -3.762144088745117, 1.7640910148620605, -0.05246543884277344], "custom_metrics": {}}}, "num_steps_sampled": 14975, "num_agent_steps_sampled": 29950, "num_steps_trained": 32096, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64192, "last_target_update_ts": 14963, "num_target_updates": 129}, "done": false, "episodes_total": 1086, "training_iteration": 56, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-30", "timestamp": 1648811730, "time_this_iter_s": 1.1734795570373535, "time_total_s": 66.74248170852661, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 66.74248170852661, "timesteps_since_restore": 1792, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 29.3, "ram_util_percent": 58.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 1.2, "episode_len_mean": 9.25, "episode_media": {}, "episodes_this_iter": 25, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 7.15, "policy1": -5.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.0, -30.0, 10.0, 14.0, -8.0, 14.0, 0.0, 4.0, -10.0, 4.0, 8.0, -30.0, -8.0, 8.0, -16.0, 0.0, -20.0, 8.0, 0.0, -16.0, 0.0, 2.0, 4.0, 4.0, -18.0, -8.0, 8.0, -30.0, 4.0, -4.0, 8.0, 12.0, 14.0, 6.0, 4.0, -14.0, 14.0, 0.0, 10.0, -6.0, 8.0, 4.0, 10.0, -8.0, 0.0, 4.0, 4.0, 4.0, -8.0, 10.0, 8.0, 4.0, 0.0, 8.0, 8.0, -14.0, 4.0, 4.0, 0.0, 4.0, 10.0, 10.0, 14.0, 8.0, 0.0, 4.0, 4.0, 4.0, 0.0, -4.0, -16.0, -4.0, 8.0, 8.0, 8.0, 8.0, 6.0, -2.0, -14.0, 8.0, 8.0, 12.0, -4.0, 8.0, 6.0, -14.0, 6.0, 8.0, 4.0, 0.0, 14.0, 8.0, 8.0, 8.0, 4.0, 10.0, -16.0, -4.0, 10.0, 0.0], "episode_lengths": [16, 20, 5, 3, 14, 3, 10, 8, 15, 8, 6, 20, 14, 6, 18, 10, 20, 6, 10, 18, 10, 9, 8, 8, 19, 14, 6, 20, 8, 12, 6, 4, 3, 7, 8, 17, 3, 10, 5, 13, 6, 8, 5, 14, 10, 8, 8, 8, 14, 5, 6, 8, 10, 6, 6, 17, 8, 8, 10, 8, 5, 5, 3, 6, 10, 8, 8, 8, 10, 12, 18, 12, 6, 6, 6, 6, 7, 11, 17, 6, 6, 4, 12, 6, 7, 17, 7, 6, 8, 10, 3, 6, 6, 6, 8, 5, 18, 12, 5, 10], "policy_policy0_reward": [4.0, -10.0, 5.0, 7.0, 6.0, 7.0, 10.0, 2.0, -5.0, 12.0, 14.0, -10.0, 6.0, 14.0, 2.0, 10.0, 0.0, 14.0, 10.0, 2.0, 10.0, 11.0, 12.0, 12.0, 1.0, 6.0, 14.0, -20.0, 12.0, 8.0, 14.0, 6.0, 7.0, 3.0, 12.0, 3.0, 7.0, 0.0, 5.0, -3.0, 4.0, 12.0, 5.0, 6.0, 10.0, 12.0, 12.0, 12.0, 6.0, 5.0, 14.0, 12.0, 0.0, 14.0, 14.0, 3.0, 12.0, 12.0, 10.0, 12.0, 5.0, 5.0, 7.0, 14.0, 10.0, 12.0, 12.0, 2.0, 10.0, 8.0, 2.0, 8.0, 14.0, 14.0, 14.0, 4.0, 3.0, -1.0, 3.0, 4.0, 14.0, 6.0, 8.0, 14.0, 3.0, 3.0, 3.0, 14.0, 2.0, 10.0, 7.0, 14.0, 14.0, 14.0, 12.0, 5.0, -8.0, 8.0, 5.0, 10.0], "policy_policy1_reward": [-16.0, -20.0, 5.0, 7.0, -14.0, 7.0, -10.0, 2.0, -5.0, -8.0, -6.0, -20.0, -14.0, -6.0, -18.0, -10.0, -20.0, -6.0, -10.0, -18.0, -10.0, -9.0, -8.0, -8.0, -19.0, -14.0, -6.0, -10.0, -8.0, -12.0, -6.0, 6.0, 7.0, 3.0, -8.0, -17.0, 7.0, 0.0, 5.0, -3.0, 4.0, -8.0, 5.0, -14.0, -10.0, -8.0, -8.0, -8.0, -14.0, 5.0, -6.0, -8.0, 0.0, -6.0, -6.0, -17.0, -8.0, -8.0, -10.0, -8.0, 5.0, 5.0, 7.0, -6.0, -10.0, -8.0, -8.0, 2.0, -10.0, -12.0, -18.0, -12.0, -6.0, -6.0, -6.0, 4.0, 3.0, -1.0, -17.0, 4.0, -6.0, 6.0, -12.0, -6.0, 3.0, -17.0, 3.0, -6.0, 2.0, -10.0, 7.0, -6.0, -6.0, -6.0, -8.0, 5.0, -8.0, -12.0, 5.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3319891064659592, "mean_inference_ms": 1.7501223422397434, "mean_action_processing_ms": 0.11959397061266383, "mean_env_wait_ms": 0.07538228263964104, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15184, "timesteps_this_iter": 32, "agent_timesteps_total": 30368, "timers": {"load_time_ms": 0.47, "load_throughput": 68013.443, "learn_time_ms": 8.35, "learn_throughput": 3832.504, "update_time_ms": 5.084}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.972496032714844, "min_q": -2.601299285888672, "max_q": 12.88165283203125, "mean_td_error": -0.029360823333263397, "model": {}}, "td_error": [-1.3464823961257935, -0.0336151123046875, 0.3998924493789673, -1.5169305801391602, -0.2321157455444336, -0.7657890319824219, 0.1206207275390625, -0.5347709655761719, -0.43324756622314453, 0.5218734741210938, 5.7662153244018555, -0.47664451599121094, -1.426020622253418, 0.08250164985656738, -0.60577392578125, -2.372321128845215, 6.23094367980957, -0.0336151123046875, -0.7993717193603516, -0.3188819885253906, -1.9807045459747314, -0.10661149024963379, -0.7915923595428467, 1.9506354331970215, -0.4881401062011719, -1.2723512649536133, -1.6012992858886719, 0.5705520510673523, -0.22293996810913086, 1.1189923286437988, -0.29024410247802734, -0.05230998992919922], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.0472495555877686, "min_q": -9.292516708374023, "max_q": 6.587960243225098, "mean_td_error": -0.34052541851997375, "model": {}}, "td_error": [-0.1989254355430603, 0.21117401123046875, 0.05737018585205078, -1.5310091972351074, 0.966747522354126, -7.3423919677734375, -2.8785500526428223, -1.209869384765625, -2.555112361907959, 1.0154097080230713, -6.156528949737549, 1.4044156074523926, -0.446871280670166, 5.95524263381958, 0.6521835327148438, -1.86124849319458, 0.09166347980499268, -0.20293402671813965, -2.4120397567749023, 1.5641040802001953, 0.636418342590332, 4.1521430015563965, -1.968994379043579, 8.325675010681152, 0.48547792434692383, 2.703646421432495, 0.08850765228271484, -2.8709869384765625, -1.4492225646972656, -7.597753047943115, 1.5491127967834473, -0.07366657257080078], "custom_metrics": {}}}, "num_steps_sampled": 15184, "num_agent_steps_sampled": 30368, "num_steps_trained": 32864, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 65728, "last_target_update_ts": 15184, "num_target_updates": 131}, "done": false, "episodes_total": 1111, "training_iteration": 57, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-31", "timestamp": 1648811731, "time_this_iter_s": 1.1796669960021973, "time_total_s": 67.92214870452881, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 67.92214870452881, "timesteps_since_restore": 1824, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 31.25, "ram_util_percent": 58.650000000000006}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 2.38, "episode_len_mean": 8.76, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"policy0": -20.0, "policy1": -19.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 7.54, "policy1": -5.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, -18.0, -8.0, 8.0, -30.0, 4.0, -4.0, 8.0, 12.0, 14.0, 6.0, 4.0, -14.0, 14.0, 0.0, 10.0, -6.0, 8.0, 4.0, 10.0, -8.0, 0.0, 4.0, 4.0, 4.0, -8.0, 10.0, 8.0, 4.0, 0.0, 8.0, 8.0, -14.0, 4.0, 4.0, 0.0, 4.0, 10.0, 10.0, 14.0, 8.0, 0.0, 4.0, 4.0, 4.0, 0.0, -4.0, -16.0, -4.0, 8.0, 8.0, 8.0, 8.0, 6.0, -2.0, -14.0, 8.0, 8.0, 12.0, -4.0, 8.0, 6.0, -14.0, 6.0, 8.0, 4.0, 0.0, 14.0, 8.0, 8.0, 8.0, 4.0, 10.0, -16.0, -4.0, 10.0, 0.0, 8.0, 10.0, -8.0, 4.0, 0.0, -12.0, 0.0, 14.0, 14.0, -4.0, 8.0, -4.0, -14.0, 4.0, 8.0, 0.0, 6.0, -8.0, 8.0, 0.0, -6.0, 8.0, 8.0], "episode_lengths": [8, 19, 14, 6, 20, 8, 12, 6, 4, 3, 7, 8, 17, 3, 10, 5, 13, 6, 8, 5, 14, 10, 8, 8, 8, 14, 5, 6, 8, 10, 6, 6, 17, 8, 8, 10, 8, 5, 5, 3, 6, 10, 8, 8, 8, 10, 12, 18, 12, 6, 6, 6, 6, 7, 11, 17, 6, 6, 4, 12, 6, 7, 17, 7, 6, 8, 10, 3, 6, 6, 6, 8, 5, 18, 12, 5, 10, 6, 5, 14, 8, 10, 16, 10, 3, 3, 12, 6, 12, 17, 8, 6, 10, 7, 14, 6, 10, 13, 6, 6], "policy_policy0_reward": [12.0, 1.0, 6.0, 14.0, -20.0, 12.0, 8.0, 14.0, 6.0, 7.0, 3.0, 12.0, 3.0, 7.0, 0.0, 5.0, -3.0, 4.0, 12.0, 5.0, 6.0, 10.0, 12.0, 12.0, 12.0, 6.0, 5.0, 14.0, 12.0, 0.0, 14.0, 14.0, 3.0, 12.0, 12.0, 10.0, 12.0, 5.0, 5.0, 7.0, 14.0, 10.0, 12.0, 12.0, 2.0, 10.0, 8.0, 2.0, 8.0, 14.0, 14.0, 14.0, 4.0, 3.0, -1.0, 3.0, 4.0, 14.0, 6.0, 8.0, 14.0, 3.0, 3.0, 3.0, 14.0, 2.0, 10.0, 7.0, 14.0, 14.0, 14.0, 12.0, 5.0, -8.0, 8.0, 5.0, 10.0, 14.0, 5.0, 6.0, 12.0, 10.0, 4.0, 10.0, 7.0, 7.0, 8.0, 14.0, 8.0, -7.0, 12.0, 14.0, 10.0, 3.0, 6.0, 14.0, 0.0, 7.0, 4.0, 4.0], "policy_policy1_reward": [-8.0, -19.0, -14.0, -6.0, -10.0, -8.0, -12.0, -6.0, 6.0, 7.0, 3.0, -8.0, -17.0, 7.0, 0.0, 5.0, -3.0, 4.0, -8.0, 5.0, -14.0, -10.0, -8.0, -8.0, -8.0, -14.0, 5.0, -6.0, -8.0, 0.0, -6.0, -6.0, -17.0, -8.0, -8.0, -10.0, -8.0, 5.0, 5.0, 7.0, -6.0, -10.0, -8.0, -8.0, 2.0, -10.0, -12.0, -18.0, -12.0, -6.0, -6.0, -6.0, 4.0, 3.0, -1.0, -17.0, 4.0, -6.0, 6.0, -12.0, -6.0, 3.0, -17.0, 3.0, -6.0, 2.0, -10.0, 7.0, -6.0, -6.0, -6.0, -8.0, 5.0, -8.0, -12.0, 5.0, -10.0, -6.0, 5.0, -14.0, -8.0, -10.0, -16.0, -10.0, 7.0, 7.0, -12.0, -6.0, -12.0, -7.0, -8.0, -6.0, -10.0, 3.0, -14.0, -6.0, 0.0, -13.0, 4.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3323489694559006, "mean_inference_ms": 1.7496004683426836, "mean_action_processing_ms": 0.11954532663820026, "mean_env_wait_ms": 0.0753833842382875, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15392, "timesteps_this_iter": 32, "agent_timesteps_total": 30784, "timers": {"load_time_ms": 0.451, "load_throughput": 70999.645, "learn_time_ms": 7.631, "learn_throughput": 4193.544, "update_time_ms": 4.736}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.355534553527832, "min_q": -1.0696001052856445, "max_q": 11.78109073638916, "mean_td_error": -0.40605756640434265, "model": {}}, "td_error": [-1.33217191696167, -0.16899633407592773, 1.3426156044006348, -0.901154637336731, -0.5345883369445801, -0.3209800720214844, -2.3497822284698486, -0.14702177047729492, -1.019516944885254, -0.056647300720214844, -0.33858680725097656, -0.019926786422729492, -0.7521820068359375, 0.3982577323913574, -0.3391761779785156, -0.0742499828338623, -0.7565240263938904, 0.08790946006774902, -1.2359929084777832, 0.7668838500976562, 0.3606076240539551, 3.410536289215088, 0.09833216667175293, -1.2489099502563477, -0.9468941688537598, 0.07168292999267578, -0.7922525405883789, -0.4130280017852783, -0.7905440330505371, -0.20477509498596191, -0.06960010528564453, -4.717165946960449], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -5.329357624053955, "min_q": -9.91832447052002, "max_q": 2.4010772705078125, "mean_td_error": -2.2212696075439453, "model": {}}, "td_error": [0.9332828521728516, -2.139890432357788, -5.4964494705200195, -4.162928104400635, -0.9201068878173828, -3.79054594039917, -3.019988536834717, -0.42868518829345703, -0.4153003692626953, -0.9552083015441895, -5.249868869781494, -8.91832447052002, -1.9147024154663086, -0.5331134796142578, -6.378836631774902, -3.8501996994018555, -0.19362705945968628, -0.736030101776123, -3.5616674423217773, 0.07520484924316406, 0.7637162208557129, -5.752166748046875, -3.79054594039917, 0.89708411693573, -0.027776718139648438, -1.0717201232910156, -7.332776069641113, -6.344451427459717, 1.2344326972961426, 0.5627665519714355, 1.7945008277893066, -0.3567049503326416], "custom_metrics": {}}}, "num_steps_sampled": 15392, "num_agent_steps_sampled": 30784, "num_steps_trained": 33568, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 67136, "last_target_update_ts": 15392, "num_target_updates": 133}, "done": false, "episodes_total": 1134, "training_iteration": 58, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-33", "timestamp": 1648811733, "time_this_iter_s": 1.0986108779907227, "time_total_s": 69.02075958251953, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 69.02075958251953, "timesteps_since_restore": 1856, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 31.2, "ram_util_percent": 58.7}}
{"episode_reward_max": 14.0, "episode_reward_min": -16.0, "episode_reward_mean": 3.58, "episode_len_mean": 8.21, "episode_media": {}, "episodes_this_iter": 29, "policy_reward_min": {"policy0": -8.0, "policy1": -18.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 7.79, "policy1": -4.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 8.0, 8.0, -14.0, 4.0, 4.0, 0.0, 4.0, 10.0, 10.0, 14.0, 8.0, 0.0, 4.0, 4.0, 4.0, 0.0, -4.0, -16.0, -4.0, 8.0, 8.0, 8.0, 8.0, 6.0, -2.0, -14.0, 8.0, 8.0, 12.0, -4.0, 8.0, 6.0, -14.0, 6.0, 8.0, 4.0, 0.0, 14.0, 8.0, 8.0, 8.0, 4.0, 10.0, -16.0, -4.0, 10.0, 0.0, 8.0, 10.0, -8.0, 4.0, 0.0, -12.0, 0.0, 14.0, 14.0, -4.0, 8.0, -4.0, -14.0, 4.0, 8.0, 0.0, 6.0, -8.0, 8.0, 0.0, -6.0, 8.0, 8.0, 0.0, 8.0, 4.0, -4.0, 4.0, 10.0, 0.0, 0.0, 10.0, 12.0, 6.0, 12.0, 8.0, 4.0, 14.0, 4.0, -12.0, 14.0, 12.0, 4.0, -16.0, 6.0, 8.0, 12.0, 12.0, 10.0, 8.0, 10.0, 4.0], "episode_lengths": [10, 6, 6, 17, 8, 8, 10, 8, 5, 5, 3, 6, 10, 8, 8, 8, 10, 12, 18, 12, 6, 6, 6, 6, 7, 11, 17, 6, 6, 4, 12, 6, 7, 17, 7, 6, 8, 10, 3, 6, 6, 6, 8, 5, 18, 12, 5, 10, 6, 5, 14, 8, 10, 16, 10, 3, 3, 12, 6, 12, 17, 8, 6, 10, 7, 14, 6, 10, 13, 6, 6, 10, 6, 8, 12, 8, 5, 10, 10, 5, 4, 7, 4, 6, 8, 3, 8, 16, 3, 4, 8, 18, 7, 6, 4, 4, 5, 6, 5, 8], "policy_policy0_reward": [0.0, 14.0, 14.0, 3.0, 12.0, 12.0, 10.0, 12.0, 5.0, 5.0, 7.0, 14.0, 10.0, 12.0, 12.0, 2.0, 10.0, 8.0, 2.0, 8.0, 14.0, 14.0, 14.0, 4.0, 3.0, -1.0, 3.0, 4.0, 14.0, 6.0, 8.0, 14.0, 3.0, 3.0, 3.0, 14.0, 2.0, 10.0, 7.0, 14.0, 14.0, 14.0, 12.0, 5.0, -8.0, 8.0, 5.0, 10.0, 14.0, 5.0, 6.0, 12.0, 10.0, 4.0, 10.0, 7.0, 7.0, 8.0, 14.0, 8.0, -7.0, 12.0, 14.0, 10.0, 3.0, 6.0, 14.0, 0.0, 7.0, 4.0, 4.0, 10.0, 14.0, 12.0, 8.0, 12.0, 5.0, 0.0, 10.0, 5.0, 6.0, 3.0, 6.0, 4.0, 12.0, 7.0, 12.0, 4.0, 7.0, 6.0, 12.0, 2.0, 3.0, 14.0, 6.0, 6.0, 5.0, 14.0, 5.0, 12.0], "policy_policy1_reward": [0.0, -6.0, -6.0, -17.0, -8.0, -8.0, -10.0, -8.0, 5.0, 5.0, 7.0, -6.0, -10.0, -8.0, -8.0, 2.0, -10.0, -12.0, -18.0, -12.0, -6.0, -6.0, -6.0, 4.0, 3.0, -1.0, -17.0, 4.0, -6.0, 6.0, -12.0, -6.0, 3.0, -17.0, 3.0, -6.0, 2.0, -10.0, 7.0, -6.0, -6.0, -6.0, -8.0, 5.0, -8.0, -12.0, 5.0, -10.0, -6.0, 5.0, -14.0, -8.0, -10.0, -16.0, -10.0, 7.0, 7.0, -12.0, -6.0, -12.0, -7.0, -8.0, -6.0, -10.0, 3.0, -14.0, -6.0, 0.0, -13.0, 4.0, 4.0, -10.0, -6.0, -8.0, -12.0, -8.0, 5.0, 0.0, -10.0, 5.0, 6.0, 3.0, 6.0, 4.0, -8.0, 7.0, -8.0, -16.0, 7.0, 6.0, -8.0, -18.0, 3.0, -6.0, 6.0, 6.0, 5.0, -6.0, 5.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.332866860702879, "mean_inference_ms": 1.7489739362886683, "mean_action_processing_ms": 0.11949017386801274, "mean_env_wait_ms": 0.07536994578467844, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15600, "timesteps_this_iter": 32, "agent_timesteps_total": 31200, "timers": {"load_time_ms": 0.467, "load_throughput": 68530.88, "learn_time_ms": 7.944, "learn_throughput": 4027.998, "update_time_ms": 5.65}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.804798603057861, "min_q": -1.7461929321289062, "max_q": 13.325382232666016, "mean_td_error": 0.20592093467712402, "model": {}}, "td_error": [-1.0157852172851562, 4.669526100158691, 1.7957894802093506, 0.48419785499572754, 0.17229938507080078, -0.9535713195800781, -0.028985977172851562, -0.9171805381774902, 0.3045922517776489, -1.270096778869629, 0.8983309268951416, -1.5580992698669434, 0.19336414337158203, -0.5404015779495239, -0.25495243072509766, -0.145751953125, 0.4667775630950928, 0.7511210441589355, 1.93003249168396, 0.7468166351318359, -0.36597740650177, -0.7461929321289062, 1.1457042694091797, 1.2748994827270508, 0.5992774963378906, -0.595311164855957, 1.7466926574707031, 0.3005361557006836, -0.7753558158874512, 0.19336414337158203, -1.1638611555099487, -0.7523288726806641], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.5330657958984375, "min_q": -9.47584342956543, "max_q": 9.192566871643066, "mean_td_error": -1.7157948017120361, "model": {}}, "td_error": [-0.20890045166015625, -4.410613536834717, 1.1683979034423828, -4.424983978271484, 1.115525245666504, -8.77385139465332, -1.20119047164917, 5.440390110015869, -2.306777000427246, -4.334346771240234, -0.3106200695037842, 0.3041328191757202, -0.14328384399414062, 0.9292411804199219, 1.6417468786239624, 0.1925668716430664, 3.2366604804992676, -4.00015926361084, -0.19513607025146484, -0.6050291061401367, -4.178013324737549, -17.042865753173828, 1.064168930053711, -0.012935280799865723, 1.4770257472991943, -2.850719690322876, 0.9292411804199219, -14.812113761901855, 0.20381951332092285, -7.05927848815918, 4.3810954093933105, -0.11862373352050781], "custom_metrics": {}}}, "num_steps_sampled": 15600, "num_agent_steps_sampled": 31200, "num_steps_trained": 34432, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 68864, "last_target_update_ts": 15600, "num_target_updates": 135}, "done": false, "episodes_total": 1163, "training_iteration": 59, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-34", "timestamp": 1648811734, "time_this_iter_s": 1.3124077320098877, "time_total_s": 70.33316731452942, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 70.33316731452942, "timesteps_since_restore": 1888, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 31.9, "ram_util_percent": 58.7}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 2.3, "episode_len_mean": 8.8, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 7.0, "policy1": -4.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-16.0, -4.0, 8.0, 8.0, 8.0, 8.0, 6.0, -2.0, -14.0, 8.0, 8.0, 12.0, -4.0, 8.0, 6.0, -14.0, 6.0, 8.0, 4.0, 0.0, 14.0, 8.0, 8.0, 8.0, 4.0, 10.0, -16.0, -4.0, 10.0, 0.0, 8.0, 10.0, -8.0, 4.0, 0.0, -12.0, 0.0, 14.0, 14.0, -4.0, 8.0, -4.0, -14.0, 4.0, 8.0, 0.0, 6.0, -8.0, 8.0, 0.0, -6.0, 8.0, 8.0, 0.0, 8.0, 4.0, -4.0, 4.0, 10.0, 0.0, 0.0, 10.0, 12.0, 6.0, 12.0, 8.0, 4.0, 14.0, 4.0, -12.0, 14.0, 12.0, 4.0, -16.0, 6.0, 8.0, 12.0, 12.0, 10.0, 8.0, 10.0, 4.0, -20.0, -20.0, 8.0, -4.0, -30.0, 8.0, -16.0, -2.0, 8.0, 8.0, -16.0, 8.0, -4.0, 4.0, 8.0, 4.0, 4.0, -12.0], "episode_lengths": [18, 12, 6, 6, 6, 6, 7, 11, 17, 6, 6, 4, 12, 6, 7, 17, 7, 6, 8, 10, 3, 6, 6, 6, 8, 5, 18, 12, 5, 10, 6, 5, 14, 8, 10, 16, 10, 3, 3, 12, 6, 12, 17, 8, 6, 10, 7, 14, 6, 10, 13, 6, 6, 10, 6, 8, 12, 8, 5, 10, 10, 5, 4, 7, 4, 6, 8, 3, 8, 16, 3, 4, 8, 18, 7, 6, 4, 4, 5, 6, 5, 8, 20, 20, 6, 12, 20, 6, 18, 11, 6, 6, 18, 6, 12, 8, 6, 8, 8, 16], "policy_policy0_reward": [2.0, 8.0, 14.0, 14.0, 14.0, 4.0, 3.0, -1.0, 3.0, 4.0, 14.0, 6.0, 8.0, 14.0, 3.0, 3.0, 3.0, 14.0, 2.0, 10.0, 7.0, 14.0, 14.0, 14.0, 12.0, 5.0, -8.0, 8.0, 5.0, 10.0, 14.0, 5.0, 6.0, 12.0, 10.0, 4.0, 10.0, 7.0, 7.0, 8.0, 14.0, 8.0, -7.0, 12.0, 14.0, 10.0, 3.0, 6.0, 14.0, 0.0, 7.0, 4.0, 4.0, 10.0, 14.0, 12.0, 8.0, 12.0, 5.0, 0.0, 10.0, 5.0, 6.0, 3.0, 6.0, 4.0, 12.0, 7.0, 12.0, 4.0, 7.0, 6.0, 12.0, 2.0, 3.0, 14.0, 6.0, 6.0, 5.0, 14.0, 5.0, 12.0, 0.0, 0.0, 14.0, -2.0, -10.0, 4.0, 2.0, 9.0, 14.0, 4.0, -8.0, 4.0, 8.0, 2.0, 14.0, 12.0, 12.0, 4.0], "policy_policy1_reward": [-18.0, -12.0, -6.0, -6.0, -6.0, 4.0, 3.0, -1.0, -17.0, 4.0, -6.0, 6.0, -12.0, -6.0, 3.0, -17.0, 3.0, -6.0, 2.0, -10.0, 7.0, -6.0, -6.0, -6.0, -8.0, 5.0, -8.0, -12.0, 5.0, -10.0, -6.0, 5.0, -14.0, -8.0, -10.0, -16.0, -10.0, 7.0, 7.0, -12.0, -6.0, -12.0, -7.0, -8.0, -6.0, -10.0, 3.0, -14.0, -6.0, 0.0, -13.0, 4.0, 4.0, -10.0, -6.0, -8.0, -12.0, -8.0, 5.0, 0.0, -10.0, 5.0, 6.0, 3.0, 6.0, 4.0, -8.0, 7.0, -8.0, -16.0, 7.0, 6.0, -8.0, -18.0, 3.0, -6.0, 6.0, 6.0, 5.0, -6.0, 5.0, -8.0, -20.0, -20.0, -6.0, -2.0, -20.0, 4.0, -18.0, -11.0, -6.0, 4.0, -8.0, 4.0, -12.0, 2.0, -6.0, -8.0, -8.0, -16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3331362109555325, "mean_inference_ms": 1.7489954888274915, "mean_action_processing_ms": 0.11947805491046809, "mean_env_wait_ms": 0.07536007542442366, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15807, "timesteps_this_iter": 32, "agent_timesteps_total": 31614, "timers": {"load_time_ms": 0.45, "load_throughput": 71131.341, "learn_time_ms": 8.238, "learn_throughput": 3884.458, "update_time_ms": 4.771}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.068282127380371, "min_q": -1.2690461874008179, "max_q": 13.787193298339844, "mean_td_error": -0.30336159467697144, "model": {}}, "td_error": [-0.33432674407958984, -0.014539718627929688, 0.12998485565185547, -0.21071910858154297, -2.7187204360961914, 0.7814092636108398, -1.8998425006866455, -1.0587902069091797, -0.19741463661193848, 1.7179579734802246, -0.7632465362548828, -0.7365093231201172, -0.9724326133728027, -1.5417747497558594, -0.4956340789794922, -0.7481846809387207, -0.833949089050293, -6.475695610046387, 1.348376750946045, -1.0348944664001465, 0.7392168045043945, -0.006590843200683594, 1.9436311721801758, 0.09189701080322266, 0.3719472885131836, -1.2546719312667847, -1.138479232788086, -0.8753020763397217, 5.5283355712890625, -1.0395057201385498, 0.12998580932617188, 1.8609099388122559], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -5.846407890319824, "min_q": -10.616063117980957, "max_q": 4.548319339752197, "mean_td_error": -1.65114164352417, "model": {}}, "td_error": [5.944493770599365, -3.9438624382019043, -6.96967887878418, -4.878911972045898, 1.5345487594604492, 1.5957496166229248, 2.4087347984313965, -0.226226806640625, -7.638776779174805, 1.187291145324707, -5.160592079162598, 1.16943359375, 1.6518365144729614, -3.630037307739258, 0.7470254898071289, 1.0548572540283203, -0.7821636199951172, 1.8025881052017212, 0.13500261306762695, -3.1650867462158203, -3.4425981044769287, 0.046295166015625, 2.872433662414551, -7.521154403686523, -1.7874259948730469, 2.060734748840332, -13.731488227844238, -3.630037307739258, 1.3704605102539062, -6.238212585449219, -5.382214069366455, -0.2895526885986328], "custom_metrics": {}}}, "num_steps_sampled": 15807, "num_agent_steps_sampled": 31614, "num_steps_trained": 35008, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 70016, "last_target_update_ts": 15807, "num_target_updates": 137}, "done": false, "episodes_total": 1181, "training_iteration": 60, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-35", "timestamp": 1648811735, "time_this_iter_s": 1.067213535308838, "time_total_s": 71.40038084983826, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584745f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584745f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 71.40038084983826, "timesteps_since_restore": 1920, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 29.6, "ram_util_percent": 58.8}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 1.94, "episode_len_mean": 8.93, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 7.17, "policy1": -5.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 4.0, 10.0, -16.0, -4.0, 10.0, 0.0, 8.0, 10.0, -8.0, 4.0, 0.0, -12.0, 0.0, 14.0, 14.0, -4.0, 8.0, -4.0, -14.0, 4.0, 8.0, 0.0, 6.0, -8.0, 8.0, 0.0, -6.0, 8.0, 8.0, 0.0, 8.0, 4.0, -4.0, 4.0, 10.0, 0.0, 0.0, 10.0, 12.0, 6.0, 12.0, 8.0, 4.0, 14.0, 4.0, -12.0, 14.0, 12.0, 4.0, -16.0, 6.0, 8.0, 12.0, 12.0, 10.0, 8.0, 10.0, 4.0, -20.0, -20.0, 8.0, -4.0, -30.0, 8.0, -16.0, -2.0, 8.0, 8.0, -16.0, 8.0, -4.0, 4.0, 8.0, 4.0, 4.0, -12.0, 8.0, -4.0, 0.0, -30.0, 0.0, 4.0, -4.0, 4.0, -12.0, 8.0, 8.0, -4.0, 8.0, 4.0, -4.0, 8.0, 4.0, 4.0, 4.0, 14.0, 0.0, 14.0, 4.0], "episode_lengths": [6, 8, 5, 18, 12, 5, 10, 6, 5, 14, 8, 10, 16, 10, 3, 3, 12, 6, 12, 17, 8, 6, 10, 7, 14, 6, 10, 13, 6, 6, 10, 6, 8, 12, 8, 5, 10, 10, 5, 4, 7, 4, 6, 8, 3, 8, 16, 3, 4, 8, 18, 7, 6, 4, 4, 5, 6, 5, 8, 20, 20, 6, 12, 20, 6, 18, 11, 6, 6, 18, 6, 12, 8, 6, 8, 8, 16, 6, 12, 10, 20, 10, 8, 12, 8, 16, 6, 6, 12, 6, 8, 12, 6, 8, 8, 8, 3, 10, 3, 8], "policy_policy0_reward": [14.0, 12.0, 5.0, -8.0, 8.0, 5.0, 10.0, 14.0, 5.0, 6.0, 12.0, 10.0, 4.0, 10.0, 7.0, 7.0, 8.0, 14.0, 8.0, -7.0, 12.0, 14.0, 10.0, 3.0, 6.0, 14.0, 0.0, 7.0, 4.0, 4.0, 10.0, 14.0, 12.0, 8.0, 12.0, 5.0, 0.0, 10.0, 5.0, 6.0, 3.0, 6.0, 4.0, 12.0, 7.0, 12.0, 4.0, 7.0, 6.0, 12.0, 2.0, 3.0, 14.0, 6.0, 6.0, 5.0, 14.0, 5.0, 12.0, 0.0, 0.0, 14.0, -2.0, -10.0, 4.0, 2.0, 9.0, 14.0, 4.0, -8.0, 4.0, 8.0, 2.0, 14.0, 12.0, 12.0, 4.0, 14.0, 8.0, 10.0, -10.0, 10.0, 12.0, 8.0, 12.0, 4.0, 14.0, 14.0, 8.0, 14.0, 12.0, 8.0, 14.0, 2.0, 2.0, 12.0, 7.0, 10.0, 7.0, 2.0], "policy_policy1_reward": [-6.0, -8.0, 5.0, -8.0, -12.0, 5.0, -10.0, -6.0, 5.0, -14.0, -8.0, -10.0, -16.0, -10.0, 7.0, 7.0, -12.0, -6.0, -12.0, -7.0, -8.0, -6.0, -10.0, 3.0, -14.0, -6.0, 0.0, -13.0, 4.0, 4.0, -10.0, -6.0, -8.0, -12.0, -8.0, 5.0, 0.0, -10.0, 5.0, 6.0, 3.0, 6.0, 4.0, -8.0, 7.0, -8.0, -16.0, 7.0, 6.0, -8.0, -18.0, 3.0, -6.0, 6.0, 6.0, 5.0, -6.0, 5.0, -8.0, -20.0, -20.0, -6.0, -2.0, -20.0, 4.0, -18.0, -11.0, -6.0, 4.0, -8.0, 4.0, -12.0, 2.0, -6.0, -8.0, -8.0, -16.0, -6.0, -12.0, -10.0, -20.0, -10.0, -8.0, -12.0, -8.0, -16.0, -6.0, -6.0, -12.0, -6.0, -8.0, -12.0, -6.0, 2.0, 2.0, -8.0, 7.0, -10.0, 7.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33343500857894603, "mean_inference_ms": 1.7487210575914878, "mean_action_processing_ms": 0.11944549748338534, "mean_env_wait_ms": 0.0753402542342727, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16013, "timesteps_this_iter": 32, "agent_timesteps_total": 32026, "timers": {"load_time_ms": 0.438, "load_throughput": 73075.477, "learn_time_ms": 7.75, "learn_throughput": 4129.192, "update_time_ms": 4.755}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.53648567199707, "min_q": -1.9508882761001587, "max_q": 12.024127006530762, "mean_td_error": 0.18050292134284973, "model": {}}, "td_error": [-0.8645992279052734, 0.005940437316894531, -1.177605390548706, -0.8645992279052734, 1.237931728363037, -0.5640521049499512, -1.5547871589660645, -0.31416893005371094, -0.3891291618347168, -0.6512665748596191, -0.32520341873168945, -0.3139004707336426, 5.934237003326416, 1.6399211883544922, 0.6742391586303711, -0.07509613037109375, -0.8645992279052734, 5.27534294128418, -1.9934873580932617, 1.7916269302368164, 1.2853593826293945, -0.39886474609375, -0.10032844543457031, 0.3766779899597168, 0.04013872146606445, 0.3014129400253296, -0.6300601959228516, -1.848398208618164, 0.03314995765686035, -0.8645992279052734, 1.7970008850097656, -0.8221406936645508], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -6.342964172363281, "min_q": -11.49047565460205, "max_q": 2.721168279647827, "mean_td_error": 0.2747039496898651, "model": {}}, "td_error": [0.31861400604248047, 3.1558074951171875, -1.576940655708313, 2.9854679107666016, 0.8353252410888672, 5.343686580657959, 1.0785980224609375, 4.191519737243652, 1.3628828525543213, 2.2353715896606445, 1.7975234985351562, 1.591482162475586, 7.991695404052734, 0.19205617904663086, -1.012333869934082, 1.389207363128662, -0.2617483139038086, -0.8028724193572998, 0.7990937232971191, -4.060845375061035, -2.0447845458984375, 1.193507194519043, -1.2526140213012695, -1.5143649578094482, -4.845691680908203, 0.7472991943359375, 1.334758996963501, 0.3217887878417969, -6.633108139038086, -3.5073318481445312, -1.1741137504577637, -1.38840913772583], "custom_metrics": {}}}, "num_steps_sampled": 16013, "num_agent_steps_sampled": 32026, "num_steps_trained": 35680, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 71360, "last_target_update_ts": 16013, "num_target_updates": 139}, "done": false, "episodes_total": 1204, "training_iteration": 61, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-36", "timestamp": 1648811736, "time_this_iter_s": 1.054335117340088, "time_total_s": 72.45471596717834, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 72.45471596717834, "timesteps_since_restore": 1952, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 31.4, "ram_util_percent": 58.8}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 2.36, "episode_len_mean": 8.72, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 7.58, "policy1": -5.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -6.0, 8.0, 8.0, 0.0, 8.0, 4.0, -4.0, 4.0, 10.0, 0.0, 0.0, 10.0, 12.0, 6.0, 12.0, 8.0, 4.0, 14.0, 4.0, -12.0, 14.0, 12.0, 4.0, -16.0, 6.0, 8.0, 12.0, 12.0, 10.0, 8.0, 10.0, 4.0, -20.0, -20.0, 8.0, -4.0, -30.0, 8.0, -16.0, -2.0, 8.0, 8.0, -16.0, 8.0, -4.0, 4.0, 8.0, 4.0, 4.0, -12.0, 8.0, -4.0, 0.0, -30.0, 0.0, 4.0, -4.0, 4.0, -12.0, 8.0, 8.0, -4.0, 8.0, 4.0, -4.0, 8.0, 4.0, 4.0, 4.0, 14.0, 0.0, 14.0, 4.0, -8.0, 6.0, 4.0, -4.0, 0.0, 8.0, 0.0, -8.0, 8.0, 8.0, 8.0, -4.0, -4.0, 8.0, 12.0, 4.0, 8.0, 8.0, 4.0, -8.0, 12.0, 4.0, 8.0, 10.0, -4.0, 8.0], "episode_lengths": [10, 13, 6, 6, 10, 6, 8, 12, 8, 5, 10, 10, 5, 4, 7, 4, 6, 8, 3, 8, 16, 3, 4, 8, 18, 7, 6, 4, 4, 5, 6, 5, 8, 20, 20, 6, 12, 20, 6, 18, 11, 6, 6, 18, 6, 12, 8, 6, 8, 8, 16, 6, 12, 10, 20, 10, 8, 12, 8, 16, 6, 6, 12, 6, 8, 12, 6, 8, 8, 8, 3, 10, 3, 8, 14, 7, 8, 12, 10, 6, 10, 14, 6, 6, 6, 12, 12, 6, 4, 8, 6, 6, 8, 14, 4, 8, 6, 5, 12, 6], "policy_policy0_reward": [0.0, 7.0, 4.0, 4.0, 10.0, 14.0, 12.0, 8.0, 12.0, 5.0, 0.0, 10.0, 5.0, 6.0, 3.0, 6.0, 4.0, 12.0, 7.0, 12.0, 4.0, 7.0, 6.0, 12.0, 2.0, 3.0, 14.0, 6.0, 6.0, 5.0, 14.0, 5.0, 12.0, 0.0, 0.0, 14.0, -2.0, -10.0, 4.0, 2.0, 9.0, 14.0, 4.0, -8.0, 4.0, 8.0, 2.0, 14.0, 12.0, 12.0, 4.0, 14.0, 8.0, 10.0, -10.0, 10.0, 12.0, 8.0, 12.0, 4.0, 14.0, 14.0, 8.0, 14.0, 12.0, 8.0, 14.0, 2.0, 2.0, 12.0, 7.0, 10.0, 7.0, 2.0, 6.0, 3.0, 12.0, 8.0, 10.0, 14.0, 10.0, 6.0, 14.0, 14.0, 14.0, 8.0, 8.0, 14.0, 6.0, 12.0, 4.0, 14.0, 12.0, -4.0, 6.0, 12.0, 14.0, 5.0, 8.0, 14.0], "policy_policy1_reward": [0.0, -13.0, 4.0, 4.0, -10.0, -6.0, -8.0, -12.0, -8.0, 5.0, 0.0, -10.0, 5.0, 6.0, 3.0, 6.0, 4.0, -8.0, 7.0, -8.0, -16.0, 7.0, 6.0, -8.0, -18.0, 3.0, -6.0, 6.0, 6.0, 5.0, -6.0, 5.0, -8.0, -20.0, -20.0, -6.0, -2.0, -20.0, 4.0, -18.0, -11.0, -6.0, 4.0, -8.0, 4.0, -12.0, 2.0, -6.0, -8.0, -8.0, -16.0, -6.0, -12.0, -10.0, -20.0, -10.0, -8.0, -12.0, -8.0, -16.0, -6.0, -6.0, -12.0, -6.0, -8.0, -12.0, -6.0, 2.0, 2.0, -8.0, 7.0, -10.0, 7.0, 2.0, -14.0, 3.0, -8.0, -12.0, -10.0, -6.0, -10.0, -14.0, -6.0, -6.0, -6.0, -12.0, -12.0, -6.0, 6.0, -8.0, 4.0, -6.0, -8.0, -4.0, 6.0, -8.0, -6.0, 5.0, -12.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33381475025588037, "mean_inference_ms": 1.74870742290571, "mean_action_processing_ms": 0.11943436023176993, "mean_env_wait_ms": 0.07532985721307885, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16229, "timesteps_this_iter": 32, "agent_timesteps_total": 32458, "timers": {"load_time_ms": 0.558, "load_throughput": 57331.053, "learn_time_ms": 8.233, "learn_throughput": 3886.617, "update_time_ms": 4.915}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.327004909515381, "min_q": -3.748234510421753, "max_q": 13.21889877319336, "mean_td_error": 0.14003941416740417, "model": {}}, "td_error": [1.3134163618087769, -0.7357149124145508, -0.9772539138793945, -2.478971481323242, -0.3460078239440918, -1.6190452575683594, -0.5484590530395508, 0.7595195770263672, 1.0609478950500488, -0.6862583160400391, -0.1807727813720703, -0.8540987968444824, 1.102079153060913, 0.05515098571777344, -4.638454437255859, 0.19484472274780273, -1.454402208328247, 3.0648815631866455, -0.43912506103515625, -0.03841209411621094, 0.6884026527404785, -0.2563507556915283, 0.46356701850891113, 1.0088200569152832, -2.8010969161987305, 0.4874833822250366, 0.5527586936950684, 0.3046407699584961, 0.5580803155899048, 6.6937665939331055, -0.860595703125, 5.087921142578125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.0053892135620117, "min_q": -9.934892654418945, "max_q": 4.780623435974121, "mean_td_error": 1.3651446104049683, "model": {}}, "td_error": [-0.5993208289146423, -1.8388919830322266, -1.4492305517196655, 3.6473796367645264, 0.43449878692626953, 0.13802099227905273, -4.7989373207092285, 1.4711418151855469, 1.0460224151611328, 2.7461986541748047, -0.8157749176025391, 0.10132026672363281, -3.04571270942688, 1.8225164413452148, 9.245064735412598, 4.0110883712768555, -1.18115234375, -4.015875816345215, -0.5318834781646729, 9.352783203125, 3.676314115524292, -0.6388304233551025, 5.104330539703369, 1.542691946029663, 2.8194613456726074, -0.5024785995483398, 6.6981072425842285, 2.3024234771728516, 4.6493024826049805, -0.9111356735229492, 3.637974739074707, -0.43279075622558594], "custom_metrics": {}}}, "num_steps_sampled": 16229, "num_agent_steps_sampled": 32458, "num_steps_trained": 36512, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 73024, "last_target_update_ts": 16229, "num_target_updates": 141}, "done": false, "episodes_total": 1230, "training_iteration": 62, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-38", "timestamp": 1648811738, "time_this_iter_s": 1.2819433212280273, "time_total_s": 73.73665928840637, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 73.73665928840637, "timesteps_since_restore": 1984, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 31.15, "ram_util_percent": 58.8}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 2.38, "episode_len_mean": 8.66, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 8.24, "policy1": -5.86}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, 12.0, 10.0, 8.0, 10.0, 4.0, -20.0, -20.0, 8.0, -4.0, -30.0, 8.0, -16.0, -2.0, 8.0, 8.0, -16.0, 8.0, -4.0, 4.0, 8.0, 4.0, 4.0, -12.0, 8.0, -4.0, 0.0, -30.0, 0.0, 4.0, -4.0, 4.0, -12.0, 8.0, 8.0, -4.0, 8.0, 4.0, -4.0, 8.0, 4.0, 4.0, 4.0, 14.0, 0.0, 14.0, 4.0, -8.0, 6.0, 4.0, -4.0, 0.0, 8.0, 0.0, -8.0, 8.0, 8.0, 8.0, -4.0, -4.0, 8.0, 12.0, 4.0, 8.0, 8.0, 4.0, -8.0, 12.0, 4.0, 8.0, 10.0, -4.0, 8.0, 4.0, -30.0, 10.0, 8.0, 4.0, 8.0, 4.0, 4.0, -4.0, 14.0, 4.0, 14.0, 4.0, 8.0, 0.0, 8.0, 8.0, -4.0, 4.0, 4.0, 8.0, 0.0, 8.0, 14.0, 4.0, 14.0, 0.0], "episode_lengths": [4, 4, 5, 6, 5, 8, 20, 20, 6, 12, 20, 6, 18, 11, 6, 6, 18, 6, 12, 8, 6, 8, 8, 16, 6, 12, 10, 20, 10, 8, 12, 8, 16, 6, 6, 12, 6, 8, 12, 6, 8, 8, 8, 3, 10, 3, 8, 14, 7, 8, 12, 10, 6, 10, 14, 6, 6, 6, 12, 12, 6, 4, 8, 6, 6, 8, 14, 4, 8, 6, 5, 12, 6, 8, 20, 5, 6, 8, 6, 8, 8, 12, 3, 8, 3, 8, 6, 10, 6, 6, 12, 8, 8, 6, 10, 6, 3, 8, 3, 10], "policy_policy0_reward": [6.0, 6.0, 5.0, 14.0, 5.0, 12.0, 0.0, 0.0, 14.0, -2.0, -10.0, 4.0, 2.0, 9.0, 14.0, 4.0, -8.0, 4.0, 8.0, 2.0, 14.0, 12.0, 12.0, 4.0, 14.0, 8.0, 10.0, -10.0, 10.0, 12.0, 8.0, 12.0, 4.0, 14.0, 14.0, 8.0, 14.0, 12.0, 8.0, 14.0, 2.0, 2.0, 12.0, 7.0, 10.0, 7.0, 2.0, 6.0, 3.0, 12.0, 8.0, 10.0, 14.0, 10.0, 6.0, 14.0, 14.0, 14.0, 8.0, 8.0, 14.0, 6.0, 12.0, 4.0, 14.0, 12.0, -4.0, 6.0, 12.0, 14.0, 5.0, 8.0, 14.0, 12.0, -10.0, 5.0, 14.0, 12.0, 14.0, 12.0, 12.0, -2.0, 7.0, 12.0, 7.0, 12.0, 4.0, 10.0, 14.0, 14.0, 8.0, 12.0, 12.0, 14.0, 10.0, 14.0, 7.0, 12.0, 7.0, 10.0], "policy_policy1_reward": [6.0, 6.0, 5.0, -6.0, 5.0, -8.0, -20.0, -20.0, -6.0, -2.0, -20.0, 4.0, -18.0, -11.0, -6.0, 4.0, -8.0, 4.0, -12.0, 2.0, -6.0, -8.0, -8.0, -16.0, -6.0, -12.0, -10.0, -20.0, -10.0, -8.0, -12.0, -8.0, -16.0, -6.0, -6.0, -12.0, -6.0, -8.0, -12.0, -6.0, 2.0, 2.0, -8.0, 7.0, -10.0, 7.0, 2.0, -14.0, 3.0, -8.0, -12.0, -10.0, -6.0, -10.0, -14.0, -6.0, -6.0, -6.0, -12.0, -12.0, -6.0, 6.0, -8.0, 4.0, -6.0, -8.0, -4.0, 6.0, -8.0, -6.0, 5.0, -12.0, -6.0, -8.0, -20.0, 5.0, -6.0, -8.0, -6.0, -8.0, -8.0, -2.0, 7.0, -8.0, 7.0, -8.0, 4.0, -10.0, -6.0, -6.0, -12.0, -8.0, -8.0, -6.0, -10.0, -6.0, 7.0, -8.0, 7.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3341691241085097, "mean_inference_ms": 1.748634964002833, "mean_action_processing_ms": 0.11942011717032769, "mean_env_wait_ms": 0.07532431254985997, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16434, "timesteps_this_iter": 32, "agent_timesteps_total": 32868, "timers": {"load_time_ms": 0.422, "load_throughput": 75863.513, "learn_time_ms": 7.93, "learn_throughput": 4035.555, "update_time_ms": 4.813}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.126028537750244, "min_q": -1.3192567825317383, "max_q": 14.293420791625977, "mean_td_error": 0.1197788193821907, "model": {}}, "td_error": [-0.755070686340332, -1.1740875244140625, -0.45703381299972534, -0.12627530097961426, -0.7855968475341797, -1.15293550491333, 0.5166616439819336, -1.3142976760864258, 0.471066951751709, -0.2632718086242676, -1.901547908782959, -0.3680112361907959, 1.000025749206543, -0.050273895263671875, 2.4695515632629395, 0.16756534576416016, 0.12094402313232422, -0.5028181076049805, 0.2105998992919922, -0.41800808906555176, 0.2530038356781006, 0.051555633544921875, 0.2760295867919922, 4.224517345428467, -0.15018939971923828, 0.3079853057861328, -0.044600486755371094, 0.4341130256652832, 0.36494898796081543, 2.3617076873779297, -0.3786582946777344, 0.44532227516174316], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -5.412294387817383, "min_q": -9.625251770019531, "max_q": 1.1629328727722168, "mean_td_error": -0.7814966440200806, "model": {}}, "td_error": [3.0946240425109863, -3.549940586090088, -12.67846965789795, -2.1567070484161377, 2.7859387397766113, 1.2155237197875977, 2.293961524963379, -4.304396629333496, -5.3746562004089355, 2.3553028106689453, 3.218812942504883, 0.8740549087524414, -7.009600639343262, 0.4699510335922241, 2.305685043334961, -0.34262222051620483, -2.7740509510040283, -0.18599212169647217, -2.3981966972351074, 0.9731512069702148, -0.711357593536377, 1.7293624877929688, -6.540549278259277, 3.4434969425201416, 0.5740489959716797, -0.977818489074707, 2.029442310333252, 3.1486620903015137, -6.20540714263916, 2.987628936767578, -2.0941171646118164, -1.2036590576171875], "custom_metrics": {}}}, "num_steps_sampled": 16434, "num_agent_steps_sampled": 32868, "num_steps_trained": 37248, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 74496, "last_target_update_ts": 16434, "num_target_updates": 143}, "done": false, "episodes_total": 1257, "training_iteration": 63, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-39", "timestamp": 1648811739, "time_this_iter_s": 1.139585018157959, "time_total_s": 74.87624430656433, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 74.87624430656433, "timesteps_since_restore": 2016, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 31.4, "ram_util_percent": 58.9}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 4.28, "episode_len_mean": 7.81, "episode_media": {}, "episodes_this_iter": 29, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 9.59, "policy1": -5.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, -4.0, 4.0, -12.0, 8.0, 8.0, -4.0, 8.0, 4.0, -4.0, 8.0, 4.0, 4.0, 4.0, 14.0, 0.0, 14.0, 4.0, -8.0, 6.0, 4.0, -4.0, 0.0, 8.0, 0.0, -8.0, 8.0, 8.0, 8.0, -4.0, -4.0, 8.0, 12.0, 4.0, 8.0, 8.0, 4.0, -8.0, 12.0, 4.0, 8.0, 10.0, -4.0, 8.0, 4.0, -30.0, 10.0, 8.0, 4.0, 8.0, 4.0, 4.0, -4.0, 14.0, 4.0, 14.0, 4.0, 8.0, 0.0, 8.0, 8.0, -4.0, 4.0, 4.0, 8.0, 0.0, 8.0, 14.0, 4.0, 14.0, 0.0, 4.0, 8.0, 6.0, 8.0, 4.0, 8.0, 12.0, 0.0, 4.0, 12.0, 0.0, 8.0, 14.0, -4.0, 14.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 4.0, 8.0, 0.0, 4.0, 8.0, -8.0, -6.0, 8.0], "episode_lengths": [8, 12, 8, 16, 6, 6, 12, 6, 8, 12, 6, 8, 8, 8, 3, 10, 3, 8, 14, 7, 8, 12, 10, 6, 10, 14, 6, 6, 6, 12, 12, 6, 4, 8, 6, 6, 8, 14, 4, 8, 6, 5, 12, 6, 8, 20, 5, 6, 8, 6, 8, 8, 12, 3, 8, 3, 8, 6, 10, 6, 6, 12, 8, 8, 6, 10, 6, 3, 8, 3, 10, 8, 6, 7, 6, 8, 6, 4, 10, 8, 4, 10, 6, 3, 12, 3, 6, 8, 6, 8, 6, 6, 8, 6, 10, 8, 6, 14, 13, 6], "policy_policy0_reward": [12.0, 8.0, 12.0, 4.0, 14.0, 14.0, 8.0, 14.0, 12.0, 8.0, 14.0, 2.0, 2.0, 12.0, 7.0, 10.0, 7.0, 2.0, 6.0, 3.0, 12.0, 8.0, 10.0, 14.0, 10.0, 6.0, 14.0, 14.0, 14.0, 8.0, 8.0, 14.0, 6.0, 12.0, 4.0, 14.0, 12.0, -4.0, 6.0, 12.0, 14.0, 5.0, 8.0, 14.0, 12.0, -10.0, 5.0, 14.0, 12.0, 14.0, 12.0, 12.0, -2.0, 7.0, 12.0, 7.0, 12.0, 4.0, 10.0, 14.0, 14.0, 8.0, 12.0, 12.0, 14.0, 10.0, 14.0, 7.0, 12.0, 7.0, 10.0, 12.0, 14.0, 3.0, 14.0, 12.0, 14.0, 6.0, 10.0, 12.0, 6.0, 10.0, 14.0, 7.0, 8.0, 7.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 12.0, 14.0, 10.0, 2.0, 14.0, -4.0, 7.0, 14.0], "policy_policy1_reward": [-8.0, -12.0, -8.0, -16.0, -6.0, -6.0, -12.0, -6.0, -8.0, -12.0, -6.0, 2.0, 2.0, -8.0, 7.0, -10.0, 7.0, 2.0, -14.0, 3.0, -8.0, -12.0, -10.0, -6.0, -10.0, -14.0, -6.0, -6.0, -6.0, -12.0, -12.0, -6.0, 6.0, -8.0, 4.0, -6.0, -8.0, -4.0, 6.0, -8.0, -6.0, 5.0, -12.0, -6.0, -8.0, -20.0, 5.0, -6.0, -8.0, -6.0, -8.0, -8.0, -2.0, 7.0, -8.0, 7.0, -8.0, 4.0, -10.0, -6.0, -6.0, -12.0, -8.0, -8.0, -6.0, -10.0, -6.0, 7.0, -8.0, 7.0, -10.0, -8.0, -6.0, 3.0, -6.0, -8.0, -6.0, 6.0, -10.0, -8.0, 6.0, -10.0, -6.0, 7.0, -12.0, 7.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -8.0, -6.0, -10.0, 2.0, -6.0, -4.0, -13.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3346120452367074, "mean_inference_ms": 1.7482119818764739, "mean_action_processing_ms": 0.11939805513416958, "mean_env_wait_ms": 0.07532344257506213, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16646, "timesteps_this_iter": 32, "agent_timesteps_total": 33292, "timers": {"load_time_ms": 0.45, "load_throughput": 71074.84, "learn_time_ms": 7.52, "learn_throughput": 4255.247, "update_time_ms": 4.614}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.42636251449585, "min_q": -1.0956025123596191, "max_q": 14.321582794189453, "mean_td_error": 0.5379825830459595, "model": {}}, "td_error": [-1.8318991661071777, 6.555445194244385, 1.2167400121688843, 4.284069061279297, 1.0165343284606934, 0.1909627914428711, -0.951894998550415, -0.5549530982971191, -0.7788591384887695, -3.9074182510375977, -1.2129697799682617, 0.7256717681884766, 0.5168251991271973, 6.586795330047607, -1.1105996370315552, 0.3587517738342285, -0.1776571273803711, 0.9783048629760742, 0.7602123022079468, 0.02580738067626953, -0.1226339340209961, -0.10238653421401978, 2.8443422317504883, 0.40959835052490234, 0.12333059310913086, -0.3744473457336426, 0.2681546211242676, 0.08768081665039062, 1.5213956832885742, -0.7876091003417969, 0.9512410163879395, -0.2930917739868164], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.30723237991333, "min_q": -8.067963600158691, "max_q": 8.250514030456543, "mean_td_error": -0.07801094651222229, "model": {}}, "td_error": [0.9840378761291504, 2.5375046730041504, 3.705570697784424, -0.19694042205810547, 3.3780245780944824, -1.8973031044006348, 0.2227489948272705, 2.4552321434020996, 0.7362484931945801, 2.0700109004974365, -2.7058067321777344, -4.047107696533203, 3.9176197052001953, -4.29822301864624, -7.2657365798950195, -0.749485969543457, 1.6630730628967285, -0.8027515411376953, -6.418643951416016, 0.2956082820892334, 1.849172592163086, -0.5166354179382324, 1.9179353713989258, 0.18920493125915527, 2.8351125717163086, -6.238936424255371, -0.42365503311157227, 9.088512420654297, -0.7373247146606445, -4.035407066345215, -3.103607654571533, 3.0955967903137207], "custom_metrics": {}}}, "num_steps_sampled": 16646, "num_agent_steps_sampled": 33292, "num_steps_trained": 38112, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 76224, "last_target_update_ts": 16646, "num_target_updates": 145}, "done": false, "episodes_total": 1286, "training_iteration": 64, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-40", "timestamp": 1648811740, "time_this_iter_s": 1.2676727771759033, "time_total_s": 76.14391708374023, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847fc20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847fc20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 76.14391708374023, "timesteps_since_restore": 2048, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 31.4, "ram_util_percent": 58.9}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 4.18, "episode_len_mean": 7.86, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 9.84, "policy1": -5.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -8.0, 8.0, 8.0, 8.0, -4.0, -4.0, 8.0, 12.0, 4.0, 8.0, 8.0, 4.0, -8.0, 12.0, 4.0, 8.0, 10.0, -4.0, 8.0, 4.0, -30.0, 10.0, 8.0, 4.0, 8.0, 4.0, 4.0, -4.0, 14.0, 4.0, 14.0, 4.0, 8.0, 0.0, 8.0, 8.0, -4.0, 4.0, 4.0, 8.0, 0.0, 8.0, 14.0, 4.0, 14.0, 0.0, 4.0, 8.0, 6.0, 8.0, 4.0, 8.0, 12.0, 0.0, 4.0, 12.0, 0.0, 8.0, 14.0, -4.0, 14.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 4.0, 8.0, 0.0, 4.0, 8.0, -8.0, -6.0, 8.0, 0.0, 8.0, 4.0, 4.0, 0.0, 8.0, -8.0, -14.0, 8.0, 8.0, -6.0, 4.0, -4.0, 0.0, 4.0, 4.0, 4.0, 4.0, 8.0, 4.0, 8.0, 4.0, 4.0, 4.0], "episode_lengths": [10, 14, 6, 6, 6, 12, 12, 6, 4, 8, 6, 6, 8, 14, 4, 8, 6, 5, 12, 6, 8, 20, 5, 6, 8, 6, 8, 8, 12, 3, 8, 3, 8, 6, 10, 6, 6, 12, 8, 8, 6, 10, 6, 3, 8, 3, 10, 8, 6, 7, 6, 8, 6, 4, 10, 8, 4, 10, 6, 3, 12, 3, 6, 8, 6, 8, 6, 6, 8, 6, 10, 8, 6, 14, 13, 6, 10, 6, 8, 8, 10, 6, 14, 17, 6, 6, 13, 8, 12, 10, 8, 8, 8, 8, 6, 8, 6, 8, 8, 8], "policy_policy0_reward": [10.0, 6.0, 14.0, 14.0, 14.0, 8.0, 8.0, 14.0, 6.0, 12.0, 4.0, 14.0, 12.0, -4.0, 6.0, 12.0, 14.0, 5.0, 8.0, 14.0, 12.0, -10.0, 5.0, 14.0, 12.0, 14.0, 12.0, 12.0, -2.0, 7.0, 12.0, 7.0, 12.0, 4.0, 10.0, 14.0, 14.0, 8.0, 12.0, 12.0, 14.0, 10.0, 14.0, 7.0, 12.0, 7.0, 10.0, 12.0, 14.0, 3.0, 14.0, 12.0, 14.0, 6.0, 10.0, 12.0, 6.0, 10.0, 14.0, 7.0, 8.0, 7.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 12.0, 14.0, 10.0, 2.0, 14.0, -4.0, 7.0, 14.0, 0.0, 14.0, 12.0, 12.0, 10.0, 14.0, 6.0, 3.0, 14.0, 14.0, 7.0, 12.0, 8.0, 10.0, 12.0, 12.0, 12.0, 12.0, 14.0, 2.0, 14.0, 12.0, 12.0, 2.0], "policy_policy1_reward": [-10.0, -14.0, -6.0, -6.0, -6.0, -12.0, -12.0, -6.0, 6.0, -8.0, 4.0, -6.0, -8.0, -4.0, 6.0, -8.0, -6.0, 5.0, -12.0, -6.0, -8.0, -20.0, 5.0, -6.0, -8.0, -6.0, -8.0, -8.0, -2.0, 7.0, -8.0, 7.0, -8.0, 4.0, -10.0, -6.0, -6.0, -12.0, -8.0, -8.0, -6.0, -10.0, -6.0, 7.0, -8.0, 7.0, -10.0, -8.0, -6.0, 3.0, -6.0, -8.0, -6.0, 6.0, -10.0, -8.0, 6.0, -10.0, -6.0, 7.0, -12.0, 7.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -8.0, -6.0, -10.0, 2.0, -6.0, -4.0, -13.0, -6.0, 0.0, -6.0, -8.0, -8.0, -10.0, -6.0, -14.0, -17.0, -6.0, -6.0, -13.0, -8.0, -12.0, -10.0, -8.0, -8.0, -8.0, -8.0, -6.0, 2.0, -6.0, -8.0, -8.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33491457094702315, "mean_inference_ms": 1.7475745759154073, "mean_action_processing_ms": 0.11934963363894831, "mean_env_wait_ms": 0.0753060749139912, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16856, "timesteps_this_iter": 32, "agent_timesteps_total": 33712, "timers": {"load_time_ms": 0.418, "load_throughput": 76564.591, "learn_time_ms": 7.584, "learn_throughput": 4219.303, "update_time_ms": 4.495}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.259389877319336, "min_q": -0.5074182748794556, "max_q": 12.629408836364746, "mean_td_error": 0.7175658345222473, "model": {}}, "td_error": [-0.6766357421875, -0.4380168914794922, 4.8630547523498535, -0.016184329986572266, 1.6123132705688477, 7.436269760131836, 3.7025933265686035, -0.6560478210449219, 0.6594375371932983, 0.3099188804626465, -0.4249582290649414, 1.3348579406738281, 0.17855167388916016, 0.47259998321533203, -0.16863536834716797, 0.18477821350097656, 0.7348594665527344, -0.745244026184082, -1.4751707315444946, 0.7348594665527344, 0.16577672958374023, -1.044393539428711, -0.3126087188720703, 4.072543621063232, 5.284653663635254, 0.043221473693847656, 1.1840884685516357, -1.870126724243164, -0.6292209625244141, -2.5239810943603516, 1.609607219696045, -0.6406546831130981], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.3256076574325562, "min_q": -6.6755218505859375, "max_q": 6.975986480712891, "mean_td_error": -0.7216272950172424, "model": {}}, "td_error": [2.604384422302246, 3.194780111312866, 2.09285044670105, 0.8371396064758301, 1.8510642051696777, -3.750596523284912, -6.311208248138428, -1.322768211364746, -0.48229312896728516, 2.383228063583374, -1.7015247344970703, 0.280454158782959, -2.2544448375701904, 0.004713535308837891, 1.8179101943969727, -2.8974952697753906, -1.4290380477905273, -0.08427309989929199, 1.946136474609375, -1.0300238132476807, 1.9322617053985596, -3.0401248931884766, -5.21348762512207, 0.1958768367767334, 2.3331069946289062, 0.37413787841796875, -12.678705215454102, -3.433018684387207, -1.3748443126678467, 0.47128772735595703, 2.7887935638427734, -1.196352481842041], "custom_metrics": {}}}, "num_steps_sampled": 16856, "num_agent_steps_sampled": 33712, "num_steps_trained": 38880, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 77760, "last_target_update_ts": 16856, "num_target_updates": 147}, "done": false, "episodes_total": 1310, "training_iteration": 65, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-41", "timestamp": 1648811741, "time_this_iter_s": 1.1172387599945068, "time_total_s": 77.26115584373474, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 77.26115584373474, "timesteps_since_restore": 2080, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 31.65, "ram_util_percent": 58.9}}
{"episode_reward_max": 14.0, "episode_reward_min": -14.0, "episode_reward_mean": 4.24, "episode_len_mean": 7.88, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"policy0": -4.0, "policy1": -17.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 10.12, "policy1": -5.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 4.0, -4.0, 14.0, 4.0, 14.0, 4.0, 8.0, 0.0, 8.0, 8.0, -4.0, 4.0, 4.0, 8.0, 0.0, 8.0, 14.0, 4.0, 14.0, 0.0, 4.0, 8.0, 6.0, 8.0, 4.0, 8.0, 12.0, 0.0, 4.0, 12.0, 0.0, 8.0, 14.0, -4.0, 14.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 4.0, 8.0, 0.0, 4.0, 8.0, -8.0, -6.0, 8.0, 0.0, 8.0, 4.0, 4.0, 0.0, 8.0, -8.0, -14.0, 8.0, 8.0, -6.0, 4.0, -4.0, 0.0, 4.0, 4.0, 4.0, 4.0, 8.0, 4.0, 8.0, 4.0, 4.0, 4.0, 8.0, 8.0, 4.0, 8.0, 4.0, 4.0, 8.0, 4.0, 8.0, -4.0, 0.0, 8.0, 4.0, 0.0, 8.0, 8.0, 4.0, 4.0, -4.0, 4.0, -8.0, 8.0, 8.0, 4.0, -8.0, 0.0], "episode_lengths": [8, 8, 12, 3, 8, 3, 8, 6, 10, 6, 6, 12, 8, 8, 6, 10, 6, 3, 8, 3, 10, 8, 6, 7, 6, 8, 6, 4, 10, 8, 4, 10, 6, 3, 12, 3, 6, 8, 6, 8, 6, 6, 8, 6, 10, 8, 6, 14, 13, 6, 10, 6, 8, 8, 10, 6, 14, 17, 6, 6, 13, 8, 12, 10, 8, 8, 8, 8, 6, 8, 6, 8, 8, 8, 6, 6, 8, 6, 8, 8, 6, 8, 6, 12, 10, 6, 8, 10, 6, 6, 8, 8, 12, 8, 14, 6, 6, 8, 14, 10], "policy_policy0_reward": [12.0, 12.0, -2.0, 7.0, 12.0, 7.0, 12.0, 4.0, 10.0, 14.0, 14.0, 8.0, 12.0, 12.0, 14.0, 10.0, 14.0, 7.0, 12.0, 7.0, 10.0, 12.0, 14.0, 3.0, 14.0, 12.0, 14.0, 6.0, 10.0, 12.0, 6.0, 10.0, 14.0, 7.0, 8.0, 7.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 12.0, 14.0, 10.0, 2.0, 14.0, -4.0, 7.0, 14.0, 0.0, 14.0, 12.0, 12.0, 10.0, 14.0, 6.0, 3.0, 14.0, 14.0, 7.0, 12.0, 8.0, 10.0, 12.0, 12.0, 12.0, 12.0, 14.0, 2.0, 14.0, 12.0, 12.0, 2.0, 14.0, 14.0, 12.0, 4.0, 12.0, 12.0, 14.0, 12.0, 14.0, 8.0, 10.0, 4.0, 12.0, 10.0, 14.0, 14.0, 12.0, 2.0, 8.0, 2.0, 6.0, 14.0, 14.0, 12.0, 6.0, 10.0], "policy_policy1_reward": [-8.0, -8.0, -2.0, 7.0, -8.0, 7.0, -8.0, 4.0, -10.0, -6.0, -6.0, -12.0, -8.0, -8.0, -6.0, -10.0, -6.0, 7.0, -8.0, 7.0, -10.0, -8.0, -6.0, 3.0, -6.0, -8.0, -6.0, 6.0, -10.0, -8.0, 6.0, -10.0, -6.0, 7.0, -12.0, 7.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -8.0, -6.0, -10.0, 2.0, -6.0, -4.0, -13.0, -6.0, 0.0, -6.0, -8.0, -8.0, -10.0, -6.0, -14.0, -17.0, -6.0, -6.0, -13.0, -8.0, -12.0, -10.0, -8.0, -8.0, -8.0, -8.0, -6.0, 2.0, -6.0, -8.0, -8.0, 2.0, -6.0, -6.0, -8.0, 4.0, -8.0, -8.0, -6.0, -8.0, -6.0, -12.0, -10.0, 4.0, -8.0, -10.0, -6.0, -6.0, -8.0, 2.0, -12.0, 2.0, -14.0, -6.0, -6.0, -8.0, -14.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33515363613847143, "mean_inference_ms": 1.7463642291722192, "mean_action_processing_ms": 0.1192533724198899, "mean_env_wait_ms": 0.0752688148401856, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17070, "timesteps_this_iter": 32, "agent_timesteps_total": 34140, "timers": {"load_time_ms": 0.457, "load_throughput": 69996.208, "learn_time_ms": 7.819, "learn_throughput": 4092.403, "update_time_ms": 4.593}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.81629753112793, "min_q": 0.6525050401687622, "max_q": 13.62870979309082, "mean_td_error": 1.0134565830230713, "model": {}}, "td_error": [0.757840633392334, 1.1136665344238281, 0.11393928527832031, 0.1472024917602539, 0.3400082588195801, 0.4726114273071289, 0.8639853000640869, 0.17417168617248535, 0.37470340728759766, 0.5994720458984375, -0.21274375915527344, -0.08429956436157227, 0.20402288436889648, 0.5710458755493164, 1.2070422172546387, -1.0850986242294312, 1.0372910499572754, 1.1800761222839355, 9.22797966003418, -1.7500228881835938, 7.462937831878662, 0.14321184158325195, 0.03339433670043945, 0.046067237854003906, 0.03913688659667969, 3.2400612831115723, 1.7874164581298828, 5.88256311416626, -0.6991919279098511, -0.8699064254760742, 0.2008647918701172, -0.08884155750274658], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.3323664665222168, "min_q": -7.4529008865356445, "max_q": 6.444113731384277, "mean_td_error": 0.06580451130867004, "model": {}}, "td_error": [-4.553001403808594, 2.052780866622925, 1.6824989318847656, -5.624657154083252, -3.7617275714874268, -1.542806625366211, -1.2769112586975098, -0.6657342910766602, 0.3482799530029297, 1.349992275238037, 1.2656946182250977, -11.297222137451172, -6.4529008865356445, -3.548255681991577, 0.2476811408996582, 2.039884090423584, -0.27909111976623535, 2.4063735008239746, 1.7567720413208008, -2.5558862686157227, 1.8935205936431885, 0.7965617179870605, -2.741408348083496, 1.3575711250305176, 0.7145414352416992, 7.160451889038086, 4.135034561157227, 6.531499862670898, -1.0979256629943848, 4.533186912536621, 5.1200642585754395, 2.1108803749084473], "custom_metrics": {}}}, "num_steps_sampled": 17070, "num_agent_steps_sampled": 34140, "num_steps_trained": 39712, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 79424, "last_target_update_ts": 17070, "num_target_updates": 149}, "done": false, "episodes_total": 1336, "training_iteration": 66, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-42", "timestamp": 1648811742, "time_this_iter_s": 1.185495376586914, "time_total_s": 78.44665122032166, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 78.44665122032166, "timesteps_since_restore": 2112, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 32.3, "ram_util_percent": 58.95}}
{"episode_reward_max": 14.0, "episode_reward_min": -14.0, "episode_reward_mean": 3.68, "episode_len_mean": 8.16, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"policy0": -4.0, "policy1": -17.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 9.94, "policy1": -6.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, 0.0, 4.0, 12.0, 0.0, 8.0, 14.0, -4.0, 14.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 4.0, 8.0, 0.0, 4.0, 8.0, -8.0, -6.0, 8.0, 0.0, 8.0, 4.0, 4.0, 0.0, 8.0, -8.0, -14.0, 8.0, 8.0, -6.0, 4.0, -4.0, 0.0, 4.0, 4.0, 4.0, 4.0, 8.0, 4.0, 8.0, 4.0, 4.0, 4.0, 8.0, 8.0, 4.0, 8.0, 4.0, 4.0, 8.0, 4.0, 8.0, -4.0, 0.0, 8.0, 4.0, 0.0, 8.0, 8.0, 4.0, 4.0, -4.0, 4.0, -8.0, 8.0, 8.0, 4.0, -8.0, 0.0, 0.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 8.0, 6.0, 8.0, -12.0, 12.0, 4.0, 0.0, 8.0, 4.0, 0.0, 0.0, 0.0, 8.0, 4.0, 4.0, 0.0, -8.0], "episode_lengths": [4, 10, 8, 4, 10, 6, 3, 12, 3, 6, 8, 6, 8, 6, 6, 8, 6, 10, 8, 6, 14, 13, 6, 10, 6, 8, 8, 10, 6, 14, 17, 6, 6, 13, 8, 12, 10, 8, 8, 8, 8, 6, 8, 6, 8, 8, 8, 6, 6, 8, 6, 8, 8, 6, 8, 6, 12, 10, 6, 8, 10, 6, 6, 8, 8, 12, 8, 14, 6, 6, 8, 14, 10, 10, 6, 6, 8, 6, 6, 6, 10, 6, 10, 6, 7, 6, 16, 4, 8, 10, 6, 8, 10, 10, 10, 6, 8, 8, 10, 14], "policy_policy0_reward": [6.0, 10.0, 12.0, 6.0, 10.0, 14.0, 7.0, 8.0, 7.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 12.0, 14.0, 10.0, 2.0, 14.0, -4.0, 7.0, 14.0, 0.0, 14.0, 12.0, 12.0, 10.0, 14.0, 6.0, 3.0, 14.0, 14.0, 7.0, 12.0, 8.0, 10.0, 12.0, 12.0, 12.0, 12.0, 14.0, 2.0, 14.0, 12.0, 12.0, 2.0, 14.0, 14.0, 12.0, 4.0, 12.0, 12.0, 14.0, 12.0, 14.0, 8.0, 10.0, 4.0, 12.0, 10.0, 14.0, 14.0, 12.0, 2.0, 8.0, 2.0, 6.0, 14.0, 14.0, 12.0, 6.0, 10.0, 10.0, 4.0, 14.0, 2.0, 14.0, 14.0, 14.0, 10.0, 14.0, 0.0, 4.0, 3.0, 14.0, 4.0, 6.0, 12.0, 10.0, 14.0, 12.0, 10.0, 10.0, 10.0, 14.0, 12.0, 12.0, 10.0, 6.0], "policy_policy1_reward": [6.0, -10.0, -8.0, 6.0, -10.0, -6.0, 7.0, -12.0, 7.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -8.0, -6.0, -10.0, 2.0, -6.0, -4.0, -13.0, -6.0, 0.0, -6.0, -8.0, -8.0, -10.0, -6.0, -14.0, -17.0, -6.0, -6.0, -13.0, -8.0, -12.0, -10.0, -8.0, -8.0, -8.0, -8.0, -6.0, 2.0, -6.0, -8.0, -8.0, 2.0, -6.0, -6.0, -8.0, 4.0, -8.0, -8.0, -6.0, -8.0, -6.0, -12.0, -10.0, 4.0, -8.0, -10.0, -6.0, -6.0, -8.0, 2.0, -12.0, 2.0, -14.0, -6.0, -6.0, -8.0, -14.0, -10.0, -10.0, 4.0, -6.0, 2.0, -6.0, -6.0, -6.0, -10.0, -6.0, 0.0, 4.0, 3.0, -6.0, -16.0, 6.0, -8.0, -10.0, -6.0, -8.0, -10.0, -10.0, -10.0, -6.0, -8.0, -8.0, -10.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33542906686402957, "mean_inference_ms": 1.7451486588616263, "mean_action_processing_ms": 0.11915403600014379, "mean_env_wait_ms": 0.0752368605220866, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17291, "timesteps_this_iter": 32, "agent_timesteps_total": 34582, "timers": {"load_time_ms": 0.446, "load_throughput": 71731.991, "learn_time_ms": 8.033, "learn_throughput": 3983.325, "update_time_ms": 4.984}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.083752632141113, "min_q": -1.672441840171814, "max_q": 14.955362319946289, "mean_td_error": 0.4623146653175354, "model": {}}, "td_error": [0.09708118438720703, 0.49013614654541016, 0.7154293060302734, -0.007122039794921875, -0.12572288513183594, -0.12572288513183594, 0.15955352783203125, 0.549809455871582, 11.225019454956055, -0.15268707275390625, 9.152402877807617, -0.672441840171814, -0.012638092041015625, 0.018564224243164062, -1.3141460418701172, -0.6986246109008789, 0.4318995475769043, 0.01598358154296875, -0.12572288513183594, -0.7268862724304199, -1.0837669372558594, -0.6346616744995117, 0.16736745834350586, 0.6413767337799072, -1.9141197204589844, -0.06570816040039062, 0.5206918716430664, 0.5206918716430664, -0.1009368896484375, -0.7430167198181152, -0.7715749740600586, -0.6364383697509766], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.3517327308654785, "min_q": -7.810408115386963, "max_q": 8.263147354125977, "mean_td_error": -1.7472195625305176, "model": {}}, "td_error": [-0.8738718032836914, 1.0524663925170898, -14.408248901367188, -0.0067059993743896484, -3.5659618377685547, -0.6420397758483887, -0.26999855041503906, -7.745616436004639, -2.8590378761291504, -4.965510368347168, -1.8588588237762451, 1.5464720726013184, -0.9159302711486816, 0.8769350051879883, 0.13296103477478027, 0.07071685791015625, -0.7368526458740234, -6.5060625076293945, -5.027518272399902, -1.1723003387451172, 3.0520448684692383, -6.469236373901367, -5.7794294357299805, -4.624296188354492, 0.4296565055847168, 1.029137134552002, 0.7676501274108887, -1.0838046073913574, -0.8270854949951172, 0.5566306114196777, -1.6993191242218018, 6.611985206604004], "custom_metrics": {}}}, "num_steps_sampled": 17291, "num_agent_steps_sampled": 34582, "num_steps_trained": 40576, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 81152, "last_target_update_ts": 17291, "num_target_updates": 151}, "done": false, "episodes_total": 1363, "training_iteration": 67, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-44", "timestamp": 1648811744, "time_this_iter_s": 1.309387445449829, "time_total_s": 79.75603866577148, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bb0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 79.75603866577148, "timesteps_since_restore": 2144, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 31.4, "ram_util_percent": 59.0}}
{"episode_reward_max": 14.0, "episode_reward_min": -14.0, "episode_reward_mean": 3.44, "episode_len_mean": 8.28, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"policy0": -2.0, "policy1": -17.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 9.82, "policy1": -6.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 0.0, 8.0, -8.0, -14.0, 8.0, 8.0, -6.0, 4.0, -4.0, 0.0, 4.0, 4.0, 4.0, 4.0, 8.0, 4.0, 8.0, 4.0, 4.0, 4.0, 8.0, 8.0, 4.0, 8.0, 4.0, 4.0, 8.0, 4.0, 8.0, -4.0, 0.0, 8.0, 4.0, 0.0, 8.0, 8.0, 4.0, 4.0, -4.0, 4.0, -8.0, 8.0, 8.0, 4.0, -8.0, 0.0, 0.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 8.0, 6.0, 8.0, -12.0, 12.0, 4.0, 0.0, 8.0, 4.0, 0.0, 0.0, 0.0, 8.0, 4.0, 4.0, 0.0, -8.0, 8.0, 0.0, 8.0, 10.0, 4.0, 0.0, 4.0, 6.0, 0.0, 8.0, 0.0, 8.0, -4.0, 14.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 0.0, 4.0, -4.0, 0.0, 8.0, -8.0], "episode_lengths": [8, 10, 6, 14, 17, 6, 6, 13, 8, 12, 10, 8, 8, 8, 8, 6, 8, 6, 8, 8, 8, 6, 6, 8, 6, 8, 8, 6, 8, 6, 12, 10, 6, 8, 10, 6, 6, 8, 8, 12, 8, 14, 6, 6, 8, 14, 10, 10, 6, 6, 8, 6, 6, 6, 10, 6, 10, 6, 7, 6, 16, 4, 8, 10, 6, 8, 10, 10, 10, 6, 8, 8, 10, 14, 6, 10, 6, 5, 8, 10, 8, 7, 10, 6, 10, 6, 12, 3, 6, 6, 8, 8, 6, 6, 10, 8, 12, 10, 6, 14], "policy_policy0_reward": [12.0, 10.0, 14.0, 6.0, 3.0, 14.0, 14.0, 7.0, 12.0, 8.0, 10.0, 12.0, 12.0, 12.0, 12.0, 14.0, 2.0, 14.0, 12.0, 12.0, 2.0, 14.0, 14.0, 12.0, 4.0, 12.0, 12.0, 14.0, 12.0, 14.0, 8.0, 10.0, 4.0, 12.0, 10.0, 14.0, 14.0, 12.0, 2.0, 8.0, 2.0, 6.0, 14.0, 14.0, 12.0, 6.0, 10.0, 10.0, 4.0, 14.0, 2.0, 14.0, 14.0, 14.0, 10.0, 14.0, 0.0, 4.0, 3.0, 14.0, 4.0, 6.0, 12.0, 10.0, 14.0, 12.0, 10.0, 10.0, 10.0, 14.0, 12.0, 12.0, 10.0, 6.0, 14.0, 10.0, 14.0, 5.0, 12.0, 10.0, 2.0, 3.0, 10.0, 14.0, 0.0, 14.0, 8.0, 7.0, 14.0, 14.0, 12.0, 12.0, 4.0, 14.0, 10.0, 12.0, -2.0, 10.0, 14.0, 6.0], "policy_policy1_reward": [-8.0, -10.0, -6.0, -14.0, -17.0, -6.0, -6.0, -13.0, -8.0, -12.0, -10.0, -8.0, -8.0, -8.0, -8.0, -6.0, 2.0, -6.0, -8.0, -8.0, 2.0, -6.0, -6.0, -8.0, 4.0, -8.0, -8.0, -6.0, -8.0, -6.0, -12.0, -10.0, 4.0, -8.0, -10.0, -6.0, -6.0, -8.0, 2.0, -12.0, 2.0, -14.0, -6.0, -6.0, -8.0, -14.0, -10.0, -10.0, 4.0, -6.0, 2.0, -6.0, -6.0, -6.0, -10.0, -6.0, 0.0, 4.0, 3.0, -6.0, -16.0, 6.0, -8.0, -10.0, -6.0, -8.0, -10.0, -10.0, -10.0, -6.0, -8.0, -8.0, -10.0, -14.0, -6.0, -10.0, -6.0, 5.0, -8.0, -10.0, 2.0, 3.0, -10.0, -6.0, 0.0, -6.0, -12.0, 7.0, -6.0, -6.0, -8.0, -8.0, 4.0, -6.0, -10.0, -8.0, -2.0, -10.0, -6.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3356740783942938, "mean_inference_ms": 1.7442426988888657, "mean_action_processing_ms": 0.11907819472542418, "mean_env_wait_ms": 0.07520873217618766, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17498, "timesteps_this_iter": 32, "agent_timesteps_total": 34996, "timers": {"load_time_ms": 0.426, "load_throughput": 75137.283, "learn_time_ms": 7.812, "learn_throughput": 4096.375, "update_time_ms": 4.608}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.037691593170166, "min_q": -0.30400019884109497, "max_q": 15.024538040161133, "mean_td_error": 0.7962669730186462, "model": {}}, "td_error": [1.1809062957763672, -0.4200315475463867, -0.37636518478393555, 0.10227108001708984, 4.150089263916016, 0.5523483753204346, -0.9895787239074707, 0.15151309967041016, -0.30276060104370117, -0.3695354461669922, 0.5272989273071289, 0.14747381210327148, -1.317582130432129, -0.7023239135742188, 0.23094844818115234, 2.74361515045166, 1.1809062957763672, 0.8575301170349121, 0.45428943634033203, -0.1531982421875, 1.6779747009277344, -0.3707275390625, 6.556412696838379, 0.538149893283844, 2.353236198425293, 6.445565223693848, -0.8753619194030762, -0.2519216537475586, 1.2231321334838867, 0.2055072784423828, 0.17795085906982422, 0.15280961990356445], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.8733056783676147, "min_q": -7.065221309661865, "max_q": 5.108453750610352, "mean_td_error": -0.5228412747383118, "model": {}}, "td_error": [-4.0011725425720215, -1.1401888132095337, -1.6838266849517822, -1.1155710220336914, 2.3952476978302, 2.191869020462036, -2.1517574787139893, 5.577056407928467, 1.5089335441589355, -3.8049349784851074, -3.6063709259033203, -3.7726755142211914, -9.124063491821289, 5.577056407928467, 0.42900681495666504, 6.808035850524902, -6.945364475250244, 1.5907344818115234, 3.037635326385498, 1.6222182512283325, 2.1606955528259277, -2.4782791137695312, -2.8848140239715576, 0.29572153091430664, 1.532351016998291, -3.4905121326446533, 2.574005365371704, -0.7042073607444763, 1.358588695526123, -3.8915462493896484, 0.34632086753845215, -4.941112041473389], "custom_metrics": {}}}, "num_steps_sampled": 17498, "num_agent_steps_sampled": 34996, "num_steps_trained": 41376, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 82752, "last_target_update_ts": 17498, "num_target_updates": 153}, "done": false, "episodes_total": 1389, "training_iteration": 68, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-45", "timestamp": 1648811745, "time_this_iter_s": 1.2311151027679443, "time_total_s": 80.98715376853943, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 80.98715376853943, "timesteps_since_restore": 2176, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 30.450000000000003, "ram_util_percent": 59.0}}
{"episode_reward_max": 14.0, "episode_reward_min": -16.0, "episode_reward_mean": 3.38, "episode_len_mean": 8.31, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"policy0": -13.0, "policy1": -18.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 9.09, "policy1": -5.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 4.0, 4.0, 8.0, 4.0, 8.0, -4.0, 0.0, 8.0, 4.0, 0.0, 8.0, 8.0, 4.0, 4.0, -4.0, 4.0, -8.0, 8.0, 8.0, 4.0, -8.0, 0.0, 0.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 8.0, 6.0, 8.0, -12.0, 12.0, 4.0, 0.0, 8.0, 4.0, 0.0, 0.0, 0.0, 8.0, 4.0, 4.0, 0.0, -8.0, 8.0, 0.0, 8.0, 10.0, 4.0, 0.0, 4.0, 6.0, 0.0, 8.0, 0.0, 8.0, -4.0, 14.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 0.0, 4.0, -4.0, 0.0, 8.0, -8.0, -6.0, 8.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 0.0, -2.0, 12.0, 14.0, 4.0, -4.0, 0.0, 4.0, -16.0, -8.0, -4.0, 4.0, 8.0], "episode_lengths": [6, 8, 8, 6, 8, 6, 12, 10, 6, 8, 10, 6, 6, 8, 8, 12, 8, 14, 6, 6, 8, 14, 10, 10, 6, 6, 8, 6, 6, 6, 10, 6, 10, 6, 7, 6, 16, 4, 8, 10, 6, 8, 10, 10, 10, 6, 8, 8, 10, 14, 6, 10, 6, 5, 8, 10, 8, 7, 10, 6, 10, 6, 12, 3, 6, 6, 8, 8, 6, 6, 10, 8, 12, 10, 6, 14, 13, 6, 6, 10, 6, 6, 6, 6, 10, 6, 10, 10, 11, 4, 3, 8, 12, 10, 8, 18, 14, 12, 8, 6], "policy_policy0_reward": [4.0, 12.0, 12.0, 14.0, 12.0, 14.0, 8.0, 10.0, 4.0, 12.0, 10.0, 14.0, 14.0, 12.0, 2.0, 8.0, 2.0, 6.0, 14.0, 14.0, 12.0, 6.0, 10.0, 10.0, 4.0, 14.0, 2.0, 14.0, 14.0, 14.0, 10.0, 14.0, 0.0, 4.0, 3.0, 14.0, 4.0, 6.0, 12.0, 10.0, 14.0, 12.0, 10.0, 10.0, 10.0, 14.0, 12.0, 12.0, 10.0, 6.0, 14.0, 10.0, 14.0, 5.0, 12.0, 10.0, 2.0, 3.0, 10.0, 14.0, 0.0, 14.0, 8.0, 7.0, 14.0, 14.0, 12.0, 12.0, 4.0, 14.0, 10.0, 12.0, -2.0, 10.0, 14.0, 6.0, -13.0, 14.0, 14.0, 10.0, 14.0, 4.0, 14.0, 14.0, 10.0, 4.0, 10.0, 10.0, -1.0, 6.0, 7.0, 2.0, 8.0, 10.0, 2.0, 2.0, 6.0, 8.0, 12.0, 14.0], "policy_policy1_reward": [4.0, -8.0, -8.0, -6.0, -8.0, -6.0, -12.0, -10.0, 4.0, -8.0, -10.0, -6.0, -6.0, -8.0, 2.0, -12.0, 2.0, -14.0, -6.0, -6.0, -8.0, -14.0, -10.0, -10.0, 4.0, -6.0, 2.0, -6.0, -6.0, -6.0, -10.0, -6.0, 0.0, 4.0, 3.0, -6.0, -16.0, 6.0, -8.0, -10.0, -6.0, -8.0, -10.0, -10.0, -10.0, -6.0, -8.0, -8.0, -10.0, -14.0, -6.0, -10.0, -6.0, 5.0, -8.0, -10.0, 2.0, 3.0, -10.0, -6.0, 0.0, -6.0, -12.0, 7.0, -6.0, -6.0, -8.0, -8.0, 4.0, -6.0, -10.0, -8.0, -2.0, -10.0, -6.0, -14.0, 7.0, -6.0, -6.0, -10.0, -6.0, 4.0, -6.0, -6.0, -10.0, 4.0, -10.0, -10.0, -1.0, 6.0, 7.0, 2.0, -12.0, -10.0, 2.0, -18.0, -14.0, -12.0, -8.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33596551507224726, "mean_inference_ms": 1.7438058729714532, "mean_action_processing_ms": 0.11903996045042514, "mean_env_wait_ms": 0.07520332573305823, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17707, "timesteps_this_iter": 32, "agent_timesteps_total": 35414, "timers": {"load_time_ms": 0.418, "load_throughput": 76603.92, "learn_time_ms": 7.915, "learn_throughput": 4043.019, "update_time_ms": 4.587}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.25647497177124, "min_q": 0.5112638473510742, "max_q": 15.108378410339355, "mean_td_error": 0.12916147708892822, "model": {}}, "td_error": [-0.023030757904052734, 0.6796159744262695, -4.308122634887695, 4.491447448730469, -0.9413690567016602, -3.1989898681640625, 0.5478253364562988, 0.8543505668640137, -0.6131668090820312, 0.29110586643218994, -2.2261457443237305, 8.178793907165527, -0.16237330436706543, 0.7886357307434082, -0.32168054580688477, 5.998435020446777, -0.0715336799621582, -3.363166332244873, 0.7190237045288086, -1.4174532890319824, 0.41181039810180664, -0.9678964614868164, 0.3125114440917969, -1.3321142196655273, 0.11133193969726562, -0.8778476715087891, 0.5741987228393555, 1.8223447799682617, -2.0123744010925293, 0.13741827011108398, 1.0324487686157227, -0.980865478515625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.746514081954956, "min_q": -7.35146427154541, "max_q": 4.902419090270996, "mean_td_error": 0.855442225933075, "model": {}}, "td_error": [7.7620015144348145, -0.18645000457763672, 4.7581586837768555, 0.07381486892700195, 4.7581586837768555, 1.7869982719421387, 0.3893442153930664, 0.06422662734985352, -0.17794251441955566, 1.9794824123382568, 2.525627613067627, 3.5938193798065186, 1.1866393089294434, 3.484217643737793, -5.70973539352417, 2.3316802978515625, 2.73638916015625, -2.1161386966705322, -2.816368579864502, -1.215165615081787, -0.4131917953491211, -0.4406759738922119, -0.1678149700164795, 2.1654696464538574, -3.133580207824707, -1.1557040214538574, 0.49852991104125977, -0.21016883850097656, 0.5735917091369629, 0.9112467765808105, 0.7631330490112305, 2.774559259414673], "custom_metrics": {}}}, "num_steps_sampled": 17707, "num_agent_steps_sampled": 35414, "num_steps_trained": 42112, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 84224, "last_target_update_ts": 17707, "num_target_updates": 155}, "done": false, "episodes_total": 1413, "training_iteration": 69, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-46", "timestamp": 1648811746, "time_this_iter_s": 1.1475937366485596, "time_total_s": 82.13474750518799, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58476cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 82.13474750518799, "timesteps_since_restore": 2208, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 30.4, "ram_util_percent": 59.1}}
{"episode_reward_max": 14.0, "episode_reward_min": -16.0, "episode_reward_mean": 3.4, "episode_len_mean": 8.3, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"policy0": -13.0, "policy1": -18.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 9.1, "policy1": -5.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 8.0, 6.0, 8.0, -12.0, 12.0, 4.0, 0.0, 8.0, 4.0, 0.0, 0.0, 0.0, 8.0, 4.0, 4.0, 0.0, -8.0, 8.0, 0.0, 8.0, 10.0, 4.0, 0.0, 4.0, 6.0, 0.0, 8.0, 0.0, 8.0, -4.0, 14.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 0.0, 4.0, -4.0, 0.0, 8.0, -8.0, -6.0, 8.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 0.0, -2.0, 12.0, 14.0, 4.0, -4.0, 0.0, 4.0, -16.0, -8.0, -4.0, 4.0, 8.0, 0.0, -4.0, 8.0, 4.0, -8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 10.0, 4.0, 0.0, 4.0, 4.0, 8.0, -8.0, 4.0, 4.0, 0.0, -12.0, 8.0, 8.0], "episode_lengths": [6, 6, 8, 6, 6, 6, 10, 6, 10, 6, 7, 6, 16, 4, 8, 10, 6, 8, 10, 10, 10, 6, 8, 8, 10, 14, 6, 10, 6, 5, 8, 10, 8, 7, 10, 6, 10, 6, 12, 3, 6, 6, 8, 8, 6, 6, 10, 8, 12, 10, 6, 14, 13, 6, 6, 10, 6, 6, 6, 6, 10, 6, 10, 10, 11, 4, 3, 8, 12, 10, 8, 18, 14, 12, 8, 6, 10, 12, 6, 8, 14, 8, 8, 6, 6, 6, 6, 5, 8, 10, 8, 8, 6, 14, 8, 8, 10, 16, 6, 6], "policy_policy0_reward": [4.0, 14.0, 2.0, 14.0, 14.0, 14.0, 10.0, 14.0, 0.0, 4.0, 3.0, 14.0, 4.0, 6.0, 12.0, 10.0, 14.0, 12.0, 10.0, 10.0, 10.0, 14.0, 12.0, 12.0, 10.0, 6.0, 14.0, 10.0, 14.0, 5.0, 12.0, 10.0, 2.0, 3.0, 10.0, 14.0, 0.0, 14.0, 8.0, 7.0, 14.0, 14.0, 12.0, 12.0, 4.0, 14.0, 10.0, 12.0, -2.0, 10.0, 14.0, 6.0, -13.0, 14.0, 14.0, 10.0, 14.0, 4.0, 14.0, 14.0, 10.0, 4.0, 10.0, 10.0, -1.0, 6.0, 7.0, 2.0, 8.0, 10.0, 2.0, 2.0, 6.0, 8.0, 12.0, 14.0, 10.0, 8.0, 14.0, 12.0, 6.0, 12.0, 2.0, 14.0, 14.0, 14.0, 14.0, 5.0, 12.0, 10.0, 2.0, 12.0, 14.0, 6.0, 2.0, 12.0, 10.0, 4.0, 14.0, 14.0], "policy_policy1_reward": [4.0, -6.0, 2.0, -6.0, -6.0, -6.0, -10.0, -6.0, 0.0, 4.0, 3.0, -6.0, -16.0, 6.0, -8.0, -10.0, -6.0, -8.0, -10.0, -10.0, -10.0, -6.0, -8.0, -8.0, -10.0, -14.0, -6.0, -10.0, -6.0, 5.0, -8.0, -10.0, 2.0, 3.0, -10.0, -6.0, 0.0, -6.0, -12.0, 7.0, -6.0, -6.0, -8.0, -8.0, 4.0, -6.0, -10.0, -8.0, -2.0, -10.0, -6.0, -14.0, 7.0, -6.0, -6.0, -10.0, -6.0, 4.0, -6.0, -6.0, -10.0, 4.0, -10.0, -10.0, -1.0, 6.0, 7.0, 2.0, -12.0, -10.0, 2.0, -18.0, -14.0, -12.0, -8.0, -6.0, -10.0, -12.0, -6.0, -8.0, -14.0, -8.0, 2.0, -6.0, -6.0, -6.0, -6.0, 5.0, -8.0, -10.0, 2.0, -8.0, -6.0, -14.0, 2.0, -8.0, -10.0, -16.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33626748753475233, "mean_inference_ms": 1.7434841149116493, "mean_action_processing_ms": 0.11901440154036193, "mean_env_wait_ms": 0.07520890142236132, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17910, "timesteps_this_iter": 32, "agent_timesteps_total": 35820, "timers": {"load_time_ms": 0.436, "load_throughput": 73419.248, "learn_time_ms": 7.756, "learn_throughput": 4125.854, "update_time_ms": 4.893}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.179121017456055, "min_q": 0.004838332533836365, "max_q": 12.741576194763184, "mean_td_error": 0.7709173560142517, "model": {}}, "td_error": [0.5642080307006836, 1.2215614318847656, 0.09830760955810547, 0.3881707191467285, 0.8305168151855469, 1.345667839050293, 1.0048383474349976, -0.06664752960205078, -3.022817611694336, 1.7435855865478516, -0.628209114074707, -0.29218292236328125, -2.821442127227783, -0.7833538055419922, -0.7156972885131836, -1.1148462295532227, -0.6361854076385498, 4.517486095428467, 1.7435855865478516, -0.5095558166503906, -0.6936187744140625, 2.184751510620117, 11.936148643493652, -0.023506641387939453, -1.806447982788086, -0.2979898452758789, 8.04647159576416, 0.32291364669799805, -0.8302793502807617, 3.0244765281677246, -0.5095539093017578, 0.4490013122558594], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.757399797439575, "min_q": -7.451732158660889, "max_q": 4.928818702697754, "mean_td_error": -1.3564233779907227, "model": {}}, "td_error": [0.28354597091674805, 0.14484214782714844, -0.45368289947509766, -1.7354118824005127, 0.7836613655090332, 0.49236297607421875, -4.431017875671387, 3.1250834465026855, -1.3284471035003662, -0.3626260757446289, -6.477267265319824, 0.08660888671875, 2.316319465637207, -1.842902660369873, 1.0006437301635742, -3.4084525108337402, -7.127156734466553, 0.028204500675201416, -1.9954164028167725, -6.02418327331543, 0.028204500675201416, 0.2634110450744629, -6.477267265319824, 3.485734462738037, 1.800546407699585, -0.4077014923095703, 2.514369010925293, -1.4880151748657227, -1.167755126953125, -14.652877807617188, -0.24876642227172852, -0.13013505935668945], "custom_metrics": {}}}, "num_steps_sampled": 17910, "num_agent_steps_sampled": 35820, "num_steps_trained": 42880, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 85760, "last_target_update_ts": 17810, "num_target_updates": 156}, "done": false, "episodes_total": 1437, "training_iteration": 70, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-48", "timestamp": 1648811748, "time_this_iter_s": 1.1375117301940918, "time_total_s": 83.27225923538208, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 83.27225923538208, "timesteps_since_restore": 2240, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 34.45, "ram_util_percent": 59.1}}
{"episode_reward_max": 14.0, "episode_reward_min": -16.0, "episode_reward_mean": 3.56, "episode_len_mean": 8.22, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"policy0": -13.0, "policy1": -18.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 8.98, "policy1": -5.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 8.0, 10.0, 4.0, 0.0, 4.0, 6.0, 0.0, 8.0, 0.0, 8.0, -4.0, 14.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 0.0, 4.0, -4.0, 0.0, 8.0, -8.0, -6.0, 8.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 0.0, -2.0, 12.0, 14.0, 4.0, -4.0, 0.0, 4.0, -16.0, -8.0, -4.0, 4.0, 8.0, 0.0, -4.0, 8.0, 4.0, -8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 10.0, 4.0, 0.0, 4.0, 4.0, 8.0, -8.0, 4.0, 4.0, 0.0, -12.0, 8.0, 8.0, 8.0, -4.0, 4.0, 8.0, 4.0, 8.0, 8.0, 0.0, 8.0, -4.0, 8.0, 14.0, -10.0, 6.0, -4.0, 8.0, 8.0, 10.0, 10.0, 0.0, 4.0, 4.0, 4.0, 0.0, 4.0, 8.0, 8.0], "episode_lengths": [10, 6, 5, 8, 10, 8, 7, 10, 6, 10, 6, 12, 3, 6, 6, 8, 8, 6, 6, 10, 8, 12, 10, 6, 14, 13, 6, 6, 10, 6, 6, 6, 6, 10, 6, 10, 10, 11, 4, 3, 8, 12, 10, 8, 18, 14, 12, 8, 6, 10, 12, 6, 8, 14, 8, 8, 6, 6, 6, 6, 5, 8, 10, 8, 8, 6, 14, 8, 8, 10, 16, 6, 6, 6, 12, 8, 6, 8, 6, 6, 10, 6, 12, 6, 3, 15, 7, 12, 6, 6, 5, 5, 10, 8, 8, 8, 10, 8, 6, 6], "policy_policy0_reward": [10.0, 14.0, 5.0, 12.0, 10.0, 2.0, 3.0, 10.0, 14.0, 0.0, 14.0, 8.0, 7.0, 14.0, 14.0, 12.0, 12.0, 4.0, 14.0, 10.0, 12.0, -2.0, 10.0, 14.0, 6.0, -13.0, 14.0, 14.0, 10.0, 14.0, 4.0, 14.0, 14.0, 10.0, 4.0, 10.0, 10.0, -1.0, 6.0, 7.0, 2.0, 8.0, 10.0, 2.0, 2.0, 6.0, 8.0, 12.0, 14.0, 10.0, 8.0, 14.0, 12.0, 6.0, 12.0, 2.0, 14.0, 14.0, 14.0, 14.0, 5.0, 12.0, 10.0, 2.0, 12.0, 14.0, 6.0, 2.0, 12.0, 10.0, 4.0, 14.0, 14.0, 4.0, 8.0, 2.0, 14.0, 12.0, 14.0, 14.0, 10.0, 14.0, 8.0, 14.0, 7.0, 5.0, 3.0, -2.0, 14.0, 14.0, 5.0, 5.0, 10.0, 2.0, 12.0, 12.0, 10.0, 12.0, 14.0, 14.0], "policy_policy1_reward": [-10.0, -6.0, 5.0, -8.0, -10.0, 2.0, 3.0, -10.0, -6.0, 0.0, -6.0, -12.0, 7.0, -6.0, -6.0, -8.0, -8.0, 4.0, -6.0, -10.0, -8.0, -2.0, -10.0, -6.0, -14.0, 7.0, -6.0, -6.0, -10.0, -6.0, 4.0, -6.0, -6.0, -10.0, 4.0, -10.0, -10.0, -1.0, 6.0, 7.0, 2.0, -12.0, -10.0, 2.0, -18.0, -14.0, -12.0, -8.0, -6.0, -10.0, -12.0, -6.0, -8.0, -14.0, -8.0, 2.0, -6.0, -6.0, -6.0, -6.0, 5.0, -8.0, -10.0, 2.0, -8.0, -6.0, -14.0, 2.0, -8.0, -10.0, -16.0, -6.0, -6.0, 4.0, -12.0, 2.0, -6.0, -8.0, -6.0, -6.0, -10.0, -6.0, -12.0, -6.0, 7.0, -15.0, 3.0, -2.0, -6.0, -6.0, 5.0, 5.0, -10.0, 2.0, -8.0, -8.0, -10.0, -8.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33652291123766964, "mean_inference_ms": 1.7426685904105046, "mean_action_processing_ms": 0.11895471590630766, "mean_env_wait_ms": 0.07519933632258181, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18119, "timesteps_this_iter": 32, "agent_timesteps_total": 36238, "timers": {"load_time_ms": 0.445, "load_throughput": 71908.775, "learn_time_ms": 7.489, "learn_throughput": 4273.048, "update_time_ms": 4.634}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.610118389129639, "min_q": -0.9304571747779846, "max_q": 12.54098129272461, "mean_td_error": 0.9611049890518188, "model": {}}, "td_error": [-0.816687822341919, -0.8327198028564453, -0.1184084415435791, 7.109194278717041, -0.04373741149902344, 0.329559326171875, 1.5275774002075195, 5.70615291595459, 0.4241032600402832, 8.695310592651367, 5.389955520629883, 0.46935105323791504, -2.3586912155151367, 0.1589679718017578, 0.46718430519104004, -0.8765730857849121, 0.454742431640625, 0.14860916137695312, 0.7034955024719238, -0.8604526519775391, -0.9506827592849731, 0.6204795837402344, -0.29306888580322266, -0.30243682861328125, 1.2842869758605957, 7.269800186157227, -0.7322118282318115, -0.19125747680664062, 0.06954282522201538, -0.6595258712768555, 1.1784858703613281, -2.21498703956604], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.1762590408325195, "min_q": -9.691119194030762, "max_q": 9.688336372375488, "mean_td_error": 0.6077964305877686, "model": {}}, "td_error": [-1.1038427352905273, 7.002711772918701, 1.249007225036621, 4.3402838706970215, -1.3091440200805664, 2.1724853515625, 8.74962043762207, -3.8074917793273926, 0.7421116828918457, -2.498049736022949, -2.493377208709717, 0.49985313415527344, -7.018121719360352, 0.09774303436279297, 5.863165855407715, 1.1616010665893555, -1.364466667175293, 2.3127636909484863, -1.6517620086669922, 0.1699085235595703, 1.578155517578125, 0.5713129043579102, -0.20730113983154297, -3.338644504547119, 0.39853811264038086, 1.183553695678711, -0.5470929145812988, -2.135120391845703, 1.3757386207580566, 0.2622861862182617, 5.863164901733398, 1.32989501953125], "custom_metrics": {}}}, "num_steps_sampled": 18119, "num_agent_steps_sampled": 36238, "num_steps_trained": 43712, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 87424, "last_target_update_ts": 18021, "num_target_updates": 158}, "done": false, "episodes_total": 1464, "training_iteration": 71, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-49", "timestamp": 1648811749, "time_this_iter_s": 1.1708176136016846, "time_total_s": 84.44307684898376, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58408dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58408dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 84.44307684898376, "timesteps_since_restore": 2272, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 31.0, "ram_util_percent": 59.1}}
{"episode_reward_max": 14.0, "episode_reward_min": -16.0, "episode_reward_mean": 4.4, "episode_len_mean": 7.8, "episode_media": {}, "episodes_this_iter": 31, "policy_reward_min": {"policy0": -2.0, "policy1": -18.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 9.2, "policy1": -4.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 0.0, 8.0, 0.0, 0.0, -2.0, 12.0, 14.0, 4.0, -4.0, 0.0, 4.0, -16.0, -8.0, -4.0, 4.0, 8.0, 0.0, -4.0, 8.0, 4.0, -8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 10.0, 4.0, 0.0, 4.0, 4.0, 8.0, -8.0, 4.0, 4.0, 0.0, -12.0, 8.0, 8.0, 8.0, -4.0, 4.0, 8.0, 4.0, 8.0, 8.0, 0.0, 8.0, -4.0, 8.0, 14.0, -10.0, 6.0, -4.0, 8.0, 8.0, 10.0, 10.0, 0.0, 4.0, 4.0, 4.0, 0.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 10.0, 8.0, 0.0, -4.0, 0.0, 4.0, 8.0, 8.0, 8.0, 0.0, 8.0, 4.0, 4.0, 0.0, 8.0, 8.0, 14.0, 8.0, 10.0, -4.0, 10.0, 14.0, 6.0, 12.0, 14.0, 14.0], "episode_lengths": [6, 6, 10, 6, 10, 10, 11, 4, 3, 8, 12, 10, 8, 18, 14, 12, 8, 6, 10, 12, 6, 8, 14, 8, 8, 6, 6, 6, 6, 5, 8, 10, 8, 8, 6, 14, 8, 8, 10, 16, 6, 6, 6, 12, 8, 6, 8, 6, 6, 10, 6, 12, 6, 3, 15, 7, 12, 6, 6, 5, 5, 10, 8, 8, 8, 10, 8, 6, 6, 6, 6, 6, 8, 6, 5, 6, 10, 12, 10, 8, 6, 6, 6, 10, 6, 8, 8, 10, 6, 6, 3, 6, 5, 12, 5, 3, 7, 4, 3, 3], "policy_policy0_reward": [14.0, 14.0, 10.0, 4.0, 10.0, 10.0, -1.0, 6.0, 7.0, 2.0, 8.0, 10.0, 2.0, 2.0, 6.0, 8.0, 12.0, 14.0, 10.0, 8.0, 14.0, 12.0, 6.0, 12.0, 2.0, 14.0, 14.0, 14.0, 14.0, 5.0, 12.0, 10.0, 2.0, 12.0, 14.0, 6.0, 2.0, 12.0, 10.0, 4.0, 14.0, 14.0, 4.0, 8.0, 2.0, 14.0, 12.0, 14.0, 14.0, 10.0, 14.0, 8.0, 14.0, 7.0, 5.0, 3.0, -2.0, 14.0, 14.0, 5.0, 5.0, 10.0, 2.0, 12.0, 12.0, 10.0, 12.0, 14.0, 14.0, 4.0, 14.0, 14.0, 12.0, 14.0, 5.0, 14.0, 10.0, 8.0, 10.0, 12.0, 14.0, 14.0, 14.0, 10.0, 14.0, 12.0, 12.0, 10.0, 14.0, 4.0, 7.0, 14.0, 5.0, -2.0, 5.0, 7.0, 3.0, 6.0, 7.0, 7.0], "policy_policy1_reward": [-6.0, -6.0, -10.0, 4.0, -10.0, -10.0, -1.0, 6.0, 7.0, 2.0, -12.0, -10.0, 2.0, -18.0, -14.0, -12.0, -8.0, -6.0, -10.0, -12.0, -6.0, -8.0, -14.0, -8.0, 2.0, -6.0, -6.0, -6.0, -6.0, 5.0, -8.0, -10.0, 2.0, -8.0, -6.0, -14.0, 2.0, -8.0, -10.0, -16.0, -6.0, -6.0, 4.0, -12.0, 2.0, -6.0, -8.0, -6.0, -6.0, -10.0, -6.0, -12.0, -6.0, 7.0, -15.0, 3.0, -2.0, -6.0, -6.0, 5.0, 5.0, -10.0, 2.0, -8.0, -8.0, -10.0, -8.0, -6.0, -6.0, 4.0, -6.0, -6.0, -8.0, -6.0, 5.0, -6.0, -10.0, -12.0, -10.0, -8.0, -6.0, -6.0, -6.0, -10.0, -6.0, -8.0, -8.0, -10.0, -6.0, 4.0, 7.0, -6.0, 5.0, -2.0, 5.0, 7.0, 3.0, 6.0, 7.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33682239159011246, "mean_inference_ms": 1.7411383001889669, "mean_action_processing_ms": 0.11884229421362197, "mean_env_wait_ms": 0.0751717673717246, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18325, "timesteps_this_iter": 32, "agent_timesteps_total": 36650, "timers": {"load_time_ms": 0.418, "load_throughput": 76477.338, "learn_time_ms": 7.853, "learn_throughput": 4074.699, "update_time_ms": 4.445}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.512028694152832, "min_q": -1.104950189590454, "max_q": 12.868396759033203, "mean_td_error": 0.23333819210529327, "model": {}}, "td_error": [0.9835081100463867, -0.41333866119384766, 0.14752864837646484, 0.8908352851867676, 1.5594453811645508, 0.7163801193237305, 0.8101031184196472, -0.22459793090820312, -0.555931568145752, 1.5766277313232422, -2.222174644470215, -1.1630172729492188, -0.3236656188964844, 1.8053147792816162, 1.4860668182373047, -0.5041475296020508, 1.3557181358337402, -0.03937339782714844, 0.7727262377738953, -0.4437265396118164, 0.4913969039916992, -0.16670799255371094, 1.0550217628479004, 0.533790111541748, -2.49526309967041, 0.4776895046234131, -0.5159096717834473, 2.157996892929077, 0.04598498344421387, -0.41333866119384766, -0.6666578054428101, 0.7485380172729492], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.381160736083984, "min_q": -9.076648712158203, "max_q": 7.807718276977539, "mean_td_error": 0.12513220310211182, "model": {}}, "td_error": [1.5230588912963867, -5.618353843688965, 3.8058838844299316, 2.4415159225463867, 2.617591381072998, -6.8400726318359375, 1.6558547019958496, 2.6559319496154785, 1.1744365692138672, -3.075860023498535, 0.47856855392456055, -3.49304461479187, -0.024393081665039062, -0.5116901397705078, -4.4060540199279785, 2.064265727996826, 1.963653326034546, 3.9536900520324707, -2.409407138824463, 0.7447500228881836, -5.3483171463012695, 3.720484733581543, 0.1592545509338379, -1.1466994285583496, -0.2668266296386719, -0.26506900787353516, -0.5175113677978516, 0.4074106216430664, 3.8378448486328125, -0.3178730010986328, 4.622405529022217, 0.41880130767822266], "custom_metrics": {}}}, "num_steps_sampled": 18325, "num_agent_steps_sampled": 36650, "num_steps_trained": 44608, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 89216, "last_target_update_ts": 18230, "num_target_updates": 160}, "done": false, "episodes_total": 1495, "training_iteration": 72, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-50", "timestamp": 1648811750, "time_this_iter_s": 1.236973762512207, "time_total_s": 85.68005061149597, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584087a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584087a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 85.68005061149597, "timesteps_since_restore": 2304, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 32.6, "ram_util_percent": 59.150000000000006}}
{"episode_reward_max": 14.0, "episode_reward_min": -16.0, "episode_reward_mean": 5.12, "episode_len_mean": 7.44, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"policy0": -2.0, "policy1": -18.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 9.36, "policy1": -4.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 10.0, 4.0, 0.0, 4.0, 4.0, 8.0, -8.0, 4.0, 4.0, 0.0, -12.0, 8.0, 8.0, 8.0, -4.0, 4.0, 8.0, 4.0, 8.0, 8.0, 0.0, 8.0, -4.0, 8.0, 14.0, -10.0, 6.0, -4.0, 8.0, 8.0, 10.0, 10.0, 0.0, 4.0, 4.0, 4.0, 0.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 10.0, 8.0, 0.0, -4.0, 0.0, 4.0, 8.0, 8.0, 8.0, 0.0, 8.0, 4.0, 4.0, 0.0, 8.0, 8.0, 14.0, 8.0, 10.0, -4.0, 10.0, 14.0, 6.0, 12.0, 14.0, 14.0, 0.0, 6.0, 10.0, 14.0, 14.0, 4.0, -16.0, 14.0, 0.0, 4.0, 8.0, 6.0, 8.0, 8.0, 8.0, -8.0, 8.0, 8.0, 0.0, 0.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, -8.0], "episode_lengths": [6, 6, 5, 8, 10, 8, 8, 6, 14, 8, 8, 10, 16, 6, 6, 6, 12, 8, 6, 8, 6, 6, 10, 6, 12, 6, 3, 15, 7, 12, 6, 6, 5, 5, 10, 8, 8, 8, 10, 8, 6, 6, 6, 6, 6, 8, 6, 5, 6, 10, 12, 10, 8, 6, 6, 6, 10, 6, 8, 8, 10, 6, 6, 3, 6, 5, 12, 5, 3, 7, 4, 3, 3, 10, 7, 5, 3, 3, 8, 18, 3, 10, 8, 6, 7, 6, 6, 6, 14, 6, 6, 10, 10, 6, 6, 6, 8, 6, 6, 14], "policy_policy0_reward": [14.0, 14.0, 5.0, 12.0, 10.0, 2.0, 12.0, 14.0, 6.0, 2.0, 12.0, 10.0, 4.0, 14.0, 14.0, 4.0, 8.0, 2.0, 14.0, 12.0, 14.0, 14.0, 10.0, 14.0, 8.0, 14.0, 7.0, 5.0, 3.0, -2.0, 14.0, 14.0, 5.0, 5.0, 10.0, 2.0, 12.0, 12.0, 10.0, 12.0, 14.0, 14.0, 4.0, 14.0, 14.0, 12.0, 14.0, 5.0, 14.0, 10.0, 8.0, 10.0, 12.0, 14.0, 14.0, 14.0, 10.0, 14.0, 12.0, 12.0, 10.0, 14.0, 4.0, 7.0, 14.0, 5.0, -2.0, 5.0, 7.0, 3.0, 6.0, 7.0, 7.0, 0.0, 3.0, 5.0, 7.0, 7.0, 12.0, 2.0, 7.0, 0.0, 12.0, 14.0, 3.0, 14.0, 14.0, 14.0, 6.0, 14.0, 14.0, 10.0, 0.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 6.0], "policy_policy1_reward": [-6.0, -6.0, 5.0, -8.0, -10.0, 2.0, -8.0, -6.0, -14.0, 2.0, -8.0, -10.0, -16.0, -6.0, -6.0, 4.0, -12.0, 2.0, -6.0, -8.0, -6.0, -6.0, -10.0, -6.0, -12.0, -6.0, 7.0, -15.0, 3.0, -2.0, -6.0, -6.0, 5.0, 5.0, -10.0, 2.0, -8.0, -8.0, -10.0, -8.0, -6.0, -6.0, 4.0, -6.0, -6.0, -8.0, -6.0, 5.0, -6.0, -10.0, -12.0, -10.0, -8.0, -6.0, -6.0, -6.0, -10.0, -6.0, -8.0, -8.0, -10.0, -6.0, 4.0, 7.0, -6.0, 5.0, -2.0, 5.0, 7.0, 3.0, 6.0, 7.0, 7.0, 0.0, 3.0, 5.0, 7.0, 7.0, -8.0, -18.0, 7.0, 0.0, -8.0, -6.0, 3.0, -6.0, -6.0, -6.0, -14.0, -6.0, -6.0, -10.0, 0.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3370768169021764, "mean_inference_ms": 1.7396783334907886, "mean_action_processing_ms": 0.11873830846587657, "mean_env_wait_ms": 0.07513959049138466, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18529, "timesteps_this_iter": 32, "agent_timesteps_total": 37058, "timers": {"load_time_ms": 0.475, "load_throughput": 67381.76, "learn_time_ms": 8.479, "learn_throughput": 3773.818, "update_time_ms": 4.872}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.983456611633301, "min_q": -1.4614075422286987, "max_q": 13.59617805480957, "mean_td_error": 0.7504307627677917, "model": {}}, "td_error": [1.9092636108398438, -0.9127750396728516, -0.3387928009033203, 0.6390048265457153, 2.023326873779297, -0.3033714294433594, -1.1104011535644531, 0.9152388572692871, -1.1327228546142578, 0.34323644638061523, -1.702225685119629, 2.7823848724365234, 0.7572186589241028, 3.5582404136657715, -0.7134909629821777, -0.5554747581481934, 0.6424775123596191, 5.457683563232422, 1.33699369430542, 0.8411617279052734, -0.7674856185913086, 3.256978988647461, -0.48244619369506836, 5.608547210693359, -0.7936630249023438, 3.3342442512512207, 0.2392439842224121, -1.9846733808517456, 1.0815353393554688, -1.5789203643798828, 2.9143452644348145, -1.2508972883224487], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -5.1881561279296875, "min_q": -9.48439884185791, "max_q": 7.351083755493164, "mean_td_error": -0.511135458946228, "model": {}}, "td_error": [0.4050159454345703, -4.923343181610107, -0.6364612579345703, -1.1291418075561523, 3.5176687240600586, 1.6304876804351807, -1.379988431930542, 1.3990049362182617, -2.43263578414917, -0.8545613288879395, -3.3995490074157715, -1.7878594398498535, 3.356656074523926, 0.9815363883972168, -0.14101791381835938, -3.323749303817749, -9.152978897094727, 2.979264259338379, -0.0201873779296875, -6.813893795013428, 2.2093605995178223, 2.026912212371826, 2.566883087158203, 0.7595996856689453, 1.1483039855957031, 2.1356935501098633, 3.1745753288269043, -1.3534164428710938, -5.7744340896606445, 0.2986335754394531, -2.9710159301757812, 1.1483049392700195], "custom_metrics": {}}}, "num_steps_sampled": 18529, "num_agent_steps_sampled": 37058, "num_steps_trained": 45408, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 90816, "last_target_update_ts": 18445, "num_target_updates": 162}, "done": false, "episodes_total": 1522, "training_iteration": 73, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-51", "timestamp": 1648811751, "time_this_iter_s": 1.171980619430542, "time_total_s": 86.85203123092651, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 86.85203123092651, "timesteps_since_restore": 2336, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 33.6, "ram_util_percent": 59.2}}
{"episode_reward_max": 14.0, "episode_reward_min": -16.0, "episode_reward_mean": 6.06, "episode_len_mean": 6.97, "episode_media": {}, "episodes_this_iter": 30, "policy_reward_min": {"policy0": -7.0, "policy1": -18.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": 9.83, "policy1": -3.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 10.0, 10.0, 0.0, 4.0, 4.0, 4.0, 0.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 10.0, 8.0, 0.0, -4.0, 0.0, 4.0, 8.0, 8.0, 8.0, 0.0, 8.0, 4.0, 4.0, 0.0, 8.0, 8.0, 14.0, 8.0, 10.0, -4.0, 10.0, 14.0, 6.0, 12.0, 14.0, 14.0, 0.0, 6.0, 10.0, 14.0, 14.0, 4.0, -16.0, 14.0, 0.0, 4.0, 8.0, 6.0, 8.0, 8.0, 8.0, -8.0, 8.0, 8.0, 0.0, 0.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, -8.0, 8.0, 8.0, 2.0, 0.0, 4.0, 4.0, 8.0, 10.0, 8.0, 4.0, 14.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 6.0, 8.0, 8.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, -12.0, 8.0], "episode_lengths": [6, 6, 5, 5, 10, 8, 8, 8, 10, 8, 6, 6, 6, 6, 6, 8, 6, 5, 6, 10, 12, 10, 8, 6, 6, 6, 10, 6, 8, 8, 10, 6, 6, 3, 6, 5, 12, 5, 3, 7, 4, 3, 3, 10, 7, 5, 3, 3, 8, 18, 3, 10, 8, 6, 7, 6, 6, 6, 14, 6, 6, 10, 10, 6, 6, 6, 8, 6, 6, 14, 6, 6, 9, 10, 8, 8, 6, 5, 6, 8, 3, 6, 8, 6, 6, 6, 6, 7, 6, 6, 3, 6, 6, 6, 6, 6, 6, 8, 16, 6], "policy_policy0_reward": [14.0, 14.0, 5.0, 5.0, 10.0, 2.0, 12.0, 12.0, 10.0, 12.0, 14.0, 14.0, 4.0, 14.0, 14.0, 12.0, 14.0, 5.0, 14.0, 10.0, 8.0, 10.0, 12.0, 14.0, 14.0, 14.0, 10.0, 14.0, 12.0, 12.0, 10.0, 14.0, 4.0, 7.0, 14.0, 5.0, -2.0, 5.0, 7.0, 3.0, 6.0, 7.0, 7.0, 0.0, 3.0, 5.0, 7.0, 7.0, 12.0, 2.0, 7.0, 0.0, 12.0, 14.0, 3.0, 14.0, 14.0, 14.0, 6.0, 14.0, 14.0, 10.0, 0.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 6.0, 14.0, 14.0, 1.0, 10.0, 12.0, 2.0, 14.0, 5.0, 14.0, 12.0, 7.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, -7.0, 14.0, 14.0, 7.0, 14.0, 14.0, 4.0, 14.0, 14.0, 14.0, 12.0, 4.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, 5.0, 5.0, -10.0, 2.0, -8.0, -8.0, -10.0, -8.0, -6.0, -6.0, 4.0, -6.0, -6.0, -8.0, -6.0, 5.0, -6.0, -10.0, -12.0, -10.0, -8.0, -6.0, -6.0, -6.0, -10.0, -6.0, -8.0, -8.0, -10.0, -6.0, 4.0, 7.0, -6.0, 5.0, -2.0, 5.0, 7.0, 3.0, 6.0, 7.0, 7.0, 0.0, 3.0, 5.0, 7.0, 7.0, -8.0, -18.0, 7.0, 0.0, -8.0, -6.0, 3.0, -6.0, -6.0, -6.0, -14.0, -6.0, -6.0, -10.0, 0.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -14.0, -6.0, -6.0, 1.0, -10.0, -8.0, 2.0, -6.0, 5.0, -6.0, -8.0, 7.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 13.0, -6.0, -6.0, 7.0, -6.0, -6.0, 4.0, -6.0, -6.0, -6.0, -8.0, -16.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3373806901734149, "mean_inference_ms": 1.7381601181075754, "mean_action_processing_ms": 0.11863958628593049, "mean_env_wait_ms": 0.07509742939428735, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18730, "timesteps_this_iter": 32, "agent_timesteps_total": 37460, "timers": {"load_time_ms": 0.452, "load_throughput": 70849.73, "learn_time_ms": 7.51, "learn_throughput": 4260.921, "update_time_ms": 4.572}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.074140548706055, "min_q": 1.7011204957962036, "max_q": 14.713607788085938, "mean_td_error": 0.03249432146549225, "model": {}}, "td_error": [-0.39242076873779297, -1.5173463821411133, 0.4047689437866211, 0.6602420806884766, 2.0949668884277344, -1.7007546424865723, 0.39888572692871094, -0.12206172943115234, -0.5379937887191772, -0.5732498168945312, 3.470823287963867, -0.6027536392211914, -3.989093780517578, -0.3468203544616699, -0.009367942810058594, 3.756500244140625, -0.5570745468139648, 0.5447320938110352, -0.6219110488891602, -0.05432891845703125, 0.9114961624145508, -0.6391258239746094, 1.3717784881591797, -1.3851561546325684, 0.2639493942260742, -0.4588170051574707, -0.39242076873779297, -0.4081997871398926, 3.756500244140625, 0.0028362274169921875, -0.48743438720703125, -1.801330327987671], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.276167869567871, "min_q": -11.260955810546875, "max_q": 5.263782501220703, "mean_td_error": -1.5309977531433105, "model": {}}, "td_error": [0.4182690382003784, 3.253955364227295, -0.3216540813446045, -4.464911460876465, -7.424748420715332, -1.9076011180877686, 2.8303680419921875, 6.137343406677246, -0.0037813186645507812, 0.9079200029373169, -7.6938982009887695, -13.634251594543457, -13.614503860473633, 2.460920810699463, -0.5066232681274414, 0.9348068237304688, -3.070657253265381, -0.8604226112365723, 1.7006220817565918, 0.8594131469726562, -5.913646221160889, -13.614503860473633, 1.7426605224609375, 0.8140735626220703, 0.3821974992752075, 1.9358162879943848, 0.900442361831665, 0.4174036979675293, -1.7187581062316895, 1.3687186241149902, -0.10666346549987793, -1.2002339363098145], "custom_metrics": {}}}, "num_steps_sampled": 18730, "num_agent_steps_sampled": 37460, "num_steps_trained": 46304, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 92608, "last_target_update_ts": 18655, "num_target_updates": 164}, "done": false, "episodes_total": 1552, "training_iteration": 74, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-53", "timestamp": 1648811753, "time_this_iter_s": 1.2133562564849854, "time_total_s": 88.0653874874115, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 88.0653874874115, "timesteps_since_restore": 2368, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 32.8, "ram_util_percent": 59.2}}
{"episode_reward_max": 14.0, "episode_reward_min": -20.0, "episode_reward_mean": 5.64, "episode_len_mean": 7.18, "episode_media": {}, "episodes_this_iter": 25, "policy_reward_min": {"policy0": -7.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": 9.52, "policy1": -3.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 0.0, 8.0, 4.0, 4.0, 0.0, 8.0, 8.0, 14.0, 8.0, 10.0, -4.0, 10.0, 14.0, 6.0, 12.0, 14.0, 14.0, 0.0, 6.0, 10.0, 14.0, 14.0, 4.0, -16.0, 14.0, 0.0, 4.0, 8.0, 6.0, 8.0, 8.0, 8.0, -8.0, 8.0, 8.0, 0.0, 0.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, -8.0, 8.0, 8.0, 2.0, 0.0, 4.0, 4.0, 8.0, 10.0, 8.0, 4.0, 14.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 6.0, 8.0, 8.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, -12.0, 8.0, 4.0, 4.0, -8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 0.0, 4.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 12.0, 8.0, -8.0, 8.0, -20.0, 4.0, 8.0, 0.0], "episode_lengths": [6, 10, 6, 8, 8, 10, 6, 6, 3, 6, 5, 12, 5, 3, 7, 4, 3, 3, 10, 7, 5, 3, 3, 8, 18, 3, 10, 8, 6, 7, 6, 6, 6, 14, 6, 6, 10, 10, 6, 6, 6, 8, 6, 6, 14, 6, 6, 9, 10, 8, 8, 6, 5, 6, 8, 3, 6, 8, 6, 6, 6, 6, 7, 6, 6, 3, 6, 6, 6, 6, 6, 6, 8, 16, 6, 8, 8, 14, 8, 8, 6, 6, 6, 6, 10, 8, 6, 6, 8, 8, 6, 6, 4, 6, 14, 6, 20, 8, 6, 10], "policy_policy0_reward": [14.0, 10.0, 14.0, 12.0, 12.0, 10.0, 14.0, 4.0, 7.0, 14.0, 5.0, -2.0, 5.0, 7.0, 3.0, 6.0, 7.0, 7.0, 0.0, 3.0, 5.0, 7.0, 7.0, 12.0, 2.0, 7.0, 0.0, 12.0, 14.0, 3.0, 14.0, 14.0, 14.0, 6.0, 14.0, 14.0, 10.0, 0.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 6.0, 14.0, 14.0, 1.0, 10.0, 12.0, 2.0, 14.0, 5.0, 14.0, 12.0, 7.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, -7.0, 14.0, 14.0, 7.0, 14.0, 14.0, 4.0, 14.0, 14.0, 14.0, 12.0, 4.0, 14.0, 12.0, 2.0, -4.0, 12.0, 12.0, 14.0, 14.0, 14.0, 14.0, 10.0, 12.0, 14.0, 14.0, 12.0, 12.0, 14.0, 4.0, 6.0, 14.0, 6.0, 4.0, 0.0, 12.0, 4.0, 10.0], "policy_policy1_reward": [-6.0, -10.0, -6.0, -8.0, -8.0, -10.0, -6.0, 4.0, 7.0, -6.0, 5.0, -2.0, 5.0, 7.0, 3.0, 6.0, 7.0, 7.0, 0.0, 3.0, 5.0, 7.0, 7.0, -8.0, -18.0, 7.0, 0.0, -8.0, -6.0, 3.0, -6.0, -6.0, -6.0, -14.0, -6.0, -6.0, -10.0, 0.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -14.0, -6.0, -6.0, 1.0, -10.0, -8.0, 2.0, -6.0, 5.0, -6.0, -8.0, 7.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 13.0, -6.0, -6.0, 7.0, -6.0, -6.0, 4.0, -6.0, -6.0, -6.0, -8.0, -16.0, -6.0, -8.0, 2.0, -4.0, -8.0, -8.0, -6.0, -6.0, -6.0, -6.0, -10.0, -8.0, -6.0, -6.0, -8.0, -8.0, -6.0, 4.0, 6.0, -6.0, -14.0, 4.0, -20.0, -8.0, 4.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33758900993480945, "mean_inference_ms": 1.7370650586914007, "mean_action_processing_ms": 0.11857212795319555, "mean_env_wait_ms": 0.07506215662408348, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18932, "timesteps_this_iter": 32, "agent_timesteps_total": 37864, "timers": {"load_time_ms": 0.421, "load_throughput": 75932.184, "learn_time_ms": 7.756, "learn_throughput": 4125.651, "update_time_ms": 4.868}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.027070999145508, "min_q": -0.9824168682098389, "max_q": 14.28715705871582, "mean_td_error": 0.6078927516937256, "model": {}}, "td_error": [1.2465243339538574, -0.2662687301635742, 2.235942840576172, 0.7076807022094727, 0.1772174835205078, 0.8370118141174316, 0.36251020431518555, -0.38536643981933594, 0.43605995178222656, 0.8080062866210938, -0.2970118522644043, -0.5861892700195312, 0.9253559112548828, 2.393413543701172, 0.6102547645568848, -1.6098194122314453, 0.4128246307373047, 0.19036054611206055, 0.43605995178222656, 2.9633989334106445, 0.8263626098632812, 0.6160306930541992, 0.08090949058532715, 1.7479066848754883, 0.2420186996459961, -0.19957351684570312, 3.9130334854125977, 0.9576516151428223, -0.8745079040527344, 0.5754809379577637, -0.29146289825439453, 0.26075267791748047], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.639798402786255, "min_q": -6.7387776374816895, "max_q": 5.584001064300537, "mean_td_error": -0.9027571678161621, "model": {}}, "td_error": [0.7946767807006836, -1.0592377185821533, -2.3006160259246826, 3.076681613922119, 2.1804895401000977, 0.2784600257873535, -0.7642593383789062, -0.21831083297729492, 2.557619571685791, 3.0332608222961426, 1.824289083480835, -1.8708038330078125, -7.413487911224365, -1.1475228071212769, 0.07640886306762695, 1.3467223644256592, -1.1856708526611328, -0.8189432621002197, -5.161311626434326, -14.840046882629395, -0.7066483497619629, 1.2708234786987305, -5.153356075286865, -0.9097332954406738, 0.9249076843261719, 0.15785932540893555, 1.1624112129211426, -1.8405170440673828, -4.630880832672119, 3.0332608222961426, -0.10778164863586426, -0.47697222232818604], "custom_metrics": {}}}, "num_steps_sampled": 18932, "num_agent_steps_sampled": 37864, "num_steps_trained": 47104, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 94208, "last_target_update_ts": 18862, "num_target_updates": 166}, "done": false, "episodes_total": 1577, "training_iteration": 75, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-54", "timestamp": 1648811754, "time_this_iter_s": 1.1593828201293945, "time_total_s": 89.2247703075409, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584085f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584085f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 89.2247703075409, "timesteps_since_restore": 2400, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 31.9, "ram_util_percent": 59.25}}
{"episode_reward_max": 14.0, "episode_reward_min": -20.0, "episode_reward_mean": 4.88, "episode_len_mean": 7.56, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"policy0": -7.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": 10.24, "policy1": -5.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 4.0, 8.0, 6.0, 8.0, 8.0, 8.0, -8.0, 8.0, 8.0, 0.0, 0.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, -8.0, 8.0, 8.0, 2.0, 0.0, 4.0, 4.0, 8.0, 10.0, 8.0, 4.0, 14.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 6.0, 8.0, 8.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, -12.0, 8.0, 4.0, 4.0, -8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 0.0, 4.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 12.0, 8.0, -8.0, 8.0, -20.0, 4.0, 8.0, 0.0, 8.0, 4.0, 0.0, 8.0, -4.0, 0.0, 8.0, 8.0, 0.0, 4.0, 8.0, 0.0, 8.0, 8.0, 8.0, 0.0, 4.0, -4.0, 4.0, -4.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [10, 8, 6, 7, 6, 6, 6, 14, 6, 6, 10, 10, 6, 6, 6, 8, 6, 6, 14, 6, 6, 9, 10, 8, 8, 6, 5, 6, 8, 3, 6, 8, 6, 6, 6, 6, 7, 6, 6, 3, 6, 6, 6, 6, 6, 6, 8, 16, 6, 8, 8, 14, 8, 8, 6, 6, 6, 6, 10, 8, 6, 6, 8, 8, 6, 6, 4, 6, 14, 6, 20, 8, 6, 10, 6, 8, 10, 6, 12, 10, 6, 6, 10, 8, 6, 10, 6, 6, 6, 10, 8, 12, 8, 12, 6, 10, 6, 6, 6, 6], "policy_policy0_reward": [0.0, 12.0, 14.0, 3.0, 14.0, 14.0, 14.0, 6.0, 14.0, 14.0, 10.0, 0.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 6.0, 14.0, 14.0, 1.0, 10.0, 12.0, 2.0, 14.0, 5.0, 14.0, 12.0, 7.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, -7.0, 14.0, 14.0, 7.0, 14.0, 14.0, 4.0, 14.0, 14.0, 14.0, 12.0, 4.0, 14.0, 12.0, 2.0, -4.0, 12.0, 12.0, 14.0, 14.0, 14.0, 14.0, 10.0, 12.0, 14.0, 14.0, 12.0, 12.0, 14.0, 4.0, 6.0, 14.0, 6.0, 4.0, 0.0, 12.0, 4.0, 10.0, 14.0, 12.0, 10.0, 14.0, -2.0, 10.0, 14.0, 14.0, 10.0, 2.0, 14.0, 10.0, 14.0, 14.0, 14.0, 10.0, 12.0, -2.0, 2.0, 8.0, 14.0, 10.0, 4.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [0.0, -8.0, -6.0, 3.0, -6.0, -6.0, -6.0, -14.0, -6.0, -6.0, -10.0, 0.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -14.0, -6.0, -6.0, 1.0, -10.0, -8.0, 2.0, -6.0, 5.0, -6.0, -8.0, 7.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 13.0, -6.0, -6.0, 7.0, -6.0, -6.0, 4.0, -6.0, -6.0, -6.0, -8.0, -16.0, -6.0, -8.0, 2.0, -4.0, -8.0, -8.0, -6.0, -6.0, -6.0, -6.0, -10.0, -8.0, -6.0, -6.0, -8.0, -8.0, -6.0, 4.0, 6.0, -6.0, -14.0, 4.0, -20.0, -8.0, 4.0, -10.0, -6.0, -8.0, -10.0, -6.0, -2.0, -10.0, -6.0, -6.0, -10.0, 2.0, -6.0, -10.0, -6.0, -6.0, -6.0, -10.0, -8.0, -2.0, 2.0, -12.0, -6.0, -10.0, 4.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.338012797046588, "mean_inference_ms": 1.7373439337556693, "mean_action_processing_ms": 0.1186135254503446, "mean_env_wait_ms": 0.07508147707547426, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19138, "timesteps_this_iter": 32, "agent_timesteps_total": 38276, "timers": {"load_time_ms": 0.521, "load_throughput": 61426.878, "learn_time_ms": 9.411, "learn_throughput": 3400.25, "update_time_ms": 5.962}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.076389789581299, "min_q": -0.8133723139762878, "max_q": 14.512382507324219, "mean_td_error": 0.06479144096374512, "model": {}}, "td_error": [1.0188820362091064, -1.0754320621490479, 1.303274154663086, -1.474827766418457, -0.06775188446044922, 3.2433226108551025, 0.0707859992980957, -2.428786516189575, 1.0475095510482788, 0.2259988784790039, -0.5827527046203613, 4.734421730041504, 0.27114802598953247, 1.483518123626709, -1.7060439586639404, 3.4409337043762207, -1.2564458847045898, 1.022568702697754, -0.7435052394866943, -0.5822446346282959, -1.7190446853637695, -1.17167329788208, 0.4907221794128418, 0.14931154251098633, 0.6554164886474609, -0.01710033416748047, -0.9903501272201538, 0.10304975509643555, 0.9537334442138672, 0.23593568801879883, -0.5096402168273926, -4.051607131958008], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.2990784645080566, "min_q": -8.882828712463379, "max_q": 4.5582594871521, "mean_td_error": 0.10049553960561752, "model": {}}, "td_error": [0.23470544815063477, -0.5264288783073425, -0.4254724979400635, -1.8448107242584229, 2.4174509048461914, 1.3093547821044922, 6.79054069519043, -1.0475504398345947, 1.3299496173858643, 3.063793420791626, 0.5637965202331543, 2.0809731483459473, -0.32213401794433594, -0.19296860694885254, -4.407831192016602, -2.3729255199432373, -6.906481742858887, -0.9164035320281982, -1.7341389656066895, 1.796764850616455, -0.5600109100341797, -4.483616828918457, -2.3408403396606445, 3.737149477005005, 1.2103137969970703, -0.29262351989746094, 2.5826022624969482, 1.2810754776000977, 0.07614898681640625, 3.6347076892852783, -1.844933271408081, 1.3257007598876953], "custom_metrics": {}}}, "num_steps_sampled": 19138, "num_agent_steps_sampled": 38276, "num_steps_trained": 47936, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 95872, "last_target_update_ts": 19078, "num_target_updates": 168}, "done": false, "episodes_total": 1603, "training_iteration": 76, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-55", "timestamp": 1648811755, "time_this_iter_s": 1.4470345973968506, "time_total_s": 90.67180490493774, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 90.67180490493774, "timesteps_since_restore": 2432, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 34.0, "ram_util_percent": 59.3}}
{"episode_reward_max": 14.0, "episode_reward_min": -20.0, "episode_reward_mean": 4.98, "episode_len_mean": 7.51, "episode_media": {}, "episodes_this_iter": 28, "policy_reward_min": {"policy0": -7.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": 10.19, "policy1": -5.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 14.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 6.0, 8.0, 8.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, -12.0, 8.0, 4.0, 4.0, -8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 0.0, 4.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 12.0, 8.0, -8.0, 8.0, -20.0, 4.0, 8.0, 0.0, 8.0, 4.0, 0.0, 8.0, -4.0, 0.0, 8.0, 8.0, 0.0, 4.0, 8.0, 0.0, 8.0, 8.0, 8.0, 0.0, 4.0, -4.0, 4.0, -4.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 0.0, 14.0, 14.0, -4.0, -4.0, 0.0, 8.0, 8.0, 8.0, 4.0, 8.0, 0.0, 8.0, 8.0, 2.0, 0.0, 4.0, 8.0, 8.0, 8.0, 8.0, 4.0, 0.0, 4.0, 8.0, 8.0, 8.0, 6.0], "episode_lengths": [8, 3, 6, 8, 6, 6, 6, 6, 7, 6, 6, 3, 6, 6, 6, 6, 6, 6, 8, 16, 6, 8, 8, 14, 8, 8, 6, 6, 6, 6, 10, 8, 6, 6, 8, 8, 6, 6, 4, 6, 14, 6, 20, 8, 6, 10, 6, 8, 10, 6, 12, 10, 6, 6, 10, 8, 6, 10, 6, 6, 6, 10, 8, 12, 8, 12, 6, 10, 6, 6, 6, 6, 10, 3, 3, 12, 12, 10, 6, 6, 6, 8, 6, 10, 6, 6, 9, 10, 8, 6, 6, 6, 6, 8, 10, 8, 6, 6, 6, 7], "policy_policy0_reward": [12.0, 7.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, -7.0, 14.0, 14.0, 7.0, 14.0, 14.0, 4.0, 14.0, 14.0, 14.0, 12.0, 4.0, 14.0, 12.0, 2.0, -4.0, 12.0, 12.0, 14.0, 14.0, 14.0, 14.0, 10.0, 12.0, 14.0, 14.0, 12.0, 12.0, 14.0, 4.0, 6.0, 14.0, 6.0, 4.0, 0.0, 12.0, 4.0, 10.0, 14.0, 12.0, 10.0, 14.0, -2.0, 10.0, 14.0, 14.0, 10.0, 2.0, 14.0, 10.0, 14.0, 14.0, 14.0, 10.0, 12.0, -2.0, 2.0, 8.0, 14.0, 10.0, 4.0, 14.0, 14.0, 14.0, 10.0, 7.0, 7.0, 8.0, 8.0, 10.0, 4.0, 14.0, 14.0, 12.0, 14.0, 10.0, 14.0, 4.0, 11.0, 10.0, 2.0, 14.0, 14.0, 14.0, 14.0, 12.0, 10.0, 12.0, 4.0, 14.0, 14.0, 3.0], "policy_policy1_reward": [-8.0, 7.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 13.0, -6.0, -6.0, 7.0, -6.0, -6.0, 4.0, -6.0, -6.0, -6.0, -8.0, -16.0, -6.0, -8.0, 2.0, -4.0, -8.0, -8.0, -6.0, -6.0, -6.0, -6.0, -10.0, -8.0, -6.0, -6.0, -8.0, -8.0, -6.0, 4.0, 6.0, -6.0, -14.0, 4.0, -20.0, -8.0, 4.0, -10.0, -6.0, -8.0, -10.0, -6.0, -2.0, -10.0, -6.0, -6.0, -10.0, 2.0, -6.0, -10.0, -6.0, -6.0, -6.0, -10.0, -8.0, -2.0, 2.0, -12.0, -6.0, -10.0, 4.0, -6.0, -6.0, -6.0, -10.0, 7.0, 7.0, -12.0, -12.0, -10.0, 4.0, -6.0, -6.0, -8.0, -6.0, -10.0, -6.0, 4.0, -9.0, -10.0, 2.0, -6.0, -6.0, -6.0, -6.0, -8.0, -10.0, -8.0, 4.0, -6.0, -6.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33861673123550845, "mean_inference_ms": 1.7385267617832774, "mean_action_processing_ms": 0.11872401214541715, "mean_env_wait_ms": 0.07514019828855467, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19344, "timesteps_this_iter": 32, "agent_timesteps_total": 38688, "timers": {"load_time_ms": 0.517, "load_throughput": 61899.981, "learn_time_ms": 8.67, "learn_throughput": 3691.042, "update_time_ms": 5.183}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.967207908630371, "min_q": -1.6825904846191406, "max_q": 15.064764022827148, "mean_td_error": 0.6861752867698669, "model": {}}, "td_error": [4.1729559898376465, 0.36803722381591797, 7.590828895568848, 0.07559490203857422, -0.9648141860961914, -0.3089871406555176, -0.40732574462890625, 1.724236011505127, 6.780569076538086, 0.36505603790283203, -0.3080320358276367, -1.987013816833496, 0.11575603485107422, 0.8918066024780273, 3.3482322692871094, -0.7165651321411133, -2.2749109268188477, 2.214505195617676, 0.11953449249267578, -0.700953483581543, 0.6340422630310059, -0.6884684562683105, -0.1591939926147461, 0.7119474411010742, -0.8150138854980469, 2.8920507431030273, -0.5358190536499023, -0.7236738204956055, 1.2394180297851562, -1.7645578384399414, 1.2525663375854492, -0.18419933319091797], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.0560531616210938, "min_q": -7.8604583740234375, "max_q": 2.7277441024780273, "mean_td_error": -0.41063013672828674, "model": {}}, "td_error": [0.31401634216308594, 3.7471094131469727, 2.2609877586364746, -4.091851234436035, 0.7666285037994385, -0.4725193977355957, 3.377959728240967, 3.050161123275757, 1.181993007659912, -4.866089344024658, 0.259387731552124, 0.7484238147735596, 1.4811315536499023, -3.973511219024658, 1.2190148830413818, -2.5111167430877686, -5.9481916427612305, 1.902184009552002, -1.1391410827636719, 0.19825959205627441, 0.841117262840271, -2.0618605613708496, -6.274223327636719, -3.587057590484619, -2.125718593597412, -1.008148193359375, 0.9070768356323242, -0.1546339988708496, 3.118691921234131, 1.3450593948364258, -3.471348285675049, 1.8260440826416016], "custom_metrics": {}}}, "num_steps_sampled": 19344, "num_agent_steps_sampled": 38688, "num_steps_trained": 48800, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 97600, "last_target_update_ts": 19293, "num_target_updates": 170}, "done": false, "episodes_total": 1631, "training_iteration": 77, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-57", "timestamp": 1648811757, "time_this_iter_s": 1.3607966899871826, "time_total_s": 92.03260159492493, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584765f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584765f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 92.03260159492493, "timesteps_since_restore": 2464, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 32.55, "ram_util_percent": 59.3}}
{"episode_reward_max": 14.0, "episode_reward_min": -20.0, "episode_reward_mean": 4.68, "episode_len_mean": 7.66, "episode_media": {}, "episodes_this_iter": 28, "policy_reward_min": {"policy0": -2.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 10.44, "policy1": -5.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 0.0, 4.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 12.0, 8.0, -8.0, 8.0, -20.0, 4.0, 8.0, 0.0, 8.0, 4.0, 0.0, 8.0, -4.0, 0.0, 8.0, 8.0, 0.0, 4.0, 8.0, 0.0, 8.0, 8.0, 8.0, 0.0, 4.0, -4.0, 4.0, -4.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 0.0, 14.0, 14.0, -4.0, -4.0, 0.0, 8.0, 8.0, 8.0, 4.0, 8.0, 0.0, 8.0, 8.0, 2.0, 0.0, 4.0, 8.0, 8.0, 8.0, 8.0, 4.0, 0.0, 4.0, 8.0, 8.0, 8.0, 6.0, 8.0, -4.0, 8.0, 8.0, 8.0, 0.0, 8.0, 4.0, 4.0, 6.0, 8.0, 4.0, 8.0, 8.0, 0.0, 0.0, 8.0, 8.0, 14.0, 8.0, 4.0, 8.0, -4.0, 4.0, 0.0, 4.0, 8.0, 0.0], "episode_lengths": [6, 6, 10, 8, 6, 6, 8, 8, 6, 6, 4, 6, 14, 6, 20, 8, 6, 10, 6, 8, 10, 6, 12, 10, 6, 6, 10, 8, 6, 10, 6, 6, 6, 10, 8, 12, 8, 12, 6, 10, 6, 6, 6, 6, 10, 3, 3, 12, 12, 10, 6, 6, 6, 8, 6, 10, 6, 6, 9, 10, 8, 6, 6, 6, 6, 8, 10, 8, 6, 6, 6, 7, 6, 12, 6, 6, 6, 10, 6, 8, 8, 7, 6, 8, 6, 6, 10, 10, 6, 6, 3, 6, 8, 6, 12, 8, 10, 8, 6, 10], "policy_policy0_reward": [14.0, 14.0, 10.0, 12.0, 14.0, 14.0, 12.0, 12.0, 14.0, 4.0, 6.0, 14.0, 6.0, 4.0, 0.0, 12.0, 4.0, 10.0, 14.0, 12.0, 10.0, 14.0, -2.0, 10.0, 14.0, 14.0, 10.0, 2.0, 14.0, 10.0, 14.0, 14.0, 14.0, 10.0, 12.0, -2.0, 2.0, 8.0, 14.0, 10.0, 4.0, 14.0, 14.0, 14.0, 10.0, 7.0, 7.0, 8.0, 8.0, 10.0, 4.0, 14.0, 14.0, 12.0, 14.0, 10.0, 14.0, 4.0, 11.0, 10.0, 2.0, 14.0, 14.0, 14.0, 14.0, 12.0, 10.0, 12.0, 4.0, 14.0, 14.0, 3.0, 14.0, 8.0, 14.0, 14.0, 14.0, 10.0, 14.0, 12.0, 12.0, 3.0, 14.0, 12.0, 14.0, 14.0, 10.0, 10.0, 14.0, 14.0, 7.0, 4.0, 12.0, 14.0, 8.0, 12.0, 10.0, 12.0, 14.0, 10.0], "policy_policy1_reward": [-6.0, -6.0, -10.0, -8.0, -6.0, -6.0, -8.0, -8.0, -6.0, 4.0, 6.0, -6.0, -14.0, 4.0, -20.0, -8.0, 4.0, -10.0, -6.0, -8.0, -10.0, -6.0, -2.0, -10.0, -6.0, -6.0, -10.0, 2.0, -6.0, -10.0, -6.0, -6.0, -6.0, -10.0, -8.0, -2.0, 2.0, -12.0, -6.0, -10.0, 4.0, -6.0, -6.0, -6.0, -10.0, 7.0, 7.0, -12.0, -12.0, -10.0, 4.0, -6.0, -6.0, -8.0, -6.0, -10.0, -6.0, 4.0, -9.0, -10.0, 2.0, -6.0, -6.0, -6.0, -6.0, -8.0, -10.0, -8.0, 4.0, -6.0, -6.0, 3.0, -6.0, -12.0, -6.0, -6.0, -6.0, -10.0, -6.0, -8.0, -8.0, 3.0, -6.0, -8.0, -6.0, -6.0, -10.0, -10.0, -6.0, -6.0, 7.0, 4.0, -8.0, -6.0, -12.0, -8.0, -10.0, -8.0, -6.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33921007025475125, "mean_inference_ms": 1.7396174543102865, "mean_action_processing_ms": 0.11881614609371854, "mean_env_wait_ms": 0.07519467053907954, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19554, "timesteps_this_iter": 32, "agent_timesteps_total": 39108, "timers": {"load_time_ms": 0.446, "load_throughput": 71701.334, "learn_time_ms": 7.622, "learn_throughput": 4198.621, "update_time_ms": 4.48}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.744032859802246, "min_q": -2.023075580596924, "max_q": 16.52457046508789, "mean_td_error": -0.3797694444656372, "model": {}}, "td_error": [-0.9679865837097168, -2.5268783569335938, 0.6074581146240234, -0.5293750762939453, 0.2050180435180664, 2.60996150970459, 0.25461381673812866, 0.1458444595336914, 1.8916473388671875, -0.6238918304443359, -0.9095044136047363, -0.46312427520751953, -0.09459066390991211, 1.8916473388671875, -0.46399927139282227, -1.2916030883789062, -0.9644274711608887, -0.32612133026123047, -3.1073150634765625, -0.824251651763916, -0.6680259704589844, -1.0230755805969238, -1.0132312774658203, -0.6309804916381836, -0.5016655921936035, 0.15988540649414062, 0.15988540649414062, -1.1064929962158203, -1.3736906051635742, -0.8563299179077148, 0.7150424718856812, -0.5270652770996094], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.3526172637939453, "min_q": -8.274831771850586, "max_q": 3.040517807006836, "mean_td_error": -1.7443345785140991, "model": {}}, "td_error": [-15.774264335632324, -1.5663325786590576, 1.1275005340576172, 0.535067617893219, -5.089999675750732, 2.0063729286193848, 2.056544303894043, -7.147336006164551, -0.11257123947143555, -7.120581150054932, -5.165773391723633, 4.0450944900512695, -7.429713726043701, 1.4751801490783691, -9.65652847290039, -2.3095784187316895, -0.31987297534942627, 0.2766242027282715, 3.394601821899414, -3.912480115890503, 4.736947059631348, 0.02756643295288086, 0.8703776597976685, 0.3413076400756836, 2.6990017890930176, 3.732417345046997, -4.153622150421143, -0.4109320640563965, -2.0388245582580566, -7.274831771850586, 0.0339055061340332, -3.693971633911133], "custom_metrics": {}}}, "num_steps_sampled": 19554, "num_agent_steps_sampled": 39108, "num_steps_trained": 49664, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 99328, "last_target_update_ts": 19500, "num_target_updates": 172}, "done": false, "episodes_total": 1659, "training_iteration": 78, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-58", "timestamp": 1648811758, "time_this_iter_s": 1.2170841693878174, "time_total_s": 93.24968576431274, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 93.24968576431274, "timesteps_since_restore": 2496, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 32.45, "ram_util_percent": 59.4}}
{"episode_reward_max": 14.0, "episode_reward_min": -8.0, "episode_reward_mean": 4.92, "episode_len_mean": 7.54, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"policy0": -2.0, "policy1": -14.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 10.86, "policy1": -5.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 8.0, 0.0, 8.0, 8.0, 8.0, 0.0, 4.0, -4.0, 4.0, -4.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 0.0, 14.0, 14.0, -4.0, -4.0, 0.0, 8.0, 8.0, 8.0, 4.0, 8.0, 0.0, 8.0, 8.0, 2.0, 0.0, 4.0, 8.0, 8.0, 8.0, 8.0, 4.0, 0.0, 4.0, 8.0, 8.0, 8.0, 6.0, 8.0, -4.0, 8.0, 8.0, 8.0, 0.0, 8.0, 4.0, 4.0, 6.0, 8.0, 4.0, 8.0, 8.0, 0.0, 0.0, 8.0, 8.0, 14.0, 8.0, 4.0, 8.0, -4.0, 4.0, 0.0, 4.0, 8.0, 0.0, 8.0, 8.0, 4.0, 8.0, 8.0, 4.0, -8.0, 0.0, 4.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 4.0, 0.0, 4.0, 0.0, 4.0, 0.0, 8.0, 8.0, 0.0, 8.0, 8.0, 8.0], "episode_lengths": [8, 6, 10, 6, 6, 6, 10, 8, 12, 8, 12, 6, 10, 6, 6, 6, 6, 10, 3, 3, 12, 12, 10, 6, 6, 6, 8, 6, 10, 6, 6, 9, 10, 8, 6, 6, 6, 6, 8, 10, 8, 6, 6, 6, 7, 6, 12, 6, 6, 6, 10, 6, 8, 8, 7, 6, 8, 6, 6, 10, 10, 6, 6, 3, 6, 8, 6, 12, 8, 10, 8, 6, 10, 6, 6, 8, 6, 6, 8, 14, 10, 8, 6, 6, 6, 8, 8, 6, 8, 10, 8, 10, 8, 10, 6, 6, 10, 6, 6, 6], "policy_policy0_reward": [2.0, 14.0, 10.0, 14.0, 14.0, 14.0, 10.0, 12.0, -2.0, 2.0, 8.0, 14.0, 10.0, 4.0, 14.0, 14.0, 14.0, 10.0, 7.0, 7.0, 8.0, 8.0, 10.0, 4.0, 14.0, 14.0, 12.0, 14.0, 10.0, 14.0, 4.0, 11.0, 10.0, 2.0, 14.0, 14.0, 14.0, 14.0, 12.0, 10.0, 12.0, 4.0, 14.0, 14.0, 3.0, 14.0, 8.0, 14.0, 14.0, 14.0, 10.0, 14.0, 12.0, 12.0, 3.0, 14.0, 12.0, 14.0, 14.0, 10.0, 10.0, 14.0, 14.0, 7.0, 4.0, 12.0, 14.0, 8.0, 12.0, 10.0, 12.0, 14.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 12.0, 6.0, 0.0, 12.0, 14.0, 14.0, 4.0, 12.0, 12.0, 14.0, 12.0, 10.0, 12.0, 10.0, 12.0, 10.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [2.0, -6.0, -10.0, -6.0, -6.0, -6.0, -10.0, -8.0, -2.0, 2.0, -12.0, -6.0, -10.0, 4.0, -6.0, -6.0, -6.0, -10.0, 7.0, 7.0, -12.0, -12.0, -10.0, 4.0, -6.0, -6.0, -8.0, -6.0, -10.0, -6.0, 4.0, -9.0, -10.0, 2.0, -6.0, -6.0, -6.0, -6.0, -8.0, -10.0, -8.0, 4.0, -6.0, -6.0, 3.0, -6.0, -12.0, -6.0, -6.0, -6.0, -10.0, -6.0, -8.0, -8.0, 3.0, -6.0, -8.0, -6.0, -6.0, -10.0, -10.0, -6.0, -6.0, 7.0, 4.0, -8.0, -6.0, -12.0, -8.0, -10.0, -8.0, -6.0, -10.0, -6.0, -6.0, -8.0, -6.0, -6.0, -8.0, -14.0, 0.0, -8.0, -6.0, -6.0, 4.0, -8.0, -8.0, -6.0, -8.0, -10.0, -8.0, -10.0, -8.0, -10.0, -6.0, -6.0, -10.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3396830198870774, "mean_inference_ms": 1.7400595745129277, "mean_action_processing_ms": 0.11884640450377523, "mean_env_wait_ms": 0.0752187263239605, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19760, "timesteps_this_iter": 32, "agent_timesteps_total": 39520, "timers": {"load_time_ms": 0.419, "load_throughput": 76342.488, "learn_time_ms": 7.792, "learn_throughput": 4107.03, "update_time_ms": 4.726}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.017742156982422, "min_q": -1.1002973318099976, "max_q": 15.980440139770508, "mean_td_error": 0.014402508735656738, "model": {}}, "td_error": [-0.6535758972167969, 4.5792131423950195, -1.9136443138122559, -0.5966000556945801, -0.4019603729248047, -0.21778202056884766, -0.8375253677368164, 0.49937689304351807, 1.4318351745605469, 0.38709545135498047, -1.796889066696167, -0.5131778717041016, -0.8470325469970703, -1.529782772064209, 1.2204582691192627, 0.041224002838134766, -1.3288838863372803, 7.35723876953125, -0.7621231079101562, 1.0862054824829102, -3.7155609130859375, -2.613675117492676, 0.49937689304351807, 0.21975040435791016, -0.5267295837402344, 0.1089029312133789, -1.0835514068603516, 6.724244117736816, -1.9343905448913574, -0.8227415084838867, -0.4860668182373047, -1.112349033355713], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.573603391647339, "min_q": -8.239717483520508, "max_q": 9.089917182922363, "mean_td_error": 0.37510257959365845, "model": {}}, "td_error": [0.9782013893127441, -0.5755367279052734, -0.7928915023803711, -8.077835083007812, 3.0615015029907227, 3.410749912261963, -2.681424617767334, -2.7497446537017822, 3.8429250717163086, 0.15911293029785156, 3.5779004096984863, -1.1535003185272217, -8.372845649719238, 0.2546072006225586, 3.410749912261963, 3.0110557079315186, 7.906926155090332, 0.28458404541015625, 2.0647459030151367, 2.6972999572753906, 0.7934885025024414, 2.2113046646118164, -0.8383803367614746, 5.274438858032227, -8.942079544067383, 3.410749912261963, -4.756137371063232, 3.248940944671631, -1.7421138286590576, -0.43419182300567627, 1.3725194931030273, 2.1481618881225586], "custom_metrics": {}}}, "num_steps_sampled": 19760, "num_agent_steps_sampled": 39520, "num_steps_trained": 50528, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 101056, "last_target_update_ts": 19710, "num_target_updates": 174}, "done": false, "episodes_total": 1686, "training_iteration": 79, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-15-59", "timestamp": 1648811759, "time_this_iter_s": 1.194037675857544, "time_total_s": 94.44372344017029, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 94.44372344017029, "timesteps_since_restore": 2528, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 31.0, "ram_util_percent": 59.4}}
{"episode_reward_max": 14.0, "episode_reward_min": -8.0, "episode_reward_mean": 5.3, "episode_len_mean": 7.35, "episode_media": {}, "episodes_this_iter": 30, "policy_reward_min": {"policy0": -1.0, "policy1": -14.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 10.35, "policy1": -5.05}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 2.0, 0.0, 4.0, 8.0, 8.0, 8.0, 8.0, 4.0, 0.0, 4.0, 8.0, 8.0, 8.0, 6.0, 8.0, -4.0, 8.0, 8.0, 8.0, 0.0, 8.0, 4.0, 4.0, 6.0, 8.0, 4.0, 8.0, 8.0, 0.0, 0.0, 8.0, 8.0, 14.0, 8.0, 4.0, 8.0, -4.0, 4.0, 0.0, 4.0, 8.0, 0.0, 8.0, 8.0, 4.0, 8.0, 8.0, 4.0, -8.0, 0.0, 4.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 4.0, 0.0, 4.0, 0.0, 4.0, 0.0, 8.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, -8.0, 8.0, 4.0, 4.0, 12.0, 12.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, -2.0, 8.0, 8.0, 0.0, 4.0, 4.0], "episode_lengths": [6, 9, 10, 8, 6, 6, 6, 6, 8, 10, 8, 6, 6, 6, 7, 6, 12, 6, 6, 6, 10, 6, 8, 8, 7, 6, 8, 6, 6, 10, 10, 6, 6, 3, 6, 8, 6, 12, 8, 10, 8, 6, 10, 6, 6, 8, 6, 6, 8, 14, 10, 8, 6, 6, 6, 8, 8, 6, 8, 10, 8, 10, 8, 10, 6, 6, 10, 6, 6, 6, 6, 6, 6, 10, 14, 6, 8, 8, 4, 4, 6, 6, 6, 6, 8, 6, 8, 6, 6, 6, 6, 6, 8, 6, 11, 6, 6, 10, 8, 8], "policy_policy0_reward": [4.0, 11.0, 10.0, 2.0, 14.0, 14.0, 14.0, 14.0, 12.0, 10.0, 12.0, 4.0, 14.0, 14.0, 3.0, 14.0, 8.0, 14.0, 14.0, 14.0, 10.0, 14.0, 12.0, 12.0, 3.0, 14.0, 12.0, 14.0, 14.0, 10.0, 10.0, 14.0, 14.0, 7.0, 4.0, 12.0, 14.0, 8.0, 12.0, 10.0, 12.0, 14.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 12.0, 6.0, 0.0, 12.0, 14.0, 14.0, 4.0, 12.0, 12.0, 14.0, 12.0, 10.0, 12.0, 10.0, 12.0, 10.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 4.0, 4.0, 14.0, 0.0, 6.0, 4.0, 2.0, 2.0, 6.0, 6.0, 4.0, 14.0, 4.0, 14.0, 2.0, 4.0, 12.0, 14.0, 14.0, 14.0, 14.0, 4.0, 12.0, 14.0, -1.0, 14.0, 14.0, 10.0, 12.0, 12.0], "policy_policy1_reward": [4.0, -9.0, -10.0, 2.0, -6.0, -6.0, -6.0, -6.0, -8.0, -10.0, -8.0, 4.0, -6.0, -6.0, 3.0, -6.0, -12.0, -6.0, -6.0, -6.0, -10.0, -6.0, -8.0, -8.0, 3.0, -6.0, -8.0, -6.0, -6.0, -10.0, -10.0, -6.0, -6.0, 7.0, 4.0, -8.0, -6.0, -12.0, -8.0, -10.0, -8.0, -6.0, -10.0, -6.0, -6.0, -8.0, -6.0, -6.0, -8.0, -14.0, 0.0, -8.0, -6.0, -6.0, 4.0, -8.0, -8.0, -6.0, -8.0, -10.0, -8.0, -10.0, -8.0, -10.0, -6.0, -6.0, -10.0, -6.0, -6.0, -6.0, 4.0, 4.0, -6.0, 0.0, -14.0, 4.0, 2.0, 2.0, 6.0, 6.0, 4.0, -6.0, 4.0, -6.0, 2.0, 4.0, -8.0, -6.0, -6.0, -6.0, -6.0, 4.0, -8.0, -6.0, -1.0, -6.0, -6.0, -10.0, -8.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3399525615216325, "mean_inference_ms": 1.7389739075203472, "mean_action_processing_ms": 0.1187555220362513, "mean_env_wait_ms": 0.07517568897870261, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19971, "timesteps_this_iter": 32, "agent_timesteps_total": 39942, "timers": {"load_time_ms": 0.433, "load_throughput": 73892.165, "learn_time_ms": 7.653, "learn_throughput": 4181.29, "update_time_ms": 4.79}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.320995330810547, "min_q": -0.769895076751709, "max_q": 14.306639671325684, "mean_td_error": 0.1973075270652771, "model": {}}, "td_error": [-0.14609622955322266, -0.5103826522827148, -0.1928846836090088, 0.7277016639709473, -1.1025047302246094, 0.1258554458618164, 0.589289665222168, 0.08607101440429688, -0.11883974075317383, 0.19490432739257812, 1.00455904006958, 0.2804255485534668, 0.24316072463989258, -0.1293792724609375, -0.9659113883972168, -0.3437623977661133, 0.4858889579772949, 3.5654869079589844, -0.002697467803955078, 0.026873111724853516, 0.2844562530517578, -1.43353271484375, -1.2874565124511719, 4.834488391876221, -0.06366920471191406, -0.3232846260070801, -0.09929752349853516, 1.733256459236145, 0.5404205322265625, -0.5103826522827148, -1.980269432067871, 0.801354169845581], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.922276020050049, "min_q": -8.692095756530762, "max_q": 3.5085084438323975, "mean_td_error": -1.0719325542449951, "model": {}}, "td_error": [-1.3770408630371094, 2.5245370864868164, 0.038196563720703125, -1.0078845024108887, 2.3376927375793457, -0.2751955986022949, -1.116584300994873, 0.8485803604125977, -8.54780387878418, 0.6402981877326965, -8.906660079956055, -2.59114670753479, -0.3474292755126953, -3.8456289768218994, -1.9067535400390625, 1.673766851425171, 1.5984349250793457, 1.6891107559204102, 1.504690170288086, -2.807934045791626, 2.0095574855804443, -1.6811341047286987, 1.5740940570831299, -7.6866302490234375, -0.1250913143157959, 0.3286380171775818, -0.5314996242523193, 2.402949810028076, -0.49356746673583984, -0.7932922840118408, 2.7552754878997803, -12.186388969421387], "custom_metrics": {}}}, "num_steps_sampled": 19971, "num_agent_steps_sampled": 39942, "num_steps_trained": 51488, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 102976, "last_target_update_ts": 19922, "num_target_updates": 176}, "done": false, "episodes_total": 1716, "training_iteration": 80, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-01", "timestamp": 1648811761, "time_this_iter_s": 1.2867650985717773, "time_total_s": 95.73048853874207, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 95.73048853874207, "timesteps_since_restore": 2560, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 32.35, "ram_util_percent": 59.4}}
{"episode_reward_max": 14.0, "episode_reward_min": -8.0, "episode_reward_mean": 5.4, "episode_len_mean": 7.3, "episode_media": {}, "episodes_this_iter": 29, "policy_reward_min": {"policy0": -1.0, "policy1": -14.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 10.7, "policy1": -5.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 8.0, 8.0, 14.0, 8.0, 4.0, 8.0, -4.0, 4.0, 0.0, 4.0, 8.0, 0.0, 8.0, 8.0, 4.0, 8.0, 8.0, 4.0, -8.0, 0.0, 4.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 4.0, 0.0, 4.0, 0.0, 4.0, 0.0, 8.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, -8.0, 8.0, 4.0, 4.0, 12.0, 12.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, -2.0, 8.0, 8.0, 0.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, -8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 4.0, 4.0, 6.0, 8.0, 8.0, 4.0, 8.0, 2.0, 8.0, 8.0, 4.0], "episode_lengths": [10, 10, 6, 6, 3, 6, 8, 6, 12, 8, 10, 8, 6, 10, 6, 6, 8, 6, 6, 8, 14, 10, 8, 6, 6, 6, 8, 8, 6, 8, 10, 8, 10, 8, 10, 6, 6, 10, 6, 6, 6, 6, 6, 6, 10, 14, 6, 8, 8, 4, 4, 6, 6, 6, 6, 8, 6, 8, 6, 6, 6, 6, 6, 8, 6, 11, 6, 6, 10, 8, 8, 6, 6, 6, 6, 10, 6, 6, 6, 6, 8, 6, 6, 14, 8, 6, 6, 6, 8, 8, 8, 7, 6, 6, 8, 6, 9, 6, 6, 8], "policy_policy0_reward": [10.0, 10.0, 14.0, 14.0, 7.0, 4.0, 12.0, 14.0, 8.0, 12.0, 10.0, 12.0, 14.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 12.0, 6.0, 0.0, 12.0, 14.0, 14.0, 4.0, 12.0, 12.0, 14.0, 12.0, 10.0, 12.0, 10.0, 12.0, 10.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 4.0, 4.0, 14.0, 0.0, 6.0, 4.0, 2.0, 2.0, 6.0, 6.0, 4.0, 14.0, 4.0, 14.0, 2.0, 4.0, 12.0, 14.0, 14.0, 14.0, 14.0, 4.0, 12.0, 14.0, -1.0, 14.0, 14.0, 10.0, 12.0, 12.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 6.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 12.0, 3.0, 14.0, 14.0, 12.0, 14.0, 1.0, 14.0, 14.0, 12.0], "policy_policy1_reward": [-10.0, -10.0, -6.0, -6.0, 7.0, 4.0, -8.0, -6.0, -12.0, -8.0, -10.0, -8.0, -6.0, -10.0, -6.0, -6.0, -8.0, -6.0, -6.0, -8.0, -14.0, 0.0, -8.0, -6.0, -6.0, 4.0, -8.0, -8.0, -6.0, -8.0, -10.0, -8.0, -10.0, -8.0, -10.0, -6.0, -6.0, -10.0, -6.0, -6.0, -6.0, 4.0, 4.0, -6.0, 0.0, -14.0, 4.0, 2.0, 2.0, 6.0, 6.0, 4.0, -6.0, 4.0, -6.0, 2.0, 4.0, -8.0, -6.0, -6.0, -6.0, -6.0, 4.0, -8.0, -6.0, -1.0, -6.0, -6.0, -10.0, -8.0, -8.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -14.0, -8.0, -6.0, -6.0, -6.0, -8.0, -8.0, -8.0, 3.0, -6.0, -6.0, -8.0, -6.0, 1.0, -6.0, -6.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34010412109425003, "mean_inference_ms": 1.737341551503556, "mean_action_processing_ms": 0.11861859685659354, "mean_env_wait_ms": 0.07510492992604223, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20175, "timesteps_this_iter": 32, "agent_timesteps_total": 40350, "timers": {"load_time_ms": 0.425, "load_throughput": 75229.936, "learn_time_ms": 7.696, "learn_throughput": 4158.09, "update_time_ms": 4.565}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.654620170593262, "min_q": 2.2725398540496826, "max_q": 13.571945190429688, "mean_td_error": 1.0079007148742676, "model": {}}, "td_error": [0.727095365524292, -0.213287353515625, 3.1797714233398438, -0.14113998413085938, 1.1067771911621094, 0.6849861145019531, 0.7952041625976562, -0.5840673446655273, -0.35285472869873047, 0.5163848400115967, 0.1837015151977539, 1.1173973083496094, -1.030421257019043, 0.8546652793884277, 0.2749929428100586, 1.4396800994873047, 0.31574010848999023, 0.5194025039672852, 0.6449718475341797, -0.4313650131225586, 0.05301523208618164, -0.22566890716552734, -0.14339637756347656, 3.2725398540496826, 0.03829383850097656, 0.6493492126464844, 9.007179260253906, 2.6258697509765625, 0.014894485473632812, 6.1676025390625, 0.43327999114990234, 0.7522268295288086], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.53559947013855, "min_q": -7.417289733886719, "max_q": 5.019806861877441, "mean_td_error": 0.2136756181716919, "model": {}}, "td_error": [1.2512874603271484, -1.8249330520629883, 6.303612232208252, -0.5744928121566772, -1.4327330589294434, 1.4691123962402344, 3.5453031063079834, -0.36875104904174805, 2.7333526611328125, 0.9735696315765381, -4.983528137207031, -8.938863754272461, 2.710024118423462, 4.721342086791992, 1.2689056396484375, -0.1409626007080078, 3.4559273719787598, -14.81962776184082, 0.40689992904663086, 2.880915641784668, 0.1349959373474121, -0.44395923614501953, 0.3106781840324402, 2.6601643562316895, 0.679619312286377, -1.1230709552764893, -0.13787269592285156, -0.35101938247680664, 2.7312331199645996, 2.6181554794311523, 0.8547134399414062, 0.2676210403442383], "custom_metrics": {}}}, "num_steps_sampled": 20175, "num_agent_steps_sampled": 40350, "num_steps_trained": 52416, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 104832, "last_target_update_ts": 20126, "num_target_updates": 178}, "done": false, "episodes_total": 1745, "training_iteration": 81, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-02", "timestamp": 1648811762, "time_this_iter_s": 1.2332913875579834, "time_total_s": 96.96377992630005, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847f170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 96.96377992630005, "timesteps_since_restore": 2592, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 31.1, "ram_util_percent": 59.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -8.0, "episode_reward_mean": 6.04, "episode_len_mean": 6.98, "episode_media": {}, "episodes_this_iter": 31, "policy_reward_min": {"policy0": -1.0, "policy1": -14.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 10.32, "policy1": -4.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 0.0, 4.0, 0.0, 8.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, -8.0, 8.0, 4.0, 4.0, 12.0, 12.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, -2.0, 8.0, 8.0, 0.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, -8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 4.0, 4.0, 6.0, 8.0, 8.0, 4.0, 8.0, 2.0, 8.0, 8.0, 4.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 14.0, 0.0, 8.0, 4.0, 8.0, 4.0, 12.0, 8.0, 0.0, 8.0, 4.0, 8.0, 12.0, 8.0, 8.0, 8.0, 0.0], "episode_lengths": [8, 10, 8, 10, 6, 6, 10, 6, 6, 6, 6, 6, 6, 10, 14, 6, 8, 8, 4, 4, 6, 6, 6, 6, 8, 6, 8, 6, 6, 6, 6, 6, 8, 6, 11, 6, 6, 10, 8, 8, 6, 6, 6, 6, 10, 6, 6, 6, 6, 8, 6, 6, 14, 8, 6, 6, 6, 8, 8, 8, 7, 6, 6, 8, 6, 9, 6, 6, 8, 6, 10, 6, 6, 6, 6, 6, 8, 6, 6, 6, 8, 8, 6, 3, 10, 6, 8, 6, 8, 4, 6, 10, 6, 8, 6, 4, 6, 6, 6, 10], "policy_policy0_reward": [12.0, 10.0, 12.0, 10.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 4.0, 4.0, 14.0, 0.0, 6.0, 4.0, 2.0, 2.0, 6.0, 6.0, 4.0, 14.0, 4.0, 14.0, 2.0, 4.0, 12.0, 14.0, 14.0, 14.0, 14.0, 4.0, 12.0, 14.0, -1.0, 14.0, 14.0, 10.0, 12.0, 12.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 6.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 12.0, 3.0, 14.0, 14.0, 12.0, 14.0, 1.0, 14.0, 14.0, 12.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 2.0, 14.0, 4.0, 4.0, 12.0, 12.0, 4.0, 7.0, 0.0, 4.0, 12.0, 14.0, 12.0, 6.0, 4.0, 10.0, 14.0, 12.0, 4.0, 6.0, 14.0, 14.0, 14.0, 10.0], "policy_policy1_reward": [-8.0, -10.0, -8.0, -10.0, -6.0, -6.0, -10.0, -6.0, -6.0, -6.0, 4.0, 4.0, -6.0, 0.0, -14.0, 4.0, 2.0, 2.0, 6.0, 6.0, 4.0, -6.0, 4.0, -6.0, 2.0, 4.0, -8.0, -6.0, -6.0, -6.0, -6.0, 4.0, -8.0, -6.0, -1.0, -6.0, -6.0, -10.0, -8.0, -8.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -14.0, -8.0, -6.0, -6.0, -6.0, -8.0, -8.0, -8.0, 3.0, -6.0, -6.0, -8.0, -6.0, 1.0, -6.0, -6.0, -8.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, 2.0, -6.0, 4.0, 4.0, -8.0, -8.0, 4.0, 7.0, 0.0, 4.0, -8.0, -6.0, -8.0, 6.0, 4.0, -10.0, -6.0, -8.0, 4.0, 6.0, -6.0, -6.0, -6.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3403750096123926, "mean_inference_ms": 1.736212931753261, "mean_action_processing_ms": 0.11852015728871265, "mean_env_wait_ms": 0.07504704126846484, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20382, "timesteps_this_iter": 32, "agent_timesteps_total": 40764, "timers": {"load_time_ms": 0.612, "load_throughput": 52251.227, "learn_time_ms": 9.057, "learn_throughput": 3533.068, "update_time_ms": 5.267}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.337381839752197, "min_q": 0.9018799066543579, "max_q": 13.873376846313477, "mean_td_error": 0.76287841796875, "model": {}}, "td_error": [0.9641447067260742, -0.13640117645263672, -1.091801643371582, 0.37464380264282227, 0.1620039939880371, 2.453209161758423, 0.5321955680847168, 2.516418933868408, 0.4911355972290039, 0.5543942451477051, 0.4911355972290039, 4.5924882888793945, 0.6053299903869629, -0.07654094696044922, 0.3736586570739746, 0.5594892501831055, 1.1955499649047852, -0.05742156505584717, 0.7586231231689453, 0.5129642486572266, -2.1043500900268555, 0.8462042808532715, 1.8607628345489502, 0.6718888282775879, 0.5838069915771484, 1.2324676513671875, 1.2668399810791016, 2.175983428955078, -0.19484615325927734, 2.943479061126709, 0.8942089080810547, -1.5395560264587402], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.5775411128997803, "min_q": -8.683135986328125, "max_q": 7.653337001800537, "mean_td_error": -1.3129962682724, "model": {}}, "td_error": [2.1008036136627197, 2.33357572555542, -3.455061912536621, 0.7313668727874756, 2.2406563758850098, -16.346588134765625, -0.09180212020874023, 1.2055559158325195, -8.767333030700684, -3.1660661697387695, -8.767333030700684, 4.454934120178223, 1.940171718597412, 1.0460283756256104, 6.0925374031066895, 1.031050682067871, -8.767333030700684, 0.028761863708496094, 1.5075922012329102, 2.736337184906006, -0.5875167846679688, -0.18283414840698242, -1.346662998199463, -9.612627983093262, -1.768378734588623, -0.4667215347290039, 1.754692554473877, 1.506568431854248, 0.7524776458740234, -12.610708236694336, 3.486422061920166, -1.0284452438354492], "custom_metrics": {}}}, "num_steps_sampled": 20382, "num_agent_steps_sampled": 40764, "num_steps_trained": 53376, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 106752, "last_target_update_ts": 20330, "num_target_updates": 180}, "done": false, "episodes_total": 1776, "training_iteration": 82, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-03", "timestamp": 1648811763, "time_this_iter_s": 1.392320156097412, "time_total_s": 98.35610008239746, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847ff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5847ff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 98.35610008239746, "timesteps_since_restore": 2624, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 30.75, "ram_util_percent": 59.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -10.0, "episode_reward_mean": 6.04, "episode_len_mean": 6.98, "episode_media": {}, "episodes_this_iter": 29, "policy_reward_min": {"policy0": -1.0, "policy1": -15.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 11.02, "policy1": -4.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 4.0, 8.0, -2.0, 8.0, 8.0, 0.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, -8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 4.0, 4.0, 6.0, 8.0, 8.0, 4.0, 8.0, 2.0, 8.0, 8.0, 4.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 14.0, 0.0, 8.0, 4.0, 8.0, 4.0, 12.0, 8.0, 0.0, 8.0, 4.0, 8.0, 12.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 10.0, 14.0, 0.0, 0.0, 4.0, 8.0, 4.0, 8.0, 8.0, 14.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, -10.0, 4.0, 8.0, 8.0, 8.0, -4.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 8, 6, 11, 6, 6, 10, 8, 8, 6, 6, 6, 6, 10, 6, 6, 6, 6, 8, 6, 6, 14, 8, 6, 6, 6, 8, 8, 8, 7, 6, 6, 8, 6, 9, 6, 6, 8, 6, 10, 6, 6, 6, 6, 6, 8, 6, 6, 6, 8, 8, 6, 3, 10, 6, 8, 6, 8, 4, 6, 10, 6, 8, 6, 4, 6, 6, 6, 10, 6, 10, 5, 3, 10, 10, 8, 6, 8, 6, 6, 3, 6, 10, 6, 6, 6, 6, 8, 6, 6, 15, 8, 6, 6, 6, 12, 6, 6], "policy_policy0_reward": [14.0, 14.0, 4.0, 12.0, 14.0, -1.0, 14.0, 14.0, 10.0, 12.0, 12.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 6.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 12.0, 3.0, 14.0, 14.0, 12.0, 14.0, 1.0, 14.0, 14.0, 12.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 2.0, 14.0, 4.0, 4.0, 12.0, 12.0, 4.0, 7.0, 0.0, 4.0, 12.0, 14.0, 12.0, 6.0, 4.0, 10.0, 14.0, 12.0, 4.0, 6.0, 14.0, 14.0, 14.0, 10.0, 14.0, 10.0, 5.0, 7.0, 10.0, 10.0, 12.0, 14.0, 12.0, 14.0, 14.0, 7.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 5.0, 2.0, 14.0, 14.0, 4.0, 8.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, 4.0, -8.0, -6.0, -1.0, -6.0, -6.0, -10.0, -8.0, -8.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -14.0, -8.0, -6.0, -6.0, -6.0, -8.0, -8.0, -8.0, 3.0, -6.0, -6.0, -8.0, -6.0, 1.0, -6.0, -6.0, -8.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, 2.0, -6.0, 4.0, 4.0, -8.0, -8.0, 4.0, 7.0, 0.0, 4.0, -8.0, -6.0, -8.0, 6.0, 4.0, -10.0, -6.0, -8.0, 4.0, 6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -10.0, 5.0, 7.0, -10.0, -10.0, -8.0, -6.0, -8.0, -6.0, -6.0, 7.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -15.0, 2.0, -6.0, -6.0, 4.0, -12.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3407938760727356, "mean_inference_ms": 1.7363054012367838, "mean_action_processing_ms": 0.11850753148132906, "mean_env_wait_ms": 0.07502607128690969, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20588, "timesteps_this_iter": 32, "agent_timesteps_total": 41176, "timers": {"load_time_ms": 0.461, "load_throughput": 69427.751, "learn_time_ms": 8.319, "learn_throughput": 3846.574, "update_time_ms": 5.416}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.17254638671875, "min_q": 1.8821245431900024, "max_q": 13.454699516296387, "mean_td_error": 1.2815485000610352, "model": {}}, "td_error": [0.5750679969787598, 0.0778665542602539, -0.21258926391601562, 1.1566753387451172, 5.777976989746094, -1.4911346435546875, -1.3370208740234375, 0.40238094329833984, 0.41132164001464844, -0.5778360366821289, 2.882124423980713, 0.35259556770324707, 6.295622825622559, 0.012237548828125, 0.1355443000793457, -2.2103967666625977, 0.03197669982910156, 0.5471415519714355, 0.494964599609375, -0.04788684844970703, 1.411231279373169, 8.221015930175781, -0.2951231002807617, 5.445408821105957, 3.0213265419006348, 0.857142448425293, 4.990623950958252, 3.170138359069824, 0.6046719551086426, -0.7846412658691406, 0.39824867248535156, 0.6928739547729492], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.5996384620666504, "min_q": -8.582240104675293, "max_q": 7.811145782470703, "mean_td_error": -0.05919012427330017, "model": {}}, "td_error": [0.04035615921020508, -0.28073787689208984, 1.95933198928833, -6.284745693206787, 0.3268623352050781, 2.3532795906066895, 3.969420909881592, 2.5439419746398926, -0.3293576240539551, 3.3392996788024902, -0.044091224670410156, 0.8809404373168945, -3.1385388374328613, 0.22724676132202148, -0.19764232635498047, -0.8936934471130371, 1.8028016090393066, -9.094511032104492, 2.6525492668151855, -0.7031674385070801, 2.528170585632324, 1.8755159378051758, -0.6361961364746094, -1.6051836013793945, -1.2969255447387695, -1.8505027294158936, 0.5139831900596619, 0.40518951416015625, -0.5020899772644043, 2.303985118865967, -1.5707216262817383, -1.1888542175292969], "custom_metrics": {}}}, "num_steps_sampled": 20588, "num_agent_steps_sampled": 41176, "num_steps_trained": 54240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 108480, "last_target_update_ts": 20538, "num_target_updates": 182}, "done": false, "episodes_total": 1805, "training_iteration": 83, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-05", "timestamp": 1648811765, "time_this_iter_s": 1.3986008167266846, "time_total_s": 99.75470089912415, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58408830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58408830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 99.75470089912415, "timesteps_since_restore": 2656, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 31.700000000000003, "ram_util_percent": 59.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -10.0, "episode_reward_mean": 6.5, "episode_len_mean": 6.75, "episode_media": {}, "episodes_this_iter": 32, "policy_reward_min": {"policy0": -1.0, "policy1": -15.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 10.35, "policy1": -3.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 4.0, 8.0, 2.0, 8.0, 8.0, 4.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 14.0, 0.0, 8.0, 4.0, 8.0, 4.0, 12.0, 8.0, 0.0, 8.0, 4.0, 8.0, 12.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 10.0, 14.0, 0.0, 0.0, 4.0, 8.0, 4.0, 8.0, 8.0, 14.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, -10.0, 4.0, 8.0, 8.0, 8.0, -4.0, 8.0, 8.0, 8.0, -4.0, -2.0, 8.0, 12.0, 0.0, 4.0, 4.0, 4.0, 8.0, 14.0, 10.0, 4.0, 0.0, 8.0, 8.0, 14.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 10.0, 14.0, 8.0, 14.0, 8.0, 8.0, 4.0, 8.0], "episode_lengths": [6, 6, 8, 6, 9, 6, 6, 8, 6, 10, 6, 6, 6, 6, 6, 8, 6, 6, 6, 8, 8, 6, 3, 10, 6, 8, 6, 8, 4, 6, 10, 6, 8, 6, 4, 6, 6, 6, 10, 6, 10, 5, 3, 10, 10, 8, 6, 8, 6, 6, 3, 6, 10, 6, 6, 6, 6, 8, 6, 6, 15, 8, 6, 6, 6, 12, 6, 6, 6, 12, 11, 6, 4, 10, 8, 8, 8, 6, 3, 5, 8, 10, 6, 6, 3, 6, 6, 8, 6, 6, 6, 6, 5, 3, 6, 3, 6, 6, 8, 6], "policy_policy0_reward": [14.0, 14.0, 12.0, 14.0, 1.0, 14.0, 14.0, 12.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 2.0, 14.0, 4.0, 4.0, 12.0, 12.0, 4.0, 7.0, 0.0, 4.0, 12.0, 14.0, 12.0, 6.0, 4.0, 10.0, 14.0, 12.0, 4.0, 6.0, 14.0, 14.0, 14.0, 10.0, 14.0, 10.0, 5.0, 7.0, 10.0, 10.0, 12.0, 14.0, 12.0, 14.0, 14.0, 7.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 5.0, 2.0, 14.0, 14.0, 4.0, 8.0, 14.0, 14.0, 14.0, 8.0, -1.0, 4.0, 6.0, 10.0, 2.0, 12.0, 12.0, 14.0, 7.0, 5.0, 12.0, 10.0, 14.0, 4.0, 7.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 5.0, 7.0, 14.0, 7.0, 4.0, 14.0, 12.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -8.0, -6.0, 1.0, -6.0, -6.0, -8.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, 2.0, -6.0, 4.0, 4.0, -8.0, -8.0, 4.0, 7.0, 0.0, 4.0, -8.0, -6.0, -8.0, 6.0, 4.0, -10.0, -6.0, -8.0, 4.0, 6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -10.0, 5.0, 7.0, -10.0, -10.0, -8.0, -6.0, -8.0, -6.0, -6.0, 7.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -15.0, 2.0, -6.0, -6.0, 4.0, -12.0, -6.0, -6.0, -6.0, -12.0, -1.0, 4.0, 6.0, -10.0, 2.0, -8.0, -8.0, -6.0, 7.0, 5.0, -8.0, -10.0, -6.0, 4.0, 7.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 5.0, 7.0, -6.0, 7.0, 4.0, -6.0, -8.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3413132034274875, "mean_inference_ms": 1.736642261921352, "mean_action_processing_ms": 0.11850664603205521, "mean_env_wait_ms": 0.07500711705766655, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20795, "timesteps_this_iter": 32, "agent_timesteps_total": 41590, "timers": {"load_time_ms": 0.429, "load_throughput": 74644.196, "learn_time_ms": 7.833, "learn_throughput": 4085.166, "update_time_ms": 4.613}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.333554267883301, "min_q": -0.7279024720191956, "max_q": 15.580739974975586, "mean_td_error": 1.1626558303833008, "model": {}}, "td_error": [1.7069206237792969, 0.6044082641601562, 2.2398173809051514, 0.2556791305541992, 0.12066364288330078, 0.4112081527709961, -0.14815425872802734, 5.498979091644287, 0.6835179328918457, 0.847926139831543, 1.5795512199401855, 0.6107769012451172, 1.1708950996398926, 0.30548858642578125, -0.20039844512939453, 0.2556791305541992, 1.375166416168213, 0.4922676086425781, 0.05932426452636719, 0.050159454345703125, 8.692438125610352, 0.7871991991996765, 0.4840888977050781, 2.600865364074707, -0.3633151054382324, 0.5235923528671265, -1.9423694610595703, 0.4678916931152344, 3.9132232666015625, -0.1455700397491455, 3.31710147857666, 0.9499602317810059], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.9687020778656006, "min_q": -8.068367958068848, "max_q": 1.734518051147461, "mean_td_error": -1.104138731956482, "model": {}}, "td_error": [-0.4536206126213074, -1.381469488143921, -4.242092609405518, -4.2838616371154785, -2.267698049545288, 1.5771117210388184, -0.38894951343536377, 3.170856475830078, -0.9190902709960938, -0.8339569568634033, -1.8705363273620605, -4.71698522567749, 0.6221733093261719, -1.8388466835021973, 1.5331077575683594, -6.194796562194824, 1.210474967956543, 3.1615724563598633, 1.030228614807129, 0.5976471900939941, -4.509838104248047, -0.49547290802001953, -2.357822895050049, -5.803048133850098, 0.37525081634521484, -6.593748092651367, -1.484593391418457, 1.480347752571106, -5.405007839202881, 2.388484239578247, 0.5141434669494629, 3.0475990772247314], "custom_metrics": {}}}, "num_steps_sampled": 20795, "num_agent_steps_sampled": 41590, "num_steps_trained": 55136, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 110272, "last_target_update_ts": 20746, "num_target_updates": 184}, "done": false, "episodes_total": 1837, "training_iteration": 84, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-06", "timestamp": 1648811766, "time_this_iter_s": 1.2578043937683105, "time_total_s": 101.01250529289246, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 101.01250529289246, "timesteps_since_restore": 2688, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 31.4, "ram_util_percent": 59.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -10.0, "episode_reward_mean": 6.2, "episode_len_mean": 6.9, "episode_media": {}, "episodes_this_iter": 28, "policy_reward_min": {"policy0": -9.0, "policy1": -15.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": 10.5, "policy1": -4.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, 8.0, 0.0, 8.0, 4.0, 8.0, 12.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 10.0, 14.0, 0.0, 0.0, 4.0, 8.0, 4.0, 8.0, 8.0, 14.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, -10.0, 4.0, 8.0, 8.0, 8.0, -4.0, 8.0, 8.0, 8.0, -4.0, -2.0, 8.0, 12.0, 0.0, 4.0, 4.0, 4.0, 8.0, 14.0, 10.0, 4.0, 0.0, 8.0, 8.0, 14.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 10.0, 14.0, 8.0, 14.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 6.0, 4.0, 4.0, 8.0, 4.0, 8.0, 14.0, 8.0, 4.0, 4.0, 8.0, 8.0, 4.0, 2.0, 2.0, -4.0, 4.0, 2.0, 8.0, 8.0, 4.0, 4.0, 0.0], "episode_lengths": [4, 6, 10, 6, 8, 6, 4, 6, 6, 6, 10, 6, 10, 5, 3, 10, 10, 8, 6, 8, 6, 6, 3, 6, 10, 6, 6, 6, 6, 8, 6, 6, 15, 8, 6, 6, 6, 12, 6, 6, 6, 12, 11, 6, 4, 10, 8, 8, 8, 6, 3, 5, 8, 10, 6, 6, 3, 6, 6, 8, 6, 6, 6, 6, 5, 3, 6, 3, 6, 6, 8, 6, 8, 6, 6, 6, 6, 7, 8, 8, 6, 8, 6, 3, 6, 8, 8, 6, 6, 8, 9, 9, 12, 8, 9, 6, 6, 8, 8, 10], "policy_policy0_reward": [6.0, 4.0, 10.0, 14.0, 12.0, 4.0, 6.0, 14.0, 14.0, 14.0, 10.0, 14.0, 10.0, 5.0, 7.0, 10.0, 10.0, 12.0, 14.0, 12.0, 14.0, 14.0, 7.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 5.0, 2.0, 14.0, 14.0, 4.0, 8.0, 14.0, 14.0, 14.0, 8.0, -1.0, 4.0, 6.0, 10.0, 2.0, 12.0, 12.0, 14.0, 7.0, 5.0, 12.0, 10.0, 14.0, 4.0, 7.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 5.0, 7.0, 14.0, 7.0, 4.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 3.0, 12.0, 12.0, 14.0, 12.0, 14.0, 7.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, -9.0, 11.0, 8.0, 12.0, 1.0, 14.0, 14.0, 12.0, 12.0, 10.0], "policy_policy1_reward": [6.0, 4.0, -10.0, -6.0, -8.0, 4.0, 6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -10.0, 5.0, 7.0, -10.0, -10.0, -8.0, -6.0, -8.0, -6.0, -6.0, 7.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -15.0, 2.0, -6.0, -6.0, 4.0, -12.0, -6.0, -6.0, -6.0, -12.0, -1.0, 4.0, 6.0, -10.0, 2.0, -8.0, -8.0, -6.0, 7.0, 5.0, -8.0, -10.0, -6.0, 4.0, 7.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 5.0, 7.0, -6.0, 7.0, 4.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 3.0, -8.0, -8.0, -6.0, -8.0, -6.0, 7.0, -6.0, -8.0, -8.0, -6.0, -6.0, -8.0, 11.0, -9.0, -12.0, -8.0, 1.0, -6.0, -6.0, -8.0, -8.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34176143217891225, "mean_inference_ms": 1.7371570259481848, "mean_action_processing_ms": 0.1185207312353237, "mean_env_wait_ms": 0.07500953955472472, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21000, "timesteps_this_iter": 32, "agent_timesteps_total": 42000, "timers": {"load_time_ms": 0.481, "load_throughput": 66572.952, "learn_time_ms": 8.169, "learn_throughput": 3917.256, "update_time_ms": 5.301}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.841937065124512, "min_q": -0.4992384910583496, "max_q": 15.293695449829102, "mean_td_error": 0.20716094970703125, "model": {}}, "td_error": [-0.009431838989257812, 3.0724782943725586, 0.13303279876708984, 0.20415735244750977, 8.599494934082031, -2.012181282043457, 1.112328052520752, 0.706944465637207, -0.3144073486328125, -0.9037742614746094, -1.1451482772827148, 0.7657356262207031, -1.089385986328125, -0.21228265762329102, -1.3692474365234375, -1.2074894905090332, 0.6915903091430664, -1.5822386741638184, -0.0019545555114746094, 0.5007615089416504, -2.543964385986328, 0.5698914527893066, 0.4706916809082031, -0.8010110855102539, 0.6592521667480469, 0.19701480865478516, -1.4068782329559326, -0.9698596000671387, -1.0835649967193604, 3.921339273452759, 1.4932117462158203, 0.18404579162597656], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.9246958494186401, "min_q": -6.969691753387451, "max_q": 6.351726531982422, "mean_td_error": 1.4111813306808472, "model": {}}, "td_error": [0.8359284400939941, 1.583642840385437, 0.0634009838104248, 0.8095302581787109, 0.2194042205810547, 1.53950834274292, -0.6917204856872559, 1.5573792457580566, 2.1926610469818115, 0.9950368404388428, 0.1689901351928711, 0.8095302581787109, -3.6050620079040527, -0.5077362060546875, 2.5751166343688965, 1.7645649909973145, 2.1595730781555176, 1.665247917175293, 2.2662670612335205, 0.2184123992919922, 2.1728248596191406, -0.3776516914367676, 0.641202449798584, -0.17345285415649414, 6.171364784240723, -0.9688141345977783, 5.508691310882568, 5.13290548324585, 6.380092620849609, 3.0260772705078125, 0.2153570055961609, 0.8095297813415527], "custom_metrics": {}}}, "num_steps_sampled": 21000, "num_agent_steps_sampled": 42000, "num_steps_trained": 56000, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 112000, "last_target_update_ts": 20953, "num_target_updates": 186}, "done": false, "episodes_total": 1865, "training_iteration": 85, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-07", "timestamp": 1648811767, "time_this_iter_s": 1.2783422470092773, "time_total_s": 102.29084753990173, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584743b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584743b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 102.29084753990173, "timesteps_since_restore": 2720, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 32.6, "ram_util_percent": 59.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -10.0, "episode_reward_mean": 6.12, "episode_len_mean": 6.94, "episode_media": {}, "episodes_this_iter": 30, "policy_reward_min": {"policy0": -9.0, "policy1": -15.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": 10.26, "policy1": -4.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, -10.0, 4.0, 8.0, 8.0, 8.0, -4.0, 8.0, 8.0, 8.0, -4.0, -2.0, 8.0, 12.0, 0.0, 4.0, 4.0, 4.0, 8.0, 14.0, 10.0, 4.0, 0.0, 8.0, 8.0, 14.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 10.0, 14.0, 8.0, 14.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 6.0, 4.0, 4.0, 8.0, 4.0, 8.0, 14.0, 8.0, 4.0, 4.0, 8.0, 8.0, 4.0, 2.0, 2.0, -4.0, 4.0, 2.0, 8.0, 8.0, 4.0, 4.0, 0.0, 0.0, 4.0, 4.0, 4.0, 2.0, 4.0, 8.0, 12.0, 8.0, 8.0, 4.0, 8.0, 6.0, 6.0, 8.0, 4.0, 8.0, 6.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, -4.0, 8.0, 14.0, 8.0], "episode_lengths": [6, 6, 15, 8, 6, 6, 6, 12, 6, 6, 6, 12, 11, 6, 4, 10, 8, 8, 8, 6, 3, 5, 8, 10, 6, 6, 3, 6, 6, 8, 6, 6, 6, 6, 5, 3, 6, 3, 6, 6, 8, 6, 8, 6, 6, 6, 6, 7, 8, 8, 6, 8, 6, 3, 6, 8, 8, 6, 6, 8, 9, 9, 12, 8, 9, 6, 6, 8, 8, 10, 10, 8, 8, 8, 9, 8, 6, 4, 6, 6, 8, 6, 7, 7, 6, 8, 6, 7, 6, 6, 6, 8, 6, 6, 6, 6, 12, 6, 3, 6], "policy_policy0_reward": [14.0, 14.0, 5.0, 2.0, 14.0, 14.0, 4.0, 8.0, 14.0, 14.0, 14.0, 8.0, -1.0, 4.0, 6.0, 10.0, 2.0, 12.0, 12.0, 14.0, 7.0, 5.0, 12.0, 10.0, 14.0, 4.0, 7.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 5.0, 7.0, 14.0, 7.0, 4.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 3.0, 12.0, 12.0, 14.0, 12.0, 14.0, 7.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, -9.0, 11.0, 8.0, 12.0, 1.0, 14.0, 14.0, 12.0, 12.0, 10.0, 10.0, 12.0, 12.0, 12.0, 1.0, 12.0, 4.0, 6.0, 4.0, 14.0, 12.0, 14.0, 3.0, 3.0, 14.0, 12.0, 14.0, -7.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 8.0, 14.0, 7.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -15.0, 2.0, -6.0, -6.0, 4.0, -12.0, -6.0, -6.0, -6.0, -12.0, -1.0, 4.0, 6.0, -10.0, 2.0, -8.0, -8.0, -6.0, 7.0, 5.0, -8.0, -10.0, -6.0, 4.0, 7.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 5.0, 7.0, -6.0, 7.0, 4.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 3.0, -8.0, -8.0, -6.0, -8.0, -6.0, 7.0, -6.0, -8.0, -8.0, -6.0, -6.0, -8.0, 11.0, -9.0, -12.0, -8.0, 1.0, -6.0, -6.0, -8.0, -8.0, -10.0, -10.0, -8.0, -8.0, -8.0, 1.0, -8.0, 4.0, 6.0, 4.0, -6.0, -8.0, -6.0, 3.0, 3.0, -6.0, -8.0, -6.0, 13.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -12.0, -6.0, 7.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34217273241565427, "mean_inference_ms": 1.7372881976774388, "mean_action_processing_ms": 0.11850883471058307, "mean_env_wait_ms": 0.075000279173017, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21205, "timesteps_this_iter": 32, "agent_timesteps_total": 42410, "timers": {"load_time_ms": 0.449, "load_throughput": 71343.076, "learn_time_ms": 8.011, "learn_throughput": 3994.278, "update_time_ms": 4.803}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.20394229888916, "min_q": -0.11878347396850586, "max_q": 13.218771934509277, "mean_td_error": -0.20229625701904297, "model": {}}, "td_error": [2.3973746299743652, -1.4279038906097412, -1.1591911315917969, -2.2699880599975586, -0.2952737808227539, -0.49169921875, 1.097038745880127, -0.8121628761291504, -0.2633504867553711, -0.9277896881103516, -0.8720965385437012, -0.31788182258605957, -4.207650184631348, -0.6927642822265625, -1.3166956901550293, -0.4023303985595703, 2.973550796508789, -1.8536391258239746, -1.2878379821777344, -0.5143887996673584, 0.5839762687683105, -1.9521698951721191, 0.019779205322265625, -1.478879451751709, -0.9191945791244507, 7.837320327758789, 3.644227981567383, -1.0558538436889648, 0.799372673034668, -0.12275028228759766, -0.521885871887207, -0.662743091583252], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.8357608318328857, "min_q": -6.8991169929504395, "max_q": 7.533415794372559, "mean_td_error": -2.317060947418213, "model": {}}, "td_error": [5.0364813804626465, 0.36136436462402344, 2.072295665740967, -0.554999589920044, -1.129617691040039, 0.07606935501098633, -7.88459587097168, -11.476737976074219, -1.0685982704162598, -0.3508634567260742, 1.2195262908935547, -1.599999189376831, -13.693864822387695, -15.498680114746094, -11.476737976074219, -0.5907059907913208, 3.4390742778778076, 2.0732195377349854, 2.099036693572998, 2.6852171421051025, -6.64207649230957, -1.6826632022857666, 0.16851425170898438, 0.9163107872009277, -1.5115928649902344, -1.4665842056274414, 1.5134212970733643, 1.8680315017700195, -7.977541446685791, -11.476737976074219, -0.6288630962371826, -0.9630569219589233], "custom_metrics": {}}}, "num_steps_sampled": 21205, "num_agent_steps_sampled": 42410, "num_steps_trained": 56928, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 113856, "last_target_update_ts": 21160, "num_target_updates": 188}, "done": false, "episodes_total": 1895, "training_iteration": 86, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-09", "timestamp": 1648811769, "time_this_iter_s": 1.332263708114624, "time_total_s": 103.62311124801636, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846ad40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846ad40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 103.62311124801636, "timesteps_since_restore": 2752, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 29.9, "ram_util_percent": 59.55}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 4.44, "episode_len_mean": 7.48, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": 9.52, "policy1": -5.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 14.0, 10.0, 4.0, 0.0, 8.0, 8.0, 14.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 10.0, 14.0, 8.0, 14.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 6.0, 4.0, 4.0, 8.0, 4.0, 8.0, 14.0, 8.0, 4.0, 4.0, 8.0, 8.0, 4.0, 2.0, 2.0, -4.0, 4.0, 2.0, 8.0, 8.0, 4.0, 4.0, 0.0, 0.0, 4.0, 4.0, 4.0, 2.0, 4.0, 8.0, 12.0, 8.0, 8.0, 4.0, 8.0, 6.0, 6.0, 8.0, 4.0, 8.0, 6.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, -4.0, 8.0, 14.0, 8.0, 8.0, 8.0, 12.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 4.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0], "episode_lengths": [6, 3, 5, 8, 10, 6, 6, 3, 6, 6, 8, 6, 6, 6, 6, 5, 3, 6, 3, 6, 6, 8, 6, 8, 6, 6, 6, 6, 7, 8, 8, 6, 8, 6, 3, 6, 8, 8, 6, 6, 8, 9, 9, 12, 8, 9, 6, 6, 8, 8, 10, 10, 8, 8, 8, 9, 8, 6, 4, 6, 6, 8, 6, 7, 7, 6, 8, 6, 7, 6, 6, 6, 8, 6, 6, 6, 6, 12, 6, 3, 6, 6, 6, 4, 8, 6, 6, 6, 6, 6, 10, 6, 8, 6, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [14.0, 7.0, 5.0, 12.0, 10.0, 14.0, 4.0, 7.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 5.0, 7.0, 14.0, 7.0, 4.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 3.0, 12.0, 12.0, 14.0, 12.0, 14.0, 7.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, -9.0, 11.0, 8.0, 12.0, 1.0, 14.0, 14.0, 12.0, 12.0, 10.0, 10.0, 12.0, 12.0, 12.0, 1.0, 12.0, 4.0, 6.0, 4.0, 14.0, 12.0, 14.0, 3.0, 3.0, 14.0, 12.0, 14.0, -7.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 8.0, 14.0, 7.0, 14.0, 14.0, 14.0, 6.0, 12.0, 4.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 12.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-6.0, 7.0, 5.0, -8.0, -10.0, -6.0, 4.0, 7.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 5.0, 7.0, -6.0, 7.0, 4.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 3.0, -8.0, -8.0, -6.0, -8.0, -6.0, 7.0, -6.0, -8.0, -8.0, -6.0, -6.0, -8.0, 11.0, -9.0, -12.0, -8.0, 1.0, -6.0, -6.0, -8.0, -8.0, -10.0, -10.0, -8.0, -8.0, -8.0, 1.0, -8.0, 4.0, 6.0, 4.0, -6.0, -8.0, -6.0, 3.0, 3.0, -6.0, -8.0, -6.0, 13.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -12.0, -6.0, 7.0, -6.0, -6.0, -6.0, 6.0, -8.0, 4.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -8.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3423667866725784, "mean_inference_ms": 1.7372764482378966, "mean_action_processing_ms": 0.11849953412596255, "mean_env_wait_ms": 0.07499982322578821, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21409, "timesteps_this_iter": 32, "agent_timesteps_total": 42818, "timers": {"load_time_ms": 0.422, "load_throughput": 75807.81, "learn_time_ms": 7.852, "learn_throughput": 4075.627, "update_time_ms": 4.714}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.422850131988525, "min_q": -1.441892147064209, "max_q": 13.794721603393555, "mean_td_error": -0.5461727380752563, "model": {}}, "td_error": [1.3693418502807617, -1.1789464950561523, 0.0003566741943359375, -3.992845058441162, -1.733254075050354, -3.8197174072265625, -1.3628239631652832, 0.09221649169921875, 0.14067602157592773, -1.7238445281982422, -0.6021437644958496, -0.4378352165222168, -0.5096540451049805, -2.006744384765625, -0.5426106452941895, -0.067840576171875, 1.7428112030029297, -0.06834888458251953, -0.2967085838317871, -2.0884766578674316, 0.3122129440307617, -1.9055156707763672, -0.26204967498779297, 0.17216014862060547, -0.5640487670898438, -0.5912046432495117, 3.9138803482055664, -0.23711198568344116, -1.7238445281982422, 2.6124680042266846, -2.8322973251342773, 0.7142165899276733], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.8401899337768555, "min_q": -6.722712516784668, "max_q": 6.573000907897949, "mean_td_error": -1.1119699478149414, "model": {}}, "td_error": [2.177617073059082, -4.086462020874023, 2.490126848220825, 1.6215429306030273, -0.4582573175430298, 2.7127737998962402, 3.131161689758301, 2.0385308265686035, 1.5891785621643066, 1.3441777229309082, -1.6854655742645264, -3.5793838500976562, 5.221560478210449, -10.476359367370605, -3.4334940910339355, 3.131161689758301, 1.731478214263916, 1.232865333557129, 1.76637601852417, -15.596689224243164, 2.7618308067321777, -0.25768327713012695, 0.04637432098388672, 0.9870109558105469, -0.09854602813720703, 1.9264588356018066, -5.138214111328125, -2.6686627864837646, -1.0787925720214844, -11.691964149475098, -10.726832389831543, -0.5164532661437988], "custom_metrics": {}}}, "num_steps_sampled": 21409, "num_agent_steps_sampled": 42818, "num_steps_trained": 57536, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 115072, "last_target_update_ts": 21389, "num_target_updates": 190}, "done": false, "episodes_total": 1914, "training_iteration": 87, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-10", "timestamp": 1648811770, "time_this_iter_s": 1.0360805988311768, "time_total_s": 104.65919184684753, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 104.65919184684753, "timesteps_since_restore": 2784, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 31.299999999999997, "ram_util_percent": 59.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 1.42, "episode_len_mean": 8.59, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": 8.01, "policy1": -6.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, 8.0, 14.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 6.0, 4.0, 4.0, 8.0, 4.0, 8.0, 14.0, 8.0, 4.0, 4.0, 8.0, 8.0, 4.0, 2.0, 2.0, -4.0, 4.0, 2.0, 8.0, 8.0, 4.0, 4.0, 0.0, 0.0, 4.0, 4.0, 4.0, 2.0, 4.0, 8.0, 12.0, 8.0, 8.0, 4.0, 8.0, 6.0, 6.0, 8.0, 4.0, 8.0, 6.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, -4.0, 8.0, 14.0, 8.0, 8.0, 8.0, 12.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 4.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 14.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, -30.0, -30.0, -30.0, -30.0], "episode_lengths": [3, 6, 3, 6, 6, 8, 6, 8, 6, 6, 6, 6, 7, 8, 8, 6, 8, 6, 3, 6, 8, 8, 6, 6, 8, 9, 9, 12, 8, 9, 6, 6, 8, 8, 10, 10, 8, 8, 8, 9, 8, 6, 4, 6, 6, 8, 6, 7, 7, 6, 8, 6, 7, 6, 6, 6, 8, 6, 6, 6, 6, 12, 6, 3, 6, 6, 6, 4, 8, 6, 6, 6, 6, 6, 10, 6, 8, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 6, 6, 6, 6, 8, 6, 6, 20, 20, 20, 20], "policy_policy0_reward": [7.0, 14.0, 7.0, 4.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 3.0, 12.0, 12.0, 14.0, 12.0, 14.0, 7.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, -9.0, 11.0, 8.0, 12.0, 1.0, 14.0, 14.0, 12.0, 12.0, 10.0, 10.0, 12.0, 12.0, 12.0, 1.0, 12.0, 4.0, 6.0, 4.0, 14.0, 12.0, 14.0, 3.0, 3.0, 14.0, 12.0, 14.0, -7.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 8.0, 14.0, 7.0, 14.0, 14.0, 14.0, 6.0, 12.0, 4.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 12.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [7.0, -6.0, 7.0, 4.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 3.0, -8.0, -8.0, -6.0, -8.0, -6.0, 7.0, -6.0, -8.0, -8.0, -6.0, -6.0, -8.0, 11.0, -9.0, -12.0, -8.0, 1.0, -6.0, -6.0, -8.0, -8.0, -10.0, -10.0, -8.0, -8.0, -8.0, 1.0, -8.0, 4.0, 6.0, 4.0, -6.0, -8.0, -6.0, 3.0, 3.0, -6.0, -8.0, -6.0, 13.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -12.0, -6.0, 7.0, -6.0, -6.0, -6.0, 6.0, -8.0, 4.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -8.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 7.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3425038383355444, "mean_inference_ms": 1.7376585566231049, "mean_action_processing_ms": 0.11852067759971004, "mean_env_wait_ms": 0.07501521616009804, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21616, "timesteps_this_iter": 32, "agent_timesteps_total": 43232, "timers": {"load_time_ms": 0.456, "load_throughput": 70193.885, "learn_time_ms": 8.254, "learn_throughput": 3876.806, "update_time_ms": 5.052}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.8280181884765625, "min_q": -1.2033084630966187, "max_q": 15.774648666381836, "mean_td_error": 0.06835605204105377, "model": {}}, "td_error": [0.8902015686035156, -0.8148589134216309, -3.838006019592285, 0.36126136779785156, -1.0112714767456055, -1.8329238891601562, -0.548858642578125, -0.12768173217773438, -0.011791706085205078, 1.1992135047912598, 7.025712490081787, -0.1618499755859375, 7.215734958648682, -1.6086231470108032, -2.3365306854248047, -0.8451085090637207, -0.34289073944091797, -0.3695378303527832, 0.21524524688720703, -1.280588150024414, -0.6413555145263672, -1.880852222442627, 1.0440149307250977, 2.633237838745117, 0.19734859466552734, 2.219421863555908, -0.4300813674926758, -1.842790126800537, -0.3370966911315918, -0.29577159881591797, -0.7360515594482422, 0.48052167892456055], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.196159839630127, "min_q": -8.82532787322998, "max_q": 5.678656578063965, "mean_td_error": -1.7524385452270508, "model": {}}, "td_error": [-1.0537440776824951, -1.705850601196289, 1.428332805633545, -3.4189722537994385, -0.28951168060302734, 0.057058095932006836, -11.070892333984375, -3.0736727714538574, 1.1135034561157227, -0.9426714777946472, 0.5961494445800781, -0.6556615829467773, -9.466593742370605, 2.6520068645477295, -3.6792256832122803, -4.7283806800842285, -4.290975093841553, 1.0712075233459473, 0.7679471969604492, -0.16087865829467773, -2.2892208099365234, -5.3855438232421875, 0.24695968627929688, 1.7100777626037598, 0.08997821807861328, -1.8565731048583984, -0.6779813170433044, -6.242744445800781, -5.075355529785156, -0.6421852111816406, 1.3334097862243652, -0.438032865524292], "custom_metrics": {}}}, "num_steps_sampled": 21616, "num_agent_steps_sampled": 43232, "num_steps_trained": 58016, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 116032, "last_target_update_ts": 21616, "num_target_updates": 192}, "done": false, "episodes_total": 1930, "training_iteration": 88, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-11", "timestamp": 1648811771, "time_this_iter_s": 0.994976282119751, "time_total_s": 105.65416812896729, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 105.65416812896729, "timesteps_since_restore": 2816, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 31.9, "ram_util_percent": 59.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 1.36, "episode_len_mean": 8.62, "episode_media": {}, "episodes_this_iter": 30, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": 8.78, "policy1": -7.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 4.0, 4.0, 0.0, 0.0, 4.0, 4.0, 4.0, 2.0, 4.0, 8.0, 12.0, 8.0, 8.0, 4.0, 8.0, 6.0, 6.0, 8.0, 4.0, 8.0, 6.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, -4.0, 8.0, 14.0, 8.0, 8.0, 8.0, 12.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 4.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 14.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, -30.0, -30.0, -30.0, -30.0, 8.0, 4.0, 8.0, 8.0, 4.0, 0.0, 0.0, 0.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 4.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 8, 8, 10, 10, 8, 8, 8, 9, 8, 6, 4, 6, 6, 8, 6, 7, 7, 6, 8, 6, 7, 6, 6, 6, 8, 6, 6, 6, 6, 12, 6, 3, 6, 6, 6, 4, 8, 6, 6, 6, 6, 6, 10, 6, 8, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 6, 6, 6, 6, 8, 6, 6, 20, 20, 20, 20, 6, 8, 6, 6, 8, 10, 10, 10, 8, 6, 6, 6, 8, 6, 6, 8, 6, 6, 8, 6, 6, 6, 8, 6, 6, 6, 8, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 12.0, 12.0, 10.0, 10.0, 12.0, 12.0, 12.0, 1.0, 12.0, 4.0, 6.0, 4.0, 14.0, 12.0, 14.0, 3.0, 3.0, 14.0, 12.0, 14.0, -7.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 8.0, 14.0, 7.0, 14.0, 14.0, 14.0, 6.0, 12.0, 4.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 12.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, -10.0, -10.0, -10.0, -10.0, 14.0, 12.0, 14.0, 14.0, 12.0, 10.0, 10.0, 10.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 12.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -8.0, -8.0, -10.0, -10.0, -8.0, -8.0, -8.0, 1.0, -8.0, 4.0, 6.0, 4.0, -6.0, -8.0, -6.0, 3.0, 3.0, -6.0, -8.0, -6.0, 13.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -12.0, -6.0, 7.0, -6.0, -6.0, -6.0, 6.0, -8.0, 4.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -8.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 7.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -20.0, -20.0, -20.0, -20.0, -6.0, -8.0, -6.0, -6.0, -8.0, -10.0, -10.0, -10.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -8.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34279066629563204, "mean_inference_ms": 1.7384628931857684, "mean_action_processing_ms": 0.1185676949108521, "mean_env_wait_ms": 0.07504195889822744, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21824, "timesteps_this_iter": 32, "agent_timesteps_total": 43648, "timers": {"load_time_ms": 0.451, "load_throughput": 70939.603, "learn_time_ms": 7.542, "learn_throughput": 4243.019, "update_time_ms": 4.602}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.856502056121826, "min_q": 0.14498019218444824, "max_q": 14.485136985778809, "mean_td_error": 0.42233043909072876, "model": {}}, "td_error": [-0.7498860359191895, 1.0215206146240234, -1.444589614868164, 7.368815898895264, -1.0676136016845703, 1.321152687072754, 1.1449801921844482, 1.1449801921844482, -1.993288516998291, -0.7496628761291504, -3.422121047973633, 0.16697216033935547, -1.961266040802002, -1.6708920001983643, 6.815324783325195, -0.32942867279052734, -0.5022773742675781, -0.060091495513916016, -0.6606636047363281, 9.857200622558594, -0.5053768157958984, -0.5989627838134766, -0.1011505126953125, -0.3711519241333008, 0.9641938209533691, -0.529109001159668, -0.9786181449890137, 0.2120380401611328, 0.12447214126586914, 0.11482810974121094, -0.06358766555786133, 1.0178327560424805], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.647671699523926, "min_q": -7.54282808303833, "max_q": 8.25360107421875, "mean_td_error": -1.3261559009552002, "model": {}}, "td_error": [1.2254643440246582, -1.4414379596710205, -0.7005705833435059, 8.077247619628906, -0.6007213592529297, 1.5019044876098633, -0.15987348556518555, -1.2323298454284668, 0.016313552856445312, -2.0770437717437744, -3.1743505001068115, -10.336088180541992, -1.2181713581085205, -10.336088180541992, -1.6078276634216309, 5.995646953582764, -2.8207359313964844, -9.816762924194336, -2.9150171279907227, -0.74639892578125, -6.3914875984191895, 1.9519777297973633, -1.9898936748504639, -0.3664207458496094, 1.0384106636047363, -0.4492058753967285, -1.0549447536468506, -5.355556011199951, 0.3768901824951172, 0.41135311126708984, 0.9627466201782227, 0.7959837913513184], "custom_metrics": {}}}, "num_steps_sampled": 21824, "num_agent_steps_sampled": 43648, "num_steps_trained": 58976, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 117952, "last_target_update_ts": 21824, "num_target_updates": 194}, "done": false, "episodes_total": 1960, "training_iteration": 89, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-12", "timestamp": 1648811772, "time_this_iter_s": 1.3835110664367676, "time_total_s": 107.03767919540405, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 107.03767919540405, "timesteps_since_restore": 2848, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 31.65, "ram_util_percent": 59.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 1.5, "episode_len_mean": 8.55, "episode_media": {}, "episodes_this_iter": 31, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 9.55, "policy1": -8.05}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.0, 8.0, 14.0, 8.0, 8.0, 8.0, 12.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 4.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 14.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, -30.0, -30.0, -30.0, -30.0, 8.0, 4.0, 8.0, 8.0, 4.0, 0.0, 0.0, 0.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 4.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 4.0, 4.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 8.0, 14.0, 4.0, 4.0, 8.0, 8.0, 8.0], "episode_lengths": [12, 6, 3, 6, 6, 6, 4, 8, 6, 6, 6, 6, 6, 10, 6, 8, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 6, 6, 6, 6, 8, 6, 6, 20, 20, 20, 20, 6, 8, 6, 6, 8, 10, 10, 10, 8, 6, 6, 6, 8, 6, 6, 8, 6, 6, 8, 6, 6, 6, 8, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 10, 8, 8, 10, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 10, 6, 10, 6, 3, 8, 8, 6, 6, 6], "policy_policy0_reward": [8.0, 14.0, 7.0, 14.0, 14.0, 14.0, 6.0, 12.0, 4.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 12.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, -10.0, -10.0, -10.0, -10.0, 14.0, 12.0, 14.0, 14.0, 12.0, 10.0, 10.0, 10.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 12.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 10.0, 12.0, 12.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 10.0, 14.0, 7.0, 12.0, 12.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-12.0, -6.0, 7.0, -6.0, -6.0, -6.0, 6.0, -8.0, 4.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -8.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 7.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -20.0, -20.0, -20.0, -20.0, -6.0, -8.0, -6.0, -6.0, -8.0, -10.0, -10.0, -10.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -8.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -10.0, -8.0, -8.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -10.0, -6.0, 7.0, -8.0, -8.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34307871229046616, "mean_inference_ms": 1.7391874816376542, "mean_action_processing_ms": 0.11861095689702456, "mean_env_wait_ms": 0.07507610147315147, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22033, "timesteps_this_iter": 32, "agent_timesteps_total": 44066, "timers": {"load_time_ms": 0.45, "load_throughput": 71172.833, "learn_time_ms": 7.979, "learn_throughput": 4010.618, "update_time_ms": 5.439}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.657752990722656, "min_q": -2.1330292224884033, "max_q": 12.927309036254883, "mean_td_error": -0.06680557131767273, "model": {}}, "td_error": [-0.07882213592529297, 1.1485958099365234, -0.17453765869140625, -0.7840790748596191, -0.7919807434082031, -0.9859280586242676, 0.169439435005188, -1.0040616989135742, -0.4873332977294922, 0.004014492034912109, -1.5145764350891113, -0.1338968276977539, -1.0750303268432617, -1.1308021545410156, 0.45365238189697266, -0.29230284690856934, -0.0998082160949707, -0.39138031005859375, 1.0719051361083984, 9.030747413635254, -1.6582894325256348, -1.6788244247436523, -0.1805591583251953, -1.020960807800293, -0.1338968276977539, 0.4528217315673828, -0.21160221099853516, 0.45183467864990234, -0.2791314125061035, 0.1640949249267578, -0.8431835174560547, -0.1338968276977539], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.557615280151367, "min_q": -8.829338073730469, "max_q": 2.164559841156006, "mean_td_error": -0.904294490814209, "model": {}}, "td_error": [-12.554308891296387, -8.308460235595703, 2.169539213180542, -0.3234086036682129, -0.0707855224609375, 1.3624439239501953, -0.13319110870361328, 2.8244833946228027, -1.3691129684448242, -1.6470736265182495, -11.206930160522461, 1.406641960144043, 0.15991830825805664, -0.35777807235717773, 1.0679898262023926, 0.1997978687286377, 0.26260948181152344, -0.6536401510238647, -0.5010867118835449, 1.4795408248901367, 1.4677410125732422, -0.028521060943603516, -0.35154151916503906, 1.122718334197998, 0.4246940612792969, -8.163700103759766, 0.6922135353088379, 4.599167823791504, -0.38382840156555176, 1.3624439239501953, 2.366434097290039, -5.852435111999512], "custom_metrics": {}}}, "num_steps_sampled": 22033, "num_agent_steps_sampled": 44066, "num_steps_trained": 59936, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 119872, "last_target_update_ts": 22033, "num_target_updates": 196}, "done": false, "episodes_total": 1991, "training_iteration": 90, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-14", "timestamp": 1648811774, "time_this_iter_s": 1.3601572513580322, "time_total_s": 108.39783644676208, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584085f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584085f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 108.39783644676208, "timesteps_since_restore": 2880, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 33.55, "ram_util_percent": 59.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 5.02, "episode_len_mean": 7.29, "episode_media": {}, "episodes_this_iter": 30, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 11.81, "policy1": -6.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 4.0, 8.0, 8.0, -30.0, -30.0, -30.0, -30.0, 8.0, 4.0, 8.0, 8.0, 4.0, 0.0, 0.0, 0.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 4.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 4.0, 4.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 8.0, 14.0, 4.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 4.0, 8.0, 8.0, 8.0, -4.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 8.0, 0.0, 14.0, 4.0, 8.0, 8.0, 10.0, 14.0, 8.0, 8.0, 8.0, 6.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 8, 6, 6, 20, 20, 20, 20, 6, 8, 6, 6, 8, 10, 10, 10, 8, 6, 6, 6, 8, 6, 6, 8, 6, 6, 8, 6, 6, 6, 8, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 10, 8, 8, 10, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 10, 6, 10, 6, 3, 8, 8, 6, 6, 6, 8, 6, 8, 8, 6, 6, 6, 12, 6, 6, 6, 6, 10, 6, 10, 6, 10, 3, 8, 6, 6, 5, 3, 6, 6, 6, 7, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 12.0, 14.0, 14.0, -10.0, -10.0, -10.0, -10.0, 14.0, 12.0, 14.0, 14.0, 12.0, 10.0, 10.0, 10.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 12.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 10.0, 12.0, 12.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 10.0, 14.0, 7.0, 12.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 12.0, 14.0, 14.0, 14.0, 8.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 10.0, 14.0, 10.0, 7.0, 12.0, 14.0, 14.0, 5.0, 7.0, 14.0, 14.0, 14.0, 3.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -8.0, -6.0, -6.0, -20.0, -20.0, -20.0, -20.0, -6.0, -8.0, -6.0, -6.0, -8.0, -10.0, -10.0, -10.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -8.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -10.0, -8.0, -8.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -10.0, -6.0, 7.0, -8.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -8.0, -8.0, -6.0, -6.0, -6.0, -12.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -10.0, -6.0, -10.0, 7.0, -8.0, -6.0, -6.0, 5.0, 7.0, -6.0, -6.0, -6.0, 3.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34342817652318297, "mean_inference_ms": 1.7396646906688928, "mean_action_processing_ms": 0.11863513036735909, "mean_env_wait_ms": 0.07509725579195539, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22233, "timesteps_this_iter": 32, "agent_timesteps_total": 44466, "timers": {"load_time_ms": 0.434, "load_throughput": 73798.718, "learn_time_ms": 7.611, "learn_throughput": 4204.553, "update_time_ms": 4.537}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.126012802124023, "min_q": 0.9037444591522217, "max_q": 13.361967086791992, "mean_td_error": 0.0015668496489524841, "model": {}}, "td_error": [-1.425185203552246, -1.2738285064697266, 0.6927490234375, 0.16263866424560547, 0.6222705841064453, 1.6926565170288086, 0.493222713470459, 0.7965383529663086, 0.7257401943206787, 0.5364189147949219, -0.17954444885253906, 0.3107481002807617, 0.22809123992919922, -0.6182346343994141, 2.141469955444336, 0.5640773773193359, -0.1925182342529297, 0.4391670227050781, -4.087381362915039, -0.2406015396118164, 0.5218505859375, 0.1370391845703125, 1.6039180755615234, -0.21597528457641602, -1.2582950592041016, 0.22636795043945312, -0.5433812141418457, -0.5239906311035156, -0.7327308654785156, -0.26403141021728516, 0.03892946243286133, -0.32805633544921875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.7048869132995605, "min_q": -7.089943885803223, "max_q": 9.415731430053711, "mean_td_error": -3.1380062103271484, "model": {}}, "td_error": [0.7061829566955566, -1.0393080711364746, -1.1937205791473389, 2.040364980697632, -0.4691481590270996, -1.1455988883972168, -0.882564902305603, 0.0084381103515625, 0.002986431121826172, -0.8228907585144043, 1.0119218826293945, -10.680156707763672, -1.1720490455627441, 1.9328131675720215, -11.848052024841309, -7.175240993499756, -11.848052024841309, -0.7816829681396484, -1.436436653137207, -10.289464950561523, 0.15961837768554688, -6.352074146270752, -1.3757545948028564, 0.41573143005371094, 0.8056533932685852, -9.717170715332031, -4.157732009887695, 1.5531902313232422, -10.289464950561523, -0.8586335182189941, -1.1829824447631836, -14.334917068481445], "custom_metrics": {}}}, "num_steps_sampled": 22233, "num_agent_steps_sampled": 44466, "num_steps_trained": 60832, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 121664, "last_target_update_ts": 22143, "num_target_updates": 197}, "done": false, "episodes_total": 2021, "training_iteration": 91, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-15", "timestamp": 1648811775, "time_this_iter_s": 1.2648487091064453, "time_total_s": 109.66268515586853, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 109.66268515586853, "timesteps_since_restore": 2912, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 31.15, "ram_util_percent": 59.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -4.0, "episode_reward_mean": 6.62, "episode_len_mean": 6.69, "episode_media": {}, "episodes_this_iter": 31, "policy_reward_min": {"policy0": 3.0, "policy1": -12.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 12.51, "policy1": -5.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 4.0, 4.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 8.0, 14.0, 4.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 4.0, 8.0, 8.0, 8.0, -4.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 8.0, 0.0, 14.0, 4.0, 8.0, 8.0, 10.0, 14.0, 8.0, 8.0, 8.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 4.0, 0.0, 8.0, 8.0, 4.0, 8.0, 8.0, 0.0, 12.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0], "episode_lengths": [8, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 10, 8, 8, 10, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 10, 6, 10, 6, 3, 8, 8, 6, 6, 6, 8, 6, 8, 8, 6, 6, 6, 12, 6, 6, 6, 6, 10, 6, 10, 6, 10, 3, 8, 6, 6, 5, 3, 6, 6, 6, 7, 6, 6, 6, 6, 6, 6, 6, 7, 7, 6, 6, 8, 6, 6, 6, 8, 8, 6, 6, 8, 10, 6, 6, 8, 6, 6, 10, 4, 6, 6, 6, 8, 6, 8], "policy_policy0_reward": [12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 10.0, 12.0, 12.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 10.0, 14.0, 7.0, 12.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 12.0, 14.0, 14.0, 14.0, 8.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 10.0, 14.0, 10.0, 7.0, 12.0, 14.0, 14.0, 5.0, 7.0, 14.0, 14.0, 14.0, 3.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 3.0, 3.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 10.0, 6.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0], "policy_policy1_reward": [-8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -10.0, -8.0, -8.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -10.0, -6.0, 7.0, -8.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -8.0, -8.0, -6.0, -6.0, -6.0, -12.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -10.0, -6.0, -10.0, 7.0, -8.0, -6.0, -6.0, 5.0, 7.0, -6.0, -6.0, -6.0, 3.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 3.0, 3.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -6.0, -8.0, -10.0, -6.0, -6.0, -8.0, -6.0, -6.0, -10.0, 6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34379479194524293, "mean_inference_ms": 1.739505211188859, "mean_action_processing_ms": 0.11861055536744505, "mean_env_wait_ms": 0.07509325401872696, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22441, "timesteps_this_iter": 32, "agent_timesteps_total": 44882, "timers": {"load_time_ms": 0.438, "load_throughput": 72999.961, "learn_time_ms": 7.713, "learn_throughput": 4148.758, "update_time_ms": 4.674}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.397710800170898, "min_q": 1.0902742147445679, "max_q": 14.780692100524902, "mean_td_error": 0.7454842925071716, "model": {}}, "td_error": [6.836275577545166, -0.6551322937011719, 3.931321144104004, -0.08057975769042969, 6.5171990394592285, 0.8099136352539062, -0.8838129043579102, -1.7433497905731201, -0.07283878326416016, -0.7062497138977051, -0.1765003204345703, -1.7051239013671875, 0.9277772903442383, -1.1480283737182617, 6.377885818481445, 0.9847946166992188, 0.27730655670166016, 3.425691604614258, -0.3196849822998047, 0.3258934020996094, -0.7913041114807129, -0.9679450988769531, 0.14861011505126953, -0.4800143241882324, 3.8219432830810547, 0.75494384765625, 0.11461734771728516, -2.294290542602539, -0.6917104721069336, -0.8151178359985352, 3.359841823577881, -1.2268352508544922], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.359447717666626, "min_q": -6.6420111656188965, "max_q": 9.454001426696777, "mean_td_error": -1.6622123718261719, "model": {}}, "td_error": [-0.1255340576171875, 1.2114338874816895, -0.05069780349731445, 1.0773935317993164, -5.337178707122803, -4.592945098876953, -14.331151962280273, 0.5023183822631836, -0.37756919860839844, -2.633625030517578, -0.09270286560058594, -2.956737995147705, 1.726618766784668, -2.7251696586608887, 1.7084801197052002, -0.7251152992248535, -1.1895864009857178, -0.6677162647247314, 0.8035502433776855, -0.257352352142334, -2.7674665451049805, -8.538816452026367, -1.597144603729248, 0.02785348892211914, -1.9261696338653564, 0.25557851791381836, -7.114175319671631, 0.9282174110412598, 9.441228866577148, -1.909092903137207, -12.67691421508789, 1.7193975448608398], "custom_metrics": {}}}, "num_steps_sampled": 22441, "num_agent_steps_sampled": 44882, "num_steps_trained": 61824, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 123648, "last_target_update_ts": 22355, "num_target_updates": 199}, "done": false, "episodes_total": 2052, "training_iteration": 92, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-17", "timestamp": 1648811777, "time_this_iter_s": 1.3999135494232178, "time_total_s": 111.06259870529175, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 111.06259870529175, "timesteps_since_restore": 2944, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 30.8, "ram_util_percent": 59.650000000000006}}
{"episode_reward_max": 14.0, "episode_reward_min": -4.0, "episode_reward_mean": 6.98, "episode_len_mean": 6.51, "episode_media": {}, "episodes_this_iter": 33, "policy_reward_min": {"policy0": 3.0, "policy1": -12.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 12.39, "policy1": -5.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, 4.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 4.0, 8.0, 8.0, 8.0, -4.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 8.0, 0.0, 14.0, 4.0, 8.0, 8.0, 10.0, 14.0, 8.0, 8.0, 8.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 4.0, 0.0, 8.0, 8.0, 4.0, 8.0, 8.0, 0.0, 12.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 10.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [3, 8, 8, 6, 6, 6, 8, 6, 8, 8, 6, 6, 6, 12, 6, 6, 6, 6, 10, 6, 10, 6, 10, 3, 8, 6, 6, 5, 3, 6, 6, 6, 7, 6, 6, 6, 6, 6, 6, 6, 7, 7, 6, 6, 8, 6, 6, 6, 8, 8, 6, 6, 8, 10, 6, 6, 8, 6, 6, 10, 4, 6, 6, 6, 8, 6, 8, 6, 8, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 5, 10, 6, 6, 6, 6, 6, 6, 6, 6, 6, 10, 8, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [7.0, 12.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 12.0, 14.0, 14.0, 14.0, 8.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 10.0, 14.0, 10.0, 7.0, 12.0, 14.0, 14.0, 5.0, 7.0, 14.0, 14.0, 14.0, 3.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 3.0, 3.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 10.0, 6.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 7.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 5.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 10.0, 12.0, 14.0, 14.0, 14.0, 4.0, 14.0, 14.0], "policy_policy1_reward": [7.0, -8.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -8.0, -8.0, -6.0, -6.0, -6.0, -12.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -10.0, -6.0, -10.0, 7.0, -8.0, -6.0, -6.0, 5.0, 7.0, -6.0, -6.0, -6.0, 3.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 3.0, 3.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -6.0, -8.0, -10.0, -6.0, -6.0, -8.0, -6.0, -6.0, -10.0, 6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 7.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 5.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -10.0, -8.0, -6.0, -6.0, -6.0, 4.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3442065232302581, "mean_inference_ms": 1.739410975978623, "mean_action_processing_ms": 0.11858187013626409, "mean_env_wait_ms": 0.07508853224846367, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22647, "timesteps_this_iter": 32, "agent_timesteps_total": 45294, "timers": {"load_time_ms": 0.424, "load_throughput": 75496.528, "learn_time_ms": 7.827, "learn_throughput": 4088.339, "update_time_ms": 4.982}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.289402961730957, "min_q": 1.2290931940078735, "max_q": 15.027351379394531, "mean_td_error": 0.5633889436721802, "model": {}}, "td_error": [1.3925724029541016, 0.6973590850830078, -0.1478567123413086, -0.45101356506347656, 0.27659034729003906, -0.06107902526855469, -0.2251262664794922, -0.2712254524230957, 0.43173837661743164, 0.4154634475708008, -1.2349634170532227, 0.355867862701416, -0.025213241577148438, 0.35717010498046875, 0.8409652709960938, -0.10519599914550781, 0.6837291717529297, 6.590935707092285, 0.2240276336669922, 0.35349464416503906, 4.837209224700928, 0.44346141815185547, 0.35598087310791016, 0.45416879653930664, 0.3823122978210449, 1.5290961265563965, 0.7275867462158203, -0.8302593231201172, -0.6856584548950195, 0.4789104461669922, 0.3912653923034668, -0.15386724472045898], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -5.149480819702148, "min_q": -8.986870765686035, "max_q": 2.7957377433776855, "mean_td_error": -0.8593824505805969, "model": {}}, "td_error": [-0.8735092878341675, -0.017317771911621094, -9.526477813720703, -6.536429405212402, 0.7011442184448242, 0.6928534507751465, 0.9035086631774902, 2.8819026947021484, -4.502687454223633, -0.5189390182495117, 0.9473519325256348, -8.208917617797852, 3.2767438888549805, -0.03590250015258789, -6.1273908615112305, 0.9473519325256348, 2.0141916275024414, 1.1955575942993164, 7.235616683959961, -1.4368199110031128, 0.9867997169494629, 1.4999384880065918, 0.6858296394348145, -2.2870547771453857, 0.09892749786376953, 1.1569750308990479, -0.2808108329772949, 0.12757086753845215, 0.28034305572509766, -6.483267784118652, 2.3846588134765625, -8.681978225708008], "custom_metrics": {}}}, "num_steps_sampled": 22647, "num_agent_steps_sampled": 45294, "num_steps_trained": 62848, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 125696, "last_target_update_ts": 22563, "num_target_updates": 201}, "done": false, "episodes_total": 2085, "training_iteration": 93, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-18", "timestamp": 1648811778, "time_this_iter_s": 1.4312708377838135, "time_total_s": 112.49386954307556, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 112.49386954307556, "timesteps_since_restore": 2976, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 30.96666666666667, "ram_util_percent": 59.70000000000001}}
{"episode_reward_max": 14.0, "episode_reward_min": -4.0, "episode_reward_mean": 8.08, "episode_len_mean": 5.96, "episode_media": {}, "episodes_this_iter": 40, "policy_reward_min": {"policy0": 3.0, "policy1": -12.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 11.24, "policy1": -3.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 6.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 4.0, 0.0, 8.0, 8.0, 4.0, 8.0, 8.0, 0.0, 12.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 10.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 14.0, 0.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 14.0, -4.0, 8.0, 8.0, 4.0, 14.0, 14.0, 14.0, 14.0, 8.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 10.0, 10.0, 10.0, -4.0], "episode_lengths": [7, 7, 6, 6, 8, 6, 6, 6, 8, 8, 6, 6, 8, 10, 6, 6, 8, 6, 6, 10, 4, 6, 6, 6, 8, 6, 8, 6, 8, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 5, 10, 6, 6, 6, 6, 6, 6, 6, 6, 6, 10, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 10, 8, 6, 6, 6, 6, 6, 6, 6, 3, 12, 6, 6, 8, 3, 3, 3, 3, 6, 3, 3, 3, 3, 5, 3, 3, 3, 4, 3, 3, 3, 5, 5, 5, 12], "policy_policy0_reward": [3.0, 3.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 10.0, 6.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 7.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 5.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 10.0, 12.0, 14.0, 14.0, 14.0, 4.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 7.0, 10.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 7.0, 8.0, 14.0, 14.0, 12.0, 7.0, 7.0, 7.0, 7.0, 4.0, 7.0, 7.0, 7.0, 7.0, 5.0, 7.0, 7.0, 7.0, 6.0, 7.0, 7.0, 7.0, 5.0, 5.0, 5.0, 8.0], "policy_policy1_reward": [3.0, 3.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -6.0, -8.0, -10.0, -6.0, -6.0, -8.0, -6.0, -6.0, -10.0, 6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 7.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 5.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -10.0, -8.0, -6.0, -6.0, -6.0, 4.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 7.0, -10.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 7.0, -12.0, -6.0, -6.0, -8.0, 7.0, 7.0, 7.0, 7.0, 4.0, 7.0, 7.0, 7.0, 7.0, 5.0, 7.0, 7.0, 7.0, 6.0, 7.0, 7.0, 7.0, 5.0, 5.0, 5.0, -12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34479876364259127, "mean_inference_ms": 1.7393967697844914, "mean_action_processing_ms": 0.11855832305339145, "mean_env_wait_ms": 0.0750920041385348, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22853, "timesteps_this_iter": 32, "agent_timesteps_total": 45706, "timers": {"load_time_ms": 0.479, "load_throughput": 66758.382, "learn_time_ms": 7.965, "learn_throughput": 4017.689, "update_time_ms": 4.958}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.550239562988281, "min_q": 1.500586986541748, "max_q": 14.156976699829102, "mean_td_error": -0.5301079154014587, "model": {}}, "td_error": [0.3349628448486328, -0.759516716003418, -2.1812801361083984, -0.24993228912353516, -0.759516716003418, -0.5693931579589844, -0.6860523223876953, 0.8252897262573242, -0.06637191772460938, 0.2947206497192383, -1.3324918746948242, -3.609548330307007, -4.908428192138672, -0.8089003562927246, 0.18180084228515625, -1.15313720703125, 0.2185831069946289, 0.8856467008590698, -0.20587635040283203, 0.5693912506103516, -0.9560728073120117, -0.4593796730041504, 0.2566523551940918, 2.2212882041931152, -4.780272006988525, 0.29509496688842773, 4.815908432006836, 0.2522134780883789, -1.3324918746948242, -0.17063522338867188, -0.24222755432128906, -2.883481979370117], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.0893988609313965, "min_q": -8.74494457244873, "max_q": 3.2376062870025635, "mean_td_error": -0.9557065963745117, "model": {}}, "td_error": [1.3910917043685913, 0.589820384979248, -0.5819699764251709, -0.18357396125793457, -0.10919356346130371, -0.5177764892578125, -0.43449926376342773, -7.275895595550537, 0.5477337837219238, -9.375839233398438, -9.305713653564453, 0.667198657989502, 0.667198657989502, -0.7460112571716309, 0.775301456451416, -1.908374547958374, -4.618456840515137, 2.4524996280670166, 2.365147113800049, -1.4748594760894775, -7.7449445724487305, 0.6174411773681641, 0.09532737731933594, -15.623620986938477, 3.09476637840271, -1.3978383541107178, 0.667198657989502, 0.4750699996948242, 5.712123870849609, 7.221268653869629, 0.8108878135681152, 2.5658817291259766], "custom_metrics": {}}}, "num_steps_sampled": 22853, "num_agent_steps_sampled": 45706, "num_steps_trained": 63808, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 127616, "last_target_update_ts": 22769, "num_target_updates": 203}, "done": false, "episodes_total": 2125, "training_iteration": 94, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-19", "timestamp": 1648811779, "time_this_iter_s": 1.3508706092834473, "time_total_s": 113.84474015235901, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 113.84474015235901, "timesteps_since_restore": 3008, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 30.950000000000003, "ram_util_percent": 59.7}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 7.66, "episode_len_mean": 6.12, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 11.28, "policy1": -3.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 10.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 14.0, 0.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 14.0, -4.0, 8.0, 8.0, 4.0, 14.0, 14.0, 14.0, 14.0, 8.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 10.0, 10.0, 10.0, -4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, -30.0, 8.0, 0.0, 0.0, 8.0, 0.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 4.0, 0.0], "episode_lengths": [6, 8, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 5, 10, 6, 6, 6, 6, 6, 6, 6, 6, 6, 10, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 10, 8, 6, 6, 6, 6, 6, 6, 6, 3, 12, 6, 6, 8, 3, 3, 3, 3, 6, 3, 3, 3, 3, 5, 3, 3, 3, 4, 3, 3, 3, 5, 5, 5, 12, 6, 6, 6, 6, 6, 6, 6, 6, 20, 6, 10, 10, 6, 10, 8, 6, 8, 6, 6, 6, 6, 6, 8, 6, 6, 8, 10], "policy_policy0_reward": [14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 7.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 5.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 10.0, 12.0, 14.0, 14.0, 14.0, 4.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 7.0, 10.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 7.0, 8.0, 14.0, 14.0, 12.0, 7.0, 7.0, 7.0, 7.0, 4.0, 7.0, 7.0, 7.0, 7.0, 5.0, 7.0, 7.0, 7.0, 6.0, 7.0, 7.0, 7.0, 5.0, 5.0, 5.0, 8.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, -10.0, 14.0, 10.0, 10.0, 14.0, 10.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 12.0, 10.0], "policy_policy1_reward": [-6.0, -8.0, -6.0, -6.0, -6.0, -6.0, 7.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 5.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -10.0, -8.0, -6.0, -6.0, -6.0, 4.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 7.0, -10.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 7.0, -12.0, -6.0, -6.0, -8.0, 7.0, 7.0, 7.0, 7.0, 4.0, 7.0, 7.0, 7.0, 7.0, 5.0, 7.0, 7.0, 7.0, 6.0, 7.0, 7.0, 7.0, 5.0, 5.0, 5.0, -12.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -20.0, -6.0, -10.0, -10.0, -6.0, -10.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -8.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34512950100868495, "mean_inference_ms": 1.7392112602629919, "mean_action_processing_ms": 0.11853267548332422, "mean_env_wait_ms": 0.07509439438300661, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23053, "timesteps_this_iter": 32, "agent_timesteps_total": 46106, "timers": {"load_time_ms": 0.497, "load_throughput": 64323.65, "learn_time_ms": 7.909, "learn_throughput": 4046.078, "update_time_ms": 4.982}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.864346027374268, "min_q": 0.7011409997940063, "max_q": 12.57753849029541, "mean_td_error": 0.53436279296875, "model": {}}, "td_error": [2.232563018798828, 0.7402048110961914, 0.35021400451660156, 1.363138198852539, 0.5894274711608887, 1.7240076065063477, 0.7099990844726562, 0.2879323959350586, 0.07855510711669922, -0.5628566741943359, -0.19058895111083984, 0.2013874053955078, 0.3470191955566406, 0.42226171493530273, 0.34642982482910156, 1.853392243385315, 0.33387184143066406, 0.7017984390258789, -2.3172502517700195, 0.21071386337280273, -0.2118244171142578, 0.004050254821777344, -0.6050844192504883, 0.33022212982177734, 3.3947787284851074, -0.3232760429382324, 0.25038623809814453, 0.6054086685180664, 1.6157703399658203, 3.0533287525177, 0.20569229125976562, -0.6420626640319824], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.731654167175293, "min_q": -7.2345452308654785, "max_q": 8.21945571899414, "mean_td_error": -1.5032222270965576, "model": {}}, "td_error": [1.7157411575317383, 1.9661235809326172, -0.3439202308654785, 0.5503907203674316, -2.0303726196289062, -1.924785852432251, 1.09083890914917, -1.1004555225372314, 4.892825126647949, -12.177556991577148, -0.6935153007507324, 5.610827445983887, -1.586315631866455, 1.09083890914917, 0.6343564987182617, -4.328393936157227, -4.328393936157227, -9.693964004516602, 1.9986664056777954, -0.79644775390625, -1.2782330513000488, 2.3263940811157227, -9.781956672668457, 1.6452248096466064, -4.206182479858398, 2.3109166622161865, -0.8792743682861328, -9.693964004516602, 0.7411813735961914, -0.5716680288314819, -11.617053031921387, 2.35501766204834], "custom_metrics": {}}}, "num_steps_sampled": 23053, "num_agent_steps_sampled": 46106, "num_steps_trained": 64672, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 129344, "last_target_update_ts": 22977, "num_target_updates": 205}, "done": false, "episodes_total": 2152, "training_iteration": 95, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-21", "timestamp": 1648811781, "time_this_iter_s": 1.213287591934204, "time_total_s": 115.05802774429321, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58408560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58408560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 115.05802774429321, "timesteps_since_restore": 3040, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 31.0, "ram_util_percent": 59.7}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 7.58, "episode_len_mean": 6.16, "episode_media": {}, "episodes_this_iter": 32, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 11.54, "policy1": -3.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 14.0, 0.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 14.0, -4.0, 8.0, 8.0, 4.0, 14.0, 14.0, 14.0, 14.0, 8.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 10.0, 10.0, 10.0, -4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, -30.0, 8.0, 0.0, 0.0, 8.0, 0.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 4.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 3, 10, 8, 6, 6, 6, 6, 6, 6, 6, 3, 12, 6, 6, 8, 3, 3, 3, 3, 6, 3, 3, 3, 3, 5, 3, 3, 3, 4, 3, 3, 3, 5, 5, 5, 12, 6, 6, 6, 6, 6, 6, 6, 6, 20, 6, 10, 10, 6, 10, 8, 6, 8, 6, 6, 6, 6, 6, 8, 6, 6, 8, 10, 6, 6, 6, 6, 6, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 10, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 7.0, 10.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 7.0, 8.0, 14.0, 14.0, 12.0, 7.0, 7.0, 7.0, 7.0, 4.0, 7.0, 7.0, 7.0, 7.0, 5.0, 7.0, 7.0, 7.0, 6.0, 7.0, 7.0, 7.0, 5.0, 5.0, 5.0, 8.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, -10.0, 14.0, 10.0, 10.0, 14.0, 10.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 12.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, 7.0, -10.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 7.0, -12.0, -6.0, -6.0, -8.0, 7.0, 7.0, 7.0, 7.0, 4.0, 7.0, 7.0, 7.0, 7.0, 5.0, 7.0, 7.0, 7.0, 6.0, 7.0, 7.0, 7.0, 5.0, 5.0, 5.0, -12.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -20.0, -6.0, -10.0, -10.0, -6.0, -10.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -8.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -8.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3454809165082055, "mean_inference_ms": 1.7388801843632438, "mean_action_processing_ms": 0.11849779220653735, "mean_env_wait_ms": 0.07509016687951126, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23257, "timesteps_this_iter": 32, "agent_timesteps_total": 46514, "timers": {"load_time_ms": 0.441, "load_throughput": 72640.433, "learn_time_ms": 8.158, "learn_throughput": 3922.534, "update_time_ms": 4.972}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.408087730407715, "min_q": -0.23084519803524017, "max_q": 15.97034740447998, "mean_td_error": 0.12978820502758026, "model": {}}, "td_error": [0.6552157402038574, -1.1492643356323242, -0.565638542175293, -0.1837000846862793, -4.236019134521484, 0.2872323989868164, 0.11988973617553711, 0.36542177200317383, -0.23158502578735352, 6.692049503326416, -0.39674854278564453, -0.11711978912353516, -0.4631805419921875, -0.29966306686401367, 0.42569875717163086, 0.8646988868713379, -0.8270964622497559, -0.1510305404663086, -0.10027503967285156, 0.19938182830810547, 0.1287064552307129, -0.9896845817565918, 2.071258783340454, 0.17523670196533203, -0.12978696823120117, 0.6494264602661133, -1.4440631866455078, 0.4333052635192871, 0.7691547870635986, -0.565638542175293, 1.9031333923339844, 0.26390647888183594], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.2145767211914062, "min_q": -7.571765899658203, "max_q": 7.774064540863037, "mean_td_error": 0.19627712666988373, "model": {}}, "td_error": [-1.3730177879333496, -9.910604476928711, -0.338778018951416, 2.3350090980529785, 0.3645198941230774, 5.8616228103637695, 0.3801383972167969, 2.4848384857177734, 0.28896570205688477, -1.4096863269805908, 0.08130079507827759, 7.835156440734863, -4.948063373565674, -0.39921998977661133, 2.2939085960388184, -1.9295958280563354, -0.9921844005584717, -1.2832856178283691, -1.6378493309020996, 2.356243133544922, 1.8721392154693604, 1.6986438035964966, -0.7793622016906738, 1.4049081802368164, -0.8331084251403809, -0.45302534103393555, -0.3766179084777832, -0.7319817543029785, -1.708597183227539, 1.9446678161621094, 2.228285789489746, 1.9554963111877441], "custom_metrics": {}}}, "num_steps_sampled": 23257, "num_agent_steps_sampled": 46514, "num_steps_trained": 65696, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 131392, "last_target_update_ts": 23187, "num_target_updates": 207}, "done": false, "episodes_total": 2184, "training_iteration": 96, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-22", "timestamp": 1648811782, "time_this_iter_s": 1.3995952606201172, "time_total_s": 116.45762300491333, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584709e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584709e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 116.45762300491333, "timesteps_since_restore": 3072, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 32.0, "ram_util_percent": 59.7}}
{"episode_reward_max": 14.0, "episode_reward_min": -30.0, "episode_reward_mean": 6.86, "episode_len_mean": 6.52, "episode_media": {}, "episodes_this_iter": 32, "policy_reward_min": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 12.48, "policy1": -5.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, 12.0, 14.0, 14.0, 14.0, 10.0, 10.0, 10.0, -4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, -30.0, 8.0, 0.0, 0.0, 8.0, 0.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 4.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 0.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 10.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [3, 4, 3, 3, 3, 5, 5, 5, 12, 6, 6, 6, 6, 6, 6, 6, 6, 20, 6, 10, 10, 6, 10, 8, 6, 8, 6, 6, 6, 6, 6, 8, 6, 6, 8, 10, 6, 6, 6, 6, 6, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 10, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 6, 6, 6, 6, 8, 8, 6, 10, 6, 10, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [7.0, 6.0, 7.0, 7.0, 7.0, 5.0, 5.0, 5.0, 8.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, -10.0, 14.0, 10.0, 10.0, 14.0, 10.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 12.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 10.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 5.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [7.0, 6.0, 7.0, 7.0, 7.0, 5.0, 5.0, 5.0, -12.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -20.0, -6.0, -10.0, -10.0, -6.0, -10.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -8.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -10.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 5.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34568938882500033, "mean_inference_ms": 1.7382025127999814, "mean_action_processing_ms": 0.11843829674047868, "mean_env_wait_ms": 0.07506667404436934, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23462, "timesteps_this_iter": 32, "agent_timesteps_total": 46924, "timers": {"load_time_ms": 0.434, "load_throughput": 73782.49, "learn_time_ms": 7.982, "learn_throughput": 4009.036, "update_time_ms": 4.698}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.24206018447876, "min_q": -3.1928722858428955, "max_q": 14.328936576843262, "mean_td_error": 0.32400810718536377, "model": {}}, "td_error": [0.3086409568786621, 8.578283309936523, -0.3529233932495117, -0.34908390045166016, -0.34908390045166016, -1.7790131568908691, 0.817380428314209, 8.097759246826172, -0.20667552947998047, 0.009644031524658203, 0.049262046813964844, -1.435795783996582, -0.7034873962402344, -0.5835094451904297, 0.6017684936523438, 1.3987302780151367, -0.4319343566894531, -0.5854310989379883, -0.12058877944946289, 0.061467647552490234, -0.8005585670471191, 0.6868782043457031, -1.529129981994629, 1.1488027572631836, -1.6912813186645508, -0.5649747848510742, -0.30286121368408203, 0.4795188903808594, -0.1442112922668457, -0.1914839744567871, 0.1730661392211914, 0.07908487319946289], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.1540627479553223, "min_q": -7.718377590179443, "max_q": 5.2783732414245605, "mean_td_error": -1.5146903991699219, "model": {}}, "td_error": [2.227985382080078, -3.6888883113861084, 1.8391313552856445, 2.583483934402466, 2.6220171451568604, 1.052180528640747, -16.245872497558594, -0.4256324768066406, 1.0368576049804688, -3.6888883113861084, 1.00734281539917, 0.051445722579956055, -4.147443771362305, -0.45439743995666504, -3.40352725982666, -9.993907928466797, 0.7671189308166504, -3.6888883113861084, 0.31626272201538086, 3.4042863845825195, -0.37747156620025635, 0.7040705680847168, -3.6888883113861084, 2.0268988609313965, -0.6595845222473145, -1.0279285907745361, 0.12294197082519531, -6.626947402954102, 2.348186492919922, -14.35569953918457, -3.68888783454895, 5.582552909851074], "custom_metrics": {}}}, "num_steps_sampled": 23462, "num_agent_steps_sampled": 46924, "num_steps_trained": 66720, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 133440, "last_target_update_ts": 23397, "num_target_updates": 209}, "done": false, "episodes_total": 2216, "training_iteration": 97, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-24", "timestamp": 1648811784, "time_this_iter_s": 1.340897560119629, "time_total_s": 117.79852056503296, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 117.79852056503296, "timesteps_since_restore": 3104, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 31.55, "ram_util_percent": 59.8}}
{"episode_reward_max": 14.0, "episode_reward_min": 0.0, "episode_reward_mean": 7.24, "episode_len_mean": 6.38, "episode_media": {}, "episodes_this_iter": 33, "policy_reward_min": {"policy0": 5.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 13.42, "policy1": -6.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 4.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 0.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 10.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0], "episode_lengths": [6, 8, 10, 6, 6, 6, 6, 6, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 10, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 6, 6, 6, 6, 8, 8, 6, 10, 6, 10, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 6, 6, 6, 8, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6], "policy_policy0_reward": [14.0, 12.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 10.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 5.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 7.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -8.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -10.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 5.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, 7.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3459869308450646, "mean_inference_ms": 1.737612566055858, "mean_action_processing_ms": 0.11838666694967127, "mean_env_wait_ms": 0.07505092827804495, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23667, "timesteps_this_iter": 32, "agent_timesteps_total": 47334, "timers": {"load_time_ms": 0.414, "load_throughput": 77376.76, "learn_time_ms": 7.962, "learn_throughput": 4019.157, "update_time_ms": 4.555}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.982768535614014, "min_q": 0.7926468253135681, "max_q": 13.708593368530273, "mean_td_error": 0.537481427192688, "model": {}}, "td_error": [0.5736207962036133, -0.0653986930847168, -0.09680747985839844, -0.47007322311401367, -0.8577451705932617, -0.1597580909729004, 4.4062347412109375, 0.17472362518310547, 1.4601678848266602, -0.6014518737792969, 4.68010139465332, 1.792646884918213, -0.4504842758178711, 1.9299185276031494, 0.32659363746643066, 0.2987527847290039, -1.2074861526489258, -0.0653986930847168, -0.7107257843017578, 0.1840970516204834, -0.7401332855224609, 6.5800676345825195, -0.1002206802368164, -0.7844161987304688, -0.45151519775390625, 0.44764137268066406, -0.4664468765258789, -0.7840919494628906, -1.7725210189819336, 4.988586902618408, -0.7477521896362305, -0.11132049560546875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.7289199829101562, "min_q": -7.763688564300537, "max_q": 4.14414119720459, "mean_td_error": -0.29650184512138367, "model": {}}, "td_error": [-6.968785762786865, -6.379505634307861, -0.12951016426086426, 2.5812087059020996, 1.08734130859375, 0.16034221649169922, -0.054434776306152344, 3.247386932373047, 1.2749390602111816, -0.7527334690093994, 1.5602045059204102, -3.2895960807800293, 0.9216852188110352, 1.6655125617980957, -5.825883865356445, -2.719697952270508, 3.2635397911071777, -1.2435872554779053, -1.5245087146759033, 2.2097034454345703, -6.968785762786865, 3.746763229370117, 3.039196014404297, -0.4490363597869873, 0.588651180267334, 0.33973026275634766, -0.34041500091552734, 4.373424053192139, -0.4278593063354492, -0.5421605110168457, -4.973598003387451, 3.0424113273620605], "custom_metrics": {}}}, "num_steps_sampled": 23667, "num_agent_steps_sampled": 47334, "num_steps_trained": 67744, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 135488, "last_target_update_ts": 23605, "num_target_updates": 211}, "done": false, "episodes_total": 2249, "training_iteration": 98, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-25", "timestamp": 1648811785, "time_this_iter_s": 1.4075536727905273, "time_total_s": 119.20607423782349, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 119.20607423782349, "timesteps_since_restore": 3136, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 31.233333333333334, "ram_util_percent": 59.79999999999999}}
{"episode_reward_max": 14.0, "episode_reward_min": 0.0, "episode_reward_mean": 7.64, "episode_len_mean": 6.18, "episode_media": {}, "episodes_this_iter": 35, "policy_reward_min": {"policy0": 5.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 13.22, "policy1": -5.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 0.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 10.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 14.0, 10.0, 14.0, 14.0], "episode_lengths": [6, 6, 6, 8, 8, 6, 10, 6, 10, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 6, 6, 6, 8, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 6, 6, 6, 8, 6, 6, 3, 5, 3, 3], "policy_policy0_reward": [14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 10.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 5.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 7.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 7.0, 5.0, 7.0, 7.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -10.0, -6.0, -10.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 5.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, 7.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, 7.0, 5.0, 7.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3463332819358434, "mean_inference_ms": 1.7369340524411938, "mean_action_processing_ms": 0.11833438437856955, "mean_env_wait_ms": 0.0750348784463144, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23875, "timesteps_this_iter": 32, "agent_timesteps_total": 47750, "timers": {"load_time_ms": 0.434, "load_throughput": 73750.057, "learn_time_ms": 7.607, "learn_throughput": 4206.608, "update_time_ms": 4.586}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.328352451324463, "min_q": 0.768338680267334, "max_q": 13.351737022399902, "mean_td_error": 0.11284519731998444, "model": {}}, "td_error": [-2.261587142944336, -0.611851692199707, -0.0844430923461914, 1.766510009765625, -2.3273048400878906, -0.7601251602172852, 3.8877501487731934, 5.679790019989014, -0.0165863037109375, 0.04633331298828125, 1.5131125450134277, -0.26404619216918945, -1.4078254699707031, 0.10578632354736328, 0.28958988189697266, -0.8811721801757812, 0.05335855484008789, -0.9928641319274902, -0.3684201240539551, 3.1525163650512695, -2.5405008792877197, 0.5207314491271973, 0.33252525329589844, 0.18816471099853516, 1.2801250219345093, -0.5225915908813477, -0.22635936737060547, 0.028036117553710938, 0.8453397750854492, -0.3998584747314453, 0.8170337677001953, -3.2301206588745117], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -5.897861003875732, "min_q": -11.016481399536133, "max_q": 6.4755635261535645, "mean_td_error": -2.300908088684082, "model": {}}, "td_error": [-0.33060240745544434, 0.011924028396606445, -8.537193298339844, -1.2161297798156738, 1.5472030639648438, -0.3798699378967285, 0.8516683578491211, -0.09904956817626953, -10.81141471862793, -2.304454803466797, -0.8952951431274414, -0.09915018081665039, -4.14126443862915, 0.866663932800293, -0.3798699378967285, -8.226391792297363, 1.3844108581542969, 1.5551857948303223, -2.338283061981201, -0.028173446655273438, 1.8790478706359863, 1.5472030639648438, -17.062320709228516, 0.015008926391601562, 1.1752433776855469, -13.215967178344727, -1.5659723281860352, -2.6072418689727783, -10.074324607849121, 0.7217233180999756, -0.6429474353790283, -0.2284255027770996], "custom_metrics": {}}}, "num_steps_sampled": 23875, "num_agent_steps_sampled": 47750, "num_steps_trained": 68800, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 137600, "last_target_update_ts": 23815, "num_target_updates": 213}, "done": false, "episodes_total": 2284, "training_iteration": 99, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-27", "timestamp": 1648811787, "time_this_iter_s": 1.4109745025634766, "time_total_s": 120.61704874038696, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58408e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58408e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 120.61704874038696, "timesteps_since_restore": 3168, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 31.7, "ram_util_percent": 59.8}}
{"episode_reward_max": 14.0, "episode_reward_min": 0.0, "episode_reward_mean": 7.88, "episode_len_mean": 6.06, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 5.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 13.14, "policy1": -5.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 14.0, 10.0, 14.0, 14.0, 10.0, 14.0, 14.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 6, 6, 6, 8, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 6, 6, 6, 8, 6, 6, 3, 5, 3, 3, 5, 3, 3, 6, 6, 6, 6, 10, 6, 8, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 7.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 7.0, 5.0, 7.0, 7.0, 5.0, 7.0, 7.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, 7.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, 7.0, 5.0, 7.0, 7.0, 5.0, 7.0, 7.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3467221952558222, "mean_inference_ms": 1.7365439977301276, "mean_action_processing_ms": 0.11831295061020733, "mean_env_wait_ms": 0.07503106626275055, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24080, "timesteps_this_iter": 32, "agent_timesteps_total": 48160, "timers": {"load_time_ms": 0.418, "load_throughput": 76612.665, "learn_time_ms": 7.745, "learn_throughput": 4131.696, "update_time_ms": 4.611}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.194882869720459, "min_q": -0.025483369827270508, "max_q": 14.922942161560059, "mean_td_error": 0.34673142433166504, "model": {}}, "td_error": [0.2626795768737793, 0.7535333633422852, -0.33697938919067383, 1.8871209621429443, 3.0281567573547363, -1.212362289428711, -0.012645244598388672, -0.13107728958129883, 2.042652130126953, 0.44225502014160156, 1.679774284362793, 0.26113414764404297, 0.2721109390258789, 0.4640171527862549, 0.46416330337524414, -2.268646001815796, 0.18701982498168945, 6.63175630569458, -0.17624282836914062, -0.2689986228942871, -1.238133430480957, -0.011231422424316406, 0.06399202346801758, -0.5804576873779297, 0.2945222854614258, -0.02045583724975586, 0.026005268096923828, -0.38501691818237305, 2.422574520111084, 2.4330928325653076, -4.24102783203125, -1.6378812789916992], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.706641435623169, "min_q": -7.912674903869629, "max_q": 9.67308235168457, "mean_td_error": -0.7154155373573303, "model": {}}, "td_error": [1.1189308166503906, -0.2612895965576172, -2.4747214317321777, 1.644576072692871, -1.1976006031036377, -0.7494425773620605, 2.2223591804504395, 1.7052536010742188, 1.1189308166503906, -2.3269145488739014, 1.1189308166503906, -0.45559024810791016, 3.1337404251098633, -0.3689112663269043, 2.0882599353790283, 1.8354897499084473, -0.9745633602142334, -4.9686079025268555, 0.6502132415771484, 4.739630699157715, -0.3278994560241699, 4.822555065155029, -12.332012176513672, -2.4677016735076904, -1.6700172424316406, -11.248066902160645, 1.9961624145507812, -0.20882177352905273, -0.8481979370117188, -7.690783977508545, 1.362910270690918, -1.8800981044769287], "custom_metrics": {}}}, "num_steps_sampled": 24080, "num_agent_steps_sampled": 48160, "num_steps_trained": 69856, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 139712, "last_target_update_ts": 24026, "num_target_updates": 215}, "done": false, "episodes_total": 2318, "training_iteration": 100, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-28", "timestamp": 1648811788, "time_this_iter_s": 1.4179556369781494, "time_total_s": 122.03500437736511, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bcdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bcdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 122.03500437736511, "timesteps_since_restore": 3200, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 31.0, "ram_util_percent": 59.8}}
{"episode_reward_max": 14.0, "episode_reward_min": 0.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 4.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 13.0, "policy1": -5.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 14.0, 10.0, 14.0, 14.0, 10.0, 14.0, 14.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 6, 6, 6, 8, 6, 6, 3, 5, 3, 3, 5, 3, 3, 6, 6, 6, 6, 10, 6, 8, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 7.0, 5.0, 7.0, 7.0, 5.0, 7.0, 7.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 7.0, 14.0, 14.0, 14.0, 14.0, 4.0, 14.0, 14.0, 14.0, 14.0, 14.0, 4.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, 7.0, 5.0, 7.0, 7.0, 5.0, 7.0, 7.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 7.0, -6.0, -6.0, -6.0, -6.0, 4.0, -6.0, -6.0, -6.0, -6.0, -6.0, 4.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3471513218597261, "mean_inference_ms": 1.7364226883915301, "mean_action_processing_ms": 0.11831234798105207, "mean_env_wait_ms": 0.0750373061565096, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24285, "timesteps_this_iter": 32, "agent_timesteps_total": 48570, "timers": {"load_time_ms": 0.41, "load_throughput": 78038.1, "learn_time_ms": 7.995, "learn_throughput": 4002.354, "update_time_ms": 4.922}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.03647232055664, "min_q": 0.2890331745147705, "max_q": 15.689470291137695, "mean_td_error": 0.28351104259490967, "model": {}}, "td_error": [1.1360759735107422, -0.11257386207580566, 0.7692818641662598, -0.06894493103027344, -0.6472440958023071, 2.392794132232666, 0.9608612060546875, -0.5010625123977661, 0.30176544189453125, -1.7112627029418945, -0.1263427734375, 0.3913431167602539, 4.657762050628662, -0.7009601593017578, 0.5317134857177734, -0.8034753799438477, -0.22120094299316406, -0.5124471187591553, 0.6965398788452148, -0.773017406463623, 1.3757076263427734, 0.5596814155578613, -2.9671239852905273, -0.09569931030273438, 1.0850954055786133, 1.2183866500854492, 0.37566518783569336, 0.5166873931884766, 0.5861663818359375, -0.2970104217529297, 0.23364925384521484, 0.8215427398681641], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.508586883544922, "min_q": -6.830886363983154, "max_q": 9.428205490112305, "mean_td_error": -0.7092514038085938, "model": {}}, "td_error": [0.41995930671691895, 0.49054479598999023, -10.524240493774414, 2.3251452445983887, 2.916112184524536, -1.1675469875335693, -0.46692562103271484, 2.8726487159729004, -8.39071273803711, -0.22944355010986328, -0.383603572845459, -0.23337078094482422, -10.524240493774414, 0.4282054901123047, -0.9314209222793579, -0.1822805404663086, 1.9406722784042358, 0.7658429145812988, -0.010414361953735352, 0.49054479598999023, -0.5517001152038574, -0.06205320358276367, 0.261014461517334, -12.020929336547852, 7.1427717208862305, -1.15773344039917, 0.4282054901123047, 1.3901314735412598, 1.238698959350586, 0.051876068115234375, -0.6453194618225098, 1.6235179901123047], "custom_metrics": {}}}, "num_steps_sampled": 24285, "num_agent_steps_sampled": 48570, "num_steps_trained": 70912, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 141824, "last_target_update_ts": 24237, "num_target_updates": 217}, "done": false, "episodes_total": 2352, "training_iteration": 101, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-30", "timestamp": 1648811790, "time_this_iter_s": 1.4765634536743164, "time_total_s": 123.51156783103943, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 123.51156783103943, "timesteps_since_restore": 3232, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 30.35, "ram_util_percent": 59.9}}
{"episode_reward_max": 14.0, "episode_reward_min": 0.0, "episode_reward_mean": 7.76, "episode_len_mean": 6.12, "episode_media": {}, "episodes_this_iter": 32, "policy_reward_min": {"policy0": 4.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 13.28, "policy1": -5.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.0, 14.0, 14.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0], "episode_lengths": [5, 3, 3, 6, 6, 6, 6, 10, 6, 8, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 6, 8, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8], "policy_policy0_reward": [5.0, 7.0, 7.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 7.0, 14.0, 14.0, 14.0, 14.0, 4.0, 14.0, 14.0, 14.0, 14.0, 14.0, 4.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0], "policy_policy1_reward": [5.0, 7.0, 7.0, -6.0, -6.0, -6.0, -6.0, -10.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 7.0, -6.0, -6.0, -6.0, -6.0, 4.0, -6.0, -6.0, -6.0, -6.0, -6.0, 4.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -8.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34755807844999054, "mean_inference_ms": 1.7365523069303013, "mean_action_processing_ms": 0.11833229754754045, "mean_env_wait_ms": 0.07505519937782636, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24487, "timesteps_this_iter": 32, "agent_timesteps_total": 48974, "timers": {"load_time_ms": 0.458, "load_throughput": 69796.01, "learn_time_ms": 8.014, "learn_throughput": 3993.22, "update_time_ms": 5.039}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.738742828369141, "min_q": 1.1663579940795898, "max_q": 13.874120712280273, "mean_td_error": -0.6823902130126953, "model": {}}, "td_error": [-2.2630958557128906, -0.45180511474609375, -1.7073612213134766, -3.177692413330078, 0.3467216491699219, 0.6672935485839844, -1.490572452545166, 4.991218566894531, -1.1972427368164062, -0.938262939453125, -0.9821500778198242, -0.8042020797729492, -0.3176884651184082, -1.44337797164917, -0.12275314331054688, -6.416806697845459, -1.766845703125, -1.5683741569519043, -0.16946983337402344, -1.1556305885314941, 0.35744428634643555, 1.037095546722412, -0.9211826324462891, 7.618494987487793, -1.5835142135620117, 0.38535356521606445, -2.1002397537231445, -1.0844426155090332, -1.9975593090057373, 0.9045610427856445, -1.5628576278686523, -2.921542167663574], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.615966796875, "min_q": -6.5431227684021, "max_q": 0.7349648475646973, "mean_td_error": -1.4040015935897827, "model": {}}, "td_error": [0.9081521034240723, -1.0031797885894775, -0.04773569107055664, -0.12127971649169922, -0.5776817798614502, 2.120208978652954, 0.4266490936279297, -5.220122814178467, 0.06303942203521729, -2.583401679992676, -0.8446903228759766, -0.3083231449127197, -0.05321311950683594, 2.221216917037964, -10.817782402038574, -8.735930442810059, -11.959722518920898, 0.12159204483032227, -5.18167781829834, 0.3452486991882324, 1.8271253108978271, -0.16608142852783203, -5.5431227684021, 1.4584355354309082, 0.4255805015563965, -0.3741300106048584, 0.06303942203521729, -3.6139111518859863, 0.8810734748840332, -0.4533339738845825, 2.112208843231201, -0.29630303382873535], "custom_metrics": {}}}, "num_steps_sampled": 24487, "num_agent_steps_sampled": 48974, "num_steps_trained": 71936, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 143872, "last_target_update_ts": 24443, "num_target_updates": 219}, "done": false, "episodes_total": 2384, "training_iteration": 102, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-31", "timestamp": 1648811791, "time_this_iter_s": 1.4252450466156006, "time_total_s": 124.93681287765503, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 124.93681287765503, "timesteps_since_restore": 3264, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 31.35, "ram_util_percent": 59.9}}
{"episode_reward_max": 14.0, "episode_reward_min": 4.0, "episode_reward_mean": 7.66, "episode_len_mean": 6.17, "episode_media": {}, "episodes_this_iter": 33, "policy_reward_min": {"policy0": 4.0, "policy1": -8.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": 13.43, "policy1": -5.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 6, 8, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 8, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 7.0, 14.0, 14.0, 14.0, 14.0, 4.0, 14.0, 14.0, 14.0, 14.0, 14.0, 4.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 4.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, 7.0, -6.0, -6.0, -6.0, -6.0, 4.0, -6.0, -6.0, -6.0, -6.0, -6.0, 4.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -8.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, 4.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34793607536638776, "mean_inference_ms": 1.7367673784893969, "mean_action_processing_ms": 0.11835082229566636, "mean_env_wait_ms": 0.07506899884715094, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24691, "timesteps_this_iter": 32, "agent_timesteps_total": 49382, "timers": {"load_time_ms": 0.444, "load_throughput": 72070.949, "learn_time_ms": 7.794, "learn_throughput": 4105.824, "update_time_ms": 4.84}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.381044387817383, "min_q": 0.14977630972862244, "max_q": 15.591239929199219, "mean_td_error": 0.8649123311042786, "model": {}}, "td_error": [0.47481536865234375, 0.2672710418701172, -0.12560629844665527, -0.38393497467041016, 7.417690277099609, -0.15563297271728516, 5.654649257659912, -0.8031158447265625, -0.33927345275878906, -0.2381458282470703, 4.6428327560424805, -0.05646181106567383, 0.43215465545654297, -0.24075603485107422, 0.9965581893920898, -0.0998849868774414, 0.7097225189208984, -0.3590679168701172, 0.47481536865234375, 1.239607810974121, -0.017249107360839844, -2.610036849975586, 1.1497763395309448, -0.7017450332641602, 0.3732185363769531, -0.3584728240966797, 5.345814228057861, -0.2171010971069336, 0.8857107162475586, 0.5373058319091797, 3.451066017150879, 0.3306710720062256], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.874016523361206, "min_q": -6.46268367767334, "max_q": 9.73571491241455, "mean_td_error": -1.4515055418014526, "model": {}}, "td_error": [-3.6094000339508057, -4.69617223739624, 2.6332244873046875, -0.6906018257141113, 0.7357149124145508, -0.07842707633972168, -0.6334972381591797, 1.327040672302246, -1.048640251159668, 2.178972005844116, -0.8608098030090332, -8.704912185668945, -0.6350445747375488, -6.705218315124512, -8.529626846313477, 2.287602424621582, -0.8506321907043457, -0.03946971893310547, -0.5328586101531982, -0.84480881690979, -3.151806354522705, -0.34527015686035156, 1.4700241088867188, -0.3942047357559204, -0.23711490631103516, 0.47142207622528076, -5.828028678894043, 1.0276027917861938, -0.84480881690979, -0.016251802444458008, -0.8540406227111816, -8.448137283325195], "custom_metrics": {}}}, "num_steps_sampled": 24691, "num_agent_steps_sampled": 49382, "num_steps_trained": 72992, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 145984, "last_target_update_ts": 24649, "num_target_updates": 221}, "done": false, "episodes_total": 2417, "training_iteration": 103, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-33", "timestamp": 1648811793, "time_this_iter_s": 1.4182846546173096, "time_total_s": 126.35509753227234, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 126.35509753227234, "timesteps_since_restore": 3296, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 32.05, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 4.0, "episode_reward_mean": 7.68, "episode_len_mean": 6.16, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 4.0, "policy1": -8.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 4.0}, "policy_reward_mean": {"policy0": 13.64, "policy1": -5.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 4.0, 8.0, 4.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 6, 8, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 8, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 4.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 4.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -8.0, -6.0, -8.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, 4.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 4.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3483695376925101, "mean_inference_ms": 1.7370790266075864, "mean_action_processing_ms": 0.1183785723270993, "mean_env_wait_ms": 0.07507496690533025, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24895, "timesteps_this_iter": 32, "agent_timesteps_total": 49790, "timers": {"load_time_ms": 0.534, "load_throughput": 59891.891, "learn_time_ms": 9.247, "learn_throughput": 3460.531, "update_time_ms": 5.93}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.653591156005859, "min_q": 0.3934949040412903, "max_q": 14.565043449401855, "mean_td_error": -0.17515233159065247, "model": {}}, "td_error": [-0.6758136749267578, -0.2916884422302246, 0.21741008758544922, 6.282928466796875, 0.4382181167602539, 0.24606657028198242, -1.8854789733886719, -0.5911049842834473, -0.01985311508178711, -2.2744574546813965, 0.592618465423584, -0.051728248596191406, -2.7198429107666016, -0.7093849182128906, 0.2602250576019287, 0.0066127777099609375, -3.6996829509735107, -0.030916690826416016, -0.19845867156982422, -1.384141445159912, 3.8985366821289062, -2.5636329650878906, -0.3818373680114746, 1.166860580444336, -0.8466081619262695, -0.26259326934814453, -0.0145721435546875, 0.3187141418457031, -0.1686992645263672, 1.166860580444336, -1.0197153091430664, -0.4097156524658203], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.1990175247192383, "min_q": -7.73554801940918, "max_q": 6.319774627685547, "mean_td_error": -0.5630642175674438, "model": {}}, "td_error": [-2.680225372314453, -0.012330174446105957, -1.2305734157562256, -1.704261302947998, -2.1877732276916504, 0.5947024822235107, -0.2187340259552002, 3.0269312858581543, 0.4763669967651367, 0.09517335891723633, -9.657715797424316, 3.4683754444122314, 0.10846692323684692, 2.8642654418945312, 4.246891498565674, -11.643587112426758, 3.1529641151428223, -3.598097562789917, 2.5132217407226562, -0.8999311923980713, 0.4095120429992676, 0.15579843521118164, 1.0415091514587402, -5.853546142578125, -2.004671096801758, -1.093521237373352, -0.31913185119628906, 0.6235847473144531, 0.09061717987060547, 1.774052619934082, -0.25397253036499023, 0.6975841522216797], "custom_metrics": {}}}, "num_steps_sampled": 24895, "num_agent_steps_sampled": 49790, "num_steps_trained": 74080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 148160, "last_target_update_ts": 24853, "num_target_updates": 223}, "done": false, "episodes_total": 2451, "training_iteration": 104, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-34", "timestamp": 1648811794, "time_this_iter_s": 1.527838945388794, "time_total_s": 127.88293647766113, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58408560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58408560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 127.88293647766113, "timesteps_since_restore": 3328, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 31.866666666666664, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 4.0, "episode_reward_mean": 7.88, "episode_len_mean": 6.06, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 4.0, "policy1": -8.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 4.0}, "policy_reward_mean": {"policy0": 13.74, "policy1": -5.86}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 8, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 4.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 4.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, 4.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, 4.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34876874066372776, "mean_inference_ms": 1.737119367669854, "mean_action_processing_ms": 0.11838672991629093, "mean_env_wait_ms": 0.07506886198471087, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25099, "timesteps_this_iter": 32, "agent_timesteps_total": 50198, "timers": {"load_time_ms": 0.467, "load_throughput": 68576.399, "learn_time_ms": 8.212, "learn_throughput": 3896.513, "update_time_ms": 5.134}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.030588150024414, "min_q": -2.2254228591918945, "max_q": 13.839601516723633, "mean_td_error": -0.5777151584625244, "model": {}}, "td_error": [-0.9506092071533203, -0.08424568176269531, -0.046975135803222656, -1.1128005981445312, -0.19598865509033203, 0.6498099565505981, -0.5212550163269043, -1.253946304321289, 0.6258988380432129, 3.1194982528686523, -0.08741140365600586, -0.01628398895263672, 1.016096591949463, -1.6452665328979492, -0.9580602645874023, -0.6738333702087402, -2.514054298400879, -1.6738901138305664, -1.1780896186828613, -0.08401107788085938, 0.4337348937988281, -0.3965930938720703, -1.336885929107666, -0.046975135803222656, -1.1682987213134766, -4.696175575256348, 2.5811493396759033, -1.3656721115112305, -1.1053581237792969, -0.9603123664855957, -0.9662723541259766, -1.8738079071044922], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.282810211181641, "min_q": -8.955352783203125, "max_q": 5.541574478149414, "mean_td_error": -1.6994407176971436, "model": {}}, "td_error": [2.3229780197143555, 2.9133589267730713, -7.509950637817383, -10.39315414428711, -6.343358039855957, -8.44422721862793, 3.0876636505126953, 0.7599911689758301, -0.32488322257995605, 0.28135204315185547, -0.14213228225708008, 3.970999002456665, -11.90561580657959, -9.262930870056152, -9.31606674194336, -9.31606674194336, 2.638556480407715, 3.9595417976379395, 3.3139896392822266, -0.06543397903442383, -1.5957927703857422, -0.12868642807006836, 1.7347466945648193, -3.2418456077575684, -9.708768844604492, -0.808837890625, -0.699376106262207, -0.1204380989074707, 3.2965657711029053, 3.2532951831817627, 0.8834381103515625, 2.5289909839630127], "custom_metrics": {}}}, "num_steps_sampled": 25099, "num_agent_steps_sampled": 50198, "num_steps_trained": 75168, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 150336, "last_target_update_ts": 25057, "num_target_updates": 225}, "done": false, "episodes_total": 2485, "training_iteration": 105, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-36", "timestamp": 1648811796, "time_this_iter_s": 1.4443511962890625, "time_total_s": 129.3272876739502, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 129.3272876739502, "timesteps_since_restore": 3360, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 30.35, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 4.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 4.0}, "policy_reward_mean": {"policy0": 13.9, "policy1": -5.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [4.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [4.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34915112361596284, "mean_inference_ms": 1.7369417732834904, "mean_action_processing_ms": 0.11838108793472671, "mean_env_wait_ms": 0.07506697857598996, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25303, "timesteps_this_iter": 32, "agent_timesteps_total": 50606, "timers": {"load_time_ms": 0.462, "load_throughput": 69216.507, "learn_time_ms": 7.777, "learn_throughput": 4114.773, "update_time_ms": 4.719}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.615076065063477, "min_q": 1.5568863153457642, "max_q": 15.806346893310547, "mean_td_error": 0.7867419719696045, "model": {}}, "td_error": [-0.2998814582824707, 0.5309357643127441, -2.7774901390075684, -0.5167412757873535, -0.26572656631469727, 0.19588947296142578, -3.6892824172973633, -3.3739547729492188, 2.5568861961364746, 6.042896747589111, 0.105194091796875, -0.4561328887939453, -1.5275087356567383, -2.0755605697631836, -0.04671335220336914, 3.5860376358032227, -6.685397624969482, 7.135223388671875, -0.31540966033935547, 0.5974698066711426, -0.1283397674560547, 0.05368232727050781, 6.5885539054870605, -0.3716850280761719, 8.763469696044922, 0.19667625427246094, 3.227731227874756, 7.74871301651001, 0.3967418670654297, 0.7223167419433594, -0.4274435043334961, -0.31540775299072266], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.355924606323242, "min_q": -7.861073017120361, "max_q": 5.355947017669678, "mean_td_error": -1.2938703298568726, "model": {}}, "td_error": [0.13275814056396484, -3.0266690254211426, 1.2413792610168457, 1.4493565559387207, -1.0733840465545654, -0.48014402389526367, 1.5975651741027832, -14.430593490600586, 0.8146357536315918, -0.5114932060241699, 3.384195327758789, 1.4493565559387207, -9.128998756408691, -0.9065163135528564, 0.21457910537719727, -1.9333596229553223, -0.5367051362991333, -0.5045194625854492, 3.4038288593292236, -0.8677463531494141, -0.7287755012512207, -0.2469007968902588, -0.037526607513427734, -0.4117612838745117, -10.320501327514648, -0.35024070739746094, -2.2492825984954834, -2.893242359161377, -0.9453964233398438, 3.5957889556884766, 2.0254640579223633, -9.128999710083008], "custom_metrics": {}}}, "num_steps_sampled": 25303, "num_agent_steps_sampled": 50606, "num_steps_trained": 76256, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 152512, "last_target_update_ts": 25261, "num_target_updates": 227}, "done": false, "episodes_total": 2519, "training_iteration": 106, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-37", "timestamp": 1648811797, "time_this_iter_s": 1.4135980606079102, "time_total_s": 130.7408857345581, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 130.7408857345581, "timesteps_since_restore": 3392, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 32.75, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34946084617091444, "mean_inference_ms": 1.7364536309970449, "mean_action_processing_ms": 0.11834724672118302, "mean_env_wait_ms": 0.07505768407668102, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25507, "timesteps_this_iter": 32, "agent_timesteps_total": 51014, "timers": {"load_time_ms": 0.47, "load_throughput": 68016.889, "learn_time_ms": 7.937, "learn_throughput": 4031.749, "update_time_ms": 4.869}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.435567855834961, "min_q": -1.0932127237319946, "max_q": 15.122152328491211, "mean_td_error": 0.6063761115074158, "model": {}}, "td_error": [-1.2455143928527832, -0.15543746948242188, 0.2775545120239258, 1.4535903930664062, -0.20143604278564453, -0.6825456619262695, 0.1454315185546875, -0.4161872863769531, -0.5271477699279785, 6.319421291351318, -0.9850072860717773, 0.19402599334716797, 4.155777454376221, -0.3136730194091797, -0.20143604278564453, 0.22377252578735352, -0.23538684844970703, 0.003204345703125, -0.03335237503051758, 7.125136375427246, 0.060671329498291016, 2.4499568939208984, 2.5105183124542236, 0.049365997314453125, -2.553311586380005, -1.02067232131958, 2.1354877948760986, -2.940366744995117, -0.8427085876464844, -1.847865104675293, -0.14548301696777344, 6.647651672363281], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -5.392799377441406, "min_q": -10.009765625, "max_q": -0.869598388671875, "mean_td_error": -1.3455462455749512, "model": {}}, "td_error": [1.6240768432617188, -5.153121471405029, 1.7658872604370117, 0.13865900039672852, -12.157901763916016, -0.03025054931640625, 0.041604042053222656, -0.24522876739501953, 0.13865900039672852, -0.7047195434570312, -1.6791634559631348, 0.041604042053222656, -0.2862119674682617, -1.5434751510620117, 0.717022180557251, 0.0814976692199707, -0.35241222381591797, -7.247834205627441, -1.5558605194091797, 1.7902154922485352, -1.32047438621521, -0.610903263092041, 2.3956189155578613, -5.885447978973389, -12.157901763916016, -0.2955303192138672, -0.16632652282714844, -2.946481943130493, 2.256937026977539, 2.2836320400238037, -1.1383605003356934, -0.8552842140197754], "custom_metrics": {}}}, "num_steps_sampled": 25507, "num_agent_steps_sampled": 51014, "num_steps_trained": 77344, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 154688, "last_target_update_ts": 25465, "num_target_updates": 229}, "done": false, "episodes_total": 2553, "training_iteration": 107, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-39", "timestamp": 1648811799, "time_this_iter_s": 1.4590115547180176, "time_total_s": 132.19989728927612, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584405f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584405f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 132.19989728927612, "timesteps_since_restore": 3424, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 30.95, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3497464372834379, "mean_inference_ms": 1.7358465043484719, "mean_action_processing_ms": 0.11830332613177542, "mean_env_wait_ms": 0.07503762107890964, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25711, "timesteps_this_iter": 32, "agent_timesteps_total": 51422, "timers": {"load_time_ms": 0.45, "load_throughput": 71056.026, "learn_time_ms": 7.64, "learn_throughput": 4188.427, "update_time_ms": 4.721}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.249653816223145, "min_q": 0.1624421775341034, "max_q": 14.288413047790527, "mean_td_error": -0.47736674547195435, "model": {}}, "td_error": [-0.8128719329833984, -0.3013324737548828, -0.00733184814453125, -0.9978737831115723, -0.7767119407653809, -0.3117799758911133, -1.6556448936462402, -1.886012077331543, -0.8353862762451172, -0.28356075286865234, -1.0166559219360352, 0.1588897705078125, 5.744875907897949, -0.7508335113525391, 0.949864387512207, 0.10855579376220703, -1.6339950561523438, 0.044989585876464844, -0.7944045066833496, -0.5964555740356445, 0.001148223876953125, -0.24787425994873047, 0.8552126884460449, -5.284213066101074, 0.017836570739746094, -1.0758452415466309, -0.7970504760742188, -0.7384085655212402, -0.05481433868408203, -0.00733184814453125, 1.7027106285095215, -3.993431568145752], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.138297080993652, "min_q": -6.684677600860596, "max_q": 7.579716682434082, "mean_td_error": -1.0271646976470947, "model": {}}, "td_error": [3.0447230339050293, -0.12172079086303711, -11.860243797302246, -0.0075092315673828125, 0.018706083297729492, 0.6897931098937988, 0.6228199005126953, -14.004927635192871, 2.695521116256714, 0.5904359817504883, 0.6827049255371094, -10.686502456665039, 0.05860137939453125, 0.15949010848999023, 1.247694492340088, -0.14874839782714844, -8.55262279510498, -0.303910493850708, 4.340151309967041, -10.689910888671875, 0.2843337059020996, 0.071441650390625, -0.12172079086303711, 0.6827049255371094, -0.38762617111206055, 2.896376848220825, 2.6668012142181396, 1.3078117370605469, 1.1744532585144043, 0.3806328773498535, -0.18755435943603516, 0.5885295867919922], "custom_metrics": {}}}, "num_steps_sampled": 25711, "num_agent_steps_sampled": 51422, "num_steps_trained": 78432, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 156864, "last_target_update_ts": 25669, "num_target_updates": 231}, "done": false, "episodes_total": 2587, "training_iteration": 108, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-40", "timestamp": 1648811800, "time_this_iter_s": 1.4193873405456543, "time_total_s": 133.61928462982178, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583e9440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583e9440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 133.61928462982178, "timesteps_since_restore": 3456, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 32.05, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35004157790158047, "mean_inference_ms": 1.735239009761146, "mean_action_processing_ms": 0.1182597235617272, "mean_env_wait_ms": 0.07501414237862272, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25915, "timesteps_this_iter": 32, "agent_timesteps_total": 51830, "timers": {"load_time_ms": 0.422, "load_throughput": 75816.375, "learn_time_ms": 7.755, "learn_throughput": 4126.221, "update_time_ms": 4.792}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.745667457580566, "min_q": -1.822800636291504, "max_q": 15.115896224975586, "mean_td_error": 0.5051827430725098, "model": {}}, "td_error": [-0.42771148681640625, -2.8999271392822266, 3.14921498298645, 0.9291419982910156, 1.6569561958312988, 0.4695014953613281, 1.225447177886963, 5.417526721954346, -0.14196014404296875, 0.015273571014404297, 0.5615134239196777, -1.2197537422180176, -0.32537841796875, 1.6504616737365723, -0.16792917251586914, -0.23322677612304688, 0.3756217956542969, 0.4621868133544922, 3.8026113510131836, -0.8848210573196411, -0.5157284736633301, -0.38210296630859375, 0.3407306671142578, -0.26988697052001953, -0.2112445831298828, 1.1456108093261719, -0.2773103713989258, 2.2109603881835938, 1.706136703491211, -1.3297920227050781, 0.44710254669189453, -0.11337804794311523], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.302036762237549, "min_q": -9.530157089233398, "max_q": 6.613924026489258, "mean_td_error": -1.6889328956604004, "model": {}}, "td_error": [-0.4113950729370117, -1.1099777221679688, 0.18751192092895508, -0.28071022033691406, -13.542192459106445, -0.2302083969116211, -0.5454936027526855, 1.7495641708374023, -1.1065263748168945, 0.9546499252319336, 0.14327478408813477, -11.410087585449219, 0.16748285293579102, -0.2302083969116211, -6.956838607788086, -0.47566699981689453, -0.5945563316345215, -0.07456636428833008, 0.45783424377441406, -0.6221635341644287, 1.5786948204040527, -0.2505052089691162, 1.8548197746276855, -0.08951759338378906, -2.681232452392578, -0.7910499572753906, -11.455805778503418, 1.3832664489746094, 0.18751192092895508, -0.3610701560974121, -9.009503364562988, -0.4811887741088867], "custom_metrics": {}}}, "num_steps_sampled": 25915, "num_agent_steps_sampled": 51830, "num_steps_trained": 79520, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 159040, "last_target_update_ts": 25873, "num_target_updates": 233}, "done": false, "episodes_total": 2621, "training_iteration": 109, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-42", "timestamp": 1648811802, "time_this_iter_s": 1.4144141674041748, "time_total_s": 135.03369879722595, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583e9830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583e9830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 135.03369879722595, "timesteps_since_restore": 3488, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 31.8, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35037174406382776, "mean_inference_ms": 1.7349055367341242, "mean_action_processing_ms": 0.11823438997391918, "mean_env_wait_ms": 0.07499505323946334, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26119, "timesteps_this_iter": 32, "agent_timesteps_total": 52238, "timers": {"load_time_ms": 0.453, "load_throughput": 70585.184, "learn_time_ms": 7.933, "learn_throughput": 4033.639, "update_time_ms": 4.928}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.428247451782227, "min_q": -0.8737064599990845, "max_q": 16.144296646118164, "mean_td_error": -0.052902571856975555, "model": {}}, "td_error": [-0.7740054130554199, -0.31034374237060547, -1.1719093322753906, -1.554337501525879, -0.5425939559936523, 4.974205017089844, -1.014946460723877, -1.904536247253418, -0.26390790939331055, -0.8242373466491699, -0.6546263694763184, -0.04753541946411133, 5.436283588409424, -0.6778469085693359, -0.5626697540283203, 0.529484748840332, -0.4472211003303528, -0.9477882385253906, -0.5445642471313477, 0.5119552612304688, 0.1303873062133789, -0.004474639892578125, 0.1303873062133789, 0.10809612274169922, 0.10809612274169922, -0.5333590507507324, -0.8714261054992676, 0.3213653564453125, -0.4229745864868164, -0.63934326171875, 1.2354040145874023, -0.4638996124267578], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.0618085861206055, "min_q": -6.011216640472412, "max_q": 2.971402645111084, "mean_td_error": -1.9387520551681519, "model": {}}, "td_error": [-9.230823516845703, -1.8560469150543213, -0.24584436416625977, -8.760725021362305, 4.223976135253906, -8.760725021362305, 0.980170726776123, -1.938798427581787, -0.2344493865966797, -0.6392240524291992, 2.934870719909668, -0.043883323669433594, 0.4521198272705078, 7.4904632568359375, -0.786287784576416, -0.02255392074584961, -0.058069705963134766, -1.1293916702270508, -9.453994750976562, -9.906597137451172, 0.980170726776123, 0.5292582511901855, -1.3130178451538086, -0.06995964050292969, -0.4652576446533203, -9.230823516845703, -8.279191970825195, -9.453994750976562, -0.46393775939941406, 3.0389809608459473, -7.25151252746582, 6.925032138824463], "custom_metrics": {}}}, "num_steps_sampled": 26119, "num_agent_steps_sampled": 52238, "num_steps_trained": 80608, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 161216, "last_target_update_ts": 26077, "num_target_updates": 235}, "done": false, "episodes_total": 2655, "training_iteration": 110, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-43", "timestamp": 1648811803, "time_this_iter_s": 1.4989895820617676, "time_total_s": 136.53268837928772, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 136.53268837928772, "timesteps_since_restore": 3520, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 31.5, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35086810621054954, "mean_inference_ms": 1.7354982990700636, "mean_action_processing_ms": 0.11827252478198674, "mean_env_wait_ms": 0.07501490150487211, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26323, "timesteps_this_iter": 32, "agent_timesteps_total": 52646, "timers": {"load_time_ms": 0.448, "load_throughput": 71407.602, "learn_time_ms": 8.928, "learn_throughput": 3584.205, "update_time_ms": 5.3}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.8468017578125, "min_q": 3.2052040100097656, "max_q": 14.970528602600098, "mean_td_error": -0.23971201479434967, "model": {}}, "td_error": [-0.8792319297790527, -0.5310382843017578, -1.0907716751098633, 0.6073970794677734, -0.7792701721191406, -0.09418201446533203, -1.7067980766296387, 0.4288787841796875, -0.4525794982910156, -1.719548225402832, -1.1425542831420898, -0.5558147430419922, 1.1445927619934082, -0.4552001953125, -1.0907716751098633, -0.5558147430419922, -0.8757619857788086, -2.15067195892334, -0.7285575866699219, -0.7779960632324219, 4.205204010009766, 0.5293245315551758, -0.5558147430419922, -0.2046213150024414, -0.41286468505859375, -0.7652368545532227, 1.0215535163879395, -0.044628143310546875, -0.38419437408447266, 0.2991480827331543, -0.8096580505371094, 2.8566980361938477], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.236293792724609, "min_q": -10.140464782714844, "max_q": 3.0352067947387695, "mean_td_error": -1.2325198650360107, "model": {}}, "td_error": [-10.80220890045166, 4.563938140869141, -0.012652397155761719, 2.634805202484131, 2.156069278717041, -8.525472640991211, 0.581446647644043, -9.599950790405273, 1.2197198867797852, -0.4222722053527832, 1.2617335319519043, 0.2777911424636841, -0.8001317977905273, -0.9732649326324463, 0.6633572578430176, 0.09737205505371094, -4.791877746582031, -11.999759674072266, -2.1515519618988037, 1.5155973434448242, -1.1271238327026367, -1.3203644752502441, -4.326554775238037, 5.124797821044922, 1.3259491920471191, 0.581446647644043, -2.359713077545166, -0.8239173889160156, -9.599950790405273, 1.2145280838012695, 6.453094482421875, 0.5244870185852051], "custom_metrics": {}}}, "num_steps_sampled": 26323, "num_agent_steps_sampled": 52646, "num_steps_trained": 81696, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 163392, "last_target_update_ts": 26281, "num_target_updates": 237}, "done": false, "episodes_total": 2689, "training_iteration": 111, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-45", "timestamp": 1648811805, "time_this_iter_s": 1.6495273113250732, "time_total_s": 138.1822156906128, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 138.1822156906128, "timesteps_since_restore": 3552, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 32.86666666666667, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35142990865378537, "mean_inference_ms": 1.7367565805106175, "mean_action_processing_ms": 0.11834720729789013, "mean_env_wait_ms": 0.0750539909514639, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26527, "timesteps_this_iter": 32, "agent_timesteps_total": 53054, "timers": {"load_time_ms": 0.436, "load_throughput": 73314.977, "learn_time_ms": 7.834, "learn_throughput": 4084.557, "update_time_ms": 4.806}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.5613203048706055, "min_q": -0.7624447345733643, "max_q": 15.00232219696045, "mean_td_error": 0.14471742510795593, "model": {}}, "td_error": [0.23221111297607422, 7.007922649383545, 0.006997108459472656, -0.40754032135009766, 0.9947824478149414, -1.255533218383789, -0.8531112670898438, -0.050393104553222656, 0.03265190124511719, 0.0844278335571289, 0.33472442626953125, 0.23755526542663574, -0.4643564224243164, -0.2084360122680664, -0.1483778953552246, -2.2433958053588867, 0.05997657775878906, -0.7279696464538574, -0.2526512145996094, -0.6013092994689941, -1.1323065757751465, 0.16244029998779297, -1.118856430053711, -3.4981131553649902, 8.536985397338867, 0.33075809478759766, -1.4708669185638428, 1.1226873397827148, -0.9225502014160156, 0.1510457992553711, 0.41801929473876953, 0.27353954315185547], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.6473093032836914, "min_q": -10.44084358215332, "max_q": 6.433485507965088, "mean_td_error": -1.800119161605835, "model": {}}, "td_error": [0.30061912536621094, -0.8010129928588867, 4.226733207702637, -0.32335829734802246, -1.0881609916687012, 0.5754127502441406, 0.4452636241912842, 2.61128568649292, 0.5084304809570312, 0.5084304809570312, 0.8463079929351807, -10.706725120544434, 2.577064037322998, -0.4352540969848633, -2.6518983840942383, 0.7321591377258301, -11.413853645324707, -0.39110660552978516, 0.22378921508789062, 0.26592016220092773, 0.47876930236816406, -0.253953218460083, 3.2923998832702637, -11.413853645324707, -1.6096796989440918, -12.154993057250977, 3.53605318069458, -1.4954862594604492, -11.413853645324707, -0.280240535736084, -12.15499496459961, -0.14402711391448975], "custom_metrics": {}}}, "num_steps_sampled": 26527, "num_agent_steps_sampled": 53054, "num_steps_trained": 82784, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 165568, "last_target_update_ts": 26485, "num_target_updates": 239}, "done": false, "episodes_total": 2723, "training_iteration": 112, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-46", "timestamp": 1648811806, "time_this_iter_s": 1.5541129112243652, "time_total_s": 139.73632860183716, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 139.73632860183716, "timesteps_since_restore": 3584, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 32.650000000000006, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.351931923070143, "mean_inference_ms": 1.7377028027999935, "mean_action_processing_ms": 0.11840219439150423, "mean_env_wait_ms": 0.07508755796233393, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26731, "timesteps_this_iter": 32, "agent_timesteps_total": 53462, "timers": {"load_time_ms": 0.451, "load_throughput": 71003.401, "learn_time_ms": 8.106, "learn_throughput": 3947.453, "update_time_ms": 5.175}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.838245868682861, "min_q": 0.4779571294784546, "max_q": 13.940208435058594, "mean_td_error": -0.12253338098526001, "model": {}}, "td_error": [1.9460506439208984, -0.11328601837158203, 0.045784950256347656, -1.0543808937072754, 0.0021200180053710938, -0.050937652587890625, -0.05526399612426758, -0.10696649551391602, -0.5897908210754395, -0.18865966796875, 0.10529613494873047, -0.043707847595214844, -0.48858702182769775, -1.0086174011230469, -0.4899787902832031, 0.1938633918762207, -0.7161107063293457, -0.919835090637207, -0.9963312149047852, -0.20704889297485352, -3.2871017456054688, -1.4055581092834473, -0.3410673141479492, 3.9475035667419434, -0.23537349700927734, -1.768972396850586, 1.1424007415771484, 5.278174877166748, 0.15962505340576172, -0.09324789047241211, -3.088467597961426, 0.5074028968811035], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.071815490722656, "min_q": -11.75667953491211, "max_q": 5.425296783447266, "mean_td_error": -2.3718340396881104, "model": {}}, "td_error": [-12.041258811950684, 1.0436553955078125, -0.3657712936401367, -0.2528895139694214, 0.38712215423583984, -7.876247406005859, -0.8808176517486572, -13.868278503417969, -2.916592597961426, 4.462066173553467, 3.841749668121338, 0.09402751922607422, 0.9156646728515625, -0.34433698654174805, -10.545106887817383, -1.9729423522949219, -0.13922202587127686, 0.5562934875488281, 1.5827932357788086, -2.0864551067352295, -9.347752571105957, 1.3928260803222656, 1.005263328552246, -0.26190829277038574, 4.030733585357666, -6.291343688964844, 0.2150592803955078, -0.05889177322387695, -11.517644882202148, -0.013235688209533691, -3.076186418533325, -11.569061279296875], "custom_metrics": {}}}, "num_steps_sampled": 26731, "num_agent_steps_sampled": 53462, "num_steps_trained": 83872, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 167744, "last_target_update_ts": 26689, "num_target_updates": 241}, "done": false, "episodes_total": 2757, "training_iteration": 113, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-48", "timestamp": 1648811808, "time_this_iter_s": 1.4596481323242188, "time_total_s": 141.19597673416138, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 141.19597673416138, "timesteps_since_restore": 3616, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 31.6, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3523004076912031, "mean_inference_ms": 1.7379542631196125, "mean_action_processing_ms": 0.11840443518077023, "mean_env_wait_ms": 0.07508725953645609, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26935, "timesteps_this_iter": 32, "agent_timesteps_total": 53870, "timers": {"load_time_ms": 0.45, "load_throughput": 71172.833, "learn_time_ms": 7.84, "learn_throughput": 4081.874, "update_time_ms": 4.851}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.1659574508667, "min_q": -0.19995391368865967, "max_q": 15.504905700683594, "mean_td_error": 0.03986257314682007, "model": {}}, "td_error": [-0.36229801177978516, -0.2410116195678711, -0.5962457656860352, -0.4141054153442383, -0.9594545364379883, -0.4591960906982422, 1.7439608573913574, 0.08738136291503906, 0.020781517028808594, -0.44753170013427734, -0.9102134704589844, 0.9797146320343018, -0.04589653015136719, -0.4179668426513672, -0.42870521545410156, -1.3949480056762695, 6.664051055908203, -1.9928126335144043, -0.1250767707824707, 0.09340858459472656, 0.1788926124572754, 0.39606618881225586, -0.805422306060791, -0.28705406188964844, 1.6720571517944336, -0.42870521545410156, -0.7684845924377441, -0.2794828414916992, 1.739919662475586, -0.014936447143554688, -1.1384086608886719, 0.21732616424560547], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.053537368774414, "min_q": -6.706839561462402, "max_q": 7.974950790405273, "mean_td_error": -0.49829694628715515, "model": {}}, "td_error": [0.46522974967956543, -1.2100369930267334, -0.5311194658279419, 2.8471381664276123, 0.5234513282775879, -0.0608668327331543, -0.798365592956543, 0.2783498764038086, 0.03162360191345215, -0.13271617889404297, -2.9030537605285645, -0.9316444396972656, -1.209932804107666, 0.1886765956878662, -1.1750116348266602, 0.2569456100463867, -3.3539950847625732, 1.9283432960510254, -1.2100369930267334, 0.26030731201171875, 1.1246967315673828, -10.839085578918457, 0.010481834411621094, 2.05853271484375, 0.5772988796234131, 0.391176700592041, -5.172790050506592, -1.0250492095947266, -0.46014881134033203, -1.102250099182129, 3.516153335571289, 1.7121944427490234], "custom_metrics": {}}}, "num_steps_sampled": 26935, "num_agent_steps_sampled": 53870, "num_steps_trained": 84960, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 169920, "last_target_update_ts": 26893, "num_target_updates": 243}, "done": false, "episodes_total": 2791, "training_iteration": 114, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-49", "timestamp": 1648811809, "time_this_iter_s": 1.449350357055664, "time_total_s": 142.64532709121704, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 142.64532709121704, "timesteps_since_restore": 3648, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 30.95, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3526423806701914, "mean_inference_ms": 1.7380063697541432, "mean_action_processing_ms": 0.1183944444330648, "mean_env_wait_ms": 0.07508222773909107, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27139, "timesteps_this_iter": 32, "agent_timesteps_total": 54278, "timers": {"load_time_ms": 0.484, "load_throughput": 66130.138, "learn_time_ms": 10.814, "learn_throughput": 2959.082, "update_time_ms": 6.269}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.70355224609375, "min_q": 4.3173675537109375, "max_q": 13.957878112792969, "mean_td_error": -0.08727690577507019, "model": {}}, "td_error": [0.7133231163024902, -0.20116901397705078, -0.5582218170166016, -0.40895843505859375, -1.2379865646362305, -3.1327638626098633, -0.21007251739501953, -0.5012640953063965, -0.5642423629760742, -0.6984872817993164, 0.3748588562011719, 0.3748588562011719, -0.3508157730102539, -0.9616756439208984, 2.882765293121338, -0.2516202926635742, -7.4774088859558105, 1.0953822135925293, 2.0790047645568848, -0.03526592254638672, -0.08771705627441406, -0.20116901397705078, -0.6984872817993164, -0.21007251739501953, 0.43451642990112305, -0.1436300277709961, 0.8085041046142578, -0.20116901397705078, 6.102887153625488, -2.01519775390625, -0.9752092361450195, 3.4636425971984863], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.6901721954345703, "min_q": -6.102092266082764, "max_q": 4.55696964263916, "mean_td_error": -2.357654571533203, "model": {}}, "td_error": [-0.06966066360473633, 0.8617343902587891, 1.298823356628418, -0.036978721618652344, -0.4046788215637207, 0.7947545051574707, -12.173803329467773, -6.441099643707275, -0.0785210132598877, -2.331176280975342, 0.11163371801376343, 0.6520185470581055, -12.173803329467773, -0.6814987659454346, -0.10924792289733887, -9.422843933105469, 2.760646343231201, 0.9686770439147949, 1.2207450866699219, 0.4096407890319824, -3.9698641300201416, 0.5882096290588379, 1.7153749465942383, -4.926319122314453, -12.173803329467773, -10.271444320678711, -0.19942665100097656, -2.742706775665283, -9.479669570922852, 0.650296688079834, 0.09220647811889648, 0.1168360710144043], "custom_metrics": {}}}, "num_steps_sampled": 27139, "num_agent_steps_sampled": 54278, "num_steps_trained": 86048, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 172096, "last_target_update_ts": 27097, "num_target_updates": 245}, "done": false, "episodes_total": 2825, "training_iteration": 115, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-51", "timestamp": 1648811811, "time_this_iter_s": 1.5376665592193604, "time_total_s": 144.1829936504364, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583eec20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583eec20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 144.1829936504364, "timesteps_since_restore": 3680, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 33.5, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3529898819931714, "mean_inference_ms": 1.7383133832580882, "mean_action_processing_ms": 0.11839527790687043, "mean_env_wait_ms": 0.07508033707989505, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27343, "timesteps_this_iter": 32, "agent_timesteps_total": 54686, "timers": {"load_time_ms": 0.429, "load_throughput": 74581.978, "learn_time_ms": 7.754, "learn_throughput": 4127.109, "update_time_ms": 4.876}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.319219589233398, "min_q": 1.4421306848526, "max_q": 12.997051239013672, "mean_td_error": 0.3583011329174042, "model": {}}, "td_error": [-0.37200260162353516, -0.03512763977050781, 0.09514868259429932, 1.4969573020935059, -0.029218196868896484, -0.09700250625610352, 0.04972362518310547, -0.37200260162353516, -0.37200260162353516, 0.5222196578979492, 5.619282245635986, -0.23195457458496094, 0.048488616943359375, 0.029961585998535156, 0.12510108947753906, -3.410978317260742, 0.6667160987854004, 0.11181640625, -0.37200260162353516, -2.790742874145508, -0.2409954071044922, -3.209501266479492, 1.5583686828613281, 0.5551097393035889, 2.714839458465576, 0.9611387252807617, -3.212094783782959, -0.31232452392578125, 7.098546028137207, 1.657759666442871, 0.029959678649902344, 3.1824498176574707], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.9150149822235107, "min_q": -9.43013858795166, "max_q": 7.456564903259277, "mean_td_error": -0.09155410528182983, "model": {}}, "td_error": [-0.21044254302978516, 3.2679152488708496, -0.486147403717041, -7.990549564361572, 0.8579363822937012, 0.47599053382873535, 0.4536738395690918, -0.45078063011169434, -0.39120960235595703, 0.895787239074707, -0.45078063011169434, -0.25757408142089844, 0.654670238494873, -0.8685169219970703, 0.5807013511657715, 6.9308953285217285, 1.4163885116577148, 2.565488815307617, 1.9834513664245605, 0.6082544326782227, 0.9339852333068848, -0.3234224319458008, -0.36288022994995117, -1.019244909286499, 1.7318081855773926, 2.1200928688049316, 0.44963502883911133, -9.540435791015625, -0.37453269958496094, 1.3081296682357788, 3.29888653755188, -10.736906051635742], "custom_metrics": {}}}, "num_steps_sampled": 27343, "num_agent_steps_sampled": 54686, "num_steps_trained": 87136, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 174272, "last_target_update_ts": 27301, "num_target_updates": 247}, "done": false, "episodes_total": 2859, "training_iteration": 116, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-53", "timestamp": 1648811813, "time_this_iter_s": 1.4800114631652832, "time_total_s": 145.66300511360168, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 145.66300511360168, "timesteps_since_restore": 3712, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 33.75, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3533220378803461, "mean_inference_ms": 1.7385794977086317, "mean_action_processing_ms": 0.11839463990339713, "mean_env_wait_ms": 0.07507984351624213, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27547, "timesteps_this_iter": 32, "agent_timesteps_total": 55094, "timers": {"load_time_ms": 0.456, "load_throughput": 70204.9, "learn_time_ms": 8.198, "learn_throughput": 3903.528, "update_time_ms": 4.847}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.185257434844971, "min_q": -0.35246893763542175, "max_q": 13.306736946105957, "mean_td_error": -0.014841638505458832, "model": {}}, "td_error": [1.6017003059387207, 0.4907526969909668, -0.8305110931396484, 0.9871535301208496, -0.006691932678222656, -0.2629413604736328, 1.0801405906677246, 0.39810895919799805, -1.2181591987609863, -0.25055360794067383, -1.2323412895202637, 0.1825876235961914, -0.8085594177246094, 0.5276074409484863, -0.2553081512451172, -0.2553081512451172, -0.9204072952270508, -0.9541664123535156, 0.9611082077026367, -0.8224325180053711, -0.9541664123535156, 0.6660149097442627, 3.8031187057495117, -1.5931291580200195, 0.5276074409484863, 0.07323646545410156, 0.4535946846008301, -0.2397480010986328, -0.1669473648071289, -0.8406410217285156, 0.47580814361572266, -1.0914597511291504], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.609522819519043, "min_q": -7.387592315673828, "max_q": 7.698956489562988, "mean_td_error": -0.2954743504524231, "model": {}}, "td_error": [3.4839823246002197, -13.212814331054688, 3.360849618911743, -1.7216367721557617, 0.5145659446716309, 0.5561685562133789, -1.6719250679016113, -7.717088222503662, 3.802420139312744, -0.008200645446777344, 3.0392894744873047, 3.2110466957092285, 0.6958589553833008, -1.3010435104370117, -0.04698300361633301, 6.924734592437744, -0.8361725807189941, 0.3549995422363281, -13.212814331054688, -0.3680499792098999, 0.14116382598876953, 0.21694183349609375, 5.557191848754883, -0.7313083410263062, -3.033036947250366, 0.3305788040161133, -0.14214563369750977, -0.34014892578125, 0.6126255989074707, -0.3873012065887451, 1.7965973615646362, 0.6764755249023438], "custom_metrics": {}}}, "num_steps_sampled": 27547, "num_agent_steps_sampled": 55094, "num_steps_trained": 88224, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 176448, "last_target_update_ts": 27505, "num_target_updates": 249}, "done": false, "episodes_total": 2893, "training_iteration": 117, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-54", "timestamp": 1648811814, "time_this_iter_s": 1.4479656219482422, "time_total_s": 147.11097073554993, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 147.11097073554993, "timesteps_since_restore": 3744, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 32.3, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35366735972399155, "mean_inference_ms": 1.738905673635747, "mean_action_processing_ms": 0.11839992430148552, "mean_env_wait_ms": 0.0750784846712909, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27751, "timesteps_this_iter": 32, "agent_timesteps_total": 55502, "timers": {"load_time_ms": 0.476, "load_throughput": 67290.548, "learn_time_ms": 8.971, "learn_throughput": 3567.173, "update_time_ms": 5.551}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.32895278930664, "min_q": 2.124873161315918, "max_q": 13.76019287109375, "mean_td_error": 0.8889201879501343, "model": {}}, "td_error": [0.2217254638671875, 1.0918455123901367, 0.38278865814208984, 0.9920806884765625, 3.124873161315918, 0.9820818901062012, 0.8586921691894531, 0.7423896789550781, 1.6826601028442383, 0.9574398994445801, 0.7000532150268555, 1.7491815090179443, -0.3815340995788574, 0.42997169494628906, -0.5394420623779297, 0.8955831527709961, 1.3031625747680664, 0.8507881164550781, 1.3054885864257812, 0.8955831527709961, 0.7012853622436523, 2.072373867034912, 0.17403459548950195, 2.985452175140381, 1.1175165176391602, 0.8242530822753906, 0.8507881164550781, 0.6038713455200195, -2.0737009048461914, 1.3762855529785156, -0.046980857849121094, 1.614854335784912], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.675464391708374, "min_q": -6.8891801834106445, "max_q": 9.81758975982666, "mean_td_error": -0.5060073137283325, "model": {}}, "td_error": [-13.543642044067383, 0.19109344482421875, -0.5071101188659668, -0.01383209228515625, -1.1749930381774902, -10.37051010131836, 1.1118359565734863, 5.8489603996276855, 0.21106243133544922, 8.983577728271484, -1.1777870655059814, -0.9456658363342285, 2.495274066925049, -0.48790597915649414, -2.424464225769043, 10.81758975982666, 3.8428077697753906, 0.45475196838378906, -12.823627471923828, 0.3109489679336548, -0.5866897106170654, 0.45475196838378906, 8.914905548095703, 3.422720193862915, -0.10520684719085693, -0.12302827835083008, -13.031291961669922, -0.2555875778198242, 0.07257556915283203, -0.34805917739868164, 0.749809741973877, -6.1554975509643555], "custom_metrics": {}}}, "num_steps_sampled": 27751, "num_agent_steps_sampled": 55502, "num_steps_trained": 89312, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 178624, "last_target_update_ts": 27709, "num_target_updates": 251}, "done": false, "episodes_total": 2927, "training_iteration": 118, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-56", "timestamp": 1648811816, "time_this_iter_s": 1.5334627628326416, "time_total_s": 148.64443349838257, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583e9320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583e9320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 148.64443349838257, "timesteps_since_restore": 3776, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 31.1, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3541199148805145, "mean_inference_ms": 1.7396128263087747, "mean_action_processing_ms": 0.11843523379530227, "mean_env_wait_ms": 0.07508876358167983, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27955, "timesteps_this_iter": 32, "agent_timesteps_total": 55910, "timers": {"load_time_ms": 0.526, "load_throughput": 60803.537, "learn_time_ms": 8.376, "learn_throughput": 3820.275, "update_time_ms": 5.421}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.342016220092773, "min_q": -0.576610803604126, "max_q": 15.16177749633789, "mean_td_error": -0.04119729995727539, "model": {}}, "td_error": [1.0196924209594727, -0.7470264434814453, -0.14446067810058594, 0.9157257080078125, -1.553208351135254, -1.559652328491211, 0.625920295715332, -1.2712889909744263, 0.04630470275878906, -0.17976665496826172, 1.340641975402832, -1.559652328491211, -0.17976665496826172, 0.8073558807373047, -0.17976665496826172, -3.3148956298828125, 0.4788050651550293, -1.6212987899780273, -0.22043466567993164, 1.0240468978881836, 0.1278390884399414, -0.42468035221099854, -0.8824186325073242, 1.1031618118286133, 0.04630470275878906, -1.7262763977050781, 1.1977691650390625, -0.14446067810058594, 1.908555030822754, 0.46506786346435547, 0.08089494705200195, 3.2026548385620117], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.4323410987854004, "min_q": -6.804168701171875, "max_q": 8.44302749633789, "mean_td_error": -1.774822473526001, "model": {}}, "td_error": [7.547574996948242, 2.076540470123291, -0.3035850524902344, -2.6332995891571045, -12.178852081298828, 0.21604013442993164, -0.314467191696167, -0.1934802532196045, -0.4571540355682373, 2.4118847846984863, -0.17902469635009766, -0.6331005096435547, -10.6495361328125, 2.170193910598755, -1.2750318050384521, 0.6206645965576172, -14.888688087463379, 0.042758941650390625, -1.8395562171936035, 0.4536304473876953, -0.0705556869506836, -10.714067459106445, -0.5569725036621094, -0.1327364444732666, 3.140934944152832, 0.6206645965576172, -10.845911026000977, 0.13501834869384766, -4.808681488037109, -0.14883947372436523, -5.642858505249023, 2.2361719608306885], "custom_metrics": {}}}, "num_steps_sampled": 27955, "num_agent_steps_sampled": 55910, "num_steps_trained": 90400, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 180800, "last_target_update_ts": 27913, "num_target_updates": 253}, "done": false, "episodes_total": 2961, "training_iteration": 119, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-57", "timestamp": 1648811817, "time_this_iter_s": 1.5823795795440674, "time_total_s": 150.22681307792664, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 150.22681307792664, "timesteps_since_restore": 3808, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 30.75, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 4.0, "episode_reward_mean": 7.96, "episode_len_mean": 6.02, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 12.0, "policy1": -8.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 13.98, "policy1": -6.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3546443266730082, "mean_inference_ms": 1.740514766783005, "mean_action_processing_ms": 0.11849118858031864, "mean_env_wait_ms": 0.07511102191838921, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28161, "timesteps_this_iter": 32, "agent_timesteps_total": 56322, "timers": {"load_time_ms": 0.438, "load_throughput": 73015.846, "learn_time_ms": 8.585, "learn_throughput": 3727.545, "update_time_ms": 5.067}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.393430709838867, "min_q": 2.8083648681640625, "max_q": 15.926748275756836, "mean_td_error": 0.3049471378326416, "model": {}}, "td_error": [-0.7152972221374512, -0.2889690399169922, 0.5215015411376953, -0.3280196189880371, 0.19398069381713867, 0.8094701766967773, -0.12162637710571289, 0.39609241485595703, -0.1163787841796875, 7.0819854736328125, 1.8141307830810547, 0.32228565216064453, -0.06806468963623047, 0.5511102676391602, 1.0825238227844238, -0.07251977920532227, 0.18050384521484375, 0.5955424308776855, -0.29846668243408203, -4.50095272064209, 2.8451833724975586, -0.10883712768554688, 0.5811357498168945, -0.06712627410888672, -0.2758216857910156, -0.8298625946044922, -0.26032161712646484, 0.23736095428466797, 0.6235189437866211, 0.09381628036499023, 0.18050193786621094, -0.30007171630859375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.0213563442230225, "min_q": -6.891292572021484, "max_q": 7.617266654968262, "mean_td_error": -2.187335252761841, "model": {}}, "td_error": [0.6694331169128418, 1.5409622192382812, -2.8398947715759277, 2.673346996307373, -5.435934066772461, -1.1912615299224854, -0.449434757232666, 0.5184550285339355, -1.8745675086975098, 2.7092199325561523, 0.9107637405395508, -0.5713052749633789, -2.9161834716796875, -1.3827333450317383, -1.7127153873443604, -0.09439277648925781, 1.7553786039352417, -0.9730219841003418, -11.487099647521973, -0.819866418838501, -1.337968111038208, -11.270212173461914, -0.47948122024536133, 0.5032601356506348, -1.0638253688812256, -2.707895517349243, -10.78713321685791, 0.4216899871826172, -10.78713321685791, -10.573814392089844, -1.1673176288604736, 0.22595548629760742], "custom_metrics": {}}}, "num_steps_sampled": 28161, "num_agent_steps_sampled": 56322, "num_steps_trained": 91488, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 182976, "last_target_update_ts": 28117, "num_target_updates": 255}, "done": false, "episodes_total": 2995, "training_iteration": 120, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-16-59", "timestamp": 1648811819, "time_this_iter_s": 1.522657871246338, "time_total_s": 151.74947094917297, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa584bc950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 151.74947094917297, "timesteps_since_restore": 3840, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 32.53333333333333, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 4.0, "episode_reward_mean": 7.92, "episode_len_mean": 6.04, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 12.0, "policy1": -8.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 13.96, "policy1": -6.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3551095972685363, "mean_inference_ms": 1.7410746468141907, "mean_action_processing_ms": 0.11852685912745212, "mean_env_wait_ms": 0.07511967687035014, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28367, "timesteps_this_iter": 32, "agent_timesteps_total": 56734, "timers": {"load_time_ms": 0.439, "load_throughput": 72928.563, "learn_time_ms": 7.835, "learn_throughput": 4084.308, "update_time_ms": 4.624}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.936910629272461, "min_q": -1.0147782564163208, "max_q": 14.322016716003418, "mean_td_error": -0.09935423731803894, "model": {}}, "td_error": [0.8442363739013672, 0.22362709045410156, -0.5142326354980469, 0.14142799377441406, 0.8401918411254883, -1.4736384153366089, 0.4405069351196289, -0.504119873046875, -3.1199169158935547, 0.021514892578125, 1.906428337097168, -0.5164089202880859, 0.4742393493652344, 2.4780306816101074, -0.07100486755371094, 0.1387934684753418, 0.11716079711914062, -0.5722980499267578, 0.11716079711914062, 0.07251691818237305, 0.16818809509277344, -2.2709035873413086, 4.880313396453857, 0.43345433473587036, -0.6502394080162048, -1.9828605651855469, -0.13775014877319336, 0.2881126403808594, 6.312923908233643, -5.28233003616333, -0.5722951889038086, -5.410165309906006], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.9603347778320312, "min_q": -10.099902153015137, "max_q": 2.420846700668335, "mean_td_error": -0.9059765934944153, "model": {}}, "td_error": [-2.74727201461792, 0.5320987701416016, 1.0476250648498535, 0.8537354469299316, 2.3517518043518066, -10.934910774230957, -0.16014432907104492, 0.04946422576904297, -0.12527227401733398, -2.4435677528381348, -0.22761034965515137, -0.2412726879119873, 1.171137809753418, -10.90273666381836, 1.2822990417480469, -0.08301067352294922, 0.5124000310897827, 0.8537354469299316, -6.067088603973389, -0.0749824047088623, 0.8613300323486328, 2.3359174728393555, 2.055022716522217, 0.8537354469299316, 0.279308557510376, -0.15981006622314453, 0.26598799228668213, -0.2339334487915039, -1.697188138961792, 1.2485017776489258, -12.2939453125, 2.8474435806274414], "custom_metrics": {}}}, "num_steps_sampled": 28367, "num_agent_steps_sampled": 56734, "num_steps_trained": 92576, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 185152, "last_target_update_ts": 28325, "num_target_updates": 257}, "done": false, "episodes_total": 3029, "training_iteration": 121, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-17-00", "timestamp": 1648811820, "time_this_iter_s": 1.4489924907684326, "time_total_s": 153.1984634399414, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58474710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 153.1984634399414, "timesteps_since_restore": 3872, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 32.25, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 4.0, "episode_reward_mean": 7.92, "episode_len_mean": 6.04, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 12.0, "policy1": -8.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 13.96, "policy1": -6.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35545290251349015, "mean_inference_ms": 1.741168398308032, "mean_action_processing_ms": 0.1185284836141799, "mean_env_wait_ms": 0.07511040311340915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28571, "timesteps_this_iter": 32, "agent_timesteps_total": 57142, "timers": {"load_time_ms": 0.485, "load_throughput": 66022.789, "learn_time_ms": 8.104, "learn_throughput": 3948.835, "update_time_ms": 5.084}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.206334114074707, "min_q": -1.569443941116333, "max_q": 14.008957862854004, "mean_td_error": 0.10321149230003357, "model": {}}, "td_error": [0.5515131950378418, 0.4170198440551758, 0.4095025062561035, 0.4062051773071289, -0.569443941116333, -0.09440469741821289, -4.471164703369141, 0.6125946044921875, -0.44606828689575195, 0.27765369415283203, -0.09440469741821289, -0.18055057525634766, 1.5618538856506348, -0.004545688629150391, 0.12369155883789062, -0.18055057525634766, -0.006246089935302734, 0.3302602767944336, 0.6360428333282471, -0.38489437103271484, 7.699087619781494, 0.21258068084716797, 0.3037452697753906, 0.23518943786621094, -1.1408119201660156, 0.34931182861328125, 0.264615535736084, -2.6906871795654297, 0.28549671173095703, -0.13054752349853516, -1.2281062602996826, 0.24882936477661133], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.8457536697387695, "min_q": -6.696046829223633, "max_q": 3.9769673347473145, "mean_td_error": -0.9075190424919128, "model": {}}, "td_error": [2.2684974670410156, -0.10677409172058105, -1.248868465423584, -1.0644774436950684, 0.16813421249389648, 0.259549617767334, -4.560491561889648, -0.005140781402587891, 0.2779994010925293, -1.1317524909973145, -0.337968111038208, 1.9302289485931396, -9.030057907104492, 0.4449629783630371, 0.11028528213500977, 0.09253549575805664, -0.005140781402587891, -0.3202115297317505, 0.26049554347991943, 0.08684682846069336, 0.2606799602508545, 0.20288467407226562, -7.052081108093262, 0.4449629783630371, 2.072974443435669, -0.2871793508529663, -7.822601795196533, -0.4792379140853882, -6.59951639175415, -1.366990089416504, 2.106748104095459, 1.3900938034057617], "custom_metrics": {}}}, "num_steps_sampled": 28571, "num_agent_steps_sampled": 57142, "num_steps_trained": 93664, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 187328, "last_target_update_ts": 28529, "num_target_updates": 259}, "done": false, "episodes_total": 3063, "training_iteration": 122, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-17-02", "timestamp": 1648811822, "time_this_iter_s": 1.4807655811309814, "time_total_s": 154.6792290210724, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 154.6792290210724, "timesteps_since_restore": 3904, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 32.25, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 4.0, "episode_reward_mean": 7.96, "episode_len_mean": 6.02, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 12.0, "policy1": -8.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 13.98, "policy1": -6.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -8.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3557296372537725, "mean_inference_ms": 1.7412410755666299, "mean_action_processing_ms": 0.11851829573681388, "mean_env_wait_ms": 0.07509655479787586, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28775, "timesteps_this_iter": 32, "agent_timesteps_total": 57550, "timers": {"load_time_ms": 0.472, "load_throughput": 67776.462, "learn_time_ms": 7.961, "learn_throughput": 4019.554, "update_time_ms": 5.065}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.222648620605469, "min_q": 3.1331875324249268, "max_q": 13.768590927124023, "mean_td_error": 0.20219285786151886, "model": {}}, "td_error": [0.07593822479248047, -0.015533447265625, 1.2016515731811523, 3.0787220001220703, -0.3325939178466797, 0.4719429016113281, -0.1523723602294922, -4.03701114654541, 0.26957035064697266, -1.1785569190979004, 1.1935334205627441, 0.09184789657592773, -0.0843343734741211, -1.747955322265625, -0.1385059356689453, -0.16541433334350586, -0.10063457489013672, -0.3002457618713379, 0.26957035064697266, -0.7600502967834473, -0.17534494400024414, 0.7289094924926758, -0.0042858123779296875, -0.0721893310546875, 1.190103530883789, -0.044648170471191406, 0.15889644622802734, -0.31821680068969727, 6.665600776672363, 0.37076807022094727, -0.044992923736572266, 0.37600231170654297], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.8497157096862793, "min_q": -6.367892265319824, "max_q": 10.146146774291992, "mean_td_error": -2.0433473587036133, "model": {}}, "td_error": [6.495167255401611, -0.4097362756729126, -9.92167854309082, 1.1461467742919922, -7.447504997253418, 0.11570405960083008, 0.22390270233154297, -0.886364221572876, 0.1506342887878418, -9.797420501708984, -1.2621734142303467, 0.5663995742797852, -0.2869253158569336, -0.09351539611816406, 0.5663995742797852, -10.637475967407227, -1.0016043186187744, 0.1506342887878418, -1.1129705905914307, -10.637475967407227, -10.637475967407227, 1.0847971439361572, -0.12813222408294678, -1.513288974761963, -0.32654905319213867, -0.4022104740142822, 2.065554141998291, -0.24416327476501465, 0.14423608779907227, -0.32654905319213867, -10.736556053161621, -0.2869253158569336], "custom_metrics": {}}}, "num_steps_sampled": 28775, "num_agent_steps_sampled": 57550, "num_steps_trained": 94752, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 189504, "last_target_update_ts": 28733, "num_target_updates": 261}, "done": false, "episodes_total": 3097, "training_iteration": 123, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-17-03", "timestamp": 1648811823, "time_this_iter_s": 1.4664337635040283, "time_total_s": 156.14566278457642, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5846a9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 156.14566278457642, "timesteps_since_restore": 3936, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 32.3, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35606229996351746, "mean_inference_ms": 1.7415915119517371, "mean_action_processing_ms": 0.11853249205569508, "mean_env_wait_ms": 0.07510358866533613, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28979, "timesteps_this_iter": 32, "agent_timesteps_total": 57958, "timers": {"load_time_ms": 0.423, "load_throughput": 75709.458, "learn_time_ms": 8.192, "learn_throughput": 3906.334, "update_time_ms": 5.739}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.553293228149414, "min_q": 3.6680409908294678, "max_q": 15.11697006225586, "mean_td_error": -0.20682711899280548, "model": {}}, "td_error": [-0.06850433349609375, 0.10107040405273438, -4.5346784591674805, -1.8163323402404785, -0.16894817352294922, 3.080756187438965, 0.90643310546875, -0.139512300491333, 0.2787818908691406, 0.5409283638000488, 0.15878963470458984, -0.1556720733642578, -0.08142375946044922, -0.22379851341247559, 0.09070301055908203, -0.08142375946044922, -0.08142375946044922, 0.06461238861083984, -0.050388336181640625, -1.485443115234375, 0.059337615966796875, -0.12313461303710938, 0.0126495361328125, 0.0356602668762207, 0.0813899040222168, -0.053983211517333984, -0.08142375946044922, -0.057755470275878906, 0.3688535690307617, -3.0976171493530273, -0.014438629150390625, -0.08253192901611328], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.7974458932876587, "min_q": -7.629762649536133, "max_q": 9.83768081665039, "mean_td_error": -1.8709230422973633, "model": {}}, "td_error": [-0.1394345760345459, -0.2277834415435791, -0.4579005241394043, 0.8376808166503906, -0.5670636892318726, 0.3030672073364258, -0.24920272827148438, -7.553437232971191, 0.032913923263549805, -0.24920272827148438, 0.07752048969268799, -0.30403757095336914, -11.699909210205078, 1.6198574304580688, -1.2411174774169922, -0.727313756942749, -0.04061412811279297, 1.9132928848266602, 0.3739957809448242, 0.876380443572998, -0.1866379976272583, -11.925945281982422, -6.448497772216797, 1.6667871475219727, -2.515430450439453, -1.0070559978485107, -0.2206122875213623, -0.10706448554992676, 0.6688065528869629, -9.597540855407715, -11.925943374633789, -0.8480968475341797], "custom_metrics": {}}}, "num_steps_sampled": 28979, "num_agent_steps_sampled": 57958, "num_steps_trained": 95840, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 191680, "last_target_update_ts": 28937, "num_target_updates": 263}, "done": false, "episodes_total": 3131, "training_iteration": 124, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-17-05", "timestamp": 1648811825, "time_this_iter_s": 1.5625183582305908, "time_total_s": 157.708181142807, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583bfe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583bfe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 157.708181142807, "timesteps_since_restore": 3968, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 31.75, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35647551584176396, "mean_inference_ms": 1.7422599448629197, "mean_action_processing_ms": 0.11858281229348502, "mean_env_wait_ms": 0.07512579219493665, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29183, "timesteps_this_iter": 32, "agent_timesteps_total": 58366, "timers": {"load_time_ms": 0.442, "load_throughput": 72456.126, "learn_time_ms": 8.542, "learn_throughput": 3746.043, "update_time_ms": 5.081}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.242371559143066, "min_q": -1.057438850402832, "max_q": 15.434591293334961, "mean_td_error": 0.14451321959495544, "model": {}}, "td_error": [-0.3374061584472656, 8.713845252990723, -0.22254085540771484, -0.20675277709960938, 0.09143400192260742, 1.9175108671188354, -0.35221385955810547, 0.018123507499694824, 0.7328472137451172, -0.3687868118286133, 0.020897865295410156, 0.4270362854003906, 0.13085079193115234, 0.14588165283203125, -0.4107809066772461, 0.020897865295410156, 1.2792975902557373, -3.4050416946411133, -0.12678241729736328, -0.24959850311279297, -0.20675277709960938, -0.24068546295166016, 0.03375720977783203, -0.1210784912109375, -0.02375173568725586, -0.11270904541015625, -0.3687868118286133, -0.03722786903381348, -2.2469701766967773, -0.4864320755004883, -0.36878490447998047, 0.9851264953613281], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.6839704513549805, "min_q": -5.044771194458008, "max_q": 6.431798934936523, "mean_td_error": -1.3434197902679443, "model": {}}, "td_error": [0.7090663909912109, 1.5643577575683594, -3.6806695461273193, -9.669057846069336, 0.747981071472168, -1.070868968963623, -0.23918843269348145, 0.2505173683166504, 0.14594554901123047, 2.009749412536621, -0.16149449348449707, -13.615467071533203, -7.272210121154785, -0.11301112174987793, -0.04615902900695801, -2.5682010650634766, -9.669057846069336, 5.50921106338501, -0.11063456535339355, 0.2863199710845947, 1.627562165260315, -0.004061460494995117, -0.07199668884277344, 0.3214149475097656, 1.8291902542114258, -3.0448291301727295, 0.02697587013244629, 0.2939577102661133, -0.5180526971817017, 0.3351266384124756, -6.630967140197754, -0.16088080406188965], "custom_metrics": {}}}, "num_steps_sampled": 29183, "num_agent_steps_sampled": 58366, "num_steps_trained": 96928, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 193856, "last_target_update_ts": 29141, "num_target_updates": 265}, "done": false, "episodes_total": 3165, "training_iteration": 125, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-17-07", "timestamp": 1648811827, "time_this_iter_s": 1.5447049140930176, "time_total_s": 159.25288605690002, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583ee8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583ee8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 159.25288605690002, "timesteps_since_restore": 4000, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 31.599999999999998, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35697185943476667, "mean_inference_ms": 1.743348954222613, "mean_action_processing_ms": 0.11867263990077262, "mean_env_wait_ms": 0.07516388271772895, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29387, "timesteps_this_iter": 32, "agent_timesteps_total": 58774, "timers": {"load_time_ms": 0.506, "load_throughput": 63253.56, "learn_time_ms": 8.334, "learn_throughput": 3839.652, "update_time_ms": 5.291}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.956558227539062, "min_q": 3.228588342666626, "max_q": 15.33854866027832, "mean_td_error": -0.00434836745262146, "model": {}}, "td_error": [0.4972391128540039, 0.19174957275390625, 0.012124061584472656, -3.2690789699554443, 0.22424936294555664, 1.1036145687103271, -0.5525074005126953, 0.09221267700195312, -0.6310787200927734, -1.4495048522949219, -0.11001205444335938, -0.030398845672607422, 0.07868576049804688, 0.14538288116455078, 0.22767305374145508, -0.05493927001953125, 0.726384162902832, 0.37523794174194336, 0.1002497673034668, 0.2176685333251953, 0.5403404235839844, 0.09780597686767578, 0.03995800018310547, 0.06953811645507812, -0.010333538055419922, 0.3115081787109375, 0.025594234466552734, 0.3273038864135742, 0.22767305374145508, 0.23914623260498047, 0.05348396301269531, 0.04388236999511719], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.012929916381836, "min_q": -6.533171653747559, "max_q": 6.255934715270996, "mean_td_error": -1.164869785308838, "model": {}}, "td_error": [-0.42792487144470215, 5.033054351806641, -5.844193935394287, -0.761035680770874, 1.8914210796356201, -10.14594841003418, 0.7617053985595703, -9.120485305786133, 0.9424676895141602, -13.906447410583496, 1.9281153678894043, -1.7513504028320312, -0.048372745513916016, -0.30002760887145996, 6.281651973724365, 0.0336151123046875, 0.43596935272216797, 1.9823598861694336, 2.5283875465393066, -9.120485305786133, 1.7040462493896484, 1.881911277770996, 0.5637307167053223, 0.5522127151489258, 0.0336151123046875, -6.892640113830566, -0.9625163078308105, 0.6106705665588379, 1.0155320167541504, -6.892640113830566, -0.8486342430114746, 1.5664057731628418], "custom_metrics": {}}}, "num_steps_sampled": 29387, "num_agent_steps_sampled": 58774, "num_steps_trained": 98016, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 196032, "last_target_update_ts": 29345, "num_target_updates": 267}, "done": false, "episodes_total": 3199, "training_iteration": 126, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-17-08", "timestamp": 1648811828, "time_this_iter_s": 1.6071865558624268, "time_total_s": 160.86007261276245, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583ee680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583ee680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 160.86007261276245, "timesteps_since_restore": 4032, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 32.25, "ram_util_percent": 59.9}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35745148995973497, "mean_inference_ms": 1.7444216179141583, "mean_action_processing_ms": 0.1187541943004344, "mean_env_wait_ms": 0.07520183711545232, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29591, "timesteps_this_iter": 32, "agent_timesteps_total": 59182, "timers": {"load_time_ms": 0.448, "load_throughput": 71445.613, "learn_time_ms": 8.19, "learn_throughput": 3907.346, "update_time_ms": 4.703}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.730257034301758, "min_q": -1.1464958190917969, "max_q": 15.230615615844727, "mean_td_error": 0.18424172699451447, "model": {}}, "td_error": [0.5974283218383789, -0.07237815856933594, -0.026649951934814453, 0.15349292755126953, -0.10708045959472656, 0.09727001190185547, 0.4600672721862793, 0.5611324310302734, 0.16277503967285156, 0.6317710876464844, 0.20068931579589844, 0.1821880340576172, 0.6740565299987793, -0.006843090057373047, 0.4629840850830078, 0.44365406036376953, -2.624823808670044, -0.4096965789794922, 0.14878559112548828, -0.03743124008178711, -3.6700193881988525, 0.08442974090576172, 6.708346843719482, 0.0921478271484375, 0.1622910499572754, 1.2432003021240234, -0.10708045959472656, -0.8808250427246094, 0.16176795959472656, 0.5289402008056641, -0.08167552947998047, 0.16282033920288086], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.1092615127563477, "min_q": -6.683858871459961, "max_q": 8.314973831176758, "mean_td_error": -0.8160945177078247, "model": {}}, "td_error": [-0.8068304061889648, -0.042224884033203125, -5.816812515258789, -0.15992474555969238, -0.29590415954589844, -0.39434361457824707, 1.3419599533081055, -2.605393886566162, -0.23215579986572266, 0.4518313407897949, -6.711084365844727, 0.2894587516784668, -0.8785560131072998, -0.3727445602416992, 0.0494685173034668, 1.3619524240493774, -0.5255239009857178, 1.2935829162597656, -0.701061487197876, 0.2021188735961914, 2.283848762512207, -10.660407066345215, 0.8855428695678711, 1.9884800910949707, 0.5003504753112793, 1.6062159538269043, -0.4585815668106079, 1.8517546653747559, -10.660407066345215, 1.3491320610046387, -0.05256223678588867, -0.19620394706726074], "custom_metrics": {}}}, "num_steps_sampled": 29591, "num_agent_steps_sampled": 59182, "num_steps_trained": 99104, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 198208, "last_target_update_ts": 29549, "num_target_updates": 269}, "done": false, "episodes_total": 3233, "training_iteration": 127, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-17-10", "timestamp": 1648811830, "time_this_iter_s": 1.5411169528961182, "time_total_s": 162.40118956565857, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583bf560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa583bf560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 162.40118956565857, "timesteps_since_restore": 4064, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 28.1, "ram_util_percent": 59.95}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35778743119972956, "mean_inference_ms": 1.744755097506926, "mean_action_processing_ms": 0.11877412299279325, "mean_env_wait_ms": 0.07521785723464072, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29795, "timesteps_this_iter": 32, "agent_timesteps_total": 59590, "timers": {"load_time_ms": 0.413, "load_throughput": 77434.794, "learn_time_ms": 7.737, "learn_throughput": 4135.719, "update_time_ms": 4.501}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.289974212646484, "min_q": 1.2512261867523193, "max_q": 15.184104919433594, "mean_td_error": 0.38614022731781006, "model": {}}, "td_error": [2.2512261867523193, -0.2058858871459961, -0.037638187408447266, 1.1136388778686523, 0.2199115753173828, 0.7125558853149414, 0.03299903869628906, 3.3625340461730957, -0.02021312713623047, -0.20349836349487305, -0.08436250686645508, -0.6382536888122559, -0.08436250686645508, -0.17722225189208984, 0.0016956329345703125, -2.646702527999878, -6.2389397621154785, 0.23845672607421875, -0.0874018669128418, -0.07606983184814453, -0.2127060890197754, 0.03299903869628906, -0.19726324081420898, -0.4378962516784668, 0.23845672607421875, 3.3693623542785645, 1.4096546173095703, 0.1670370101928711, 2.635448932647705, -0.11797094345092773, 8.201190948486328, -0.1642932891845703], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.0703258514404297, "min_q": -8.60214900970459, "max_q": 8.5736665725708, "mean_td_error": -1.1594527959823608, "model": {}}, "td_error": [-9.42306900024414, -0.6370975971221924, 0.528071403503418, 0.09187030792236328, 7.37906551361084, 0.6373715400695801, 0.368316650390625, -3.3975484371185303, 0.13254404067993164, 1.2355313301086426, 0.368316650390625, 2.7709813117980957, 2.0506014823913574, 0.5925908088684082, 2.975438117980957, -0.3067305088043213, -6.076190948486328, -1.1412386894226074, -0.23395538330078125, -8.57217788696289, -0.6678087711334229, -0.0716710090637207, -0.23110580444335938, -4.923991680145264, 1.3149995803833008, 6.395923614501953, -8.398584365844727, 1.2916226387023926, -0.9010872840881348, -9.42306900024414, -11.383011817932129, 0.5526070594787598], "custom_metrics": {}}}, "num_steps_sampled": 29795, "num_agent_steps_sampled": 59590, "num_steps_trained": 100192, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 200384, "last_target_update_ts": 29753, "num_target_updates": 271}, "done": false, "episodes_total": 3267, "training_iteration": 128, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-17-11", "timestamp": 1648811831, "time_this_iter_s": 1.369405746459961, "time_total_s": 163.77059531211853, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 163.77059531211853, "timesteps_since_restore": 4096, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 21.65, "ram_util_percent": 53.2}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3579562808100362, "mean_inference_ms": 1.744140604100359, "mean_action_processing_ms": 0.11872440653077224, "mean_env_wait_ms": 0.07520739592098097, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29999, "timesteps_this_iter": 32, "agent_timesteps_total": 59998, "timers": {"load_time_ms": 0.42, "load_throughput": 76247.076, "learn_time_ms": 7.389, "learn_throughput": 4330.82, "update_time_ms": 4.76}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.542635917663574, "min_q": 0.18753916025161743, "max_q": 15.150012969970703, "mean_td_error": -0.24644288420677185, "model": {}}, "td_error": [-0.07620620727539062, 0.2179584503173828, 0.42369842529296875, -0.0449824333190918, -0.9576985836029053, 0.12029027938842773, 0.014895439147949219, -0.14926815032958984, -7.9439287185668945, -0.03127002716064453, 0.03046274185180664, -0.3563060760498047, 0.24176311492919922, -0.012258529663085938, 0.015078544616699219, 0.4803962707519531, -1.5660076141357422, 0.07947826385498047, -0.06302165985107422, -0.0972433090209961, -0.06302165985107422, -0.07479286193847656, -1.8770227432250977, 0.07237720489501953, 0.949397087097168, 0.1302652359008789, 2.8467822074890137, 0.2399749755859375, 0.3419017791748047, 0.09741497039794922, -0.7260074615478516, -0.14927101135253906], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -3.209848403930664, "min_q": -9.285402297973633, "max_q": 12.844536781311035, "mean_td_error": -0.4697391092777252, "model": {}}, "td_error": [-0.35746097564697266, -7.70695686340332, -2.41281795501709, 0.7952814102172852, 2.3167102336883545, 2.926295757293701, -0.34235548973083496, 2.167865037918091, 0.04121971130371094, 3.4265518188476562, 3.844536781311035, -0.37379908561706543, 1.2895770072937012, -0.3664698600769043, -1.8365237712860107, 0.04121971130371094, 1.3108601570129395, 1.3108601570129395, -0.35746097564697266, -10.017587661743164, -0.17776453495025635, -1.3856210708618164, 1.2345552444458008, 0.04121971130371094, -2.3132171630859375, 2.5155444145202637, -0.2668328285217285, 1.0496649742126465, -0.5137753486633301, -10.359899520874023, 1.6316285133361816, -2.186699390411377], "custom_metrics": {}}}, "num_steps_sampled": 29999, "num_agent_steps_sampled": 59998, "num_steps_trained": 101280, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 202560, "last_target_update_ts": 29957, "num_target_updates": 273}, "done": false, "episodes_total": 3301, "training_iteration": 129, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-17-13", "timestamp": 1648811833, "time_this_iter_s": 1.3541646003723145, "time_total_s": 165.12475991249084, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa5848fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 165.12475991249084, "timesteps_since_restore": 4128, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 19.05, "ram_util_percent": 53.2}}
{"episode_reward_max": 8.0, "episode_reward_min": 8.0, "episode_reward_mean": 8.0, "episode_len_mean": 6.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_max": {"policy0": 14.0, "policy1": -6.0}, "policy_reward_mean": {"policy0": 14.0, "policy1": -6.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0], "episode_lengths": [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [-6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3580284259668955, "mean_inference_ms": 1.742995749831344, "mean_action_processing_ms": 0.11863502417517253, "mean_env_wait_ms": 0.0751662281162977, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 30203, "timesteps_this_iter": 32, "agent_timesteps_total": 60406, "timers": {"load_time_ms": 0.434, "load_throughput": 73782.49, "learn_time_ms": 7.361, "learn_throughput": 4347.33, "update_time_ms": 4.439}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.768531799316406, "min_q": -0.3391042649745941, "max_q": 14.84035587310791, "mean_td_error": -0.44080650806427, "model": {}}, "td_error": [0.4191112518310547, -0.009578704833984375, 0.04843902587890625, -5.854724884033203, 0.3175816535949707, -0.06068229675292969, 0.4287691116333008, 0.058147430419921875, 0.058147430419921875, 0.35790157318115234, -6.043854713439941, -0.045789241790771484, 0.20799636840820312, 0.06144142150878906, 0.029039382934570312, 0.29658985137939453, -0.004046440124511719, -0.038753509521484375, 0.17542028427124023, 0.29658985137939453, -0.1693248748779297, 0.12762117385864258, 0.11779975891113281, 0.6039032936096191, -0.009578704833984375, 1.5784428119659424, 0.058147430419921875, 0.07773065567016602, -7.953467845916748, 0.04613161087036133, 0.05814552307128906, 0.6608957052230835], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.253347873687744, "min_q": -7.039941310882568, "max_q": 9.611299514770508, "mean_td_error": 0.03952991962432861, "model": {}}, "td_error": [1.884082317352295, -10.24867057800293, -0.10071539878845215, 0.013570070266723633, 0.29548168182373047, -0.3099478483200073, -0.10804057121276855, -0.47759008407592773, 0.22090530395507812, 1.8564075231552124, 2.416661262512207, 0.6112995147705078, -1.2176194190979004, -0.3485560417175293, 1.883885383605957, 4.126407623291016, 0.11281108856201172, 0.49774789810180664, 0.29548168182373047, 0.6448464393615723, 5.484108924865723, -0.3234133720397949, -0.23512506484985352, -0.26023292541503906, -5.7070441246032715, 0.11281108856201172, -0.09039878845214844, -0.21157407760620117, 2.8013734817504883, -11.495634078979492, 9.459720611572266, -0.31808149814605713], "custom_metrics": {}}}, "num_steps_sampled": 30203, "num_agent_steps_sampled": 60406, "num_steps_trained": 102368, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 204736, "last_target_update_ts": 30161, "num_target_updates": 275}, "done": true, "episodes_total": 3335, "training_iteration": 130, "trial_id": "d62fa_00000", "experiment_id": "bcb160d56a954b349b4bbe987e40beb7", "date": "2022-04-01_04-17-14", "timestamp": 1648811834, "time_this_iter_s": 1.3737919330596924, "time_total_s": 166.49855184555054, "pid": 19968, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7faa58440ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 166.49855184555054, "timesteps_since_restore": 4160, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 19.5, "ram_util_percent": 53.2}}
