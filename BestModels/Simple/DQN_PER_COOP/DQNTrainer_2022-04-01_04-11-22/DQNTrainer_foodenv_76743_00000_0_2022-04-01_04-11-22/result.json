{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.771929824561404, "episode_len_mean": 17.789473684210527, "episode_media": {}, "episodes_this_iter": 57, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.385964912280702, "policy1": -6.385964912280702}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, 8.0, 16.0, 22.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, 22.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -40.0, -20.0, -20.0, 0.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 10, 16, 12, 9, 20, 20, 20, 12, 20, 20, 20, 9, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 4.0, 8.0, 11.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, 11.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -20.0, -10.0, -10.0, 0.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 4.0, 8.0, 11.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, 11.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -20.0, -10.0, -10.0, 0.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27786804537467763, "mean_inference_ms": 1.5777766410940386, "mean_action_processing_ms": 0.09836304951183904, "mean_env_wait_ms": 0.06566587927306228, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1014, "timesteps_this_iter": 32, "agent_timesteps_total": 2028, "timers": {"load_time_ms": 0.452, "load_throughput": 70752.624, "learn_time_ms": 312.649, "learn_throughput": 102.351, "update_time_ms": 6.339}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -0.3010759949684143, "min_q": -0.9126817584037781, "max_q": 0.32941052317619324, "mean_td_error": -0.3353292942047119, "model": {}}, "td_error": [0.7900476455688477, -9.476641654968262, 0.18028044700622559, 1.2315980195999146, 0.38541746139526367, 1.1500840187072754, -9.660634994506836, 0.5378077030181885, 1.0408021211624146, 0.9927923679351807, 0.786128044128418, 0.9665673971176147, 0.4723970890045166, 0.6946125030517578, 0.08596590161323547, 1.1840133666992188, 1.104079246520996, 0.25887781381607056, 0.18028044700622559, 0.5596625804901123, 0.2367616891860962, 0.5203996896743774, 0.5338175296783447, 0.23175948858261108, 0.464324951171875, 0.36813053488731384, 0.6917102336883545, 0.6974208950996399, -10.030817031860352, 0.6809210777282715, 0.26203423738479614, 1.1488627195358276], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 0.14957398176193237, "min_q": -0.3788982629776001, "max_q": 0.6936180591583252, "mean_td_error": 0.6002287864685059, "model": {}}, "td_error": [1.2182807922363281, 1.4353182315826416, 0.7136898636817932, 1.3576122522354126, 0.9455446004867554, -8.598501205444336, 1.4573473930358887, 0.5085705518722534, 1.5434942245483398, -8.971863746643066, 1.9145948886871338, 1.014810562133789, 1.017248511314392, 1.1961796283721924, 1.7883769273757935, 1.602455496788025, 0.9528239965438843, 1.3623442649841309, 1.5361366271972656, 0.6778309345245361, 1.3556532859802246, 0.8391449451446533, 1.0179247856140137, 1.6407544612884521, 1.2887141704559326, 1.295971393585205, 1.6419486999511719, 1.1149064302444458, 0.6906952261924744, 1.4714542627334595, 0.4216254949569702, 1.7562347650527954], "custom_metrics": {}}}, "num_steps_sampled": 1014, "num_agent_steps_sampled": 2028, "num_steps_trained": 32, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64, "last_target_update_ts": 1014, "num_target_updates": 1}, "done": false, "episodes_total": 57, "training_iteration": 1, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-36", "timestamp": 1648811496, "time_this_iter_s": 2.893098831176758, "time_total_s": 2.893098831176758, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2.893098831176758, "timesteps_since_restore": 32, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 12.68, "ram_util_percent": 32.82}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.243243243243244, "episode_len_mean": 18.06756756756757, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.121621621621622, "policy1": -7.121621621621622}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, 8.0, 16.0, 22.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, 22.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -40.0, -20.0, -20.0, 0.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 10.0, 0.0], "episode_lengths": [20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 10, 16, 12, 9, 20, 20, 20, 12, 20, 20, 20, 9, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 4.0, 8.0, 11.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, 11.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -20.0, -10.0, -10.0, 0.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 5.0, 0.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 4.0, 8.0, 11.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, 11.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -20.0, -10.0, -10.0, 0.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 5.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27749849650352615, "mean_inference_ms": 1.5707779227269842, "mean_action_processing_ms": 0.0982883688980375, "mean_env_wait_ms": 0.06565365920935892, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1337, "timesteps_this_iter": 32, "agent_timesteps_total": 2674, "timers": {"load_time_ms": 0.45, "load_throughput": 71180.382, "learn_time_ms": 7.103, "learn_throughput": 4505.084, "update_time_ms": 5.852}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.433836936950684, "min_q": -8.63487434387207, "max_q": 2.5823287963867188, "mean_td_error": 4.805768013000488, "model": {}}, "td_error": [5.517897605895996, 4.476386070251465, 12.504562377929688, -0.36591649055480957, -3.1471805572509766, 8.24594783782959, 4.605888843536377, -3.69700288772583, 2.0102241039276123, 5.886847496032715, 2.6845645904541016, 1.0982513427734375, 1.0234870910644531, 8.372718811035156, 8.357076644897461, 5.517897605895996, 3.4861841201782227, 14.774186134338379, 3.6360654830932617, 2.0163588523864746, 8.27465534210205, 3.7782273292541504, 1.936553716659546, 2.0594491958618164, 2.2778759002685547, 10.655799865722656, 9.106870651245117, 6.932491302490234, 3.2589669227600098, 5.788278579711914, 6.922694206237793, 5.788281440734863], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.90078866481781, "min_q": -5.976984977722168, "max_q": 2.8741614818573, "mean_td_error": 4.239736557006836, "model": {}}, "td_error": [-0.7638719081878662, 3.619490146636963, 8.615591049194336, 1.4652924537658691, 9.643218994140625, -1.4720033407211304, 4.237346172332764, 8.48420238494873, 2.315708637237549, 9.806329727172852, 13.10799789428711, 1.1134108304977417, 0.34700095653533936, 7.963698863983154, 8.711468696594238, 6.087554931640625, 1.250199794769287, 4.102189540863037, 14.180776596069336, 0.0019292831420898438, 4.7658467292785645, 10.436174392700195, 4.140047550201416, 5.612492084503174, 3.9243969917297363, 1.4331810474395752, 2.992793560028076, -0.5265829563140869, 1.2051217555999756, 0.7147951126098633, -3.7129907608032227, 1.8687710762023926], "custom_metrics": {}}}, "num_steps_sampled": 1337, "num_agent_steps_sampled": 2674, "num_steps_trained": 576, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 1152, "last_target_update_ts": 1242, "num_target_updates": 3}, "done": false, "episodes_total": 74, "training_iteration": 2, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-37", "timestamp": 1648811497, "time_this_iter_s": 1.1190826892852783, "time_total_s": 4.012181520462036, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f7a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f7a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4.012181520462036, "timesteps_since_restore": 64, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 12.7, "ram_util_percent": 33.0}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.565217391304348, "episode_len_mean": 18.152173913043477, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.282608695652174, "policy1": -7.282608695652174}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, 8.0, 16.0, 22.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, 22.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -40.0, -20.0, -20.0, 0.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 10.0, 0.0, -20.0, 8.0, 14.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 10, 16, 12, 9, 20, 20, 20, 12, 20, 20, 20, 9, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 16, 13, 20, 20, 20, 8, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 4.0, 8.0, 11.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, 11.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -20.0, -10.0, -10.0, 0.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 5.0, 0.0, -10.0, 4.0, 7.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 4.0, 8.0, 11.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, 11.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -20.0, -10.0, -10.0, 0.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 5.0, 0.0, -10.0, 4.0, 7.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27728648487020885, "mean_inference_ms": 1.5643517056322944, "mean_action_processing_ms": 0.0983008494341888, "mean_env_wait_ms": 0.06562770827054044, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1670, "timesteps_this_iter": 32, "agent_timesteps_total": 3340, "timers": {"load_time_ms": 0.425, "load_throughput": 75382.043, "learn_time_ms": 6.857, "learn_throughput": 4666.706, "update_time_ms": 5.537}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -6.392936706542969, "min_q": -10.987218856811523, "max_q": -3.801574468612671, "mean_td_error": -0.04243972897529602, "model": {}}, "td_error": [0.9343276023864746, 0.24237823486328125, 1.2807393074035645, 0.7231631278991699, 1.1585803031921387, 1.1285085678100586, -0.5323371887207031, -3.9411256313323975, 0.6745157241821289, 0.1705613136291504, -0.4487590789794922, -0.9558601379394531, 1.0373096466064453, 0.5241003036499023, 0.8276596069335938, -0.564967155456543, 1.0673789978027344, 0.3979148864746094, 0.08328437805175781, -0.5323371887207031, 0.509824275970459, -0.9022836685180664, 0.9760675430297852, -0.3730659484863281, 0.8156733512878418, 0.8657641410827637, -8.487177848815918, 0.8064155578613281, 0.5380983352661133, 0.35697412490844727, 1.0630736351013184, -0.8024702072143555], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.68582820892334, "min_q": -4.773852825164795, "max_q": -0.3295932114124298, "mean_td_error": 0.3419409394264221, "model": {}}, "td_error": [1.4773573875427246, 0.13679265975952148, 0.024927139282226562, 1.1343883275985718, 0.0362858772277832, 0.4562187194824219, 1.3736907243728638, -6.114488124847412, 1.0475618839263916, 1.4842529296875, 0.38466525077819824, 0.46024787425994873, 0.47978782653808594, 2.4134583473205566, 0.30983638763427734, 0.5737674236297607, 0.45689964294433594, -1.643934726715088, -3.6146955490112305, 2.1986582279205322, 0.4389164447784424, -3.1515369415283203, 0.5676047801971436, 0.14037656784057617, 0.8862829208374023, 1.260754108428955, 1.3512766361236572, 2.3597426414489746, 0.1140143871307373, 1.3972785472869873, 1.6225759983062744, 0.8791462182998657], "custom_metrics": {}}}, "num_steps_sampled": 1670, "num_agent_steps_sampled": 3340, "num_steps_trained": 1152, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 2304, "last_target_update_ts": 1590, "num_target_updates": 6}, "done": false, "episodes_total": 92, "training_iteration": 3, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-39", "timestamp": 1648811499, "time_this_iter_s": 1.1816253662109375, "time_total_s": 5.193806886672974, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101dfd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101dfd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5.193806886672974, "timesteps_since_restore": 96, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 14.05, "ram_util_percent": 33.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.14, "episode_len_mean": 18.27, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.57, "policy1": -7.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, 20.0, 8.0, 16.0, 22.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, 22.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -40.0, -20.0, -20.0, 0.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 10.0, 0.0, -20.0, 8.0, 14.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, 10.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 10, 16, 12, 9, 20, 20, 20, 12, 20, 20, 20, 9, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 16, 13, 20, 20, 20, 8, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 15, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 4.0, 8.0, 11.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, 11.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -20.0, -10.0, -10.0, 0.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 5.0, 0.0, -10.0, 4.0, 7.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, 5.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 4.0, 8.0, 11.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, 11.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -20.0, -10.0, -10.0, 0.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 5.0, 0.0, -10.0, 4.0, 7.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, 5.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2771161143606853, "mean_inference_ms": 1.5579170226849663, "mean_action_processing_ms": 0.09835906217251734, "mean_env_wait_ms": 0.06564916368438967, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1979, "timesteps_this_iter": 32, "agent_timesteps_total": 3958, "timers": {"load_time_ms": 0.436, "load_throughput": 73443.353, "learn_time_ms": 7.007, "learn_throughput": 4566.704, "update_time_ms": 5.112}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.103753089904785, "min_q": -10.133040428161621, "max_q": -6.097497463226318, "mean_td_error": -1.3606746196746826, "model": {}}, "td_error": [0.048604488372802734, 0.2742910385131836, -6.818394660949707, -0.26985836029052734, -6.2034382820129395, 0.41143131256103516, 0.08774757385253906, 0.5748205184936523, -0.1248016357421875, 0.30831336975097656, -7.1863603591918945, 1.0623369216918945, -0.010168075561523438, -6.257725238800049, 0.36295127868652344, -0.025216102600097656, 1.0075831413269043, 0.28310489654541016, -0.21106910705566406, -7.204384803771973, 0.4087510108947754, -0.14021778106689453, 0.5625772476196289, 1.0623369216918945, 0.12940025329589844, -16.792137145996094, 0.057250022888183594, 0.5289101600646973, -0.22910785675048828, 0.9287476539611816, 0.17756032943725586, -0.345426082611084], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -5.227612495422363, "min_q": -6.677248477935791, "max_q": -2.833996057510376, "mean_td_error": -1.722437858581543, "model": {}}, "td_error": [0.5739293098449707, 0.5636610984802246, 0.08462715148925781, -1.7626183032989502, 0.44085168838500977, -10.82929515838623, -8.110597610473633, -0.04535484313964844, 1.0619120597839355, 0.45426177978515625, 0.6385879516601562, 0.4674205780029297, 0.5404610633850098, 0.572535514831543, 0.6003255844116211, 0.5693016052246094, 0.5233521461486816, 0.19641494750976562, 0.4228963851928711, 0.061421871185302734, 1.0115184783935547, 0.5973095893859863, -3.550220012664795, -0.9571235179901123, -8.611252784729004, 0.5233068466186523, -12.47443962097168, -15.072510719299316, -5.635831356048584, 0.7809076309204102, 0.6365747451782227, 0.6096549034118652], "custom_metrics": {}}}, "num_steps_sampled": 1979, "num_agent_steps_sampled": 3958, "num_steps_trained": 1664, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 3328, "last_target_update_ts": 1939, "num_target_updates": 9}, "done": false, "episodes_total": 108, "training_iteration": 4, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-40", "timestamp": 1648811500, "time_this_iter_s": 1.0668556690216064, "time_total_s": 6.26066255569458, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6.26066255569458, "timesteps_since_restore": 128, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 13.9, "ram_util_percent": 33.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.32, "episode_len_mean": 18.36, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.16, "policy1": -8.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -40.0, -20.0, -20.0, 0.0, 24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 10.0, 0.0, -20.0, 8.0, 14.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, 10.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 24.0, -20.0, 28.0, 30.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 16, 13, 20, 20, 20, 8, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 8, 20, 6, 5, 12, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -20.0, -10.0, -10.0, 0.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 5.0, 0.0, -10.0, 4.0, 7.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, 5.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 12.0, -10.0, 14.0, 15.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -20.0, -10.0, -10.0, 0.0, 12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 5.0, 0.0, -10.0, 4.0, 7.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, 5.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 12.0, -10.0, 14.0, 15.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2768572616459813, "mean_inference_ms": 1.5474978243699855, "mean_action_processing_ms": 0.09833873641478628, "mean_env_wait_ms": 0.06560865486900622, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2304, "timesteps_this_iter": 32, "agent_timesteps_total": 4608, "timers": {"load_time_ms": 0.406, "load_throughput": 78914.468, "learn_time_ms": 6.916, "learn_throughput": 4627.256, "update_time_ms": 5.176}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.338168144226074, "min_q": -10.249595642089844, "max_q": -7.087826728820801, "mean_td_error": -2.2696406841278076, "model": {}}, "td_error": [0.7169981002807617, -8.899222373962402, 0.5596933364868164, 0.6177515983581543, -7.818981647491455, 0.3155508041381836, -8.188713073730469, 0.8388338088989258, -8.207717895507812, -8.188713073730469, 0.8066244125366211, 0.6904850006103516, -7.61094856262207, 1.1428394317626953, 0.6607279777526855, 0.8490133285522461, 0.6946067810058594, -27.0869197845459, 1.3614678382873535, 0.8487005233764648, -7.153557777404785, 1.386031150817871, 0.693122386932373, 1.0929784774780273, -0.03100299835205078, 0.5946388244628906, 0.6569042205810547, 0.7592668533325195, 1.2015600204467773, 0.4786710739135742, 0.7184534072875977, -7.127643585205078], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -6.19473934173584, "min_q": -7.752388000488281, "max_q": -3.344912528991699, "mean_td_error": -1.3085522651672363, "model": {}}, "td_error": [-7.254659175872803, -12.3449125289917, 0.9838042259216309, 0.554384708404541, -1.2206802368164062, 0.9600458145141602, 0.7753481864929199, 1.0437116622924805, 1.3903770446777344, 1.2850341796875, 1.2765083312988281, 0.6031265258789062, 0.9422130584716797, 0.8276019096374512, 0.9992647171020508, -4.881165027618408, 1.3377504348754883, 0.8249249458312988, -6.166604995727539, 0.4427947998046875, 0.8797531127929688, 0.6213064193725586, 0.986361026763916, 0.6724724769592285, 0.592015266418457, 0.5890903472900391, -7.149360656738281, -6.497347354888916, 1.5303096771240234, -7.846640110015869, -9.397059440612793, 0.7665576934814453], "custom_metrics": {}}}, "num_steps_sampled": 2304, "num_agent_steps_sampled": 4608, "num_steps_trained": 2272, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 4544, "last_target_update_ts": 2284, "num_target_updates": 12}, "done": false, "episodes_total": 127, "training_iteration": 5, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-41", "timestamp": 1648811501, "time_this_iter_s": 1.2777721881866455, "time_total_s": 7.538434743881226, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f73b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f73b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 7.538434743881226, "timesteps_since_restore": 160, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 16.55, "ram_util_percent": 33.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.88, "episode_len_mean": 18.34, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.94, "policy1": -7.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 10.0, 0.0, -20.0, 8.0, 14.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, 10.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 24.0, -20.0, 28.0, 30.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [8, 20, 8, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 16, 13, 20, 20, 20, 8, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 8, 20, 6, 5, 12, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 5.0, 0.0, -10.0, 4.0, 7.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, 5.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 12.0, -10.0, 14.0, 15.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [12.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 5.0, 0.0, -10.0, 4.0, 7.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, 5.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 12.0, -10.0, 14.0, 15.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2764786729873554, "mean_inference_ms": 1.5369737254675646, "mean_action_processing_ms": 0.09822790363062303, "mean_env_wait_ms": 0.06552347173371326, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2604, "timesteps_this_iter": 32, "agent_timesteps_total": 5208, "timers": {"load_time_ms": 0.426, "load_throughput": 75107.85, "learn_time_ms": 6.546, "learn_throughput": 4888.68, "update_time_ms": 4.913}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.731786727905273, "min_q": -12.186394691467285, "max_q": -8.597418785095215, "mean_td_error": -3.298344612121582, "model": {}}, "td_error": [0.596226692199707, -7.484169006347656, 0.13162803649902344, -10.007979393005371, -9.990279197692871, -11.101592063903809, -10.084178924560547, 0.29924488067626953, -9.368812561035156, -0.05985450744628906, -7.387759208679199, 0.8220911026000977, -7.21031379699707, 0.5892457962036133, -0.18993091583251953, -1.1655292510986328, -8.126008033752441, -20.82125473022461, -0.5886878967285156, -6.305870056152344, 0.5177526473999023, 0.38411426544189453, -0.33321475982666016, -0.0759124755859375, 0.17977619171142578, 0.39060020446777344, 0.45183849334716797, 0.2927970886230469, -0.05545997619628906, 0.7180700302124023, -0.1396198272705078, -0.42398929595947266], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.545185089111328, "min_q": -10.146405220031738, "max_q": -7.281827449798584, "mean_td_error": -5.41909646987915, "model": {}}, "td_error": [-0.0017833709716796875, -0.38973093032836914, -26.921770095825195, 0.16838645935058594, -7.479426383972168, 0.07230377197265625, -8.935176849365234, -0.24190235137939453, -17.143455505371094, 0.23551082611083984, 0.4622201919555664, 0.14694881439208984, -17.330320358276367, -7.673189640045166, -0.2721223831176758, -0.17719650268554688, -8.393420219421387, -0.06232929229736328, -0.1744098663330078, -10.177694320678711, -8.456449508666992, -9.755109786987305, -16.316293716430664, -8.685224533081055, -0.03882789611816406, -0.01798534393310547, -0.07851791381835938, -18.984224319458008, -0.14815282821655273, 1.2757539749145508, -8.257705688476562, 0.3402128219604492], "custom_metrics": {}}}, "num_steps_sampled": 2604, "num_agent_steps_sampled": 5208, "num_steps_trained": 2784, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 5568, "last_target_update_ts": 2524, "num_target_updates": 14}, "done": false, "episodes_total": 143, "training_iteration": 6, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-42", "timestamp": 1648811502, "time_this_iter_s": 1.0137860774993896, "time_total_s": 8.552220821380615, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 8.552220821380615, "timesteps_since_restore": 192, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 12.6, "ram_util_percent": 33.2}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.3, "episode_len_mean": 18.65, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.15, "policy1": -8.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, 10.0, 0.0, -20.0, 8.0, 14.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, 10.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 24.0, -20.0, 28.0, 30.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 6.0, -20.0, 10.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 16, 13, 20, 20, 20, 8, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 8, 20, 6, 5, 12, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 17, 20, 15, 14, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 5.0, 0.0, -10.0, 4.0, 7.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, 5.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 12.0, -10.0, 14.0, 15.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 3.0, -10.0, 5.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, 5.0, 0.0, -10.0, 4.0, 7.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, 5.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 12.0, -10.0, 14.0, 15.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 3.0, -10.0, 5.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2761634134285126, "mean_inference_ms": 1.5261400206958478, "mean_action_processing_ms": 0.09816599355018302, "mean_env_wait_ms": 0.06547227806668095, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2927, "timesteps_this_iter": 32, "agent_timesteps_total": 5854, "timers": {"load_time_ms": 0.441, "load_throughput": 72507.011, "learn_time_ms": 6.956, "learn_throughput": 4600.673, "update_time_ms": 5.067}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.759977340698242, "min_q": -12.95999526977539, "max_q": -9.118114471435547, "mean_td_error": -1.256203532218933, "model": {}}, "td_error": [1.1733112335205078, 0.9018945693969727, 0.9078397750854492, 0.7309503555297852, 1.092207908630371, 0.7188091278076172, -11.563419342041016, 0.5347070693969727, 0.5636825561523438, 1.7068252563476562, -11.741175651550293, 0.22139453887939453, 0.2375316619873047, 0.4804573059082031, 0.9555692672729492, -8.822206497192383, 0.81292724609375, 2.235306739807129, 0.7897787094116211, -10.030634880065918, 0.8090152740478516, -11.912803649902344, 0.6492195129394531, 1.5509252548217773, -9.769102096557617, 0.7320566177368164, 1.0371627807617188, 0.92095947265625, 1.875457763671875, 0.12643146514892578, 0.9519109725952148, 0.9244966506958008], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -9.324914932250977, "min_q": -10.802006721496582, "max_q": -6.333130359649658, "mean_td_error": -3.046653985977173, "model": {}}, "td_error": [0.06090259552001953, 0.17087841033935547, 0.2935829162597656, 0.5409746170043945, -7.291258811950684, -17.99427032470703, -0.27779102325439453, 0.20322704315185547, 0.1871175765991211, -0.11158084869384766, -9.460240364074707, -0.13311481475830078, 0.6146140098571777, -7.672189712524414, -8.549790382385254, 0.27304649353027344, 0.2395334243774414, 0.4912271499633789, -0.257657527923584, -9.440101623535156, 0.42527055740356445, -0.024450302124023438, 0.721796989440918, 0.004570960998535156, 0.5245351791381836, 0.5250663757324219, -19.799297332763672, 0.22349071502685547, -6.782908916473389, -9.648234367370605, 0.3543586730957031, -5.904237270355225], "custom_metrics": {}}}, "num_steps_sampled": 2927, "num_agent_steps_sampled": 5854, "num_steps_trained": 3328, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 6656, "last_target_update_ts": 2867, "num_target_updates": 17}, "done": false, "episodes_total": 160, "training_iteration": 7, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-43", "timestamp": 1648811503, "time_this_iter_s": 1.1238815784454346, "time_total_s": 9.67610239982605, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 9.67610239982605, "timesteps_since_restore": 224, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 15.0, "ram_util_percent": 33.2}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.64, "episode_len_mean": 18.62, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.82, "policy1": -7.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, 10.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 24.0, -20.0, 28.0, 30.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 6.0, -20.0, 10.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, 18.0], "episode_lengths": [13, 20, 20, 20, 8, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 8, 20, 6, 5, 12, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 17, 20, 15, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 11], "policy_policy0_reward": [7.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, 5.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 12.0, -10.0, 14.0, 15.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 3.0, -10.0, 5.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 9.0], "policy_policy1_reward": [7.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, 5.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 12.0, -10.0, 14.0, 15.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 3.0, -10.0, 5.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2760333799885258, "mean_inference_ms": 1.5196320559278758, "mean_action_processing_ms": 0.09815060228491329, "mean_env_wait_ms": 0.0654050937687563, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3235, "timesteps_this_iter": 32, "agent_timesteps_total": 6470, "timers": {"load_time_ms": 0.425, "load_throughput": 75310.138, "learn_time_ms": 7.204, "learn_throughput": 4441.839, "update_time_ms": 5.158}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.258420944213867, "min_q": -16.108203887939453, "max_q": -8.336461067199707, "mean_td_error": -3.1772851943969727, "model": {}}, "td_error": [0.5256271362304688, -4.047540664672852, 0.6815042495727539, -14.430122375488281, 0.6193761825561523, 0.8181619644165039, 0.7610387802124023, 0.880279541015625, 0.645258903503418, 0.3120079040527344, 0.5210809707641602, 0.5974578857421875, 4.2041168212890625, 0.8045673370361328, -23.702030181884766, 0.6948575973510742, 1.537001609802246, 1.6356897354125977, 0.7255420684814453, -10.154312133789062, 0.7618169784545898, 0.0916452407836914, -21.999168395996094, 0.3559303283691406, 1.537001609802246, 0.8786840438842773, -0.004384040832519531, -12.270963668823242, 0.8879613876342773, -21.838220596313477, 1.0617122650146484, -14.764704704284668], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -9.723875045776367, "min_q": -11.864293098449707, "max_q": -4.607507705688477, "mean_td_error": -0.43195995688438416, "model": {}}, "td_error": [-10.455713272094727, 1.3167915344238281, 0.9330692291259766, 0.4864997863769531, 0.900456428527832, -1.5711112022399902, -1.13267183303833, 0.7195844650268555, -0.03183269500732422, 0.2055377960205078, 1.463144302368164, -1.2229108810424805, 1.1211700439453125, -2.394230365753174, 1.563880443572998, 0.6488351821899414, 0.6097531318664551, 0.1716156005859375, -0.2905869483947754, -9.190731048583984, -0.5904655456542969, 0.8299932479858398, -4.009662628173828, 0.8096017837524414, 0.19585895538330078, 0.604914665222168, 0.16891860961914062, 0.6605491638183594, 0.3154792785644531, 1.2194328308105469, 1.0466337203979492, 1.0754766464233398], "custom_metrics": {}}}, "num_steps_sampled": 3235, "num_agent_steps_sampled": 6470, "num_steps_trained": 3840, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 7680, "last_target_update_ts": 3224, "num_target_updates": 20}, "done": false, "episodes_total": 176, "training_iteration": 8, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-44", "timestamp": 1648811504, "time_this_iter_s": 1.0660955905914307, "time_total_s": 10.74219799041748, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 10.74219799041748, "timesteps_since_restore": 256, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 15.6, "ram_util_percent": 33.2}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.94, "episode_len_mean": 18.47, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.47, "policy1": -7.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, 12.0, 10.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 24.0, -20.0, 28.0, 30.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 6.0, -20.0, 10.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, 18.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, 10.0, -20.0, -40.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, 28.0], "episode_lengths": [20, 20, 20, 20, 20, 14, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 8, 20, 6, 5, 12, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 17, 20, 15, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 11, 10, 20, 20, 20, 20, 20, 13, 15, 20, 20, 20, 20, 20, 18, 20, 20, 20, 6], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 6.0, 5.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 12.0, -10.0, 14.0, 15.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 3.0, -10.0, 5.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 9.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, 5.0, -10.0, -20.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, 14.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 6.0, 5.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 12.0, -10.0, 14.0, 15.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 3.0, -10.0, 5.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 9.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, 5.0, -10.0, -20.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27589838265173283, "mean_inference_ms": 1.513189895652011, "mean_action_processing_ms": 0.09807310805295938, "mean_env_wait_ms": 0.06531868461797012, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3557, "timesteps_this_iter": 32, "agent_timesteps_total": 7114, "timers": {"load_time_ms": 0.434, "load_throughput": 73701.46, "learn_time_ms": 7.072, "learn_throughput": 4524.676, "update_time_ms": 4.711}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.756040573120117, "min_q": -16.231632232666016, "max_q": -9.181037902832031, "mean_td_error": -2.1785695552825928, "model": {}}, "td_error": [0.7929582595825195, -2.448300361633301, 0.5559253692626953, -4.344944953918457, 0.39122867584228516, 0.5731487274169922, 0.4096336364746094, -1.1046829223632812, 0.8298912048339844, 0.6437883377075195, -0.3421773910522461, -2.946535110473633, 0.17793750762939453, -13.491007804870605, -0.9290075302124023, 0.20379066467285156, -13.755603790283203, 1.2376794815063477, -1.3682403564453125, -4.438511848449707, 1.1556730270385742, -0.11024284362792969, 0.5523099899291992, -13.740240097045898, 0.9411993026733398, -0.08156871795654297, -6.95149040222168, 1.3236236572265625, -13.491007804870605, 0.2600669860839844, 0.1957988739013672, -0.41531848907470703], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -9.18991756439209, "min_q": -12.077432632446289, "max_q": -5.2664475440979, "mean_td_error": -3.152494430541992, "model": {}}, "td_error": [1.0025272369384766, 0.35169315338134766, 0.9683399200439453, 0.6428613662719727, -19.59062957763672, -10.701743125915527, -5.7958598136901855, 0.9359893798828125, 0.49130821228027344, -4.213761806488037, 0.2696266174316406, -2.986220359802246, -7.085649490356445, 0.5752110481262207, 0.43252992630004883, -9.887899398803711, -0.25576305389404297, -10.563607215881348, -0.012926101684570312, 0.8968915939331055, 0.9552030563354492, 0.20546579360961914, 0.7645416259765625, 1.194528579711914, -5.756672382354736, 0.8677568435668945, -26.335987091064453, -10.379524230957031, 0.1600790023803711, 1.1729402542114258, -0.41305017471313477, 1.2119855880737305], "custom_metrics": {}}}, "num_steps_sampled": 3557, "num_agent_steps_sampled": 7114, "num_steps_trained": 4416, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 8832, "last_target_update_ts": 3551, "num_target_updates": 23}, "done": false, "episodes_total": 194, "training_iteration": 9, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-46", "timestamp": 1648811506, "time_this_iter_s": 1.1325929164886475, "time_total_s": 11.874790906906128, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 11.874790906906128, "timesteps_since_restore": 288, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 15.0, "ram_util_percent": 33.2}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.54, "episode_len_mean": 18.37, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.27, "policy1": -7.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 24.0, -20.0, 28.0, 30.0, 16.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 6.0, -20.0, 10.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, 18.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, 10.0, -20.0, -40.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, 28.0, -20.0, -40.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 8, 20, 6, 5, 12, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 17, 20, 15, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 11, 10, 20, 20, 20, 20, 20, 13, 15, 20, 20, 20, 20, 20, 18, 20, 20, 20, 6, 20, 20, 10, 20, 20, 20, 20, 20, 18, 20, 20, 6, 19, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, 12.0, -10.0, 14.0, 15.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 3.0, -10.0, 5.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 9.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, 5.0, -10.0, -20.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, 12.0, -10.0, 14.0, 15.0, 8.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 3.0, -10.0, 5.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 9.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, 5.0, -10.0, -20.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2759792969384581, "mean_inference_ms": 1.509513845344624, "mean_action_processing_ms": 0.09808668436998971, "mean_env_wait_ms": 0.06528232931075292, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3890, "timesteps_this_iter": 32, "agent_timesteps_total": 7780, "timers": {"load_time_ms": 0.444, "load_throughput": 72074.819, "learn_time_ms": 7.893, "learn_throughput": 4054.169, "update_time_ms": 4.654}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.203283309936523, "min_q": -18.344738006591797, "max_q": -7.904478549957275, "mean_td_error": -3.3775033950805664, "model": {}}, "td_error": [-0.9842529296875, 0.0058879852294921875, -0.1981220245361328, 0.41508007049560547, 0.3936920166015625, -3.8246145248413086, 0.4927997589111328, -16.413511276245117, -0.05745697021484375, 1.3690309524536133, -10.364006042480469, 0.5149726867675781, -0.09714412689208984, -24.576622009277344, 0.6917915344238281, 0.33840084075927734, 1.4419984817504883, -5.763909339904785, -2.8436317443847656, 2.742341995239258, -16.479272842407227, -0.3519401550292969, -3.0481762886047363, -0.5759305953979492, 0.08661842346191406, 0.06532955169677734, -16.700716018676758, 1.1581439971923828, 0.45329856872558594, -16.163942337036133, -0.5847511291503906, 0.7785086631774902], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.484903335571289, "min_q": -13.97096061706543, "max_q": -6.595365047454834, "mean_td_error": -2.9772565364837646, "model": {}}, "td_error": [-1.5755367279052734, 0.4357151985168457, -0.6430816650390625, -4.972586154937744, -1.3048925399780273, 0.7612552642822266, -0.4748349189758301, 0.4840888977050781, -0.5377974510192871, -4.872955799102783, -6.855365753173828, -0.9043483734130859, -11.21212100982666, 1.1120691299438477, -1.8293399810791016, -7.421379089355469, -0.16671466827392578, -4.367951393127441, -0.09385490417480469, -0.13302898406982422, -0.48293113708496094, 0.37566471099853516, -0.6791095733642578, -22.707319259643555, 0.3223743438720703, -0.09385490417480469, 0.6142020225524902, -0.7647266387939453, -0.3709287643432617, -22.12884521484375, -4.1802287101745605, -0.6038436889648438], "custom_metrics": {}}}, "num_steps_sampled": 3890, "num_agent_steps_sampled": 7780, "num_steps_trained": 4992, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 9984, "last_target_update_ts": 3890, "num_target_updates": 26}, "done": false, "episodes_total": 212, "training_iteration": 10, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-47", "timestamp": 1648811507, "time_this_iter_s": 1.2306513786315918, "time_total_s": 13.10544228553772, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 13.10544228553772, "timesteps_since_restore": 320, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 20.95, "ram_util_percent": 33.2}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.68, "episode_len_mean": 18.44, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -7.34, "policy1": -7.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 6.0, -20.0, 10.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, 18.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, 10.0, -20.0, -40.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, 28.0, -20.0, -40.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 12.0, 14.0, -40.0, -20.0, -20.0, -40.0, -40.0, 22.0, 24.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, 20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 17, 20, 15, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 11, 10, 20, 20, 20, 20, 20, 13, 15, 20, 20, 20, 20, 20, 18, 20, 20, 20, 6, 20, 20, 10, 20, 20, 20, 20, 20, 18, 20, 20, 6, 19, 20, 20, 20, 20, 20, 20, 20, 14, 13, 20, 20, 20, 20, 20, 9, 8, 20, 20, 20, 6, 20, 18, 10, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 3.0, -10.0, 5.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 9.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, 5.0, -10.0, -20.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 6.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 11.0, 12.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, 10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 3.0, -10.0, 5.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 9.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, 5.0, -10.0, -20.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 6.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 11.0, 12.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, 10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27673598483255213, "mean_inference_ms": 1.5107987927903355, "mean_action_processing_ms": 0.09849705859575182, "mean_env_wait_ms": 0.06548017617456639, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4228, "timesteps_this_iter": 32, "agent_timesteps_total": 8456, "timers": {"load_time_ms": 0.449, "load_throughput": 71203.039, "learn_time_ms": 7.834, "learn_throughput": 4084.744, "update_time_ms": 4.947}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.113641738891602, "min_q": -17.65914535522461, "max_q": -8.534445762634277, "mean_td_error": -3.7987375259399414, "model": {}}, "td_error": [-13.362943649291992, -3.289889335632324, 0.3116006851196289, 0.6304130554199219, -25.761676788330078, 0.23036861419677734, -0.06643867492675781, -3.408297538757324, -10.604764938354492, -3.455242156982422, -14.681010246276855, 0.8519630432128906, 1.5349140167236328, -15.191579818725586, 1.326873779296875, 0.6334991455078125, 0.9790019989013672, 0.8817005157470703, 0.3104085922241211, 1.673370361328125, 0.21025466918945312, -0.08461189270019531, -14.270012855529785, 0.204132080078125, 0.18001174926757812, 0.8783140182495117, 0.80828857421875, -0.7162799835205078, -0.8040952682495117, 0.2504768371582031, -12.104205131530762, -15.654144287109375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.622922897338867, "min_q": -15.301863670349121, "max_q": -6.154556751251221, "mean_td_error": -1.8292286396026611, "model": {}}, "td_error": [0.6664524078369141, 0.4988279342651367, -13.253634452819824, 0.9155254364013672, 0.16834640502929688, 1.0306987762451172, -0.14087677001953125, -21.657852172851562, 0.2752218246459961, 1.0849628448486328, -3.8917832374572754, -0.4508676528930664, 0.9861955642700195, 2.5765743255615234, 1.19622802734375, -0.8311381340026855, -0.6647429466247559, -19.937049865722656, -0.9991121292114258, 0.11682510375976562, 0.7408437728881836, 0.9130115509033203, 1.178776741027832, -0.40150928497314453, -4.6825151443481445, -7.219588279724121, 0.742243766784668, 1.5357255935668945, 0.4805746078491211, 0.5720977783203125, 0.4734764099121094, -0.5572514533996582], "custom_metrics": {}}}, "num_steps_sampled": 4228, "num_agent_steps_sampled": 8456, "num_steps_trained": 5632, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 11264, "last_target_update_ts": 4228, "num_target_updates": 29}, "done": false, "episodes_total": 232, "training_iteration": 11, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-48", "timestamp": 1648811508, "time_this_iter_s": 1.3706932067871094, "time_total_s": 14.476135492324829, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 14.476135492324829, "timesteps_since_restore": 352, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 19.299999999999997, "ram_util_percent": 33.2}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.12, "episode_len_mean": 18.26, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -7.06, "policy1": -7.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, -20.0, 10.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, 18.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, 10.0, -20.0, -40.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, 28.0, -20.0, -40.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 12.0, 14.0, -40.0, -20.0, -20.0, -40.0, -40.0, 22.0, 24.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, 20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [17, 20, 15, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 11, 10, 20, 20, 20, 20, 20, 13, 15, 20, 20, 20, 20, 20, 18, 20, 20, 20, 6, 20, 20, 10, 20, 20, 20, 20, 20, 18, 20, 20, 6, 19, 20, 20, 20, 20, 20, 20, 20, 14, 13, 20, 20, 20, 20, 20, 9, 8, 20, 20, 20, 6, 20, 18, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 20, 20], "policy_policy0_reward": [3.0, -10.0, 5.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 9.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, 5.0, -10.0, -20.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 6.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 11.0, 12.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, 10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [3.0, -10.0, 5.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 9.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, 5.0, -10.0, -20.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 6.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 11.0, 12.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, 10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27785461637762054, "mean_inference_ms": 1.5169111012043337, "mean_action_processing_ms": 0.09919786726551624, "mean_env_wait_ms": 0.06589213412241253, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4547, "timesteps_this_iter": 32, "agent_timesteps_total": 9094, "timers": {"load_time_ms": 0.446, "load_throughput": 71724.324, "learn_time_ms": 8.128, "learn_throughput": 3937.101, "update_time_ms": 4.983}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -15.579732894897461, "min_q": -18.19029998779297, "max_q": -9.238519668579102, "mean_td_error": -3.8725552558898926, "model": {}}, "td_error": [1.756998062133789, -24.3038387298584, -17.19029998779297, -13.618779182434082, 1.7145004272460938, 1.2569398880004883, -13.626591682434082, -3.335433006286621, 0.3127603530883789, 0.7330684661865234, 0.9358901977539062, 0.015127182006835938, 3.3633594512939453, 0.17406654357910156, 1.208444595336914, -15.829080581665039, 1.8391456604003906, -17.139230728149414, 1.011892318725586, -4.054472923278809, 0.11389923095703125, 1.0855207443237305, 1.344522476196289, 0.6375255584716797, 1.609619140625, 0.8007259368896484, -1.9914464950561523, -14.063216209411621, -16.4664249420166, 1.0900688171386719, -3.894834518432617, 0.5877952575683594], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -12.352544784545898, "min_q": -17.1176815032959, "max_q": -8.597755432128906, "mean_td_error": -3.058994770050049, "model": {}}, "td_error": [-0.6107597351074219, 0.007483482360839844, -1.0972986221313477, -0.18106460571289062, -0.46223926544189453, -19.255403518676758, -2.268979072570801, -0.9392623901367188, -0.27103233337402344, 0.0793609619140625, -14.085575103759766, -0.5714130401611328, -0.6107597351074219, -0.3602714538574219, -0.6307106018066406, 0.0044956207275390625, -24.574094772338867, -5.63950252532959, -0.20652484893798828, -1.3238019943237305, -12.400646209716797, -0.7701883316040039, -3.847609519958496, 0.9041900634765625, -2.5302581787109375, 0.09251785278320312, 0.24841785430908203, -0.0012378692626953125, -0.007860183715820312, -0.3383769989013672, -6.007198333740234, -0.23222732543945312], "custom_metrics": {}}}, "num_steps_sampled": 4547, "num_agent_steps_sampled": 9094, "num_steps_trained": 6176, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 12352, "last_target_update_ts": 4447, "num_target_updates": 31}, "done": false, "episodes_total": 249, "training_iteration": 12, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-50", "timestamp": 1648811510, "time_this_iter_s": 1.2798404693603516, "time_total_s": 15.75597596168518, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 15.75597596168518, "timesteps_since_restore": 384, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 17.65, "ram_util_percent": 33.3}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.74, "episode_len_mean": 17.57, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -5.87, "policy1": -5.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, 18.0, 20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, 10.0, -20.0, -40.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, 28.0, -20.0, -40.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 12.0, 14.0, -40.0, -20.0, -20.0, -40.0, -40.0, 22.0, 24.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, 20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 14.0, 20.0, 4.0, -20.0, -20.0, 24.0, 30.0, -20.0, -40.0, -20.0, 30.0, 8.0, 10.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 11, 10, 20, 20, 20, 20, 20, 13, 15, 20, 20, 20, 20, 20, 18, 20, 20, 20, 6, 20, 20, 10, 20, 20, 20, 20, 20, 18, 20, 20, 6, 19, 20, 20, 20, 20, 20, 20, 20, 14, 13, 20, 20, 20, 20, 20, 9, 8, 20, 20, 20, 6, 20, 18, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 20, 20, 7, 13, 10, 18, 20, 20, 8, 5, 20, 20, 20, 5, 16, 15, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 9.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, 5.0, -10.0, -20.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 6.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 11.0, 12.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, 10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 7.0, 10.0, 2.0, -10.0, -10.0, 12.0, 15.0, -10.0, -20.0, -10.0, 15.0, 4.0, 5.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 9.0, 10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, 5.0, -10.0, -20.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 6.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 11.0, 12.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, 10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 7.0, 10.0, 2.0, -10.0, -10.0, 12.0, 15.0, -10.0, -20.0, -10.0, 15.0, 4.0, 5.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2790875417534383, "mean_inference_ms": 1.5245674359403774, "mean_action_processing_ms": 0.09991500070648719, "mean_env_wait_ms": 0.0663192809903934, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4764, "timesteps_this_iter": 32, "agent_timesteps_total": 9528, "timers": {"load_time_ms": 0.447, "load_throughput": 71548.445, "learn_time_ms": 7.873, "learn_throughput": 4064.777, "update_time_ms": 4.928}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -15.821708679199219, "min_q": -20.528928756713867, "max_q": -10.523603439331055, "mean_td_error": -2.8441100120544434, "model": {}}, "td_error": [0.6038970947265625, -1.5950584411621094, 0.3866443634033203, -4.204746246337891, -29.22015380859375, 0.4328880310058594, 1.071040153503418, -0.3642454147338867, 2.5517568588256836, -18.318811416625977, 0.9660606384277344, -0.4326190948486328, 0.4393177032470703, -0.7650423049926758, 3.0256242752075195, 1.4705047607421875, 1.0185012817382812, -2.892754554748535, -0.8372344970703125, -0.010248184204101562, -0.4904966354370117, 0.5122127532958984, 1.3748798370361328, -9.523603439331055, 1.4705047607421875, 0.9548273086547852, -11.935914039611816, 0.7652063369750977, -10.989266395568848, 0.0062274932861328125, 0.2971820831298828, -16.77860450744629], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -12.637754440307617, "min_q": -17.97673988342285, "max_q": -6.999354362487793, "mean_td_error": -1.428916573524475, "model": {}}, "td_error": [-1.7531147003173828, -0.3753194808959961, -1.0018949508666992, -12.462653160095215, 0.3166522979736328, -2.8741025924682617, 0.08762359619140625, -12.950516700744629, -0.3939018249511719, 0.636164665222168, 2.2241744995117188, 0.6333274841308594, -0.045739173889160156, 0.2436847686767578, -0.7458686828613281, 0.008182525634765625, 0.3533592224121094, -5.999354362487793, 0.5763368606567383, 1.0231761932373047, 0.5415554046630859, -0.16895771026611328, 1.057053565979004, 0.3219156265258789, -0.2155780792236328, -0.5776119232177734, -0.15328598022460938, -15.852727890014648, 0.5995035171508789, -0.15375423431396484, 0.8009700775146484, 0.575373649597168], "custom_metrics": {}}}, "num_steps_sampled": 4764, "num_agent_steps_sampled": 9528, "num_steps_trained": 6656, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 13312, "last_target_update_ts": 4668, "num_target_updates": 33}, "done": false, "episodes_total": 264, "training_iteration": 13, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-51", "timestamp": 1648811511, "time_this_iter_s": 0.9590213298797607, "time_total_s": 16.71499729156494, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 16.71499729156494, "timesteps_since_restore": 416, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 15.7, "ram_util_percent": 33.3}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -10.62, "episode_len_mean": 17.11, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -5.31, "policy1": -5.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -20.0, 28.0, -20.0, -40.0, 20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 4.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 12.0, 14.0, -40.0, -20.0, -20.0, -40.0, -40.0, 22.0, 24.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, 20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 14.0, 20.0, 4.0, -20.0, -20.0, 24.0, 30.0, -20.0, -40.0, -20.0, 30.0, 8.0, 10.0, -20.0, 30.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, 24.0, 28.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, 32.0], "episode_lengths": [20, 20, 20, 20, 20, 18, 20, 20, 20, 6, 20, 20, 10, 20, 20, 20, 20, 20, 18, 20, 20, 6, 19, 20, 20, 20, 20, 20, 20, 20, 14, 13, 20, 20, 20, 20, 20, 9, 8, 20, 20, 20, 6, 20, 18, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 20, 20, 7, 13, 10, 18, 20, 20, 8, 5, 20, 20, 20, 5, 16, 15, 20, 5, 9, 20, 20, 20, 20, 20, 12, 20, 20, 8, 6, 20, 20, 20, 16, 20, 20, 20, 4], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 6.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 11.0, 12.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, 10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 7.0, 10.0, 2.0, -10.0, -10.0, 12.0, 15.0, -10.0, -20.0, -10.0, 15.0, 4.0, 5.0, -10.0, 15.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, 12.0, 14.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, 16.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, 10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 6.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 11.0, 12.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, 10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 7.0, 10.0, 2.0, -10.0, -10.0, 12.0, 15.0, -10.0, -20.0, -10.0, 15.0, 4.0, 5.0, -10.0, 15.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, 12.0, 14.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28084188162258994, "mean_inference_ms": 1.535852635295128, "mean_action_processing_ms": 0.10090005951886173, "mean_env_wait_ms": 0.06694134871839673, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5084, "timesteps_this_iter": 32, "agent_timesteps_total": 10168, "timers": {"load_time_ms": 0.438, "load_throughput": 73107.32, "learn_time_ms": 7.2, "learn_throughput": 4444.31, "update_time_ms": 4.299}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -15.294953346252441, "min_q": -21.93868064880371, "max_q": -10.726109504699707, "mean_td_error": -1.9504936933517456, "model": {}}, "td_error": [0.10305404663085938, 1.182978630065918, -19.73127555847168, 0.45335865020751953, 0.9101495742797852, 0.6493692398071289, 0.24583053588867188, 0.8199357986450195, 0.6517486572265625, -22.320051193237305, -0.3573417663574219, 1.332590103149414, 0.810089111328125, 0.5183725357055664, -13.203197479248047, 2.4726734161376953, 0.2665596008300781, 0.26250267028808594, -1.2585220336914062, 0.047043800354003906, -0.10191154479980469, -1.5731964111328125, 1.048111915588379, 0.7232875823974609, 0.25214195251464844, -0.6124029159545898, -0.4872474670410156, 1.8240623474121094, -17.71565055847168, 1.076258659362793, 1.337615966796875, -2.0427379608154297], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.624580383300781, "min_q": -18.577844619750977, "max_q": -10.776744842529297, "mean_td_error": -2.939948558807373, "model": {}}, "td_error": [-0.19847869873046875, -0.8381204605102539, 0.15990924835205078, -0.4442300796508789, -15.468381881713867, -0.30306053161621094, -0.2589855194091797, 0.016569137573242188, -0.5971164703369141, -0.600804328918457, 0.14235973358154297, 0.5478811264038086, -0.4840850830078125, 0.7843093872070312, -0.35745906829833984, -0.6112203598022461, -15.954113006591797, -4.464173316955566, -0.5170106887817383, -10.707077026367188, -12.174629211425781, -31.05123519897461, 0.008512496948242188, 0.07658195495605469, -1.0561542510986328, -0.8645200729370117, 0.11813735961914062, 0.411956787109375, 0.24573707580566406, 0.7428169250488281, 0.7120800018310547, -1.094346046447754], "custom_metrics": {}}}, "num_steps_sampled": 5084, "num_agent_steps_sampled": 10168, "num_steps_trained": 7296, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 14592, "last_target_update_ts": 4984, "num_target_updates": 36}, "done": false, "episodes_total": 284, "training_iteration": 14, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-52", "timestamp": 1648811512, "time_this_iter_s": 1.2379772663116455, "time_total_s": 17.952974557876587, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f7b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f7b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 17.952974557876587, "timesteps_since_restore": 448, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 18.55, "ram_util_percent": 33.5}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -9.02, "episode_len_mean": 16.71, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -4.51, "policy1": -4.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 28.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 12.0, 14.0, -40.0, -20.0, -20.0, -40.0, -40.0, 22.0, 24.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, 20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 14.0, 20.0, 4.0, -20.0, -20.0, 24.0, 30.0, -20.0, -40.0, -20.0, 30.0, 8.0, 10.0, -20.0, 30.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, 24.0, 28.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, 32.0, -20.0, 30.0, -20.0, -20.0, -40.0, -40.0, 22.0, -40.0, 12.0, 24.0, -20.0, -20.0, -20.0, 24.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 6, 19, 20, 20, 20, 20, 20, 20, 20, 14, 13, 20, 20, 20, 20, 20, 9, 8, 20, 20, 20, 6, 20, 18, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 20, 20, 7, 13, 10, 18, 20, 20, 8, 5, 20, 20, 20, 5, 16, 15, 20, 5, 9, 20, 20, 20, 20, 20, 12, 20, 20, 8, 6, 20, 20, 20, 16, 20, 20, 20, 4, 20, 5, 20, 20, 20, 20, 9, 20, 14, 8, 20, 20, 20, 8, 8, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 14.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 6.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 11.0, 12.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, 10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 7.0, 10.0, 2.0, -10.0, -10.0, 12.0, 15.0, -10.0, -20.0, -10.0, 15.0, 4.0, 5.0, -10.0, 15.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, 12.0, 14.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, 16.0, -10.0, 15.0, -10.0, -10.0, -20.0, -20.0, 11.0, -20.0, 6.0, 12.0, -10.0, -10.0, -10.0, 12.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 14.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 6.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 11.0, 12.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, 10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 7.0, 10.0, 2.0, -10.0, -10.0, 12.0, 15.0, -10.0, -20.0, -10.0, 15.0, 4.0, 5.0, -10.0, 15.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, 12.0, 14.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, 16.0, -10.0, 15.0, -10.0, -10.0, -20.0, -20.0, 11.0, -20.0, 6.0, 12.0, -10.0, -10.0, -10.0, 12.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28257748448954945, "mean_inference_ms": 1.5474811210808708, "mean_action_processing_ms": 0.10187337326591557, "mean_env_wait_ms": 0.06757625490252211, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5416, "timesteps_this_iter": 32, "agent_timesteps_total": 10832, "timers": {"load_time_ms": 0.459, "load_throughput": 69654.745, "learn_time_ms": 7.934, "learn_throughput": 4033.057, "update_time_ms": 4.885}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.738481521606445, "min_q": -19.84507942199707, "max_q": -11.617897033691406, "mean_td_error": -2.213550329208374, "model": {}}, "td_error": [-11.602935791015625, 1.1792011260986328, 0.5048160552978516, 0.13168621063232422, 0.8083839416503906, -14.3551607131958, 1.7175273895263672, -4.690013885498047, 0.6568918228149414, 0.871678352355957, -0.04601097106933594, -14.851531028747559, 1.4804410934448242, 0.9053478240966797, -0.09752464294433594, -1.0610065460205078, 1.3287429809570312, -14.174139022827148, 1.4952526092529297, 2.1900997161865234, 1.2201194763183594, 0.6862354278564453, -0.29225730895996094, -1.7180061340332031, 0.059378623962402344, -21.649648666381836, 2.2023067474365234, 1.8766756057739258, -1.8437070846557617, -4.145490646362305, -0.41426753997802734, 0.7933082580566406], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.125959396362305, "min_q": -19.365406036376953, "max_q": -10.602723121643066, "mean_td_error": -1.8491969108581543, "model": {}}, "td_error": [0.8530864715576172, 1.7541704177856445, 1.1019134521484375, 0.1594257354736328, -16.606956481933594, 1.1944494247436523, 1.1304283142089844, 0.34865856170654297, -17.38752555847168, -0.1599903106689453, -5.540280342102051, -18.162080764770508, 0.7805461883544922, -0.4056262969970703, 0.3538064956665039, -0.11198902130126953, 0.7148380279541016, 0.8549919128417969, 0.7335729598999023, -1.107712745666504, -14.621186256408691, 1.047201156616211, -0.08886337280273438, 1.392582893371582, 0.12827682495117188, -0.20546531677246094, 0.5420103073120117, 1.4164981842041016, 0.15792274475097656, 0.5839223861694336, -0.06300544738769531, 0.03807640075683594], "custom_metrics": {}}}, "num_steps_sampled": 5416, "num_agent_steps_sampled": 10832, "num_steps_trained": 7936, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 15872, "last_target_update_ts": 5336, "num_target_updates": 39}, "done": false, "episodes_total": 304, "training_iteration": 15, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-53", "timestamp": 1648811513, "time_this_iter_s": 1.2877731323242188, "time_total_s": 19.240747690200806, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 19.240747690200806, "timesteps_since_restore": 480, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 22.45, "ram_util_percent": 34.0}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -9.1, "episode_len_mean": 16.75, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -4.55, "policy1": -4.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.0, 24.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, 20.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 14.0, 20.0, 4.0, -20.0, -20.0, 24.0, 30.0, -20.0, -40.0, -20.0, 30.0, 8.0, 10.0, -20.0, 30.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, 24.0, 28.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, 32.0, -20.0, 30.0, -20.0, -20.0, -40.0, -40.0, 22.0, -40.0, 12.0, 24.0, -20.0, -20.0, -20.0, 24.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 32.0, 0.0, -40.0, -40.0, -20.0], "episode_lengths": [9, 8, 20, 20, 20, 6, 20, 18, 10, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 19, 20, 20, 8, 20, 20, 20, 20, 20, 7, 13, 10, 18, 20, 20, 8, 5, 20, 20, 20, 5, 16, 15, 20, 5, 9, 20, 20, 20, 20, 20, 12, 20, 20, 8, 6, 20, 20, 20, 16, 20, 20, 20, 4, 20, 5, 20, 20, 20, 20, 9, 20, 14, 8, 20, 20, 20, 8, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 4, 20, 20, 20, 20], "policy_policy0_reward": [11.0, 12.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, 10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 7.0, 10.0, 2.0, -10.0, -10.0, 12.0, 15.0, -10.0, -20.0, -10.0, 15.0, 4.0, 5.0, -10.0, 15.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, 12.0, 14.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, 16.0, -10.0, 15.0, -10.0, -10.0, -20.0, -20.0, 11.0, -20.0, 6.0, 12.0, -10.0, -10.0, -10.0, 12.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 16.0, 0.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [11.0, 12.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, 10.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 7.0, 10.0, 2.0, -10.0, -10.0, 12.0, 15.0, -10.0, -20.0, -10.0, 15.0, 4.0, 5.0, -10.0, 15.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, 12.0, 14.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, 16.0, -10.0, 15.0, -10.0, -10.0, -20.0, -20.0, 11.0, -20.0, 6.0, 12.0, -10.0, -10.0, -10.0, 12.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 16.0, 0.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2837210056523879, "mean_inference_ms": 1.5555298117835008, "mean_action_processing_ms": 0.10254285413832108, "mean_env_wait_ms": 0.06802150442774746, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5732, "timesteps_this_iter": 32, "agent_timesteps_total": 11464, "timers": {"load_time_ms": 0.454, "load_throughput": 70462.898, "learn_time_ms": 7.344, "learn_throughput": 4357.435, "update_time_ms": 4.53}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -16.82680320739746, "min_q": -21.93215560913086, "max_q": -10.030786514282227, "mean_td_error": -4.2961015701293945, "model": {}}, "td_error": [-2.808797836303711, 0.4657630920410156, -19.979211807250977, -0.42719078063964844, 0.8417816162109375, -8.312045097351074, -27.975433349609375, -1.5690927505493164, 0.6160526275634766, 2.6054859161376953, -19.156505584716797, -14.09277057647705, 2.4155445098876953, -18.3916072845459, -1.2328977584838867, 0.2362842559814453, -0.6323890686035156, -12.431443214416504, -1.0051345825195312, 0.6645145416259766, 1.5561294555664062, -0.6916618347167969, -1.829315185546875, -1.6801605224609375, 0.09070968627929688, -0.6805934906005859, -0.743499755859375, 0.05828285217285156, -1.4581413269042969, 3.009139060974121, -14.260163307189941, -0.6768856048583984], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -16.16550064086914, "min_q": -20.341678619384766, "max_q": -11.448465347290039, "mean_td_error": -3.8977208137512207, "model": {}}, "td_error": [-0.46738433837890625, 0.7161350250244141, 0.7293510437011719, -17.674949645996094, -0.24491214752197266, 0.3612995147705078, -16.64983367919922, 0.0975494384765625, 0.7267313003540039, 0.6912899017333984, 0.09404277801513672, 0.48924827575683594, 0.4037322998046875, -0.4095296859741211, -24.66193389892578, -0.2600412368774414, -1.2013158798217773, -27.63812828063965, -15.994804382324219, 0.09066390991210938, -0.27558326721191406, 0.17093658447265625, -17.54495620727539, -2.3153076171875, -0.4071331024169922, -0.5581550598144531, -3.647113800048828, -0.575892448425293, 0.7411746978759766, 0.10299873352050781, 0.1263742446899414, 0.2583808898925781], "custom_metrics": {}}}, "num_steps_sampled": 5732, "num_agent_steps_sampled": 11464, "num_steps_trained": 8480, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 16960, "last_target_update_ts": 5672, "num_target_updates": 42}, "done": false, "episodes_total": 321, "training_iteration": 16, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-54", "timestamp": 1648811514, "time_this_iter_s": 1.174222469329834, "time_total_s": 20.41497015953064, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 20.41497015953064, "timesteps_since_restore": 512, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 23.45, "ram_util_percent": 34.65}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -10.06, "episode_len_mean": 16.83, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -5.03, "policy1": -5.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 2.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 14.0, 20.0, 4.0, -20.0, -20.0, 24.0, 30.0, -20.0, -40.0, -20.0, 30.0, 8.0, 10.0, -20.0, 30.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, 24.0, 28.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, 32.0, -20.0, 30.0, -20.0, -20.0, -40.0, -40.0, 22.0, -40.0, 12.0, 24.0, -20.0, -20.0, -20.0, 24.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 32.0, 0.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 34.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 19, 20, 20, 8, 20, 20, 20, 20, 20, 7, 13, 10, 18, 20, 20, 8, 5, 20, 20, 20, 5, 16, 15, 20, 5, 9, 20, 20, 20, 20, 20, 12, 20, 20, 8, 6, 20, 20, 20, 16, 20, 20, 20, 4, 20, 5, 20, 20, 20, 20, 9, 20, 14, 8, 20, 20, 20, 8, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 6, 20, 20, 20, 20, 20, 8, 3, 20, 20, 20], "policy_policy0_reward": [-10.0, 1.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 7.0, 10.0, 2.0, -10.0, -10.0, 12.0, 15.0, -10.0, -20.0, -10.0, 15.0, 4.0, 5.0, -10.0, 15.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, 12.0, 14.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, 16.0, -10.0, 15.0, -10.0, -10.0, -20.0, -20.0, 11.0, -20.0, 6.0, 12.0, -10.0, -10.0, -10.0, 12.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 16.0, 0.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 17.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 1.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 7.0, 10.0, 2.0, -10.0, -10.0, 12.0, 15.0, -10.0, -20.0, -10.0, 15.0, 4.0, 5.0, -10.0, 15.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, 12.0, 14.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, 16.0, -10.0, 15.0, -10.0, -10.0, -20.0, -20.0, 11.0, -20.0, 6.0, 12.0, -10.0, -10.0, -10.0, 12.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 16.0, 0.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 17.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2845510368430952, "mean_inference_ms": 1.561074509817858, "mean_action_processing_ms": 0.10300355704204862, "mean_env_wait_ms": 0.06833561738525264, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6043, "timesteps_this_iter": 32, "agent_timesteps_total": 12086, "timers": {"load_time_ms": 0.437, "load_throughput": 73191.039, "learn_time_ms": 7.443, "learn_throughput": 4299.177, "update_time_ms": 4.938}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.08956527709961, "min_q": -22.11027717590332, "max_q": -4.315462589263916, "mean_td_error": -5.111753463745117, "model": {}}, "td_error": [0.7647876739501953, 0.02502727508544922, -6.935833930969238, -20.260883331298828, -1.9198369979858398, -2.0248756408691406, 1.1501636505126953, -22.07681655883789, -1.630000114440918, -3.0747427940368652, -8.371904373168945, 0.45088958740234375, -13.315462112426758, 1.3107051849365234, 0.14773941040039062, 0.40488719940185547, -1.1982784271240234, -21.11027717590332, -0.36011219024658203, -8.222293853759766, 1.0026044845581055, -1.9072179794311523, -4.816025257110596, -20.981849670410156, -0.7339878082275391, -11.779287338256836, -1.3956184387207031, -0.19579124450683594, -0.6101150512695312, -10.635558128356934, -7.896871566772461, 2.620708465576172], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -15.557159423828125, "min_q": -19.69165802001953, "max_q": -3.026287078857422, "mean_td_error": -1.7948732376098633, "model": {}}, "td_error": [0.5849475860595703, 5.03784704208374, 2.491901397705078, 0.2449626922607422, 0.0423126220703125, 0.5732278823852539, -7.456901550292969, 0.7708892822265625, -24.685340881347656, -3.649524688720703, -0.5327987670898438, 0.7619113922119141, 0.5474004745483398, -9.375518798828125, 1.0941638946533203, -0.16611766815185547, -0.0606689453125, -12.026287078857422, 0.9213333129882812, 0.42029762268066406, 0.9832077026367188, 0.22979164123535156, 0.10253334045410156, -0.0035228729248046875, 1.0676441192626953, -4.466358184814453, -0.5528011322021484, 0.3043346405029297, -3.36501407623291, -8.10888957977295, 0.30862998962402344, 0.5264644622802734], "custom_metrics": {}}}, "num_steps_sampled": 6043, "num_agent_steps_sampled": 12086, "num_steps_trained": 9024, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 18048, "last_target_update_ts": 6023, "num_target_updates": 45}, "done": false, "episodes_total": 339, "training_iteration": 17, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-56", "timestamp": 1648811516, "time_this_iter_s": 1.1486952304840088, "time_total_s": 21.56366539001465, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f78c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f78c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 21.56366539001465, "timesteps_since_restore": 544, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 25.7, "ram_util_percent": 35.2}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -8.94, "episode_len_mean": 16.47, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -4.47, "policy1": -4.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 8.0, 10.0, -20.0, 30.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, 16.0, -40.0, -20.0, 24.0, 28.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -20.0, 32.0, -20.0, 30.0, -20.0, -20.0, -40.0, -40.0, 22.0, -40.0, 12.0, 24.0, -20.0, -20.0, -20.0, 24.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 32.0, 0.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 34.0, -20.0, -20.0, -20.0, 16.0, 24.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, 20.0, -40.0, 24.0, 12.0, 32.0, -20.0, -20.0, -20.0, 28.0, -20.0], "episode_lengths": [5, 16, 15, 20, 5, 9, 20, 20, 20, 20, 20, 12, 20, 20, 8, 6, 20, 20, 20, 16, 20, 20, 20, 4, 20, 5, 20, 20, 20, 20, 9, 20, 14, 8, 20, 20, 20, 8, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 6, 20, 20, 20, 20, 20, 8, 3, 20, 20, 20, 12, 8, 20, 20, 5, 20, 20, 20, 5, 20, 20, 10, 20, 8, 14, 4, 20, 20, 20, 6, 20], "policy_policy0_reward": [15.0, 4.0, 5.0, -10.0, 15.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, 12.0, 14.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, 16.0, -10.0, 15.0, -10.0, -10.0, -20.0, -20.0, 11.0, -20.0, 6.0, 12.0, -10.0, -10.0, -10.0, 12.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 16.0, 0.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 17.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, 10.0, -20.0, 12.0, 6.0, 16.0, -10.0, -10.0, -10.0, 14.0, -10.0], "policy_policy1_reward": [15.0, 4.0, 5.0, -10.0, 15.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, 8.0, -20.0, -10.0, 12.0, 14.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -10.0, 16.0, -10.0, 15.0, -10.0, -10.0, -20.0, -20.0, 11.0, -20.0, 6.0, 12.0, -10.0, -10.0, -10.0, 12.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 16.0, 0.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 17.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, 10.0, -20.0, 12.0, 6.0, 16.0, -10.0, -10.0, -10.0, 14.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28520202900747, "mean_inference_ms": 1.5640911175315977, "mean_action_processing_ms": 0.10326073018879142, "mean_env_wait_ms": 0.06851967153420721, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6355, "timesteps_this_iter": 32, "agent_timesteps_total": 12710, "timers": {"load_time_ms": 0.439, "load_throughput": 72829.632, "learn_time_ms": 7.524, "learn_throughput": 4253.144, "update_time_ms": 4.836}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.901752471923828, "min_q": -22.24839973449707, "max_q": -8.933305740356445, "mean_td_error": -2.395942449569702, "model": {}}, "td_error": [1.4987163543701172, 0.10537242889404297, -12.515804290771484, 0.008100509643554688, 0.27555084228515625, -19.291126251220703, -2.7760419845581055, 1.3861818313598633, 0.5188627243041992, 1.1627740859985352, -0.10175228118896484, -8.938273429870605, -0.5335359573364258, 1.4336442947387695, 1.4382562637329102, 1.3861818313598633, 2.4156646728515625, 1.091048240661621, -0.21313953399658203, -0.7280292510986328, 2.7440290451049805, 2.1897449493408203, 2.39398193359375, 0.8033933639526367, 1.3594112396240234, -0.7600269317626953, -20.90175437927246, 1.1900053024291992, -1.0770177841186523, -6.640647888183594, 1.8380260467529297, -27.43195343017578], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -16.048992156982422, "min_q": -19.645965576171875, "max_q": -2.6367974281311035, "mean_td_error": -1.985309362411499, "model": {}}, "td_error": [1.8267974853515625, 1.195383071899414, 0.8254327774047852, -1.4212161302566528, 0.6806163787841797, 0.20862388610839844, -11.64886474609375, 0.5781497955322266, 0.6424322128295898, 0.22205543518066406, 1.0372390747070312, -18.534955978393555, 1.0575695037841797, -25.97214126586914, 0.5312862396240234, -3.173158645629883, 0.4324016571044922, 2.141451835632324, -5.294308662414551, 0.5980682373046875, 0.07435417175292969, 1.0877094268798828, 1.344400405883789, 0.7637405395507812, 1.0411796569824219, 0.4919748306274414, 0.6760663986206055, 1.1259479522705078, -17.78331756591797, 0.9091176986694336, 0.3897247314453125, 0.4163379669189453], "custom_metrics": {}}}, "num_steps_sampled": 6355, "num_agent_steps_sampled": 12710, "num_steps_trained": 9696, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 19392, "last_target_update_ts": 6355, "num_target_updates": 48}, "done": false, "episodes_total": 360, "training_iteration": 18, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-57", "timestamp": 1648811517, "time_this_iter_s": 1.2908141613006592, "time_total_s": 22.854479551315308, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f7b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f7b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 22.854479551315308, "timesteps_since_restore": 576, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 23.35, "ram_util_percent": 35.5}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -9.2, "episode_len_mean": 16.7, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -4.6, "policy1": -4.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, -20.0, -20.0, -20.0, 32.0, -20.0, 30.0, -20.0, -20.0, -40.0, -40.0, 22.0, -40.0, 12.0, 24.0, -20.0, -20.0, -20.0, 24.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 32.0, 0.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 34.0, -20.0, -20.0, -20.0, 16.0, 24.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, 20.0, -40.0, 24.0, 12.0, 32.0, -20.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 0.0, 16.0, 16.0, 20.0, -20.0, -20.0, -20.0, 24.0, 16.0, -20.0, 24.0, 6.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [16, 20, 20, 20, 4, 20, 5, 20, 20, 20, 20, 9, 20, 14, 8, 20, 20, 20, 8, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 6, 20, 20, 20, 20, 20, 8, 3, 20, 20, 20, 12, 8, 20, 20, 5, 20, 20, 20, 5, 20, 20, 10, 20, 8, 14, 4, 20, 20, 20, 6, 20, 20, 20, 20, 20, 12, 12, 10, 20, 20, 20, 8, 12, 20, 8, 17, 20, 20, 20, 20], "policy_policy0_reward": [4.0, -10.0, -10.0, -10.0, 16.0, -10.0, 15.0, -10.0, -10.0, -20.0, -20.0, 11.0, -20.0, 6.0, 12.0, -10.0, -10.0, -10.0, 12.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 16.0, 0.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 17.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, 10.0, -20.0, 12.0, 6.0, 16.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 0.0, 8.0, 8.0, 10.0, -10.0, -10.0, -10.0, 12.0, 8.0, -10.0, 12.0, 3.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [4.0, -10.0, -10.0, -10.0, 16.0, -10.0, 15.0, -10.0, -10.0, -20.0, -20.0, 11.0, -20.0, 6.0, 12.0, -10.0, -10.0, -10.0, 12.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 16.0, 0.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 17.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, 10.0, -20.0, 12.0, 6.0, 16.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 0.0, 8.0, 8.0, 10.0, -10.0, -10.0, -10.0, 12.0, 8.0, -10.0, 12.0, 3.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2855084063541961, "mean_inference_ms": 1.565002213807516, "mean_action_processing_ms": 0.10334126539866562, "mean_env_wait_ms": 0.06859698573689671, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6674, "timesteps_this_iter": 32, "agent_timesteps_total": 13348, "timers": {"load_time_ms": 0.434, "load_throughput": 73648.885, "learn_time_ms": 7.279, "learn_throughput": 4396.012, "update_time_ms": 4.473}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -12.483491897583008, "min_q": -22.778261184692383, "max_q": 0.29796141386032104, "mean_td_error": -2.4040839672088623, "model": {}}, "td_error": [0.24455738067626953, -19.7293701171875, -9.89565658569336, 1.8971481323242188, -0.5407600402832031, 1.5185909271240234, 0.6376686096191406, 3.798953056335449, 2.3926000595092773, 1.6291923522949219, -0.05737113952636719, 1.8480224609375, 1.307380199432373, 1.3349781036376953, -0.027405738830566406, 0.5888824462890625, -4.245168209075928, 1.384317398071289, 1.3532686233520508, 1.8447551727294922, 0.6199626922607422, 0.1744375228881836, 1.0442085266113281, 1.7619800567626953, -1.3323020935058594, -15.76092529296875, -17.77984619140625, -7.448366165161133, -10.17646312713623, 0.42327022552490234, 2.210218906402588, -17.951446533203125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -15.667011260986328, "min_q": -20.95514488220215, "max_q": -4.180356502532959, "mean_td_error": -5.445440769195557, "model": {}}, "td_error": [-11.870601654052734, -1.3660736083984375, 0.10739517211914062, -15.691673278808594, -4.788819313049316, -0.972447395324707, -4.067943572998047, -1.2071876525878906, 0.3079710006713867, -0.023410797119140625, -17.74470329284668, -25.6630802154541, -1.6469173431396484, -0.44849395751953125, -0.6740264892578125, 0.4939718246459961, -14.338233947753906, -17.892892837524414, -4.211820602416992, -25.387929916381836, -0.41771888732910156, -0.6640796661376953, -2.09792423248291, -0.6921367645263672, 0.65386962890625, -5.370227813720703, -0.41521453857421875, 1.1280860900878906, -1.235574722290039, -18.91249656677246, 0.9570989608764648, -0.1008758544921875], "custom_metrics": {}}}, "num_steps_sampled": 6674, "num_agent_steps_sampled": 13348, "num_steps_trained": 10304, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 20608, "last_target_update_ts": 6674, "num_target_updates": 51}, "done": false, "episodes_total": 379, "training_iteration": 19, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-11-58", "timestamp": 1648811518, "time_this_iter_s": 1.1804051399230957, "time_total_s": 24.034884691238403, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 24.034884691238403, "timesteps_since_restore": 608, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 16.1, "ram_util_percent": 35.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -9.28, "episode_len_mean": 16.94, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -4.64, "policy1": -4.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 32.0, 0.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 34.0, -20.0, -20.0, -20.0, 16.0, 24.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, 20.0, -40.0, 24.0, 12.0, 32.0, -20.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 0.0, 16.0, 16.0, 20.0, -20.0, -20.0, -20.0, 24.0, 16.0, -20.0, 24.0, 6.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, 4.0, -20.0, -20.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 12.0, 16.0, -20.0, -20.0], "episode_lengths": [8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 6, 20, 20, 20, 20, 20, 8, 3, 20, 20, 20, 12, 8, 20, 20, 5, 20, 20, 20, 5, 20, 20, 10, 20, 8, 14, 4, 20, 20, 20, 6, 20, 20, 20, 20, 20, 12, 12, 10, 20, 20, 20, 8, 12, 20, 8, 17, 20, 20, 20, 20, 20, 10, 20, 20, 18, 20, 20, 6, 20, 20, 8, 20, 20, 20, 20, 14, 12, 20, 20], "policy_policy0_reward": [12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 16.0, 0.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 17.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, 10.0, -20.0, 12.0, 6.0, 16.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 0.0, 8.0, 8.0, 10.0, -10.0, -10.0, -10.0, 12.0, 8.0, -10.0, 12.0, 3.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, 2.0, -10.0, -10.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 6.0, 8.0, -10.0, -10.0], "policy_policy1_reward": [12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 16.0, 0.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 17.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, 10.0, -20.0, 12.0, 6.0, 16.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 0.0, 8.0, 8.0, 10.0, -10.0, -10.0, -10.0, 12.0, 8.0, -10.0, 12.0, 3.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, 2.0, -10.0, -10.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 6.0, 8.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2856073346286864, "mean_inference_ms": 1.5647913831480098, "mean_action_processing_ms": 0.10330231740139423, "mean_env_wait_ms": 0.06859122997578553, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7002, "timesteps_this_iter": 32, "agent_timesteps_total": 14004, "timers": {"load_time_ms": 0.442, "load_throughput": 72374.078, "learn_time_ms": 7.322, "learn_throughput": 4370.674, "update_time_ms": 4.615}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.484315872192383, "min_q": -21.814868927001953, "max_q": 5.031968116760254, "mean_td_error": -0.9186485409736633, "model": {}}, "td_error": [-14.9752836227417, -2.2466869354248047, 2.3300304412841797, -8.78941535949707, 2.412179946899414, -1.2233190536499023, -0.7419300079345703, 1.7512664794921875, 0.07807254791259766, 2.923196792602539, -6.019831657409668, 2.4331722259521484, 1.607461929321289, -2.1782546043395996, 2.1281747817993164, 4.825434684753418, 1.3660869598388672, -7.821126937866211, -1.5200109481811523, 2.247952461242676, -1.0144233703613281, 1.3988447189331055, 0.4415435791015625, 1.6740360260009766, -8.949118614196777, 8.32409954071045, -8.75405216217041, 4.703823566436768, 0.29230499267578125, -0.6116142272949219, 1.6827888488769531, -7.172155380249023], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -15.57731819152832, "min_q": -22.351451873779297, "max_q": -3.468280076980591, "mean_td_error": -4.703962326049805, "model": {}}, "td_error": [0.6506729125976562, -19.073558807373047, -20.76076889038086, -15.617950439453125, -0.7582225799560547, 0.005370140075683594, -9.447437286376953, 0.5761232376098633, -12.831185340881348, 0.5095930099487305, -0.1002960205078125, 0.1800098419189453, 0.9013748168945312, -3.9100704193115234, -5.523907661437988, -10.50121021270752, -4.078246593475342, 0.28558921813964844, 0.9924688339233398, 0.1617259979248047, -3.3578319549560547, -10.782797813415527, -26.740760803222656, 1.351912498474121, -2.5734100341796875, -7.736167907714844, -0.6328315734863281, 0.27141380310058594, -0.08599090576171875, -1.167128562927246, -0.09090995788574219, -0.6423587799072266], "custom_metrics": {}}}, "num_steps_sampled": 7002, "num_agent_steps_sampled": 14004, "num_steps_trained": 10912, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 21824, "last_target_update_ts": 7002, "num_target_updates": 54}, "done": false, "episodes_total": 398, "training_iteration": 20, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-00", "timestamp": 1648811520, "time_this_iter_s": 1.193052053451538, "time_total_s": 25.22793674468994, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 25.22793674468994, "timesteps_since_restore": 640, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 14.35, "ram_util_percent": 35.650000000000006}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -6.96, "episode_len_mean": 16.38, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -3.48, "policy1": -3.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -40.0, 24.0, 34.0, -20.0, -20.0, -20.0, 16.0, 24.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, 20.0, -40.0, 24.0, 12.0, 32.0, -20.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 0.0, 16.0, 16.0, 20.0, -20.0, -20.0, -20.0, 24.0, 16.0, -20.0, 24.0, 6.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, 4.0, -20.0, -20.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 12.0, 16.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 16.0, 18.0, 24.0, 24.0, -40.0, 16.0, -20.0, 8.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 14, 20, 6, 20, 20, 20, 20, 20, 8, 3, 20, 20, 20, 12, 8, 20, 20, 5, 20, 20, 20, 5, 20, 20, 10, 20, 8, 14, 4, 20, 20, 20, 6, 20, 20, 20, 20, 20, 12, 12, 10, 20, 20, 20, 8, 12, 20, 8, 17, 20, 20, 20, 20, 20, 10, 20, 20, 18, 20, 20, 6, 20, 20, 8, 20, 20, 20, 20, 14, 12, 20, 20, 4, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 6, 12, 11, 8, 8, 20, 12, 20, 16, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 17.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, 10.0, -20.0, 12.0, 6.0, 16.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 0.0, 8.0, 8.0, 10.0, -10.0, -10.0, -10.0, 12.0, 8.0, -10.0, 12.0, 3.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, 2.0, -10.0, -10.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 6.0, 8.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 8.0, 9.0, 12.0, 12.0, -20.0, 8.0, -10.0, 4.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -20.0, 12.0, 17.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, 10.0, -20.0, 12.0, 6.0, 16.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 0.0, 8.0, 8.0, 10.0, -10.0, -10.0, -10.0, 12.0, 8.0, -10.0, 12.0, 3.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, 2.0, -10.0, -10.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 6.0, 8.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 8.0, 9.0, 12.0, 12.0, -20.0, 8.0, -10.0, 4.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28563875287332596, "mean_inference_ms": 1.5636684925580184, "mean_action_processing_ms": 0.10318603580455693, "mean_env_wait_ms": 0.06853819813132372, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7330, "timesteps_this_iter": 32, "agent_timesteps_total": 14660, "timers": {"load_time_ms": 0.453, "load_throughput": 70622.325, "learn_time_ms": 7.359, "learn_throughput": 4348.274, "update_time_ms": 4.699}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.402111053466797, "min_q": -22.40247917175293, "max_q": 2.137556552886963, "mean_td_error": -1.7693870067596436, "model": {}}, "td_error": [-2.673212766647339, 0.41554737091064453, 2.623528480529785, -5.388635158538818, 2.908928871154785, -0.41111183166503906, -4.445073127746582, -5.915606498718262, -5.148153781890869, 0.0005927085876464844, -8.487719535827637, 1.8758862018585205, 1.6303787231445312, 1.877436637878418, 0.1885528564453125, -4.243290424346924, -20.171245574951172, 2.1154732704162598, 0.3068885803222656, 1.6370487213134766, 1.3060812950134277, -16.135448455810547, 1.3868494033813477, 0.3700675964355469, -0.3660011291503906, -1.604574203491211, -3.420830488204956, -3.870187759399414, -0.27007102966308594, 1.0918288230895996, 0.7353572845458984, 5.460329532623291], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.32360553741455, "min_q": -21.350454330444336, "max_q": 1.0389336347579956, "mean_td_error": -3.547959566116333, "model": {}}, "td_error": [0.25965118408203125, 0.8650016784667969, -2.7495975494384766, -25.64365577697754, -0.6900520324707031, -2.3714780807495117, -0.1333146095275879, -2.0767316818237305, 2.038933753967285, -0.8813915252685547, -0.45085716247558594, -9.65534782409668, 0.09178924560546875, 0.29342079162597656, 1.8294763565063477, -0.043094635009765625, 0.11562538146972656, 0.22064971923828125, 1.0292186737060547, 3.6367130279541016, -0.23015785217285156, -8.991780281066895, 4.645618438720703, -15.672521591186523, 0.8859987258911133, -28.4279842376709, -17.318212509155273, -3.217589855194092, -12.167787551879883, 0.9401836395263672, 0.24144268035888672, 0.09312629699707031], "custom_metrics": {}}}, "num_steps_sampled": 7330, "num_agent_steps_sampled": 14660, "num_steps_trained": 11584, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 23168, "last_target_update_ts": 7330, "num_target_updates": 57}, "done": false, "episodes_total": 419, "training_iteration": 21, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-01", "timestamp": 1648811521, "time_this_iter_s": 1.272139549255371, "time_total_s": 26.500076293945312, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 26.500076293945312, "timesteps_since_restore": 672, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 15.850000000000001, "ram_util_percent": 35.7}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -4.86, "episode_len_mean": 16.13, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -2.43, "policy1": -2.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, 20.0, -40.0, 24.0, 12.0, 32.0, -20.0, -20.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, 0.0, 16.0, 16.0, 20.0, -20.0, -20.0, -20.0, 24.0, 16.0, -20.0, 24.0, 6.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, 4.0, -20.0, -20.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 12.0, 16.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 16.0, 18.0, 24.0, 24.0, -40.0, 16.0, -20.0, 8.0, -20.0, 14.0, 2.0, -20.0, -20.0, -20.0, 26.0, -20.0, 20.0, -20.0, 22.0, -20.0, -20.0, -20.0, 16.0, 22.0, 24.0, 18.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [8, 20, 20, 5, 20, 20, 20, 5, 20, 20, 10, 20, 8, 14, 4, 20, 20, 20, 6, 20, 20, 20, 20, 20, 12, 12, 10, 20, 20, 20, 8, 12, 20, 8, 17, 20, 20, 20, 20, 20, 10, 20, 20, 18, 20, 20, 6, 20, 20, 8, 20, 20, 20, 20, 14, 12, 20, 20, 4, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 6, 12, 11, 8, 8, 20, 12, 20, 16, 20, 13, 19, 20, 20, 20, 7, 20, 10, 20, 9, 20, 20, 20, 12, 9, 8, 11, 20, 20, 20, 20], "policy_policy0_reward": [12.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, 10.0, -20.0, 12.0, 6.0, 16.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 0.0, 8.0, 8.0, 10.0, -10.0, -10.0, -10.0, 12.0, 8.0, -10.0, 12.0, 3.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, 2.0, -10.0, -10.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 6.0, 8.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 8.0, 9.0, 12.0, 12.0, -20.0, 8.0, -10.0, 4.0, -10.0, 7.0, 1.0, -10.0, -10.0, -10.0, 13.0, -10.0, 10.0, -10.0, 11.0, -10.0, -10.0, -10.0, 8.0, 11.0, 12.0, 9.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [12.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, 10.0, -20.0, 12.0, 6.0, 16.0, -10.0, -10.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, 0.0, 8.0, 8.0, 10.0, -10.0, -10.0, -10.0, 12.0, 8.0, -10.0, 12.0, 3.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, 2.0, -10.0, -10.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 6.0, 8.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 8.0, 9.0, 12.0, 12.0, -20.0, 8.0, -10.0, 4.0, -10.0, 7.0, 1.0, -10.0, -10.0, -10.0, 13.0, -10.0, 10.0, -10.0, 11.0, -10.0, -10.0, -10.0, 8.0, 11.0, 12.0, 9.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2856241057103802, "mean_inference_ms": 1.5621059326427555, "mean_action_processing_ms": 0.10304279406510189, "mean_env_wait_ms": 0.06845914626575601, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7668, "timesteps_this_iter": 32, "agent_timesteps_total": 15336, "timers": {"load_time_ms": 0.427, "load_throughput": 74927.554, "learn_time_ms": 7.489, "learn_throughput": 4273.157, "update_time_ms": 5.843}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -6.215031623840332, "min_q": -21.754199981689453, "max_q": 0.5647350549697876, "mean_td_error": -0.4146822690963745, "model": {}}, "td_error": [0.22526466846466064, -6.338872909545898, 10.428720474243164, 0.8273727893829346, 13.291845321655273, -1.4704431295394897, 1.2047216892242432, -19.49367332458496, -1.0699405670166016, 0.8048171997070312, 1.0711578130722046, 0.7720623016357422, -1.470555305480957, 6.285120010375977, 0.5018963813781738, -20.655868530273438, 1.6565284729003906, 2.0338993072509766, 1.5744609832763672, 0.24939024448394775, -9.835424423217773, -0.4521232843399048, 5.409526824951172, 2.5609912872314453, 0.9006800651550293, -0.13261687755584717, -0.39936137199401855, -2.3835625648498535, 6.010069847106934, -2.6906611919403076, 2.4062366485595703, -5.091489315032959], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.261184692382812, "min_q": -20.082063674926758, "max_q": 1.532291054725647, "mean_td_error": -2.0693376064300537, "model": {}}, "td_error": [1.4563465118408203, 0.49862098693847656, 2.892880439758301, 0.9904870986938477, 4.163608551025391, 0.9079341888427734, 4.474687576293945, 0.20007705688476562, 1.4188709259033203, 4.442647933959961, -0.753875732421875, 0.5487518310546875, 0.014169692993164062, -13.282951354980469, 0.17954444885253906, -11.644387245178223, 1.379075050354004, 0.7376022338867188, -1.0595788955688477, 0.8923530578613281, -0.2057781219482422, 0.7401494979858398, -11.28706169128418, -1.221832275390625, 2.728181838989258, 0.4258708953857422, -2.5558204650878906, -20.045448303222656, -14.09378433227539, -20.619915008544922, 0.6962223052978516, 0.7635555267333984], "custom_metrics": {}}}, "num_steps_sampled": 7668, "num_agent_steps_sampled": 15336, "num_steps_trained": 12256, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 24512, "last_target_update_ts": 7668, "num_target_updates": 60}, "done": false, "episodes_total": 440, "training_iteration": 22, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-02", "timestamp": 1648811522, "time_this_iter_s": 1.3175158500671387, "time_total_s": 27.81759214401245, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c44d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c44d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 27.81759214401245, "timesteps_since_restore": 704, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 15.75, "ram_util_percent": 35.7}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -2.22, "episode_len_mean": 15.51, "episode_media": {}, "episodes_this_iter": 25, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -1.11, "policy1": -1.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 20.0, -20.0, -20.0, -20.0, 24.0, 16.0, -20.0, 24.0, 6.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, 4.0, -20.0, -20.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 12.0, 16.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 16.0, 18.0, 24.0, 24.0, -40.0, 16.0, -20.0, 8.0, -20.0, 14.0, 2.0, -20.0, -20.0, -20.0, 26.0, -20.0, 20.0, -20.0, 22.0, -20.0, -20.0, -20.0, 16.0, 22.0, 24.0, 18.0, -20.0, -20.0, -20.0, -20.0, 30.0, 16.0, 28.0, 22.0, -20.0, -20.0, 24.0, 24.0, 28.0, 24.0, 4.0, 28.0, -20.0, -20.0, -20.0, 28.0, 28.0, -20.0, -20.0, 20.0, 8.0, 28.0, -20.0, -20.0, -20.0], "episode_lengths": [12, 10, 20, 20, 20, 8, 12, 20, 8, 17, 20, 20, 20, 20, 20, 10, 20, 20, 18, 20, 20, 6, 20, 20, 8, 20, 20, 20, 20, 14, 12, 20, 20, 4, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 6, 12, 11, 8, 8, 20, 12, 20, 16, 20, 13, 19, 20, 20, 20, 7, 20, 10, 20, 9, 20, 20, 20, 12, 9, 8, 11, 20, 20, 20, 20, 5, 12, 6, 9, 20, 20, 8, 8, 6, 8, 18, 6, 20, 20, 20, 6, 6, 20, 20, 10, 16, 6, 20, 20, 20], "policy_policy0_reward": [8.0, 10.0, -10.0, -10.0, -10.0, 12.0, 8.0, -10.0, 12.0, 3.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, 2.0, -10.0, -10.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 6.0, 8.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 8.0, 9.0, 12.0, 12.0, -20.0, 8.0, -10.0, 4.0, -10.0, 7.0, 1.0, -10.0, -10.0, -10.0, 13.0, -10.0, 10.0, -10.0, 11.0, -10.0, -10.0, -10.0, 8.0, 11.0, 12.0, 9.0, -10.0, -10.0, -10.0, -10.0, 15.0, 8.0, 14.0, 11.0, -10.0, -10.0, 12.0, 12.0, 14.0, 12.0, 2.0, 14.0, -10.0, -10.0, -10.0, 14.0, 14.0, -10.0, -10.0, 10.0, 4.0, 14.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [8.0, 10.0, -10.0, -10.0, -10.0, 12.0, 8.0, -10.0, 12.0, 3.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, 2.0, -10.0, -10.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 6.0, 8.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 8.0, 9.0, 12.0, 12.0, -20.0, 8.0, -10.0, 4.0, -10.0, 7.0, 1.0, -10.0, -10.0, -10.0, 13.0, -10.0, 10.0, -10.0, 11.0, -10.0, -10.0, -10.0, 8.0, 11.0, 12.0, 9.0, -10.0, -10.0, -10.0, -10.0, 15.0, 8.0, 14.0, 11.0, -10.0, -10.0, 12.0, 12.0, 14.0, 12.0, 2.0, 14.0, -10.0, -10.0, -10.0, 14.0, 14.0, -10.0, -10.0, 10.0, 4.0, 14.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28546769621271256, "mean_inference_ms": 1.5591611894622348, "mean_action_processing_ms": 0.10278988751641766, "mean_env_wait_ms": 0.06829320047314762, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7998, "timesteps_this_iter": 32, "agent_timesteps_total": 15996, "timers": {"load_time_ms": 0.41, "load_throughput": 78133.501, "learn_time_ms": 7.32, "learn_throughput": 4371.785, "update_time_ms": 4.519}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.010035991668701, "min_q": -19.242565155029297, "max_q": -0.3524644374847412, "mean_td_error": -1.4484381675720215, "model": {}}, "td_error": [1.87241530418396, -3.3508100509643555, 1.5686581134796143, 0.20213532447814941, 1.7041771411895752, -10.573277473449707, -5.819218158721924, 0.9986907243728638, 0.21305131912231445, -10.84281063079834, -0.5161924362182617, 0.07657670974731445, 3.3764896392822266, 2.4266433715820312, 1.2823152542114258, -13.129678726196289, 0.978935956954956, -7.239006042480469, 1.2129530906677246, 0.412813663482666, 1.5300666093826294, 0.08341336250305176, -7.373770713806152, -1.394348382949829, 0.8437453508377075, -0.5283355712890625, 2.3236641883850098, 3.4542274475097656, 1.4215081930160522, -0.6993343830108643, -12.061477661132812, 1.1957626342773438], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.257888793945312, "min_q": -19.147258758544922, "max_q": 0.19273912906646729, "mean_td_error": -4.845170497894287, "model": {}}, "td_error": [-14.307129859924316, -2.231076240539551, 0.7652020454406738, -1.2137928009033203, -10.88802719116211, -18.92768096923828, -0.8235483169555664, -1.7499408721923828, -0.8718396425247192, -26.635738372802734, 1.7479028701782227, -1.3883399963378906, 2.012267589569092, 0.8612871170043945, 2.884829044342041, 1.9219799041748047, -13.228803634643555, -26.83244514465332, 0.15119552612304688, -12.391200065612793, -13.89712905883789, 1.0999364852905273, 1.4866113662719727, -0.7783641815185547, -0.05758476257324219, -13.228803634643555, -2.5460386276245117, 1.647531509399414, -13.672311782836914, 1.7710113525390625, 2.107789993286133, 2.1667861938476562], "custom_metrics": {}}}, "num_steps_sampled": 7998, "num_agent_steps_sampled": 15996, "num_steps_trained": 13056, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 26112, "last_target_update_ts": 7998, "num_target_updates": 63}, "done": false, "episodes_total": 465, "training_iteration": 23, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-04", "timestamp": 1648811524, "time_this_iter_s": 1.3536252975463867, "time_total_s": 29.171217441558838, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f7290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f7290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 29.171217441558838, "timesteps_since_restore": 736, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 15.9, "ram_util_percent": 35.7}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -1.1, "episode_len_mean": 15.05, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -0.55, "policy1": -0.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 12.0, 16.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 16.0, 18.0, 24.0, 24.0, -40.0, 16.0, -20.0, 8.0, -20.0, 14.0, 2.0, -20.0, -20.0, -20.0, 26.0, -20.0, 20.0, -20.0, 22.0, -20.0, -20.0, -20.0, 16.0, 22.0, 24.0, 18.0, -20.0, -20.0, -20.0, -20.0, 30.0, 16.0, 28.0, 22.0, -20.0, -20.0, 24.0, 24.0, 28.0, 24.0, 4.0, 28.0, -20.0, -20.0, -20.0, 28.0, 28.0, -20.0, -20.0, 20.0, 8.0, 28.0, -20.0, -20.0, -20.0, 12.0, -20.0, 16.0, 28.0, -40.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, 18.0, 16.0, 28.0, 10.0, 12.0, 18.0, -20.0, 28.0, -20.0], "episode_lengths": [6, 20, 20, 8, 20, 20, 20, 20, 14, 12, 20, 20, 4, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 6, 12, 11, 8, 8, 20, 12, 20, 16, 20, 13, 19, 20, 20, 20, 7, 20, 10, 20, 9, 20, 20, 20, 12, 9, 8, 11, 20, 20, 20, 20, 5, 12, 6, 9, 20, 20, 8, 8, 6, 8, 18, 6, 20, 20, 20, 6, 6, 20, 20, 10, 16, 6, 20, 20, 20, 14, 20, 12, 6, 20, 10, 20, 20, 20, 20, 20, 12, 11, 12, 6, 15, 14, 11, 20, 6, 20], "policy_policy0_reward": [14.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 6.0, 8.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 8.0, 9.0, 12.0, 12.0, -20.0, 8.0, -10.0, 4.0, -10.0, 7.0, 1.0, -10.0, -10.0, -10.0, 13.0, -10.0, 10.0, -10.0, 11.0, -10.0, -10.0, -10.0, 8.0, 11.0, 12.0, 9.0, -10.0, -10.0, -10.0, -10.0, 15.0, 8.0, 14.0, 11.0, -10.0, -10.0, 12.0, 12.0, 14.0, 12.0, 2.0, 14.0, -10.0, -10.0, -10.0, 14.0, 14.0, -10.0, -10.0, 10.0, 4.0, 14.0, -10.0, -10.0, -10.0, 6.0, -10.0, 8.0, 14.0, -20.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, 9.0, 8.0, 14.0, 5.0, 6.0, 9.0, -10.0, 14.0, -10.0], "policy_policy1_reward": [14.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 6.0, 8.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 8.0, 9.0, 12.0, 12.0, -20.0, 8.0, -10.0, 4.0, -10.0, 7.0, 1.0, -10.0, -10.0, -10.0, 13.0, -10.0, 10.0, -10.0, 11.0, -10.0, -10.0, -10.0, 8.0, 11.0, 12.0, 9.0, -10.0, -10.0, -10.0, -10.0, 15.0, 8.0, 14.0, 11.0, -10.0, -10.0, 12.0, 12.0, 14.0, 12.0, 2.0, 14.0, -10.0, -10.0, -10.0, 14.0, 14.0, -10.0, -10.0, 10.0, 4.0, 14.0, -10.0, -10.0, -10.0, 6.0, -10.0, 8.0, 14.0, -20.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, 9.0, 8.0, 14.0, 5.0, 6.0, 9.0, -10.0, 14.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2854269148878664, "mean_inference_ms": 1.5570864547314733, "mean_action_processing_ms": 0.10262630676422095, "mean_env_wait_ms": 0.06817941854914317, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8307, "timesteps_this_iter": 32, "agent_timesteps_total": 16614, "timers": {"load_time_ms": 0.437, "load_throughput": 73306.968, "learn_time_ms": 7.556, "learn_throughput": 4234.773, "update_time_ms": 4.711}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -5.428021430969238, "min_q": -15.555228233337402, "max_q": -0.1849309206008911, "mean_td_error": -2.6723365783691406, "model": {}}, "td_error": [-22.049835205078125, 3.0053348541259766, 0.9420056343078613, -0.37282657623291016, -1.3367996215820312, -1.6943583488464355, -4.551888942718506, -1.0888638496398926, -0.024297714233398438, 2.3098950386047363, -11.016603469848633, 2.6244773864746094, -0.8494076728820801, -0.3099546432495117, -10.325193405151367, 0.31520748138427734, 1.8465371131896973, -1.3464903831481934, 1.7572650909423828, 0.3051316738128662, -24.55522918701172, -23.626972198486328, 1.8903305530548096, -0.8414766788482666, 4.908670902252197, -2.8152425289154053, 0.0939779281616211, -0.4161027669906616, 0.7682557106018066, 0.27039480209350586, 1.4584331512451172, -0.7891445159912109], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -7.201889991760254, "min_q": -14.262693405151367, "max_q": 0.0064585208892822266, "mean_td_error": -2.2917845249176025, "model": {}}, "td_error": [-15.323978424072266, -2.19808292388916, 0.18629586696624756, -14.86697006225586, 4.048973083496094, 1.8654603958129883, 1.634462833404541, -9.503835678100586, 0.13847887516021729, 3.1055049896240234, -0.8302445411682129, -10.272035598754883, 3.6054086685180664, 1.5232133865356445, 0.7623934745788574, -6.092736721038818, 2.800326108932495, -12.186925888061523, -0.130859375, 2.187729835510254, -0.31182193756103516, 1.43536376953125, 0.6744284629821777, -8.993541717529297, -1.8634757995605469, 0.3192100524902344, -3.098146438598633, -0.4094209671020508, -2.309415817260742, -0.056075096130371094, 3.5018672943115234, -12.678659439086914], "custom_metrics": {}}}, "num_steps_sampled": 8307, "num_agent_steps_sampled": 16614, "num_steps_trained": 13728, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 27456, "last_target_update_ts": 8307, "num_target_updates": 66}, "done": false, "episodes_total": 486, "training_iteration": 24, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-05", "timestamp": 1648811525, "time_this_iter_s": 1.2219626903533936, "time_total_s": 30.39318013191223, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 30.39318013191223, "timesteps_since_restore": 768, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 16.1, "ram_util_percent": 35.7}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": 2.04, "episode_len_mean": 14.28, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": 1.02, "policy1": 1.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 16.0, 18.0, 24.0, 24.0, -40.0, 16.0, -20.0, 8.0, -20.0, 14.0, 2.0, -20.0, -20.0, -20.0, 26.0, -20.0, 20.0, -20.0, 22.0, -20.0, -20.0, -20.0, 16.0, 22.0, 24.0, 18.0, -20.0, -20.0, -20.0, -20.0, 30.0, 16.0, 28.0, 22.0, -20.0, -20.0, 24.0, 24.0, 28.0, 24.0, 4.0, 28.0, -20.0, -20.0, -20.0, 28.0, 28.0, -20.0, -20.0, 20.0, 8.0, 28.0, -20.0, -20.0, -20.0, 12.0, -20.0, 16.0, 28.0, -40.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, 18.0, 16.0, 28.0, 10.0, 12.0, 18.0, -20.0, 28.0, -20.0, 20.0, 24.0, 28.0, 10.0, 28.0, -20.0, -20.0, -20.0, 12.0, 10.0, 10.0, 14.0, 24.0, 26.0, 22.0, -40.0, -40.0, 12.0, -20.0, -20.0, 24.0, 16.0, 4.0], "episode_lengths": [6, 12, 11, 8, 8, 20, 12, 20, 16, 20, 13, 19, 20, 20, 20, 7, 20, 10, 20, 9, 20, 20, 20, 12, 9, 8, 11, 20, 20, 20, 20, 5, 12, 6, 9, 20, 20, 8, 8, 6, 8, 18, 6, 20, 20, 20, 6, 6, 20, 20, 10, 16, 6, 20, 20, 20, 14, 20, 12, 6, 20, 10, 20, 20, 20, 20, 20, 12, 11, 12, 6, 15, 14, 11, 20, 6, 20, 10, 8, 6, 15, 6, 20, 20, 20, 14, 15, 15, 13, 8, 7, 9, 20, 20, 14, 20, 20, 8, 12, 18], "policy_policy0_reward": [14.0, 8.0, 9.0, 12.0, 12.0, -20.0, 8.0, -10.0, 4.0, -10.0, 7.0, 1.0, -10.0, -10.0, -10.0, 13.0, -10.0, 10.0, -10.0, 11.0, -10.0, -10.0, -10.0, 8.0, 11.0, 12.0, 9.0, -10.0, -10.0, -10.0, -10.0, 15.0, 8.0, 14.0, 11.0, -10.0, -10.0, 12.0, 12.0, 14.0, 12.0, 2.0, 14.0, -10.0, -10.0, -10.0, 14.0, 14.0, -10.0, -10.0, 10.0, 4.0, 14.0, -10.0, -10.0, -10.0, 6.0, -10.0, 8.0, 14.0, -20.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, 9.0, 8.0, 14.0, 5.0, 6.0, 9.0, -10.0, 14.0, -10.0, 10.0, 12.0, 14.0, 5.0, 14.0, -10.0, -10.0, -10.0, 6.0, 5.0, 5.0, 7.0, 12.0, 13.0, 11.0, -20.0, -20.0, 6.0, -10.0, -10.0, 12.0, 8.0, 2.0], "policy_policy1_reward": [14.0, 8.0, 9.0, 12.0, 12.0, -20.0, 8.0, -10.0, 4.0, -10.0, 7.0, 1.0, -10.0, -10.0, -10.0, 13.0, -10.0, 10.0, -10.0, 11.0, -10.0, -10.0, -10.0, 8.0, 11.0, 12.0, 9.0, -10.0, -10.0, -10.0, -10.0, 15.0, 8.0, 14.0, 11.0, -10.0, -10.0, 12.0, 12.0, 14.0, 12.0, 2.0, 14.0, -10.0, -10.0, -10.0, 14.0, 14.0, -10.0, -10.0, 10.0, 4.0, 14.0, -10.0, -10.0, -10.0, 6.0, -10.0, 8.0, 14.0, -20.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, 9.0, 8.0, 14.0, 5.0, 6.0, 9.0, -10.0, 14.0, -10.0, 10.0, 12.0, 14.0, 5.0, 14.0, -10.0, -10.0, -10.0, 6.0, 5.0, 5.0, 7.0, 12.0, 13.0, 11.0, -20.0, -20.0, 6.0, -10.0, -10.0, 12.0, 8.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28545499200447805, "mean_inference_ms": 1.55496566932155, "mean_action_processing_ms": 0.10248184742847957, "mean_env_wait_ms": 0.06807342175108946, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8625, "timesteps_this_iter": 32, "agent_timesteps_total": 17250, "timers": {"load_time_ms": 0.428, "load_throughput": 74777.273, "learn_time_ms": 7.283, "learn_throughput": 4393.868, "update_time_ms": 4.581}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.563037872314453, "min_q": -7.079771995544434, "max_q": 6.464661598205566, "mean_td_error": -1.358400583267212, "model": {}}, "td_error": [-1.281937599182129, -0.3929147720336914, 2.4188294410705566, -0.12209081649780273, -14.41789436340332, 0.5346841812133789, 2.134394884109497, 0.03628432750701904, 0.7821674346923828, -0.014858484268188477, -1.3525407314300537, -2.887183666229248, 1.040581226348877, -12.81041431427002, -0.41895437240600586, 2.577247381210327, 0.5178411602973938, -0.42649126052856445, -0.4550662040710449, 0.5909876823425293, -9.89797306060791, -1.7502684593200684, 1.1809685230255127, 1.2279987335205078, 0.786658525466919, -2.1976165771484375, 0.5205824375152588, -0.6461260318756104, 0.21990633010864258, -8.86639404296875, -2.5353384017944336, 2.4361143112182617], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -5.720503330230713, "min_q": -13.825108528137207, "max_q": -2.3480727672576904, "mean_td_error": -2.1774559020996094, "model": {}}, "td_error": [-0.3675107955932617, 0.12035918235778809, 1.3497419357299805, -14.935054779052734, -6.226752758026123, 0.6299328804016113, -0.3088650703430176, -10.869336128234863, -0.25405120849609375, 1.064854621887207, 0.267423152923584, -1.7511649131774902, 0.7420816421508789, 2.3101391792297363, -10.771543502807617, 0.0807037353515625, 0.827106237411499, 0.2853231430053711, -11.344048500061035, 1.1704273223876953, 1.240152359008789, 0.4642601013183594, -16.042407989501953, 0.8482575416564941, 1.301407814025879, 0.49770689010620117, -11.977350234985352, 0.888190746307373, 0.45266294479370117, 0.4152815341949463, -0.11383438110351562, 0.32732057571411133], "custom_metrics": {}}}, "num_steps_sampled": 8625, "num_agent_steps_sampled": 17250, "num_steps_trained": 14464, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 28928, "last_target_update_ts": 8625, "num_target_updates": 69}, "done": false, "episodes_total": 509, "training_iteration": 25, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-06", "timestamp": 1648811526, "time_this_iter_s": 1.2761986255645752, "time_total_s": 31.669378757476807, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83efdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83efdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 31.669378757476807, "timesteps_since_restore": 800, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 15.8, "ram_util_percent": 35.7}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": 3.88, "episode_len_mean": 14.06, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": 1.94, "policy1": 1.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 22.0, 24.0, 18.0, -20.0, -20.0, -20.0, -20.0, 30.0, 16.0, 28.0, 22.0, -20.0, -20.0, 24.0, 24.0, 28.0, 24.0, 4.0, 28.0, -20.0, -20.0, -20.0, 28.0, 28.0, -20.0, -20.0, 20.0, 8.0, 28.0, -20.0, -20.0, -20.0, 12.0, -20.0, 16.0, 28.0, -40.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, 18.0, 16.0, 28.0, 10.0, 12.0, 18.0, -20.0, 28.0, -20.0, 20.0, 24.0, 28.0, 10.0, 28.0, -20.0, -20.0, -20.0, 12.0, 10.0, 10.0, 14.0, 24.0, 26.0, 22.0, -40.0, -40.0, 12.0, -20.0, -20.0, 24.0, 16.0, 4.0, -20.0, 0.0, 0.0, 20.0, 12.0, -20.0, 16.0, 22.0, 14.0, 24.0, 20.0, 26.0, -20.0, 16.0, 24.0, 6.0, -20.0, -20.0, 16.0, 22.0, 0.0, 12.0, 12.0], "episode_lengths": [12, 9, 8, 11, 20, 20, 20, 20, 5, 12, 6, 9, 20, 20, 8, 8, 6, 8, 18, 6, 20, 20, 20, 6, 6, 20, 20, 10, 16, 6, 20, 20, 20, 14, 20, 12, 6, 20, 10, 20, 20, 20, 20, 20, 12, 11, 12, 6, 15, 14, 11, 20, 6, 20, 10, 8, 6, 15, 6, 20, 20, 20, 14, 15, 15, 13, 8, 7, 9, 20, 20, 14, 20, 20, 8, 12, 18, 20, 20, 20, 10, 14, 20, 12, 9, 13, 8, 10, 7, 20, 12, 8, 17, 20, 20, 12, 9, 20, 14, 14], "policy_policy0_reward": [8.0, 11.0, 12.0, 9.0, -10.0, -10.0, -10.0, -10.0, 15.0, 8.0, 14.0, 11.0, -10.0, -10.0, 12.0, 12.0, 14.0, 12.0, 2.0, 14.0, -10.0, -10.0, -10.0, 14.0, 14.0, -10.0, -10.0, 10.0, 4.0, 14.0, -10.0, -10.0, -10.0, 6.0, -10.0, 8.0, 14.0, -20.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, 9.0, 8.0, 14.0, 5.0, 6.0, 9.0, -10.0, 14.0, -10.0, 10.0, 12.0, 14.0, 5.0, 14.0, -10.0, -10.0, -10.0, 6.0, 5.0, 5.0, 7.0, 12.0, 13.0, 11.0, -20.0, -20.0, 6.0, -10.0, -10.0, 12.0, 8.0, 2.0, -10.0, 0.0, 0.0, 10.0, 6.0, -10.0, 8.0, 11.0, 7.0, 12.0, 10.0, 13.0, -10.0, 8.0, 12.0, 3.0, -10.0, -10.0, 8.0, 11.0, 0.0, 6.0, 6.0], "policy_policy1_reward": [8.0, 11.0, 12.0, 9.0, -10.0, -10.0, -10.0, -10.0, 15.0, 8.0, 14.0, 11.0, -10.0, -10.0, 12.0, 12.0, 14.0, 12.0, 2.0, 14.0, -10.0, -10.0, -10.0, 14.0, 14.0, -10.0, -10.0, 10.0, 4.0, 14.0, -10.0, -10.0, -10.0, 6.0, -10.0, 8.0, 14.0, -20.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, 9.0, 8.0, 14.0, 5.0, 6.0, 9.0, -10.0, 14.0, -10.0, 10.0, 12.0, 14.0, 5.0, 14.0, -10.0, -10.0, -10.0, 6.0, 5.0, 5.0, 7.0, 12.0, 13.0, 11.0, -20.0, -20.0, 6.0, -10.0, -10.0, 12.0, 8.0, 2.0, -10.0, 0.0, 0.0, 10.0, 6.0, -10.0, 8.0, 11.0, 7.0, 12.0, 10.0, 13.0, -10.0, 8.0, 12.0, 3.0, -10.0, -10.0, 8.0, 11.0, 0.0, 6.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28542493312593575, "mean_inference_ms": 1.5526939255232954, "mean_action_processing_ms": 0.10230770711973552, "mean_env_wait_ms": 0.06794359762187603, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8954, "timesteps_this_iter": 32, "agent_timesteps_total": 17908, "timers": {"load_time_ms": 0.42, "load_throughput": 76268.74, "learn_time_ms": 7.51, "learn_throughput": 4260.961, "update_time_ms": 5.361}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.2564060688018799, "min_q": -8.166133880615234, "max_q": 8.25241756439209, "mean_td_error": -0.9595835208892822, "model": {}}, "td_error": [3.7572553157806396, 0.6700927019119263, -12.573369026184082, -0.3394742012023926, -0.033344268798828125, -0.8589920997619629, -2.636378526687622, -1.954609751701355, 0.34953200817108154, -0.7475824356079102, -0.6155605316162109, -0.5127758979797363, -1.0744969844818115, -0.8914117813110352, 2.999239444732666, 1.0265514850616455, -6.574495315551758, -0.8458895683288574, -0.8643593788146973, -0.7889957427978516, 0.9095149040222168, 0.6875171661376953, -1.767596960067749, -2.1018247604370117, 0.12577033042907715, -2.2813782691955566, 0.5415029525756836, -0.05259513854980469, -1.5607895851135254, 4.577036380767822, -7.881807327270508, 0.6070408821105957], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -6.883249759674072, "min_q": -13.623749732971191, "max_q": -1.9455344676971436, "mean_td_error": -1.9049723148345947, "model": {}}, "td_error": [-0.2802906036376953, 1.0487489700317383, 0.5884714126586914, -0.08966255187988281, -0.0074939727783203125, -3.8845791816711426, -15.279989242553711, 0.836421012878418, -4.626829147338867, -7.786224365234375, -11.350614547729492, -0.8562664985656738, -0.1562967300415039, -0.34759092330932617, 0.28716278076171875, -17.88595962524414, -6.974752902984619, 0.1529526710510254, 0.5810823440551758, 0.20363998413085938, 1.9763777256011963, -0.2781691551208496, 0.09082603454589844, -0.6105937957763672, 0.9404399394989014, -0.6161251068115234, 0.0055027008056640625, 1.6524181365966797, -0.13316726684570312, 0.8476386070251465, 0.14680814743041992, 0.847001314163208], "custom_metrics": {}}}, "num_steps_sampled": 8954, "num_agent_steps_sampled": 17908, "num_steps_trained": 15200, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 30400, "last_target_update_ts": 8954, "num_target_updates": 72}, "done": false, "episodes_total": 532, "training_iteration": 26, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-08", "timestamp": 1648811528, "time_this_iter_s": 1.3107163906097412, "time_total_s": 32.98009514808655, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 32.98009514808655, "timesteps_since_restore": 832, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 14.5, "ram_util_percent": 35.7}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": 1.82, "episode_len_mean": 14.49, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": 0.91, "policy1": 0.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 28.0, 28.0, -20.0, -20.0, 20.0, 8.0, 28.0, -20.0, -20.0, -20.0, 12.0, -20.0, 16.0, 28.0, -40.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, 16.0, 18.0, 16.0, 28.0, 10.0, 12.0, 18.0, -20.0, 28.0, -20.0, 20.0, 24.0, 28.0, 10.0, 28.0, -20.0, -20.0, -20.0, 12.0, 10.0, 10.0, 14.0, 24.0, 26.0, 22.0, -40.0, -40.0, 12.0, -20.0, -20.0, 24.0, 16.0, 4.0, -20.0, 0.0, 0.0, 20.0, 12.0, -20.0, 16.0, 22.0, 14.0, 24.0, 20.0, 26.0, -20.0, 16.0, 24.0, 6.0, -20.0, -20.0, 16.0, 22.0, 0.0, 12.0, 12.0, 12.0, -40.0, 28.0, -20.0, 4.0, 16.0, 28.0, -40.0, -20.0, -20.0, -40.0, -20.0, 28.0, -20.0, 32.0, 16.0, 28.0, 10.0, -20.0, -20.0, -20.0, 20.0], "episode_lengths": [20, 6, 6, 20, 20, 10, 16, 6, 20, 20, 20, 14, 20, 12, 6, 20, 10, 20, 20, 20, 20, 20, 12, 11, 12, 6, 15, 14, 11, 20, 6, 20, 10, 8, 6, 15, 6, 20, 20, 20, 14, 15, 15, 13, 8, 7, 9, 20, 20, 14, 20, 20, 8, 12, 18, 20, 20, 20, 10, 14, 20, 12, 9, 13, 8, 10, 7, 20, 12, 8, 17, 20, 20, 12, 9, 20, 14, 14, 14, 20, 6, 20, 18, 12, 6, 20, 20, 20, 20, 20, 6, 20, 4, 12, 6, 15, 20, 20, 20, 10], "policy_policy0_reward": [-10.0, 14.0, 14.0, -10.0, -10.0, 10.0, 4.0, 14.0, -10.0, -10.0, -10.0, 6.0, -10.0, 8.0, 14.0, -20.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, 9.0, 8.0, 14.0, 5.0, 6.0, 9.0, -10.0, 14.0, -10.0, 10.0, 12.0, 14.0, 5.0, 14.0, -10.0, -10.0, -10.0, 6.0, 5.0, 5.0, 7.0, 12.0, 13.0, 11.0, -20.0, -20.0, 6.0, -10.0, -10.0, 12.0, 8.0, 2.0, -10.0, 0.0, 0.0, 10.0, 6.0, -10.0, 8.0, 11.0, 7.0, 12.0, 10.0, 13.0, -10.0, 8.0, 12.0, 3.0, -10.0, -10.0, 8.0, 11.0, 0.0, 6.0, 6.0, 6.0, -20.0, 14.0, -10.0, 2.0, 8.0, 14.0, -20.0, -10.0, -10.0, -20.0, -10.0, 14.0, -10.0, 16.0, 8.0, 14.0, 5.0, -10.0, -10.0, -10.0, 10.0], "policy_policy1_reward": [-10.0, 14.0, 14.0, -10.0, -10.0, 10.0, 4.0, 14.0, -10.0, -10.0, -10.0, 6.0, -10.0, 8.0, 14.0, -20.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, 8.0, 9.0, 8.0, 14.0, 5.0, 6.0, 9.0, -10.0, 14.0, -10.0, 10.0, 12.0, 14.0, 5.0, 14.0, -10.0, -10.0, -10.0, 6.0, 5.0, 5.0, 7.0, 12.0, 13.0, 11.0, -20.0, -20.0, 6.0, -10.0, -10.0, 12.0, 8.0, 2.0, -10.0, 0.0, 0.0, 10.0, 6.0, -10.0, 8.0, 11.0, 7.0, 12.0, 10.0, 13.0, -10.0, 8.0, 12.0, 3.0, -10.0, -10.0, 8.0, 11.0, 0.0, 6.0, 6.0, 6.0, -20.0, 14.0, -10.0, 2.0, 8.0, 14.0, -20.0, -10.0, -10.0, -20.0, -10.0, 14.0, -10.0, 16.0, 8.0, 14.0, 5.0, -10.0, -10.0, -10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2853456191317031, "mean_inference_ms": 1.5506669113968272, "mean_action_processing_ms": 0.10214930012946781, "mean_env_wait_ms": 0.06781480370582578, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9283, "timesteps_this_iter": 32, "agent_timesteps_total": 18566, "timers": {"load_time_ms": 0.423, "load_throughput": 75692.38, "learn_time_ms": 7.441, "learn_throughput": 4300.32, "update_time_ms": 4.647}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.2850768566131592, "min_q": -5.637804985046387, "max_q": 3.6381378173828125, "mean_td_error": -0.7119777202606201, "model": {}}, "td_error": [-2.8443350791931152, -0.46099603176116943, 1.7786943912506104, 2.117593288421631, 2.395991325378418, -1.7507820129394531, 0.3699169158935547, -2.4852418899536133, 1.1252386569976807, 1.2801649570465088, -7.083639144897461, 2.681396484375, 2.7047677040100098, 0.8543117046356201, -12.597150802612305, -0.4031388759613037, -2.8830180168151855, -1.1135832071304321, 3.0244529247283936, 1.877722978591919, 0.3442411422729492, 3.7209455966949463, 1.2342894077301025, -0.32986974716186523, 0.18488097190856934, 1.71921968460083, -6.42538070678711e-05, 1.852168083190918, -1.9118527173995972, -14.637804985046387, -3.2827036380767822, -0.26510363817214966], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -6.962050437927246, "min_q": -11.790933609008789, "max_q": -3.8667516708374023, "mean_td_error": -1.463036298751831, "model": {}}, "td_error": [-0.9186630249023438, -0.4575767517089844, 1.1514654159545898, 1.3249125480651855, -9.305837631225586, 0.4847111701965332, -15.635074615478516, 1.4781522750854492, -0.6360969543457031, -0.11601638793945312, 0.024822235107421875, 0.5771923065185547, 0.05767631530761719, 0.11863422393798828, -0.8330249786376953, 0.08364248275756836, 0.5991990566253662, -0.1500096321105957, 1.075913906097412, 0.2068338394165039, -1.89599609375, -0.2440328598022461, 0.16109752655029297, -8.842059135437012, 1.961500644683838, 0.8872737884521484, 0.5517563819885254, -0.0518951416015625, -0.3144993782043457, 0.5821084976196289, -18.562936782836914, -0.18033123016357422], "custom_metrics": {}}}, "num_steps_sampled": 9283, "num_agent_steps_sampled": 18566, "num_steps_trained": 15904, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 31808, "last_target_update_ts": 9283, "num_target_updates": 75}, "done": false, "episodes_total": 554, "training_iteration": 27, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-09", "timestamp": 1648811529, "time_this_iter_s": 1.2785379886627197, "time_total_s": 34.25863313674927, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 34.25863313674927, "timesteps_since_restore": 864, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 14.8, "ram_util_percent": 35.75}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": 3.12, "episode_len_mean": 14.44, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": 1.56, "policy1": 1.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 16.0, 18.0, 16.0, 28.0, 10.0, 12.0, 18.0, -20.0, 28.0, -20.0, 20.0, 24.0, 28.0, 10.0, 28.0, -20.0, -20.0, -20.0, 12.0, 10.0, 10.0, 14.0, 24.0, 26.0, 22.0, -40.0, -40.0, 12.0, -20.0, -20.0, 24.0, 16.0, 4.0, -20.0, 0.0, 0.0, 20.0, 12.0, -20.0, 16.0, 22.0, 14.0, 24.0, 20.0, 26.0, -20.0, 16.0, 24.0, 6.0, -20.0, -20.0, 16.0, 22.0, 0.0, 12.0, 12.0, 12.0, -40.0, 28.0, -20.0, 4.0, 16.0, 28.0, -40.0, -20.0, -20.0, -40.0, -20.0, 28.0, -20.0, 32.0, 16.0, 28.0, 10.0, -20.0, -20.0, -20.0, 20.0, 12.0, -20.0, 14.0, -20.0, -20.0, 4.0, 16.0, 26.0, 0.0, -20.0, 24.0, 4.0, 26.0, 18.0, -20.0, 24.0, 14.0, 16.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 12, 11, 12, 6, 15, 14, 11, 20, 6, 20, 10, 8, 6, 15, 6, 20, 20, 20, 14, 15, 15, 13, 8, 7, 9, 20, 20, 14, 20, 20, 8, 12, 18, 20, 20, 20, 10, 14, 20, 12, 9, 13, 8, 10, 7, 20, 12, 8, 17, 20, 20, 12, 9, 20, 14, 14, 14, 20, 6, 20, 18, 12, 6, 20, 20, 20, 20, 20, 6, 20, 4, 12, 6, 15, 20, 20, 20, 10, 14, 20, 13, 20, 20, 18, 12, 7, 20, 20, 8, 18, 7, 11, 20, 8, 13, 12, 20, 20, 20], "policy_policy0_reward": [-20.0, 8.0, 9.0, 8.0, 14.0, 5.0, 6.0, 9.0, -10.0, 14.0, -10.0, 10.0, 12.0, 14.0, 5.0, 14.0, -10.0, -10.0, -10.0, 6.0, 5.0, 5.0, 7.0, 12.0, 13.0, 11.0, -20.0, -20.0, 6.0, -10.0, -10.0, 12.0, 8.0, 2.0, -10.0, 0.0, 0.0, 10.0, 6.0, -10.0, 8.0, 11.0, 7.0, 12.0, 10.0, 13.0, -10.0, 8.0, 12.0, 3.0, -10.0, -10.0, 8.0, 11.0, 0.0, 6.0, 6.0, 6.0, -20.0, 14.0, -10.0, 2.0, 8.0, 14.0, -20.0, -10.0, -10.0, -20.0, -10.0, 14.0, -10.0, 16.0, 8.0, 14.0, 5.0, -10.0, -10.0, -10.0, 10.0, 6.0, -10.0, 7.0, -10.0, -10.0, 2.0, 8.0, 13.0, 0.0, -10.0, 12.0, 2.0, 13.0, 9.0, -10.0, 12.0, 7.0, 8.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 8.0, 9.0, 8.0, 14.0, 5.0, 6.0, 9.0, -10.0, 14.0, -10.0, 10.0, 12.0, 14.0, 5.0, 14.0, -10.0, -10.0, -10.0, 6.0, 5.0, 5.0, 7.0, 12.0, 13.0, 11.0, -20.0, -20.0, 6.0, -10.0, -10.0, 12.0, 8.0, 2.0, -10.0, 0.0, 0.0, 10.0, 6.0, -10.0, 8.0, 11.0, 7.0, 12.0, 10.0, 13.0, -10.0, 8.0, 12.0, 3.0, -10.0, -10.0, 8.0, 11.0, 0.0, 6.0, 6.0, 6.0, -20.0, 14.0, -10.0, 2.0, 8.0, 14.0, -20.0, -10.0, -10.0, -20.0, -10.0, 14.0, -10.0, 16.0, 8.0, 14.0, 5.0, -10.0, -10.0, -10.0, 10.0, 6.0, -10.0, 7.0, -10.0, -10.0, 2.0, 8.0, 13.0, 0.0, -10.0, 12.0, 2.0, 13.0, 9.0, -10.0, 12.0, 7.0, 8.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28523723114790017, "mean_inference_ms": 1.5487406367919079, "mean_action_processing_ms": 0.10199963892415521, "mean_env_wait_ms": 0.06770264488088482, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9604, "timesteps_this_iter": 32, "agent_timesteps_total": 19208, "timers": {"load_time_ms": 0.432, "load_throughput": 74124.774, "learn_time_ms": 7.617, "learn_throughput": 4200.92, "update_time_ms": 4.621}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.5956525802612305, "min_q": -3.4768013954162598, "max_q": 11.453048706054688, "mean_td_error": -0.40196797251701355, "model": {}}, "td_error": [-7.625107765197754, 3.077608108520508, -0.5496244430541992, -1.9940552711486816, -1.5091133117675781, 1.680534839630127, -10.226167678833008, -0.04870271682739258, 1.921762466430664, -1.8827171325683594, -5.330982685089111, 5.853010177612305, -1.8247394561767578, 0.33383989334106445, 1.7828389406204224, -1.629584789276123, -4.514610290527344, 3.74294376373291, 6.8986430168151855, 0.11954569816589355, -1.4508665800094604, -1.6575571298599243, 1.917311191558838, 0.8178901672363281, -0.12458628416061401, -8.793420791625977, 4.199341773986816, 0.595728874206543, 0.17790746688842773, 2.827627658843994, -0.1641101837158203, 0.5164375305175781], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.449936866760254, "min_q": -12.64816665649414, "max_q": -5.454522609710693, "mean_td_error": -1.90791916847229, "model": {}}, "td_error": [-7.103888988494873, 0.9367499351501465, -7.082942008972168, 0.8399624824523926, -9.41600513458252, -9.656063079833984, 0.7944536209106445, -5.56723165512085, -8.597223281860352, 0.06790828704833984, 0.2897491455078125, 0.48096656799316406, 0.11550521850585938, 0.16703081130981445, 0.9196929931640625, 0.22459030151367188, 0.08506917953491211, 0.8633365631103516, 0.39533138275146484, 0.6651906967163086, 1.059189796447754, 0.28645849227905273, -11.64816665649414, 1.1700234413146973, 0.4918069839477539, 0.2637662887573242, 0.14693355560302734, 0.8855857849121094, -15.401954650878906, 1.3641576766967773, 0.45453643798828125, 0.4520683288574219], "custom_metrics": {}}}, "num_steps_sampled": 9604, "num_agent_steps_sampled": 19208, "num_steps_trained": 16576, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 33152, "last_target_update_ts": 9604, "num_target_updates": 78}, "done": false, "episodes_total": 575, "training_iteration": 28, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-10", "timestamp": 1648811530, "time_this_iter_s": 1.2433631420135498, "time_total_s": 35.50199627876282, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 35.50199627876282, "timesteps_since_restore": 896, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 15.15, "ram_util_percent": 35.8}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 3.32, "episode_len_mean": 14.34, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 1.66, "policy1": 1.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, 12.0, -20.0, -20.0, 24.0, 16.0, 4.0, -20.0, 0.0, 0.0, 20.0, 12.0, -20.0, 16.0, 22.0, 14.0, 24.0, 20.0, 26.0, -20.0, 16.0, 24.0, 6.0, -20.0, -20.0, 16.0, 22.0, 0.0, 12.0, 12.0, 12.0, -40.0, 28.0, -20.0, 4.0, 16.0, 28.0, -40.0, -20.0, -20.0, -40.0, -20.0, 28.0, -20.0, 32.0, 16.0, 28.0, 10.0, -20.0, -20.0, -20.0, 20.0, 12.0, -20.0, 14.0, -20.0, -20.0, 4.0, 16.0, 26.0, 0.0, -20.0, 24.0, 4.0, 26.0, 18.0, -20.0, 24.0, 14.0, 16.0, -20.0, -20.0, -20.0, 14.0, 34.0, 34.0, 26.0, 12.0, 18.0, 20.0, 12.0, -20.0, 28.0, 34.0, 28.0, -20.0, -20.0, -20.0, 16.0, 24.0, -20.0, -20.0, 28.0, 28.0, 4.0, 6.0, 4.0, 24.0, -20.0], "episode_lengths": [20, 20, 14, 20, 20, 8, 12, 18, 20, 20, 20, 10, 14, 20, 12, 9, 13, 8, 10, 7, 20, 12, 8, 17, 20, 20, 12, 9, 20, 14, 14, 14, 20, 6, 20, 18, 12, 6, 20, 20, 20, 20, 20, 6, 20, 4, 12, 6, 15, 20, 20, 20, 10, 14, 20, 13, 20, 20, 18, 12, 7, 20, 20, 8, 18, 7, 11, 20, 8, 13, 12, 20, 20, 20, 13, 3, 3, 7, 14, 11, 10, 14, 20, 6, 3, 6, 20, 20, 20, 12, 8, 20, 20, 6, 6, 18, 17, 18, 8, 20], "policy_policy0_reward": [-20.0, -20.0, 6.0, -10.0, -10.0, 12.0, 8.0, 2.0, -10.0, 0.0, 0.0, 10.0, 6.0, -10.0, 8.0, 11.0, 7.0, 12.0, 10.0, 13.0, -10.0, 8.0, 12.0, 3.0, -10.0, -10.0, 8.0, 11.0, 0.0, 6.0, 6.0, 6.0, -20.0, 14.0, -10.0, 2.0, 8.0, 14.0, -20.0, -10.0, -10.0, -20.0, -10.0, 14.0, -10.0, 16.0, 8.0, 14.0, 5.0, -10.0, -10.0, -10.0, 10.0, 6.0, -10.0, 7.0, -10.0, -10.0, 2.0, 8.0, 13.0, 0.0, -10.0, 12.0, 2.0, 13.0, 9.0, -10.0, 12.0, 7.0, 8.0, -10.0, -10.0, -10.0, 7.0, 17.0, 17.0, 13.0, 6.0, 9.0, 10.0, 6.0, -10.0, 14.0, 17.0, 14.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 14.0, 14.0, 2.0, 3.0, 2.0, 12.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, 6.0, -10.0, -10.0, 12.0, 8.0, 2.0, -10.0, 0.0, 0.0, 10.0, 6.0, -10.0, 8.0, 11.0, 7.0, 12.0, 10.0, 13.0, -10.0, 8.0, 12.0, 3.0, -10.0, -10.0, 8.0, 11.0, 0.0, 6.0, 6.0, 6.0, -20.0, 14.0, -10.0, 2.0, 8.0, 14.0, -20.0, -10.0, -10.0, -20.0, -10.0, 14.0, -10.0, 16.0, 8.0, 14.0, 5.0, -10.0, -10.0, -10.0, 10.0, 6.0, -10.0, 7.0, -10.0, -10.0, 2.0, 8.0, 13.0, 0.0, -10.0, 12.0, 2.0, 13.0, 9.0, -10.0, 12.0, 7.0, 8.0, -10.0, -10.0, -10.0, 7.0, 17.0, 17.0, 13.0, 6.0, 9.0, 10.0, 6.0, -10.0, 14.0, 17.0, 14.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 14.0, 14.0, 2.0, 3.0, 2.0, 12.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2851119390527298, "mean_inference_ms": 1.5463805750987683, "mean_action_processing_ms": 0.10180787133472823, "mean_env_wait_ms": 0.067571099938445, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9927, "timesteps_this_iter": 32, "agent_timesteps_total": 19854, "timers": {"load_time_ms": 0.417, "load_throughput": 76814.358, "learn_time_ms": 7.196, "learn_throughput": 4446.681, "update_time_ms": 4.538}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 1.3521989583969116, "min_q": -3.7903099060058594, "max_q": 12.694904327392578, "mean_td_error": -0.7189725637435913, "model": {}}, "td_error": [-1.1790838241577148, -1.0882678031921387, -1.1883349418640137, -0.7353394031524658, -0.010446786880493164, 0.6705079078674316, -2.0756633281707764, 0.5113525390625, 1.0396908521652222, 0.4141561985015869, 0.3012118935585022, -0.10049676895141602, -3.0696792602539062, -0.9566948413848877, 0.1800849437713623, -3.153529644012451, 0.20390459895133972, -1.2631868124008179, -0.8157124519348145, -4.422186851501465, -4.436621189117432, -2.574556827545166, 3.0923404693603516, 0.12162041664123535, -3.2897744178771973, 5.211674690246582, -0.12024855613708496, -1.4327168464660645, 0.28701066970825195, -4.371767044067383, 0.8336153030395508, 0.4100170135498047], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -9.353157043457031, "min_q": -13.142776489257812, "max_q": -5.552703857421875, "mean_td_error": -2.6367735862731934, "model": {}}, "td_error": [0.4123830795288086, 0.701807975769043, -7.909347057342529, 1.6571235656738281, -7.21887731552124, 0.36649322509765625, -11.753408432006836, 1.5871024131774902, -11.140604972839355, -10.6815767288208, 0.39459228515625, 0.3177375793457031, 0.7556295394897461, 1.2493019104003906, 0.3437070846557617, 1.5317339897155762, 0.6790804862976074, 1.1022272109985352, 0.7147984504699707, -0.10957717895507812, -11.099408149719238, 0.4035506248474121, 0.2400493621826172, 0.8347535133361816, 0.5825891494750977, -11.596519470214844, 1.563568115234375, -3.191044330596924, -11.140604972839355, 1.4659461975097656, 0.22465229034423828, -15.664613723754883], "custom_metrics": {}}}, "num_steps_sampled": 9927, "num_agent_steps_sampled": 19854, "num_steps_trained": 17344, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 34688, "last_target_update_ts": 9927, "num_target_updates": 81}, "done": false, "episodes_total": 601, "training_iteration": 29, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-12", "timestamp": 1648811532, "time_this_iter_s": 1.2999851703643799, "time_total_s": 36.8019814491272, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83eff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83eff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 36.8019814491272, "timesteps_since_restore": 928, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 14.3, "ram_util_percent": 35.8}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 4.82, "episode_len_mean": 13.59, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 2.41, "policy1": 2.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 22.0, 0.0, 12.0, 12.0, 12.0, -40.0, 28.0, -20.0, 4.0, 16.0, 28.0, -40.0, -20.0, -20.0, -40.0, -20.0, 28.0, -20.0, 32.0, 16.0, 28.0, 10.0, -20.0, -20.0, -20.0, 20.0, 12.0, -20.0, 14.0, -20.0, -20.0, 4.0, 16.0, 26.0, 0.0, -20.0, 24.0, 4.0, 26.0, 18.0, -20.0, 24.0, 14.0, 16.0, -20.0, -20.0, -20.0, 14.0, 34.0, 34.0, 26.0, 12.0, 18.0, 20.0, 12.0, -20.0, 28.0, 34.0, 28.0, -20.0, -20.0, -20.0, 16.0, 24.0, -20.0, -20.0, 28.0, 28.0, 4.0, 6.0, 4.0, 24.0, -20.0, 28.0, -40.0, -40.0, -20.0, 28.0, -20.0, 26.0, 28.0, 28.0, 28.0, 28.0, -20.0, 20.0, 28.0, -20.0, -20.0, 10.0, -20.0, -20.0, 30.0, 30.0, 24.0, 4.0, 28.0, 8.0, 30.0], "episode_lengths": [12, 9, 20, 14, 14, 14, 20, 6, 20, 18, 12, 6, 20, 20, 20, 20, 20, 6, 20, 4, 12, 6, 15, 20, 20, 20, 10, 14, 20, 13, 20, 20, 18, 12, 7, 20, 20, 8, 18, 7, 11, 20, 8, 13, 12, 20, 20, 20, 13, 3, 3, 7, 14, 11, 10, 14, 20, 6, 3, 6, 20, 20, 20, 12, 8, 20, 20, 6, 6, 18, 17, 18, 8, 20, 6, 20, 20, 20, 6, 20, 7, 6, 6, 6, 6, 20, 10, 6, 20, 20, 15, 20, 20, 5, 5, 8, 18, 6, 16, 5], "policy_policy0_reward": [8.0, 11.0, 0.0, 6.0, 6.0, 6.0, -20.0, 14.0, -10.0, 2.0, 8.0, 14.0, -20.0, -10.0, -10.0, -20.0, -10.0, 14.0, -10.0, 16.0, 8.0, 14.0, 5.0, -10.0, -10.0, -10.0, 10.0, 6.0, -10.0, 7.0, -10.0, -10.0, 2.0, 8.0, 13.0, 0.0, -10.0, 12.0, 2.0, 13.0, 9.0, -10.0, 12.0, 7.0, 8.0, -10.0, -10.0, -10.0, 7.0, 17.0, 17.0, 13.0, 6.0, 9.0, 10.0, 6.0, -10.0, 14.0, 17.0, 14.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 14.0, 14.0, 2.0, 3.0, 2.0, 12.0, -10.0, 14.0, -20.0, -20.0, -10.0, 14.0, -10.0, 13.0, 14.0, 14.0, 14.0, 14.0, -10.0, 10.0, 14.0, -10.0, -10.0, 5.0, -10.0, -10.0, 15.0, 15.0, 12.0, 2.0, 14.0, 4.0, 15.0], "policy_policy1_reward": [8.0, 11.0, 0.0, 6.0, 6.0, 6.0, -20.0, 14.0, -10.0, 2.0, 8.0, 14.0, -20.0, -10.0, -10.0, -20.0, -10.0, 14.0, -10.0, 16.0, 8.0, 14.0, 5.0, -10.0, -10.0, -10.0, 10.0, 6.0, -10.0, 7.0, -10.0, -10.0, 2.0, 8.0, 13.0, 0.0, -10.0, 12.0, 2.0, 13.0, 9.0, -10.0, 12.0, 7.0, 8.0, -10.0, -10.0, -10.0, 7.0, 17.0, 17.0, 13.0, 6.0, 9.0, 10.0, 6.0, -10.0, 14.0, 17.0, 14.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 14.0, 14.0, 2.0, 3.0, 2.0, 12.0, -10.0, 14.0, -20.0, -20.0, -10.0, 14.0, -10.0, 13.0, 14.0, 14.0, 14.0, 14.0, -10.0, 10.0, 14.0, -10.0, -10.0, 5.0, -10.0, -10.0, 15.0, 15.0, 12.0, 2.0, 14.0, 4.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28508158432401287, "mean_inference_ms": 1.5445789324645198, "mean_action_processing_ms": 0.10164071478258765, "mean_env_wait_ms": 0.06746623143991931, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10244, "timesteps_this_iter": 32, "agent_timesteps_total": 20488, "timers": {"load_time_ms": 0.431, "load_throughput": 74313.564, "learn_time_ms": 7.225, "learn_throughput": 4428.78, "update_time_ms": 4.656}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.0821115970611572, "min_q": -3.4591126441955566, "max_q": 12.819114685058594, "mean_td_error": 0.06490348279476166, "model": {}}, "td_error": [1.0223398208618164, 0.9957766532897949, 2.216480255126953, 1.729217529296875, -1.521650791168213, 2.4248828887939453, -5.142385482788086, -0.531264066696167, -0.009812355041503906, -0.28133344650268555, 1.1711493730545044, -0.4583420753479004, 2.710689067840576, 2.241652488708496, -6.376210689544678, -0.8834981918334961, -0.02432495355606079, 3.0906643867492676, -1.8810255527496338, -0.28055810928344727, -0.4635481834411621, -1.249114990234375, -1.9578056335449219, 5.649107933044434, 1.1557164192199707, -1.6437978744506836, 1.0087246894836426, 0.7109224796295166, 0.561314582824707, 3.4808363914489746, -0.2730879783630371, -5.114801406860352], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -9.89101791381836, "min_q": -13.741043090820312, "max_q": -4.637542724609375, "mean_td_error": -2.1207351684570312, "model": {}}, "td_error": [-21.294893264770508, 1.4321489334106445, -0.16870498657226562, 0.7248935699462891, -0.32218360900878906, 0.9197988510131836, 0.4697751998901367, -4.888368606567383, -0.031424522399902344, -6.215041637420654, 0.38504695892333984, -16.422794342041016, 0.6065273284912109, 1.9399137496948242, 0.14767837524414062, -0.9319992065429688, -1.028609275817871, 0.5027952194213867, -0.7715110778808594, 1.1677908897399902, 1.081416130065918, 0.06584644317626953, 0.3048410415649414, -11.60085391998291, 2.3959760665893555, 0.5902242660522461, 1.7157878875732422, -21.294893264770508, -0.17205524444580078, 0.7773313522338867, 0.2961540222167969, 1.7558631896972656], "custom_metrics": {}}}, "num_steps_sampled": 10244, "num_agent_steps_sampled": 20488, "num_steps_trained": 18176, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 36352, "last_target_update_ts": 10244, "num_target_updates": 84}, "done": false, "episodes_total": 627, "training_iteration": 30, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-13", "timestamp": 1648811533, "time_this_iter_s": 1.366457223892212, "time_total_s": 38.16843867301941, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d15f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d15f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 38.16843867301941, "timesteps_since_restore": 960, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 15.3, "ram_util_percent": 35.8}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 8.42, "episode_len_mean": 12.89, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 4.21, "policy1": 4.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 12.0, -20.0, 14.0, -20.0, -20.0, 4.0, 16.0, 26.0, 0.0, -20.0, 24.0, 4.0, 26.0, 18.0, -20.0, 24.0, 14.0, 16.0, -20.0, -20.0, -20.0, 14.0, 34.0, 34.0, 26.0, 12.0, 18.0, 20.0, 12.0, -20.0, 28.0, 34.0, 28.0, -20.0, -20.0, -20.0, 16.0, 24.0, -20.0, -20.0, 28.0, 28.0, 4.0, 6.0, 4.0, 24.0, -20.0, 28.0, -40.0, -40.0, -20.0, 28.0, -20.0, 26.0, 28.0, 28.0, 28.0, 28.0, -20.0, 20.0, 28.0, -20.0, -20.0, 10.0, -20.0, -20.0, 30.0, 30.0, 24.0, 4.0, 28.0, 8.0, 30.0, 6.0, 28.0, -20.0, 24.0, 8.0, 10.0, 14.0, 0.0, 16.0, 8.0, 6.0, 16.0, -20.0, -20.0, 32.0, 0.0, 28.0, 18.0, 32.0, 28.0, 28.0, 32.0, 34.0, 4.0, 20.0, 12.0], "episode_lengths": [10, 14, 20, 13, 20, 20, 18, 12, 7, 20, 20, 8, 18, 7, 11, 20, 8, 13, 12, 20, 20, 20, 13, 3, 3, 7, 14, 11, 10, 14, 20, 6, 3, 6, 20, 20, 20, 12, 8, 20, 20, 6, 6, 18, 17, 18, 8, 20, 6, 20, 20, 20, 6, 20, 7, 6, 6, 6, 6, 20, 10, 6, 20, 20, 15, 20, 20, 5, 5, 8, 18, 6, 16, 5, 17, 6, 20, 8, 16, 15, 13, 20, 12, 16, 17, 12, 20, 20, 4, 20, 6, 11, 4, 6, 6, 4, 3, 18, 10, 14], "policy_policy0_reward": [10.0, 6.0, -10.0, 7.0, -10.0, -10.0, 2.0, 8.0, 13.0, 0.0, -10.0, 12.0, 2.0, 13.0, 9.0, -10.0, 12.0, 7.0, 8.0, -10.0, -10.0, -10.0, 7.0, 17.0, 17.0, 13.0, 6.0, 9.0, 10.0, 6.0, -10.0, 14.0, 17.0, 14.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 14.0, 14.0, 2.0, 3.0, 2.0, 12.0, -10.0, 14.0, -20.0, -20.0, -10.0, 14.0, -10.0, 13.0, 14.0, 14.0, 14.0, 14.0, -10.0, 10.0, 14.0, -10.0, -10.0, 5.0, -10.0, -10.0, 15.0, 15.0, 12.0, 2.0, 14.0, 4.0, 15.0, 3.0, 14.0, -10.0, 12.0, 4.0, 5.0, 7.0, 0.0, 8.0, 4.0, 3.0, 8.0, -10.0, -10.0, 16.0, 0.0, 14.0, 9.0, 16.0, 14.0, 14.0, 16.0, 17.0, 2.0, 10.0, 6.0], "policy_policy1_reward": [10.0, 6.0, -10.0, 7.0, -10.0, -10.0, 2.0, 8.0, 13.0, 0.0, -10.0, 12.0, 2.0, 13.0, 9.0, -10.0, 12.0, 7.0, 8.0, -10.0, -10.0, -10.0, 7.0, 17.0, 17.0, 13.0, 6.0, 9.0, 10.0, 6.0, -10.0, 14.0, 17.0, 14.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 14.0, 14.0, 2.0, 3.0, 2.0, 12.0, -10.0, 14.0, -20.0, -20.0, -10.0, 14.0, -10.0, 13.0, 14.0, 14.0, 14.0, 14.0, -10.0, 10.0, 14.0, -10.0, -10.0, 5.0, -10.0, -10.0, 15.0, 15.0, 12.0, 2.0, 14.0, 4.0, 15.0, 3.0, 14.0, -10.0, 12.0, 4.0, 5.0, 7.0, 0.0, 8.0, 4.0, 3.0, 8.0, -10.0, -10.0, 16.0, 0.0, 14.0, 9.0, 16.0, 14.0, 14.0, 16.0, 17.0, 2.0, 10.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.285115594068555, "mean_inference_ms": 1.543040668512588, "mean_action_processing_ms": 0.1014736365146305, "mean_env_wait_ms": 0.06737417521244693, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10562, "timesteps_this_iter": 32, "agent_timesteps_total": 21124, "timers": {"load_time_ms": 0.432, "load_throughput": 74067.506, "learn_time_ms": 7.057, "learn_throughput": 4534.49, "update_time_ms": 4.463}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.173573970794678, "min_q": -3.4056873321533203, "max_q": 12.42829704284668, "mean_td_error": 0.4897976219654083, "model": {}}, "td_error": [-0.4682873487472534, 0.8172285556793213, -0.4589376449584961, -0.3810412883758545, -0.8635518550872803, -0.13600730895996094, 3.280756950378418, 1.2218284606933594, -1.4589072465896606, 2.2051000595092773, 5.34354305267334, 2.881962776184082, 8.402262687683105, -10.903421401977539, 1.1584463119506836, 0.3169851303100586, 0.11042499542236328, 3.330376625061035, 0.1751117706298828, 1.1259307861328125, -0.5382814407348633, -6.769603729248047, -0.3032490015029907, 0.857722282409668, 0.3860435485839844, 4.682849884033203, 0.43063223361968994, 0.8993053436279297, 0.9242045879364014, 0.3075895309448242, -0.5813028812408447, -0.3221912384033203], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.285487174987793, "min_q": -14.339584350585938, "max_q": -5.881072044372559, "mean_td_error": -3.4388585090637207, "model": {}}, "td_error": [0.24805164337158203, 0.9596128463745117, 0.6401968002319336, -7.780646324157715, 0.9924073219299316, 0.6810970306396484, 0.6052618026733398, 0.5706825256347656, -22.163623809814453, -0.3822140693664551, 0.9697027206420898, -0.8245391845703125, -2.7360763549804688, -20.373146057128906, 0.5684127807617188, -0.2513265609741211, -1.2171697616577148, 0.443267822265625, 1.5357694625854492, 0.10927581787109375, 0.6465644836425781, -17.717140197753906, 1.6312365531921387, -17.752300262451172, -13.12096881866455, -0.21976423263549805, -0.9316177368164062, -17.06075096130371, 0.9997549057006836, 1.7990899085998535, 0.6569023132324219, -1.5694770812988281], "custom_metrics": {}}}, "num_steps_sampled": 10562, "num_agent_steps_sampled": 21124, "num_steps_trained": 18976, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 37952, "last_target_update_ts": 10562, "num_target_updates": 87}, "done": false, "episodes_total": 653, "training_iteration": 31, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-14", "timestamp": 1648811534, "time_this_iter_s": 1.3225889205932617, "time_total_s": 39.49102759361267, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 39.49102759361267, "timesteps_since_restore": 992, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 16.35, "ram_util_percent": 35.8}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 8.74, "episode_len_mean": 12.73, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 4.37, "policy1": 4.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, 18.0, 20.0, 12.0, -20.0, 28.0, 34.0, 28.0, -20.0, -20.0, -20.0, 16.0, 24.0, -20.0, -20.0, 28.0, 28.0, 4.0, 6.0, 4.0, 24.0, -20.0, 28.0, -40.0, -40.0, -20.0, 28.0, -20.0, 26.0, 28.0, 28.0, 28.0, 28.0, -20.0, 20.0, 28.0, -20.0, -20.0, 10.0, -20.0, -20.0, 30.0, 30.0, 24.0, 4.0, 28.0, 8.0, 30.0, 6.0, 28.0, -20.0, 24.0, 8.0, 10.0, 14.0, 0.0, 16.0, 8.0, 6.0, 16.0, -20.0, -20.0, 32.0, 0.0, 28.0, 18.0, 32.0, 28.0, 28.0, 32.0, 34.0, 4.0, 20.0, 12.0, 32.0, 22.0, -20.0, 4.0, -20.0, 10.0, -20.0, 24.0, 6.0, 28.0, 24.0, 28.0, 14.0, 28.0, -20.0, 16.0, -40.0, 8.0, 10.0, 22.0, 12.0, 30.0, -20.0, 24.0, 16.0, -20.0], "episode_lengths": [14, 11, 10, 14, 20, 6, 3, 6, 20, 20, 20, 12, 8, 20, 20, 6, 6, 18, 17, 18, 8, 20, 6, 20, 20, 20, 6, 20, 7, 6, 6, 6, 6, 20, 10, 6, 20, 20, 15, 20, 20, 5, 5, 8, 18, 6, 16, 5, 17, 6, 20, 8, 16, 15, 13, 20, 12, 16, 17, 12, 20, 20, 4, 20, 6, 11, 4, 6, 6, 4, 3, 18, 10, 14, 4, 9, 20, 18, 20, 15, 20, 8, 17, 6, 8, 6, 13, 6, 20, 12, 20, 16, 15, 9, 14, 5, 20, 8, 12, 20], "policy_policy0_reward": [6.0, 9.0, 10.0, 6.0, -10.0, 14.0, 17.0, 14.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 14.0, 14.0, 2.0, 3.0, 2.0, 12.0, -10.0, 14.0, -20.0, -20.0, -10.0, 14.0, -10.0, 13.0, 14.0, 14.0, 14.0, 14.0, -10.0, 10.0, 14.0, -10.0, -10.0, 5.0, -10.0, -10.0, 15.0, 15.0, 12.0, 2.0, 14.0, 4.0, 15.0, 3.0, 14.0, -10.0, 12.0, 4.0, 5.0, 7.0, 0.0, 8.0, 4.0, 3.0, 8.0, -10.0, -10.0, 16.0, 0.0, 14.0, 9.0, 16.0, 14.0, 14.0, 16.0, 17.0, 2.0, 10.0, 6.0, 16.0, 11.0, -10.0, 2.0, -10.0, 5.0, -10.0, 12.0, 3.0, 14.0, 12.0, 14.0, 7.0, 14.0, -10.0, 8.0, -20.0, 4.0, 5.0, 11.0, 6.0, 15.0, -10.0, 12.0, 8.0, -10.0], "policy_policy1_reward": [6.0, 9.0, 10.0, 6.0, -10.0, 14.0, 17.0, 14.0, -10.0, -10.0, -10.0, 8.0, 12.0, -10.0, -10.0, 14.0, 14.0, 2.0, 3.0, 2.0, 12.0, -10.0, 14.0, -20.0, -20.0, -10.0, 14.0, -10.0, 13.0, 14.0, 14.0, 14.0, 14.0, -10.0, 10.0, 14.0, -10.0, -10.0, 5.0, -10.0, -10.0, 15.0, 15.0, 12.0, 2.0, 14.0, 4.0, 15.0, 3.0, 14.0, -10.0, 12.0, 4.0, 5.0, 7.0, 0.0, 8.0, 4.0, 3.0, 8.0, -10.0, -10.0, 16.0, 0.0, 14.0, 9.0, 16.0, 14.0, 14.0, 16.0, 17.0, 2.0, 10.0, 6.0, 16.0, 11.0, -10.0, 2.0, -10.0, 5.0, -10.0, 12.0, 3.0, 14.0, 12.0, 14.0, 7.0, 14.0, -10.0, 8.0, -20.0, 4.0, 5.0, 11.0, 6.0, 15.0, -10.0, 12.0, 8.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2852417708614986, "mean_inference_ms": 1.5418510896063762, "mean_action_processing_ms": 0.10132370787466663, "mean_env_wait_ms": 0.06728329066960734, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10903, "timesteps_this_iter": 32, "agent_timesteps_total": 21806, "timers": {"load_time_ms": 0.426, "load_throughput": 75196.217, "learn_time_ms": 7.134, "learn_throughput": 4485.557, "update_time_ms": 4.311}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.0150299072265625, "min_q": -3.588446617126465, "max_q": 9.965612411499023, "mean_td_error": -0.12075597792863846, "model": {}}, "td_error": [-8.883025169372559, 1.131911277770996, -0.13797855377197266, -6.992007732391357, -0.5037169456481934, 1.161865234375, 1.8453998565673828, -0.28517913818359375, -0.18423223495483398, -2.110116481781006, -1.182283639907837, 3.1389498710632324, 1.7953044176101685, 0.039589881896972656, 0.5377928614616394, 0.7942543029785156, 0.6552705764770508, -0.6755867004394531, 2.1662237644195557, -0.6322705745697021, 0.16598224639892578, 1.8434970378875732, 0.28597211837768555, -1.4707436561584473, -1.2504111528396606, -0.18853521347045898, 0.7781753540039062, 2.257725238800049, -0.4228057861328125, -0.1191052794456482, 0.9485337734222412, 1.6273584365844727], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.971120834350586, "min_q": -14.428485870361328, "max_q": -7.061098098754883, "mean_td_error": -1.8448988199234009, "model": {}}, "td_error": [-3.683070182800293, -0.9951200485229492, -12.09366512298584, -3.281858444213867, 0.0975179672241211, -0.13107013702392578, -0.7666959762573242, -5.309679985046387, 1.4670944213867188, -11.57614517211914, 0.6010408401489258, -0.8563022613525391, -0.09233760833740234, 0.6711397171020508, -0.09868717193603516, 0.19142532348632812, 1.2616519927978516, -0.3118267059326172, 1.0649223327636719, -20.214244842529297, -3.807610511779785, 0.13104629516601562, -0.7397127151489258, 1.1445646286010742, 2.508546829223633, -0.47123241424560547, -0.9390630722045898, -0.8644866943359375, 0.9124355316162109, 1.9791278839111328, -1.3236417770385742, -3.5108261108398438], "custom_metrics": {}}}, "num_steps_sampled": 10903, "num_agent_steps_sampled": 21806, "num_steps_trained": 19808, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 39616, "last_target_update_ts": 10903, "num_target_updates": 90}, "done": false, "episodes_total": 679, "training_iteration": 32, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-16", "timestamp": 1648811536, "time_this_iter_s": 1.4076666831970215, "time_total_s": 40.89869427680969, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 40.89869427680969, "timesteps_since_restore": 1024, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 16.15, "ram_util_percent": 35.849999999999994}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 7.82, "episode_len_mean": 13.19, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 3.91, "policy1": 3.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 28.0, -40.0, -40.0, -20.0, 28.0, -20.0, 26.0, 28.0, 28.0, 28.0, 28.0, -20.0, 20.0, 28.0, -20.0, -20.0, 10.0, -20.0, -20.0, 30.0, 30.0, 24.0, 4.0, 28.0, 8.0, 30.0, 6.0, 28.0, -20.0, 24.0, 8.0, 10.0, 14.0, 0.0, 16.0, 8.0, 6.0, 16.0, -20.0, -20.0, 32.0, 0.0, 28.0, 18.0, 32.0, 28.0, 28.0, 32.0, 34.0, 4.0, 20.0, 12.0, 32.0, 22.0, -20.0, 4.0, -20.0, 10.0, -20.0, 24.0, 6.0, 28.0, 24.0, 28.0, 14.0, 28.0, -20.0, 16.0, -40.0, 8.0, 10.0, 22.0, 12.0, 30.0, -20.0, 24.0, 16.0, -20.0, 8.0, -20.0, -20.0, 8.0, 18.0, 8.0, 28.0, 4.0, -20.0, 28.0, -20.0, 0.0, 6.0, -20.0, 20.0, 4.0, 10.0, 28.0, 4.0, 20.0, -20.0], "episode_lengths": [20, 6, 20, 20, 20, 6, 20, 7, 6, 6, 6, 6, 20, 10, 6, 20, 20, 15, 20, 20, 5, 5, 8, 18, 6, 16, 5, 17, 6, 20, 8, 16, 15, 13, 20, 12, 16, 17, 12, 20, 20, 4, 20, 6, 11, 4, 6, 6, 4, 3, 18, 10, 14, 4, 9, 20, 18, 20, 15, 20, 8, 17, 6, 8, 6, 13, 6, 20, 12, 20, 16, 15, 9, 14, 5, 20, 8, 12, 20, 16, 20, 20, 16, 11, 16, 6, 18, 20, 6, 20, 20, 17, 20, 10, 18, 15, 6, 18, 10, 20], "policy_policy0_reward": [-10.0, 14.0, -20.0, -20.0, -10.0, 14.0, -10.0, 13.0, 14.0, 14.0, 14.0, 14.0, -10.0, 10.0, 14.0, -10.0, -10.0, 5.0, -10.0, -10.0, 15.0, 15.0, 12.0, 2.0, 14.0, 4.0, 15.0, 3.0, 14.0, -10.0, 12.0, 4.0, 5.0, 7.0, 0.0, 8.0, 4.0, 3.0, 8.0, -10.0, -10.0, 16.0, 0.0, 14.0, 9.0, 16.0, 14.0, 14.0, 16.0, 17.0, 2.0, 10.0, 6.0, 16.0, 11.0, -10.0, 2.0, -10.0, 5.0, -10.0, 12.0, 3.0, 14.0, 12.0, 14.0, 7.0, 14.0, -10.0, 8.0, -20.0, 4.0, 5.0, 11.0, 6.0, 15.0, -10.0, 12.0, 8.0, -10.0, 4.0, -10.0, -10.0, 4.0, 9.0, 4.0, 14.0, 2.0, -10.0, 14.0, -10.0, 0.0, 3.0, -10.0, 10.0, 2.0, 5.0, 14.0, 2.0, 10.0, -10.0], "policy_policy1_reward": [-10.0, 14.0, -20.0, -20.0, -10.0, 14.0, -10.0, 13.0, 14.0, 14.0, 14.0, 14.0, -10.0, 10.0, 14.0, -10.0, -10.0, 5.0, -10.0, -10.0, 15.0, 15.0, 12.0, 2.0, 14.0, 4.0, 15.0, 3.0, 14.0, -10.0, 12.0, 4.0, 5.0, 7.0, 0.0, 8.0, 4.0, 3.0, 8.0, -10.0, -10.0, 16.0, 0.0, 14.0, 9.0, 16.0, 14.0, 14.0, 16.0, 17.0, 2.0, 10.0, 6.0, 16.0, 11.0, -10.0, 2.0, -10.0, 5.0, -10.0, 12.0, 3.0, 14.0, 12.0, 14.0, 7.0, 14.0, -10.0, 8.0, -20.0, 4.0, 5.0, 11.0, 6.0, 15.0, -10.0, 12.0, 8.0, -10.0, 4.0, -10.0, -10.0, 4.0, 9.0, 4.0, 14.0, 2.0, -10.0, 14.0, -10.0, 0.0, 3.0, -10.0, 10.0, 2.0, 5.0, 14.0, 2.0, 10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28528550907861655, "mean_inference_ms": 1.5408970906408386, "mean_action_processing_ms": 0.10120047227612224, "mean_env_wait_ms": 0.06720573760982233, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11226, "timesteps_this_iter": 32, "agent_timesteps_total": 22452, "timers": {"load_time_ms": 0.446, "load_throughput": 71712.828, "learn_time_ms": 7.557, "learn_throughput": 4234.559, "update_time_ms": 4.801}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.194719314575195, "min_q": -2.4954161643981934, "max_q": 11.657461166381836, "mean_td_error": 0.6357347965240479, "model": {}}, "td_error": [2.6813912391662598, -2.6980600357055664, 0.23590946197509766, 0.32982301712036133, 0.6231803894042969, -3.8587446212768555, 2.0222907066345215, -0.6596746444702148, 0.40283775329589844, -3.751408576965332, -4.907803535461426, 5.960991382598877, 4.591231346130371, -0.27724790573120117, 1.8228508234024048, 0.4323549270629883, 0.9158425331115723, -0.3876149654388428, 0.7921296954154968, 1.2533912658691406, 1.6431941986083984, 3.945552349090576, 1.513106346130371, 1.6947166919708252, 1.8785839080810547, -0.5916056632995605, 2.0725865364074707, 0.514888346195221, 1.5866107940673828, -0.3618640899658203, -1.8004379272460938, 2.724513053894043], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.742242813110352, "min_q": -14.917315483093262, "max_q": -6.811950206756592, "mean_td_error": -4.222273349761963, "model": {}}, "td_error": [-20.242990493774414, 0.2019186019897461, 1.4392590522766113, 1.5485343933105469, -18.513731002807617, 2.609847068786621, 1.359084129333496, -0.26059722900390625, -0.07132911682128906, -6.029511451721191, -18.744319915771484, 1.1738815307617188, 0.18323421478271484, -3.1119604110717773, -18.08173370361328, 0.9581785202026367, 1.4777755737304688, -6.461485862731934, 0.03853893280029297, -0.44028377532958984, 0.46253395080566406, -17.80249786376953, -6.937492370605469, 0.6372547149658203, -1.3207893371582031, 0.6922874450683594, 0.6128501892089844, 0.35437679290771484, -20.613304138183594, -12.584593772888184, 2.614924907684326, -0.26059722900390625], "custom_metrics": {}}}, "num_steps_sampled": 11226, "num_agent_steps_sampled": 22452, "num_steps_trained": 20480, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 40960, "last_target_update_ts": 11226, "num_target_updates": 93}, "done": false, "episodes_total": 700, "training_iteration": 33, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-17", "timestamp": 1648811537, "time_this_iter_s": 1.2330656051635742, "time_total_s": 42.13175988197327, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 42.13175988197327, "timesteps_since_restore": 1056, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 16.200000000000003, "ram_util_percent": 35.9}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 8.32, "episode_len_mean": 13.44, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 4.16, "policy1": 4.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, 4.0, 28.0, 8.0, 30.0, 6.0, 28.0, -20.0, 24.0, 8.0, 10.0, 14.0, 0.0, 16.0, 8.0, 6.0, 16.0, -20.0, -20.0, 32.0, 0.0, 28.0, 18.0, 32.0, 28.0, 28.0, 32.0, 34.0, 4.0, 20.0, 12.0, 32.0, 22.0, -20.0, 4.0, -20.0, 10.0, -20.0, 24.0, 6.0, 28.0, 24.0, 28.0, 14.0, 28.0, -20.0, 16.0, -40.0, 8.0, 10.0, 22.0, 12.0, 30.0, -20.0, 24.0, 16.0, -20.0, 8.0, -20.0, -20.0, 8.0, 18.0, 8.0, 28.0, 4.0, -20.0, 28.0, -20.0, 0.0, 6.0, -20.0, 20.0, 4.0, 10.0, 28.0, 4.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, 20.0, 12.0, 24.0, 4.0, 22.0, 14.0, 20.0, 24.0, 16.0, 24.0, 24.0, -20.0, 4.0, -20.0, 20.0, 28.0, -20.0], "episode_lengths": [8, 18, 6, 16, 5, 17, 6, 20, 8, 16, 15, 13, 20, 12, 16, 17, 12, 20, 20, 4, 20, 6, 11, 4, 6, 6, 4, 3, 18, 10, 14, 4, 9, 20, 18, 20, 15, 20, 8, 17, 6, 8, 6, 13, 6, 20, 12, 20, 16, 15, 9, 14, 5, 20, 8, 12, 20, 16, 20, 20, 16, 11, 16, 6, 18, 20, 6, 20, 20, 17, 20, 10, 18, 15, 6, 18, 10, 20, 20, 20, 20, 20, 17, 10, 14, 8, 18, 9, 13, 10, 8, 12, 8, 8, 20, 18, 20, 10, 6, 20], "policy_policy0_reward": [12.0, 2.0, 14.0, 4.0, 15.0, 3.0, 14.0, -10.0, 12.0, 4.0, 5.0, 7.0, 0.0, 8.0, 4.0, 3.0, 8.0, -10.0, -10.0, 16.0, 0.0, 14.0, 9.0, 16.0, 14.0, 14.0, 16.0, 17.0, 2.0, 10.0, 6.0, 16.0, 11.0, -10.0, 2.0, -10.0, 5.0, -10.0, 12.0, 3.0, 14.0, 12.0, 14.0, 7.0, 14.0, -10.0, 8.0, -20.0, 4.0, 5.0, 11.0, 6.0, 15.0, -10.0, 12.0, 8.0, -10.0, 4.0, -10.0, -10.0, 4.0, 9.0, 4.0, 14.0, 2.0, -10.0, 14.0, -10.0, 0.0, 3.0, -10.0, 10.0, 2.0, 5.0, 14.0, 2.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 10.0, 6.0, 12.0, 2.0, 11.0, 7.0, 10.0, 12.0, 8.0, 12.0, 12.0, -10.0, 2.0, -10.0, 10.0, 14.0, -10.0], "policy_policy1_reward": [12.0, 2.0, 14.0, 4.0, 15.0, 3.0, 14.0, -10.0, 12.0, 4.0, 5.0, 7.0, 0.0, 8.0, 4.0, 3.0, 8.0, -10.0, -10.0, 16.0, 0.0, 14.0, 9.0, 16.0, 14.0, 14.0, 16.0, 17.0, 2.0, 10.0, 6.0, 16.0, 11.0, -10.0, 2.0, -10.0, 5.0, -10.0, 12.0, 3.0, 14.0, 12.0, 14.0, 7.0, 14.0, -10.0, 8.0, -20.0, 4.0, 5.0, 11.0, 6.0, 15.0, -10.0, 12.0, 8.0, -10.0, 4.0, -10.0, -10.0, 4.0, 9.0, 4.0, 14.0, 2.0, -10.0, 14.0, -10.0, 0.0, 3.0, -10.0, 10.0, 2.0, 5.0, 14.0, 2.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 10.0, 6.0, 12.0, 2.0, 11.0, 7.0, 10.0, 12.0, 8.0, 12.0, 12.0, -10.0, 2.0, -10.0, 10.0, 14.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28530112582216627, "mean_inference_ms": 1.5399375504745973, "mean_action_processing_ms": 0.10109914788361266, "mean_env_wait_ms": 0.06712790177465973, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11535, "timesteps_this_iter": 32, "agent_timesteps_total": 23070, "timers": {"load_time_ms": 0.445, "load_throughput": 71962.752, "learn_time_ms": 7.367, "learn_throughput": 4343.588, "update_time_ms": 4.637}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.890237808227539, "min_q": -3.8884525299072266, "max_q": 13.544395446777344, "mean_td_error": -0.1931857168674469, "model": {}}, "td_error": [0.28184938430786133, 1.1124145984649658, -0.27311038970947266, 1.0253019332885742, 0.5180482864379883, 0.16203951835632324, 1.3271632194519043, 0.15071916580200195, 2.167695999145508, -9.0562162399292, 2.308640956878662, -0.5651671886444092, 2.1129627227783203, -0.5135250091552734, 0.15053129196166992, 4.6239752769470215, 0.7146506309509277, 0.47249269485473633, 0.22973012924194336, 0.1258912980556488, 1.0805549621582031, 0.11143875122070312, -5.269108772277832, -2.115812301635742, -3.3591017723083496, -3.5328307151794434, -0.5287327766418457, 1.9501094818115234, -1.8494168519973755, 0.3240630626678467, -0.448333740234375, 0.37913990020751953], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.032352447509766, "min_q": -15.54964542388916, "max_q": -6.321518898010254, "mean_td_error": -3.2342758178710938, "model": {}}, "td_error": [1.7689447402954102, -4.203118324279785, 1.6174325942993164, -12.811484336853027, 0.4699544906616211, -5.797182083129883, -18.14783477783203, -12.743595123291016, -0.6410493850708008, -0.3487825393676758, -3.6899185180664062, -0.7177472114562988, 0.33181190490722656, 1.5587644577026367, -0.7454061508178711, 2.1340036392211914, -1.9815192222595215, 1.210775375366211, -1.0765795707702637, -1.3813629150390625, -0.00206756591796875, 1.6449241638183594, -2.0507116317749023, -6.787745475769043, -0.8157796859741211, -17.116870880126953, -22.093673706054688, 0.4828767776489258, 0.3743715286254883, -2.391608238220215, -0.1079092025756836, 0.5612611770629883], "custom_metrics": {}}}, "num_steps_sampled": 11535, "num_agent_steps_sampled": 23070, "num_steps_trained": 21184, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 42368, "last_target_update_ts": 11441, "num_target_updates": 95}, "done": false, "episodes_total": 722, "training_iteration": 34, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-18", "timestamp": 1648811538, "time_this_iter_s": 1.2578027248382568, "time_total_s": 43.38956260681152, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 43.38956260681152, "timesteps_since_restore": 1088, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 14.9, "ram_util_percent": 35.9}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 7.14, "episode_len_mean": 13.83, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 3.57, "policy1": 3.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 18.0, 32.0, 28.0, 28.0, 32.0, 34.0, 4.0, 20.0, 12.0, 32.0, 22.0, -20.0, 4.0, -20.0, 10.0, -20.0, 24.0, 6.0, 28.0, 24.0, 28.0, 14.0, 28.0, -20.0, 16.0, -40.0, 8.0, 10.0, 22.0, 12.0, 30.0, -20.0, 24.0, 16.0, -20.0, 8.0, -20.0, -20.0, 8.0, 18.0, 8.0, 28.0, 4.0, -20.0, 28.0, -20.0, 0.0, 6.0, -20.0, 20.0, 4.0, 10.0, 28.0, 4.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, 20.0, 12.0, 24.0, 4.0, 22.0, 14.0, 20.0, 24.0, 16.0, 24.0, 24.0, -20.0, 4.0, -20.0, 20.0, 28.0, -20.0, 16.0, 20.0, 2.0, -40.0, 12.0, 2.0, 20.0, 8.0, 8.0, 20.0, 24.0, 24.0, 2.0, -20.0, 8.0, 6.0, -20.0, 4.0, 8.0, 0.0, -20.0], "episode_lengths": [6, 11, 4, 6, 6, 4, 3, 18, 10, 14, 4, 9, 20, 18, 20, 15, 20, 8, 17, 6, 8, 6, 13, 6, 20, 12, 20, 16, 15, 9, 14, 5, 20, 8, 12, 20, 16, 20, 20, 16, 11, 16, 6, 18, 20, 6, 20, 20, 17, 20, 10, 18, 15, 6, 18, 10, 20, 20, 20, 20, 20, 17, 10, 14, 8, 18, 9, 13, 10, 8, 12, 8, 8, 20, 18, 20, 10, 6, 20, 12, 10, 19, 20, 14, 19, 10, 16, 16, 10, 8, 8, 19, 20, 16, 17, 20, 18, 16, 20, 20], "policy_policy0_reward": [14.0, 9.0, 16.0, 14.0, 14.0, 16.0, 17.0, 2.0, 10.0, 6.0, 16.0, 11.0, -10.0, 2.0, -10.0, 5.0, -10.0, 12.0, 3.0, 14.0, 12.0, 14.0, 7.0, 14.0, -10.0, 8.0, -20.0, 4.0, 5.0, 11.0, 6.0, 15.0, -10.0, 12.0, 8.0, -10.0, 4.0, -10.0, -10.0, 4.0, 9.0, 4.0, 14.0, 2.0, -10.0, 14.0, -10.0, 0.0, 3.0, -10.0, 10.0, 2.0, 5.0, 14.0, 2.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 10.0, 6.0, 12.0, 2.0, 11.0, 7.0, 10.0, 12.0, 8.0, 12.0, 12.0, -10.0, 2.0, -10.0, 10.0, 14.0, -10.0, 8.0, 10.0, 1.0, -20.0, 6.0, 1.0, 10.0, 4.0, 4.0, 10.0, 12.0, 12.0, 1.0, -10.0, 4.0, 3.0, -10.0, 2.0, 4.0, 0.0, -10.0], "policy_policy1_reward": [14.0, 9.0, 16.0, 14.0, 14.0, 16.0, 17.0, 2.0, 10.0, 6.0, 16.0, 11.0, -10.0, 2.0, -10.0, 5.0, -10.0, 12.0, 3.0, 14.0, 12.0, 14.0, 7.0, 14.0, -10.0, 8.0, -20.0, 4.0, 5.0, 11.0, 6.0, 15.0, -10.0, 12.0, 8.0, -10.0, 4.0, -10.0, -10.0, 4.0, 9.0, 4.0, 14.0, 2.0, -10.0, 14.0, -10.0, 0.0, 3.0, -10.0, 10.0, 2.0, 5.0, 14.0, 2.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 10.0, 6.0, 12.0, 2.0, 11.0, 7.0, 10.0, 12.0, 8.0, 12.0, 12.0, -10.0, 2.0, -10.0, 10.0, 14.0, -10.0, 8.0, 10.0, 1.0, -20.0, 6.0, 1.0, 10.0, 4.0, 4.0, 10.0, 12.0, 12.0, 1.0, -10.0, 4.0, 3.0, -10.0, 2.0, 4.0, 0.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2852854166738028, "mean_inference_ms": 1.5388692320537771, "mean_action_processing_ms": 0.1010135421925295, "mean_env_wait_ms": 0.06705393492575898, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11863, "timesteps_this_iter": 32, "agent_timesteps_total": 23726, "timers": {"load_time_ms": 0.423, "load_throughput": 75636.928, "learn_time_ms": 7.303, "learn_throughput": 4381.947, "update_time_ms": 4.932}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.1621663570404053, "min_q": -6.420190811157227, "max_q": 9.687400817871094, "mean_td_error": -0.4048077464103699, "model": {}}, "td_error": [2.5897836685180664, -0.44298839569091797, 0.2971804141998291, -0.3076450824737549, 0.15630817413330078, 0.24216818809509277, 0.5755786895751953, 0.1761455535888672, -9.550490379333496, 1.642387866973877, 0.4085884094238281, 2.9808125495910645, 1.4371970891952515, 0.2512122392654419, -3.106058359146118, 0.143662691116333, 1.8532845973968506, -1.5397329330444336, 1.3064923286437988, 0.23067474365234375, -1.0123920440673828, -3.4387383460998535, 1.57465398311615, 1.6573307514190674, -0.6446447372436523, -1.3611869812011719, 0.2699306011199951, -5.352904319763184, -0.13694190979003906, -0.00647890567779541, 0.2470133900642395, -4.094051361083984], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.680196762084961, "min_q": -17.730728149414062, "max_q": -0.8741273880004883, "mean_td_error": -2.412992477416992, "model": {}}, "td_error": [-8.250247955322266, 1.6008272171020508, 1.4481401443481445, 0.8295950889587402, -0.4209861755371094, 0.9104490280151367, 1.273146390914917, -9.874127388000488, 1.902991771697998, -14.109689712524414, 0.11846160888671875, 3.592034339904785, 0.9636669158935547, -16.730728149414062, 2.0755605697631836, -0.316129207611084, 1.9862775802612305, -13.303128242492676, 1.0801429748535156, 3.29034423828125, -11.362587928771973, 3.5561490058898926, 1.5945053100585938, 0.5360736846923828, -0.5606937408447266, -1.0094327926635742, -16.019058227539062, 1.3549795150756836, -7.036368370056152, -8.425644874572754, 0.720698356628418, 1.3690180778503418], "custom_metrics": {}}}, "num_steps_sampled": 11863, "num_agent_steps_sampled": 23726, "num_steps_trained": 21856, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 43712, "last_target_update_ts": 11769, "num_target_updates": 98}, "done": false, "episodes_total": 743, "training_iteration": 35, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-20", "timestamp": 1648811540, "time_this_iter_s": 1.247938632965088, "time_total_s": 44.63750123977661, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 44.63750123977661, "timesteps_since_restore": 1120, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 13.55, "ram_util_percent": 35.9}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": 4.54, "episode_len_mean": 14.73, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": 2.27, "policy1": 2.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 14.0, 28.0, -20.0, 16.0, -40.0, 8.0, 10.0, 22.0, 12.0, 30.0, -20.0, 24.0, 16.0, -20.0, 8.0, -20.0, -20.0, 8.0, 18.0, 8.0, 28.0, 4.0, -20.0, 28.0, -20.0, 0.0, 6.0, -20.0, 20.0, 4.0, 10.0, 28.0, 4.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, 20.0, 12.0, 24.0, 4.0, 22.0, 14.0, 20.0, 24.0, 16.0, 24.0, 24.0, -20.0, 4.0, -20.0, 20.0, 28.0, -20.0, 16.0, 20.0, 2.0, -40.0, 12.0, 2.0, 20.0, 8.0, 8.0, 20.0, 24.0, 24.0, 2.0, -20.0, 8.0, 6.0, -20.0, 4.0, 8.0, 0.0, -20.0, 16.0, -20.0, 8.0, -20.0, 16.0, 24.0, 16.0, 16.0, -20.0, 0.0, -20.0, 20.0, 8.0, 20.0, -20.0, 20.0, -20.0, -20.0, 16.0, 18.0, 8.0], "episode_lengths": [6, 13, 6, 20, 12, 20, 16, 15, 9, 14, 5, 20, 8, 12, 20, 16, 20, 20, 16, 11, 16, 6, 18, 20, 6, 20, 20, 17, 20, 10, 18, 15, 6, 18, 10, 20, 20, 20, 20, 20, 17, 10, 14, 8, 18, 9, 13, 10, 8, 12, 8, 8, 20, 18, 20, 10, 6, 20, 12, 10, 19, 20, 14, 19, 10, 16, 16, 10, 8, 8, 19, 20, 16, 17, 20, 18, 16, 20, 20, 12, 20, 16, 20, 12, 8, 12, 12, 20, 20, 20, 10, 16, 10, 20, 10, 20, 20, 12, 11, 16], "policy_policy0_reward": [14.0, 7.0, 14.0, -10.0, 8.0, -20.0, 4.0, 5.0, 11.0, 6.0, 15.0, -10.0, 12.0, 8.0, -10.0, 4.0, -10.0, -10.0, 4.0, 9.0, 4.0, 14.0, 2.0, -10.0, 14.0, -10.0, 0.0, 3.0, -10.0, 10.0, 2.0, 5.0, 14.0, 2.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 10.0, 6.0, 12.0, 2.0, 11.0, 7.0, 10.0, 12.0, 8.0, 12.0, 12.0, -10.0, 2.0, -10.0, 10.0, 14.0, -10.0, 8.0, 10.0, 1.0, -20.0, 6.0, 1.0, 10.0, 4.0, 4.0, 10.0, 12.0, 12.0, 1.0, -10.0, 4.0, 3.0, -10.0, 2.0, 4.0, 0.0, -10.0, 8.0, -10.0, 4.0, -10.0, 8.0, 12.0, 8.0, 8.0, -10.0, 0.0, -10.0, 10.0, 4.0, 10.0, -10.0, 10.0, -10.0, -10.0, 8.0, 9.0, 4.0], "policy_policy1_reward": [14.0, 7.0, 14.0, -10.0, 8.0, -20.0, 4.0, 5.0, 11.0, 6.0, 15.0, -10.0, 12.0, 8.0, -10.0, 4.0, -10.0, -10.0, 4.0, 9.0, 4.0, 14.0, 2.0, -10.0, 14.0, -10.0, 0.0, 3.0, -10.0, 10.0, 2.0, 5.0, 14.0, 2.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 10.0, 6.0, 12.0, 2.0, 11.0, 7.0, 10.0, 12.0, 8.0, 12.0, 12.0, -10.0, 2.0, -10.0, 10.0, 14.0, -10.0, 8.0, 10.0, 1.0, -20.0, 6.0, 1.0, 10.0, 4.0, 4.0, 10.0, 12.0, 12.0, 1.0, -10.0, 4.0, 3.0, -10.0, 2.0, 4.0, 0.0, -10.0, 8.0, -10.0, 4.0, -10.0, 8.0, 12.0, 8.0, 8.0, -10.0, 0.0, -10.0, 10.0, 4.0, 10.0, -10.0, 10.0, -10.0, -10.0, 8.0, 9.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2852319024682542, "mean_inference_ms": 1.5375875799083152, "mean_action_processing_ms": 0.10093392409678746, "mean_env_wait_ms": 0.06698497822067054, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12180, "timesteps_this_iter": 32, "agent_timesteps_total": 24360, "timers": {"load_time_ms": 0.418, "load_throughput": 76525.302, "learn_time_ms": 6.8, "learn_throughput": 4706.075, "update_time_ms": 4.664}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 1.6845781803131104, "min_q": -5.0462517738342285, "max_q": 8.095492362976074, "mean_td_error": -0.03299658000469208, "model": {}}, "td_error": [0.914867639541626, -0.17677640914916992, 0.6906156539916992, -0.681574821472168, -0.596646785736084, -0.2894020080566406, -0.11177109181880951, -1.0229387283325195, 0.03333711624145508, 4.072486400604248, -0.16252517700195312, 1.5203624963760376, 1.125533103942871, -0.5313091278076172, -0.07956719398498535, -1.028455376625061, -4.0462517738342285, 0.22577285766601562, 2.1027793884277344, -1.022966980934143, 2.57084321975708, 0.8752541542053223, -1.1681065559387207, -0.7804836630821228, 2.438845634460449, -1.0326611995697021, -7.229660511016846, 0.7023875713348389, 0.24237918853759766, 1.4387973546981812, -0.14666271209716797, 0.09760808944702148], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -9.635025024414062, "min_q": -17.13189697265625, "max_q": -0.795734167098999, "mean_td_error": -5.223695755004883, "model": {}}, "td_error": [1.1770687103271484, -1.3904094696044922, 1.091902732849121, 1.0606002807617188, -12.893211364746094, -1.476480484008789, -0.7858419418334961, -22.30982208251953, -1.3532323837280273, -14.260361671447754, -13.34139347076416, -24.562763214111328, -2.298065662384033, -0.6206464767456055, -1.9627766609191895, 0.0012989044189453125, -3.372109889984131, -0.1564922332763672, 0.3501625061035156, -2.424135208129883, 0.07082462310791016, -1.903315544128418, -9.715191841125488, 0.13659095764160156, -3.111260414123535, -1.879396915435791, -9.795734405517578, -11.352770805358887, -2.107304573059082, -12.091378211975098, -15.499984741210938, -0.38263893127441406], "custom_metrics": {}}}, "num_steps_sampled": 12180, "num_agent_steps_sampled": 24360, "num_steps_trained": 22528, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 45056, "last_target_update_ts": 12101, "num_target_updates": 101}, "done": false, "episodes_total": 764, "training_iteration": 36, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-21", "timestamp": 1648811541, "time_this_iter_s": 1.220933198928833, "time_total_s": 45.858434438705444, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 45.858434438705444, "timesteps_since_restore": 1152, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 15.350000000000001, "ram_util_percent": 35.9}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": 3.82, "episode_len_mean": 14.89, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": 1.91, "policy1": 1.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, -20.0, -20.0, 8.0, 18.0, 8.0, 28.0, 4.0, -20.0, 28.0, -20.0, 0.0, 6.0, -20.0, 20.0, 4.0, 10.0, 28.0, 4.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, 20.0, 12.0, 24.0, 4.0, 22.0, 14.0, 20.0, 24.0, 16.0, 24.0, 24.0, -20.0, 4.0, -20.0, 20.0, 28.0, -20.0, 16.0, 20.0, 2.0, -40.0, 12.0, 2.0, 20.0, 8.0, 8.0, 20.0, 24.0, 24.0, 2.0, -20.0, 8.0, 6.0, -20.0, 4.0, 8.0, 0.0, -20.0, 16.0, -20.0, 8.0, -20.0, 16.0, 24.0, 16.0, 16.0, -20.0, 0.0, -20.0, 20.0, 8.0, 20.0, -20.0, 20.0, -20.0, -20.0, 16.0, 18.0, 8.0, 18.0, 4.0, -20.0, 24.0, 20.0, -20.0, 28.0, 12.0, -20.0, 18.0, 28.0, 24.0, -40.0, -20.0, -20.0], "episode_lengths": [16, 20, 20, 16, 11, 16, 6, 18, 20, 6, 20, 20, 17, 20, 10, 18, 15, 6, 18, 10, 20, 20, 20, 20, 20, 17, 10, 14, 8, 18, 9, 13, 10, 8, 12, 8, 8, 20, 18, 20, 10, 6, 20, 12, 10, 19, 20, 14, 19, 10, 16, 16, 10, 8, 8, 19, 20, 16, 17, 20, 18, 16, 20, 20, 12, 20, 16, 20, 12, 8, 12, 12, 20, 20, 20, 10, 16, 10, 20, 10, 20, 20, 12, 11, 16, 11, 18, 20, 8, 10, 20, 6, 14, 20, 11, 6, 8, 20, 20, 20], "policy_policy0_reward": [4.0, -10.0, -10.0, 4.0, 9.0, 4.0, 14.0, 2.0, -10.0, 14.0, -10.0, 0.0, 3.0, -10.0, 10.0, 2.0, 5.0, 14.0, 2.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 10.0, 6.0, 12.0, 2.0, 11.0, 7.0, 10.0, 12.0, 8.0, 12.0, 12.0, -10.0, 2.0, -10.0, 10.0, 14.0, -10.0, 8.0, 10.0, 1.0, -20.0, 6.0, 1.0, 10.0, 4.0, 4.0, 10.0, 12.0, 12.0, 1.0, -10.0, 4.0, 3.0, -10.0, 2.0, 4.0, 0.0, -10.0, 8.0, -10.0, 4.0, -10.0, 8.0, 12.0, 8.0, 8.0, -10.0, 0.0, -10.0, 10.0, 4.0, 10.0, -10.0, 10.0, -10.0, -10.0, 8.0, 9.0, 4.0, 9.0, 2.0, -10.0, 12.0, 10.0, -10.0, 14.0, 6.0, -10.0, 9.0, 14.0, 12.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [4.0, -10.0, -10.0, 4.0, 9.0, 4.0, 14.0, 2.0, -10.0, 14.0, -10.0, 0.0, 3.0, -10.0, 10.0, 2.0, 5.0, 14.0, 2.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 10.0, 6.0, 12.0, 2.0, 11.0, 7.0, 10.0, 12.0, 8.0, 12.0, 12.0, -10.0, 2.0, -10.0, 10.0, 14.0, -10.0, 8.0, 10.0, 1.0, -20.0, 6.0, 1.0, 10.0, 4.0, 4.0, 10.0, 12.0, 12.0, 1.0, -10.0, 4.0, 3.0, -10.0, 2.0, 4.0, 0.0, -10.0, 8.0, -10.0, 4.0, -10.0, 8.0, 12.0, 8.0, 8.0, -10.0, 0.0, -10.0, 10.0, 4.0, 10.0, -10.0, 10.0, -10.0, -10.0, 8.0, 9.0, 4.0, 9.0, 2.0, -10.0, 12.0, 10.0, -10.0, 14.0, 6.0, -10.0, 9.0, 14.0, 12.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28516761400029755, "mean_inference_ms": 1.536530001679647, "mean_action_processing_ms": 0.10087184440580028, "mean_env_wait_ms": 0.06693605185074364, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12392, "timesteps_this_iter": 32, "agent_timesteps_total": 24784, "timers": {"load_time_ms": 0.424, "load_throughput": 75466.814, "learn_time_ms": 7.133, "learn_throughput": 4486.187, "update_time_ms": 4.536}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.5113027095794678, "min_q": -4.600282669067383, "max_q": 11.916229248046875, "mean_td_error": -0.5902063846588135, "model": {}}, "td_error": [-0.5444602966308594, 0.9802050590515137, 1.7850477695465088, -0.009721517562866211, -2.7921595573425293, 0.7760567665100098, 0.6420217752456665, -2.919797658920288, 0.924583911895752, 0.5553855895996094, -0.003107726573944092, 0.645228385925293, 0.3167678117752075, 2.8482413291931152, -2.8468525409698486, 0.5044901371002197, 0.3496980667114258, 0.3179636001586914, -2.032104253768921, 3.010011672973633, -1.589287519454956, 3.7426843643188477, -7.614432334899902, -0.7721242904663086, -3.2493114471435547, 0.5303487777709961, 1.3807311058044434, 1.7606201171875, -11.421021461486816, -8.465153694152832, 0.3504800796508789, 3.952364683151245], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.91877269744873, "min_q": -15.878173828125, "max_q": -0.2634091377258301, "mean_td_error": -2.892557144165039, "model": {}}, "td_error": [0.44875240325927734, 0.4856834411621094, -0.30583858489990234, 0.15798282623291016, -21.25612449645996, -15.674623489379883, 0.011606216430664062, -3.057734966278076, 0.7742424011230469, 0.16803455352783203, 0.2805900573730469, -1.700395107269287, -11.775954246520996, -20.634323120117188, 1.4277496337890625, -5.652146816253662, 1.8620424270629883, 0.020918846130371094, 0.9184770584106445, 2.008756637573242, -20.634323120117188, -9.805784225463867, 1.9705562591552734, -0.7497572898864746, 1.7300996780395508, 1.666274070739746, 0.8646594285964966, 1.1199727058410645, 1.4277496337890625, -0.27121829986572266, -0.9338774681091309, 2.5461244583129883], "custom_metrics": {}}}, "num_steps_sampled": 12392, "num_agent_steps_sampled": 24784, "num_steps_trained": 23008, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 46016, "last_target_update_ts": 12318, "num_target_updates": 103}, "done": false, "episodes_total": 779, "training_iteration": 37, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-22", "timestamp": 1648811542, "time_this_iter_s": 0.9727165699005127, "time_total_s": 46.83115100860596, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83efc20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83efc20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 46.83115100860596, "timesteps_since_restore": 1184, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 12.5, "ram_util_percent": 35.9}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": 6.0, "episode_len_mean": 14.1, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": 3.0, "policy1": 3.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, 20.0, 12.0, 24.0, 4.0, 22.0, 14.0, 20.0, 24.0, 16.0, 24.0, 24.0, -20.0, 4.0, -20.0, 20.0, 28.0, -20.0, 16.0, 20.0, 2.0, -40.0, 12.0, 2.0, 20.0, 8.0, 8.0, 20.0, 24.0, 24.0, 2.0, -20.0, 8.0, 6.0, -20.0, 4.0, 8.0, 0.0, -20.0, 16.0, -20.0, 8.0, -20.0, 16.0, 24.0, 16.0, 16.0, -20.0, 0.0, -20.0, 20.0, 8.0, 20.0, -20.0, 20.0, -20.0, -20.0, 16.0, 18.0, 8.0, 18.0, 4.0, -20.0, 24.0, 20.0, -20.0, 28.0, 12.0, -20.0, 18.0, 28.0, 24.0, -40.0, -20.0, -20.0, 20.0, 14.0, 24.0, -20.0, 28.0, 20.0, 12.0, 28.0, 28.0, -20.0, 8.0, 24.0, 12.0, 12.0, 22.0, 20.0, 22.0, 18.0, 20.0], "episode_lengths": [10, 20, 20, 20, 20, 20, 17, 10, 14, 8, 18, 9, 13, 10, 8, 12, 8, 8, 20, 18, 20, 10, 6, 20, 12, 10, 19, 20, 14, 19, 10, 16, 16, 10, 8, 8, 19, 20, 16, 17, 20, 18, 16, 20, 20, 12, 20, 16, 20, 12, 8, 12, 12, 20, 20, 20, 10, 16, 10, 20, 10, 20, 20, 12, 11, 16, 11, 18, 20, 8, 10, 20, 6, 14, 20, 11, 6, 8, 20, 20, 20, 10, 13, 8, 20, 6, 10, 14, 6, 6, 20, 16, 8, 14, 14, 9, 10, 9, 11, 10], "policy_policy0_reward": [10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 10.0, 6.0, 12.0, 2.0, 11.0, 7.0, 10.0, 12.0, 8.0, 12.0, 12.0, -10.0, 2.0, -10.0, 10.0, 14.0, -10.0, 8.0, 10.0, 1.0, -20.0, 6.0, 1.0, 10.0, 4.0, 4.0, 10.0, 12.0, 12.0, 1.0, -10.0, 4.0, 3.0, -10.0, 2.0, 4.0, 0.0, -10.0, 8.0, -10.0, 4.0, -10.0, 8.0, 12.0, 8.0, 8.0, -10.0, 0.0, -10.0, 10.0, 4.0, 10.0, -10.0, 10.0, -10.0, -10.0, 8.0, 9.0, 4.0, 9.0, 2.0, -10.0, 12.0, 10.0, -10.0, 14.0, 6.0, -10.0, 9.0, 14.0, 12.0, -20.0, -10.0, -10.0, 10.0, 7.0, 12.0, -10.0, 14.0, 10.0, 6.0, 14.0, 14.0, -10.0, 4.0, 12.0, 6.0, 6.0, 11.0, 10.0, 11.0, 9.0, 10.0], "policy_policy1_reward": [10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, 10.0, 6.0, 12.0, 2.0, 11.0, 7.0, 10.0, 12.0, 8.0, 12.0, 12.0, -10.0, 2.0, -10.0, 10.0, 14.0, -10.0, 8.0, 10.0, 1.0, -20.0, 6.0, 1.0, 10.0, 4.0, 4.0, 10.0, 12.0, 12.0, 1.0, -10.0, 4.0, 3.0, -10.0, 2.0, 4.0, 0.0, -10.0, 8.0, -10.0, 4.0, -10.0, 8.0, 12.0, 8.0, 8.0, -10.0, 0.0, -10.0, 10.0, 4.0, 10.0, -10.0, 10.0, -10.0, -10.0, 8.0, 9.0, 4.0, 9.0, 2.0, -10.0, 12.0, 10.0, -10.0, 14.0, 6.0, -10.0, 9.0, 14.0, 12.0, -20.0, -10.0, -10.0, 10.0, 7.0, 12.0, -10.0, 14.0, 10.0, 6.0, 14.0, 14.0, -10.0, 4.0, 12.0, 6.0, 6.0, 11.0, 10.0, 11.0, 9.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2851920142648339, "mean_inference_ms": 1.5355073611370387, "mean_action_processing_ms": 0.1008299540014994, "mean_env_wait_ms": 0.06689365066122721, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12606, "timesteps_this_iter": 32, "agent_timesteps_total": 25212, "timers": {"load_time_ms": 0.444, "load_throughput": 72001.356, "learn_time_ms": 7.508, "learn_throughput": 4262.003, "update_time_ms": 4.661}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.203644752502441, "min_q": -4.255309104919434, "max_q": 14.568161010742188, "mean_td_error": 0.029017478227615356, "model": {}}, "td_error": [-3.891630172729492, 0.5974311828613281, 0.9750913381576538, -7.085911750793457, 0.7470970153808594, 1.1558141708374023, 1.7817020416259766, -1.6577696800231934, 1.992763638496399, 1.966273307800293, 0.9097709655761719, -1.1051359176635742, 1.0241737365722656, 2.5834813117980957, 0.8364701271057129, 1.2825899124145508, -1.5175867080688477, 2.1346359252929688, 0.47590482234954834, 0.18138444423675537, 0.9227519035339355, 3.229323148727417, -1.132728099822998, 1.8106377124786377, -0.36365699768066406, 2.0837275981903076, 0.08515501022338867, -1.4373650550842285, 1.6381540298461914, -10.493707656860352, -0.12943601608276367, 1.329155445098877], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.448001861572266, "min_q": -16.011812210083008, "max_q": -3.913865566253662, "mean_td_error": -0.8860434293746948, "model": {}}, "td_error": [-22.516874313354492, 0.5523681640625, 2.282139778137207, -0.0756378173828125, 4.004105567932129, -2.293585777282715, 0.4267134666442871, -4.889498710632324, 1.6763811111450195, -9.298355102539062, 0.815760612487793, 0.5335521697998047, 5.104213714599609, 3.1449432373046875, 1.1822967529296875, 2.4077577590942383, -0.10195541381835938, -2.2064247131347656, 2.860759735107422, 0.8239059448242188, 0.03490877151489258, 0.8851933479309082, -1.2812833786010742, -0.11923336982727051, 0.1869802474975586, -3.30989408493042, 1.132308006286621, 4.622066497802734, 2.9053993225097656, -4.137881278991699, -1.5145454406738281, -12.189977645874023], "custom_metrics": {}}}, "num_steps_sampled": 12606, "num_agent_steps_sampled": 25212, "num_steps_trained": 23616, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 47232, "last_target_update_ts": 12529, "num_target_updates": 105}, "done": false, "episodes_total": 798, "training_iteration": 38, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-23", "timestamp": 1648811543, "time_this_iter_s": 0.9703168869018555, "time_total_s": 47.80146789550781, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 47.80146789550781, "timesteps_since_restore": 1216, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 15.8, "ram_util_percent": 35.9}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": 8.98, "episode_len_mean": 13.21, "episode_media": {}, "episodes_this_iter": 28, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": 4.49, "policy1": 4.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, 2.0, 20.0, 8.0, 8.0, 20.0, 24.0, 24.0, 2.0, -20.0, 8.0, 6.0, -20.0, 4.0, 8.0, 0.0, -20.0, 16.0, -20.0, 8.0, -20.0, 16.0, 24.0, 16.0, 16.0, -20.0, 0.0, -20.0, 20.0, 8.0, 20.0, -20.0, 20.0, -20.0, -20.0, 16.0, 18.0, 8.0, 18.0, 4.0, -20.0, 24.0, 20.0, -20.0, 28.0, 12.0, -20.0, 18.0, 28.0, 24.0, -40.0, -20.0, -20.0, 20.0, 14.0, 24.0, -20.0, 28.0, 20.0, 12.0, 28.0, 28.0, -20.0, 8.0, 24.0, 12.0, 12.0, 22.0, 20.0, 22.0, 18.0, 20.0, 20.0, -20.0, 28.0, 16.0, -20.0, -20.0, 18.0, 28.0, 22.0, 28.0, 20.0, -20.0, 24.0, 24.0, 30.0, 24.0, 16.0, 28.0, 12.0, 8.0, 28.0, 18.0, 24.0, 20.0, 16.0, 12.0, 20.0, 14.0], "episode_lengths": [14, 19, 10, 16, 16, 10, 8, 8, 19, 20, 16, 17, 20, 18, 16, 20, 20, 12, 20, 16, 20, 12, 8, 12, 12, 20, 20, 20, 10, 16, 10, 20, 10, 20, 20, 12, 11, 16, 11, 18, 20, 8, 10, 20, 6, 14, 20, 11, 6, 8, 20, 20, 20, 10, 13, 8, 20, 6, 10, 14, 6, 6, 20, 16, 8, 14, 14, 9, 10, 9, 11, 10, 10, 20, 6, 12, 20, 20, 11, 6, 9, 6, 10, 20, 8, 8, 5, 8, 12, 6, 14, 16, 6, 11, 8, 10, 12, 14, 10, 13], "policy_policy0_reward": [6.0, 1.0, 10.0, 4.0, 4.0, 10.0, 12.0, 12.0, 1.0, -10.0, 4.0, 3.0, -10.0, 2.0, 4.0, 0.0, -10.0, 8.0, -10.0, 4.0, -10.0, 8.0, 12.0, 8.0, 8.0, -10.0, 0.0, -10.0, 10.0, 4.0, 10.0, -10.0, 10.0, -10.0, -10.0, 8.0, 9.0, 4.0, 9.0, 2.0, -10.0, 12.0, 10.0, -10.0, 14.0, 6.0, -10.0, 9.0, 14.0, 12.0, -20.0, -10.0, -10.0, 10.0, 7.0, 12.0, -10.0, 14.0, 10.0, 6.0, 14.0, 14.0, -10.0, 4.0, 12.0, 6.0, 6.0, 11.0, 10.0, 11.0, 9.0, 10.0, 10.0, -10.0, 14.0, 8.0, -10.0, -10.0, 9.0, 14.0, 11.0, 14.0, 10.0, -10.0, 12.0, 12.0, 15.0, 12.0, 8.0, 14.0, 6.0, 4.0, 14.0, 9.0, 12.0, 10.0, 8.0, 6.0, 10.0, 7.0], "policy_policy1_reward": [6.0, 1.0, 10.0, 4.0, 4.0, 10.0, 12.0, 12.0, 1.0, -10.0, 4.0, 3.0, -10.0, 2.0, 4.0, 0.0, -10.0, 8.0, -10.0, 4.0, -10.0, 8.0, 12.0, 8.0, 8.0, -10.0, 0.0, -10.0, 10.0, 4.0, 10.0, -10.0, 10.0, -10.0, -10.0, 8.0, 9.0, 4.0, 9.0, 2.0, -10.0, 12.0, 10.0, -10.0, 14.0, 6.0, -10.0, 9.0, 14.0, 12.0, -20.0, -10.0, -10.0, 10.0, 7.0, 12.0, -10.0, 14.0, 10.0, 6.0, 14.0, 14.0, -10.0, 4.0, 12.0, 6.0, 6.0, 11.0, 10.0, 11.0, 9.0, 10.0, 10.0, -10.0, 14.0, 8.0, -10.0, -10.0, 9.0, 14.0, 11.0, 14.0, 10.0, -10.0, 12.0, 12.0, 15.0, 12.0, 8.0, 14.0, 6.0, 4.0, 14.0, 9.0, 12.0, 10.0, 8.0, 6.0, 10.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2853416792062872, "mean_inference_ms": 1.5339914666173282, "mean_action_processing_ms": 0.10077501000384086, "mean_env_wait_ms": 0.06685699994877957, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12917, "timesteps_this_iter": 32, "agent_timesteps_total": 25834, "timers": {"load_time_ms": 0.431, "load_throughput": 74219.049, "learn_time_ms": 7.658, "learn_throughput": 4178.881, "update_time_ms": 4.671}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.2330849170684814, "min_q": -3.885580062866211, "max_q": 10.700919151306152, "mean_td_error": 0.010624341666698456, "model": {}}, "td_error": [1.3016760349273682, 2.0025148391723633, -1.7217602729797363, 0.4979921579360962, 2.65248703956604, 0.16695894300937653, 0.24934953451156616, -1.7820333242416382, -3.67954683303833, -0.6828479766845703, 0.4059213399887085, -0.6979022026062012, 0.05548882484436035, -3.376741886138916, 1.605733871459961, -0.4275014400482178, 0.08384513854980469, -7.011876106262207, 1.3261351585388184, 1.9996423721313477, 0.8963460922241211, -0.3820796012878418, 3.8474361896514893, -0.4400444030761719, 1.8926538228988647, 0.7939339876174927, 1.7009191513061523, 3.0029001235961914, -2.0265085697174072, 0.4575692415237427, -6.11727237701416, 3.746589422225952], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -9.075246810913086, "min_q": -15.463520050048828, "max_q": 1.3159377574920654, "mean_td_error": -2.830738067626953, "model": {}}, "td_error": [0.9634237289428711, 2.4270248413085938, -0.6182518005371094, -7.6840620040893555, 2.8405604362487793, 2.0474853515625, 1.4423646926879883, -17.809513092041016, 1.118631362915039, -2.4934120178222656, 2.5329360961914062, -7.426675796508789, -13.479242324829102, 0.7008461952209473, -17.075820922851562, -7.966576099395752, -14.244636535644531, -2.4417290687561035, 1.7453136444091797, -2.103422164916992, -6.263643264770508, 1.3063554763793945, -0.4367341995239258, 0.8954324722290039, 1.4582233428955078, 0.44699370861053467, 1.2825400829315186, 0.16290950775146484, 2.0864553451538086, -14.025670051574707, -1.1483168601989746, 1.1765928268432617], "custom_metrics": {}}}, "num_steps_sampled": 12917, "num_agent_steps_sampled": 25834, "num_steps_trained": 24512, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 49024, "last_target_update_ts": 12858, "num_target_updates": 108}, "done": false, "episodes_total": 826, "training_iteration": 39, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-25", "timestamp": 1648811545, "time_this_iter_s": 1.4141523838043213, "time_total_s": 49.215620279312134, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f7b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101f7b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 49.215620279312134, "timesteps_since_restore": 1248, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 16.2, "ram_util_percent": 35.96666666666667}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 13.14, "episode_len_mean": 11.63, "episode_media": {}, "episodes_this_iter": 30, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 6.57, "policy1": 6.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -20.0, 20.0, -20.0, -20.0, 16.0, 18.0, 8.0, 18.0, 4.0, -20.0, 24.0, 20.0, -20.0, 28.0, 12.0, -20.0, 18.0, 28.0, 24.0, -40.0, -20.0, -20.0, 20.0, 14.0, 24.0, -20.0, 28.0, 20.0, 12.0, 28.0, 28.0, -20.0, 8.0, 24.0, 12.0, 12.0, 22.0, 20.0, 22.0, 18.0, 20.0, 20.0, -20.0, 28.0, 16.0, -20.0, -20.0, 18.0, 28.0, 22.0, 28.0, 20.0, -20.0, 24.0, 24.0, 30.0, 24.0, 16.0, 28.0, 12.0, 8.0, 28.0, 18.0, 24.0, 20.0, 16.0, 12.0, 20.0, 14.0, 28.0, 8.0, 24.0, 28.0, 34.0, 28.0, 20.0, 8.0, 12.0, 6.0, 4.0, 26.0, 8.0, 14.0, 18.0, 2.0, 24.0, 24.0, 28.0, 34.0, 34.0, 20.0, -20.0, -20.0, 30.0, 24.0, 28.0, 34.0, 10.0, 28.0], "episode_lengths": [10, 20, 10, 20, 20, 12, 11, 16, 11, 18, 20, 8, 10, 20, 6, 14, 20, 11, 6, 8, 20, 20, 20, 10, 13, 8, 20, 6, 10, 14, 6, 6, 20, 16, 8, 14, 14, 9, 10, 9, 11, 10, 10, 20, 6, 12, 20, 20, 11, 6, 9, 6, 10, 20, 8, 8, 5, 8, 12, 6, 14, 16, 6, 11, 8, 10, 12, 14, 10, 13, 6, 16, 8, 6, 3, 6, 10, 16, 14, 17, 18, 7, 16, 13, 11, 19, 8, 8, 6, 3, 3, 10, 20, 20, 5, 8, 6, 3, 15, 6], "policy_policy0_reward": [10.0, -10.0, 10.0, -10.0, -10.0, 8.0, 9.0, 4.0, 9.0, 2.0, -10.0, 12.0, 10.0, -10.0, 14.0, 6.0, -10.0, 9.0, 14.0, 12.0, -20.0, -10.0, -10.0, 10.0, 7.0, 12.0, -10.0, 14.0, 10.0, 6.0, 14.0, 14.0, -10.0, 4.0, 12.0, 6.0, 6.0, 11.0, 10.0, 11.0, 9.0, 10.0, 10.0, -10.0, 14.0, 8.0, -10.0, -10.0, 9.0, 14.0, 11.0, 14.0, 10.0, -10.0, 12.0, 12.0, 15.0, 12.0, 8.0, 14.0, 6.0, 4.0, 14.0, 9.0, 12.0, 10.0, 8.0, 6.0, 10.0, 7.0, 14.0, 4.0, 12.0, 14.0, 17.0, 14.0, 10.0, 4.0, 6.0, 3.0, 2.0, 13.0, 4.0, 7.0, 9.0, 1.0, 12.0, 12.0, 14.0, 17.0, 17.0, 10.0, -10.0, -10.0, 15.0, 12.0, 14.0, 17.0, 5.0, 14.0], "policy_policy1_reward": [10.0, -10.0, 10.0, -10.0, -10.0, 8.0, 9.0, 4.0, 9.0, 2.0, -10.0, 12.0, 10.0, -10.0, 14.0, 6.0, -10.0, 9.0, 14.0, 12.0, -20.0, -10.0, -10.0, 10.0, 7.0, 12.0, -10.0, 14.0, 10.0, 6.0, 14.0, 14.0, -10.0, 4.0, 12.0, 6.0, 6.0, 11.0, 10.0, 11.0, 9.0, 10.0, 10.0, -10.0, 14.0, 8.0, -10.0, -10.0, 9.0, 14.0, 11.0, 14.0, 10.0, -10.0, 12.0, 12.0, 15.0, 12.0, 8.0, 14.0, 6.0, 4.0, 14.0, 9.0, 12.0, 10.0, 8.0, 6.0, 10.0, 7.0, 14.0, 4.0, 12.0, 14.0, 17.0, 14.0, 10.0, 4.0, 6.0, 3.0, 2.0, 13.0, 4.0, 7.0, 9.0, 1.0, 12.0, 12.0, 14.0, 17.0, 17.0, 10.0, -10.0, -10.0, 15.0, 12.0, 14.0, 17.0, 5.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.285658995400236, "mean_inference_ms": 1.532695517323411, "mean_action_processing_ms": 0.10072582877612439, "mean_env_wait_ms": 0.06684330078243646, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13224, "timesteps_this_iter": 32, "agent_timesteps_total": 26448, "timers": {"load_time_ms": 0.444, "load_throughput": 72074.819, "learn_time_ms": 7.468, "learn_throughput": 4285.026, "update_time_ms": 4.373}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.411221027374268, "min_q": -3.8257312774658203, "max_q": 15.215639114379883, "mean_td_error": 0.25128015875816345, "model": {}}, "td_error": [0.4181840419769287, -0.4068748950958252, 1.0951728820800781, -0.5828123092651367, 2.2786216735839844, -2.5242700576782227, 8.017631530761719, 1.4899463653564453, -0.46796321868896484, -1.9349714517593384, -5.63539981842041, 0.1453855037689209, -0.5895198583602905, -0.26227664947509766, 0.1276257038116455, 0.7039964199066162, -0.5567352771759033, -0.8608748316764832, 2.67466402053833, -3.159963607788086, -1.9738759994506836, 0.06033015251159668, 1.0194158554077148, -0.6672223210334778, -1.0980300903320312, 0.7058925628662109, -1.1158742904663086, -0.5870733261108398, 4.342842102050781, 6.854918479919434, 1.7928104400634766, -1.2627344131469727], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.4360671043396, "min_q": -12.844921112060547, "max_q": 13.537077903747559, "mean_td_error": -2.6967201232910156, "model": {}}, "td_error": [-3.0357861518859863, 0.508878231048584, -6.117433071136475, -4.449673652648926, -4.1731181144714355, -1.7436156272888184, 1.3528966903686523, 3.521815776824951, -10.267389297485352, -1.136124849319458, 0.36554527282714844, -5.615080833435059, 1.608828067779541, -6.965646266937256, -14.515420913696289, 1.1480350494384766, -0.9964823722839355, -4.02664852142334, -13.650635719299316, -16.913204193115234, 1.0932979583740234, -3.1547598838806152, -2.7076072692871094, 3.731447219848633, 5.242796421051025, -0.6426267623901367, 0.37779760360717773, 4.537077903747559, -6.113587379455566, -2.110869884490967, -2.4069161415100098, 0.9591646194458008], "custom_metrics": {}}}, "num_steps_sampled": 13224, "num_agent_steps_sampled": 26448, "num_steps_trained": 25376, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 50752, "last_target_update_ts": 13181, "num_target_updates": 111}, "done": false, "episodes_total": 856, "training_iteration": 40, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-26", "timestamp": 1648811546, "time_this_iter_s": 1.3529441356658936, "time_total_s": 50.56856441497803, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 50.56856441497803, "timesteps_since_restore": 1280, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 16.2, "ram_util_percent": 36.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -20.0, "episode_reward_mean": 16.46, "episode_len_mean": 10.47, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 8.23, "policy1": 8.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 14.0, 24.0, -20.0, 28.0, 20.0, 12.0, 28.0, 28.0, -20.0, 8.0, 24.0, 12.0, 12.0, 22.0, 20.0, 22.0, 18.0, 20.0, 20.0, -20.0, 28.0, 16.0, -20.0, -20.0, 18.0, 28.0, 22.0, 28.0, 20.0, -20.0, 24.0, 24.0, 30.0, 24.0, 16.0, 28.0, 12.0, 8.0, 28.0, 18.0, 24.0, 20.0, 16.0, 12.0, 20.0, 14.0, 28.0, 8.0, 24.0, 28.0, 34.0, 28.0, 20.0, 8.0, 12.0, 6.0, 4.0, 26.0, 8.0, 14.0, 18.0, 2.0, 24.0, 24.0, 28.0, 34.0, 34.0, 20.0, -20.0, -20.0, 30.0, 24.0, 28.0, 34.0, 10.0, 28.0, 22.0, 34.0, 30.0, -20.0, 28.0, -20.0, 24.0, 14.0, -20.0, 32.0, 12.0, 34.0, 34.0, 30.0, 30.0, -20.0, 30.0, 32.0, 16.0, 32.0, 28.0, 28.0, -20.0], "episode_lengths": [10, 13, 8, 20, 6, 10, 14, 6, 6, 20, 16, 8, 14, 14, 9, 10, 9, 11, 10, 10, 20, 6, 12, 20, 20, 11, 6, 9, 6, 10, 20, 8, 8, 5, 8, 12, 6, 14, 16, 6, 11, 8, 10, 12, 14, 10, 13, 6, 16, 8, 6, 3, 6, 10, 16, 14, 17, 18, 7, 16, 13, 11, 19, 8, 8, 6, 3, 3, 10, 20, 20, 5, 8, 6, 3, 15, 6, 9, 3, 5, 20, 6, 20, 8, 13, 20, 4, 14, 3, 3, 5, 5, 20, 5, 4, 12, 4, 6, 6, 20], "policy_policy0_reward": [10.0, 7.0, 12.0, -10.0, 14.0, 10.0, 6.0, 14.0, 14.0, -10.0, 4.0, 12.0, 6.0, 6.0, 11.0, 10.0, 11.0, 9.0, 10.0, 10.0, -10.0, 14.0, 8.0, -10.0, -10.0, 9.0, 14.0, 11.0, 14.0, 10.0, -10.0, 12.0, 12.0, 15.0, 12.0, 8.0, 14.0, 6.0, 4.0, 14.0, 9.0, 12.0, 10.0, 8.0, 6.0, 10.0, 7.0, 14.0, 4.0, 12.0, 14.0, 17.0, 14.0, 10.0, 4.0, 6.0, 3.0, 2.0, 13.0, 4.0, 7.0, 9.0, 1.0, 12.0, 12.0, 14.0, 17.0, 17.0, 10.0, -10.0, -10.0, 15.0, 12.0, 14.0, 17.0, 5.0, 14.0, 11.0, 17.0, 15.0, -10.0, 14.0, -10.0, 12.0, 7.0, -10.0, 16.0, 6.0, 17.0, 17.0, 15.0, 15.0, -10.0, 15.0, 16.0, 8.0, 16.0, 14.0, 14.0, -10.0], "policy_policy1_reward": [10.0, 7.0, 12.0, -10.0, 14.0, 10.0, 6.0, 14.0, 14.0, -10.0, 4.0, 12.0, 6.0, 6.0, 11.0, 10.0, 11.0, 9.0, 10.0, 10.0, -10.0, 14.0, 8.0, -10.0, -10.0, 9.0, 14.0, 11.0, 14.0, 10.0, -10.0, 12.0, 12.0, 15.0, 12.0, 8.0, 14.0, 6.0, 4.0, 14.0, 9.0, 12.0, 10.0, 8.0, 6.0, 10.0, 7.0, 14.0, 4.0, 12.0, 14.0, 17.0, 14.0, 10.0, 4.0, 6.0, 3.0, 2.0, 13.0, 4.0, 7.0, 9.0, 1.0, 12.0, 12.0, 14.0, 17.0, 17.0, 10.0, -10.0, -10.0, 15.0, 12.0, 14.0, 17.0, 5.0, 14.0, 11.0, 17.0, 15.0, -10.0, 14.0, -10.0, 12.0, 7.0, -10.0, 16.0, 6.0, 17.0, 17.0, 15.0, 15.0, -10.0, 15.0, 16.0, 8.0, 16.0, 14.0, 14.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2860023587954386, "mean_inference_ms": 1.5317983178155685, "mean_action_processing_ms": 0.10068808133509581, "mean_env_wait_ms": 0.06683321622937909, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13439, "timesteps_this_iter": 32, "agent_timesteps_total": 26878, "timers": {"load_time_ms": 0.426, "load_throughput": 75141.489, "learn_time_ms": 7.098, "learn_throughput": 4508.065, "update_time_ms": 4.449}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.139641761779785, "min_q": -3.193758726119995, "max_q": 11.516716003417969, "mean_td_error": -1.1111465692520142, "model": {}}, "td_error": [-1.1378860473632812, -1.6024723052978516, -1.4521920680999756, -3.2711868286132812, -7.698770523071289, -0.4961634874343872, 0.020639419555664062, 0.7644863128662109, -0.0701441764831543, 0.33293676376342773, -11.22476577758789, -0.6359596252441406, -2.5665407180786133, -2.0805463790893555, -2.611941337585449, -1.1844215393066406, 0.010283470153808594, -0.5923013687133789, 0.523597240447998, 0.24573683738708496, 0.6180944442749023, 0.39800775051116943, 1.0029796361923218, 2.5946602821350098, -1.5574336051940918, 4.972013473510742, -2.2601699829101562, -0.5406532287597656, 3.2835159301757812, 0.25945568084716797, -3.420375108718872, -6.179174900054932], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -4.857464790344238, "min_q": -10.632223129272461, "max_q": -1.104374647140503, "mean_td_error": -1.6812515258789062, "model": {}}, "td_error": [-2.2622737884521484, 0.06958389282226562, -0.44380974769592285, 0.6328425407409668, 2.3036742210388184, 2.4777960777282715, -1.1215271949768066, -0.1901073455810547, -1.279815912246704, -2.2622737884521484, 0.9711761474609375, -3.6774303913116455, -5.176246643066406, 2.7968201637268066, -12.179222106933594, 3.472538948059082, -0.817072868347168, -1.0708985328674316, 0.8985781669616699, 0.19475078582763672, -17.475849151611328, -4.89448356628418, -2.407280921936035, -10.268936157226562, -0.6386721134185791, 0.895258903503418, -0.41300344467163086, -4.073306560516357, 0.8002424240112305, 0.6658000946044922, 1.4685750007629395, -0.7954769134521484], "custom_metrics": {}}}, "num_steps_sampled": 13439, "num_agent_steps_sampled": 26878, "num_steps_trained": 26048, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 52096, "last_target_update_ts": 13391, "num_target_updates": 113}, "done": false, "episodes_total": 879, "training_iteration": 41, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-27", "timestamp": 1648811547, "time_this_iter_s": 0.9854018688201904, "time_total_s": 51.55396628379822, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 51.55396628379822, "timesteps_since_restore": 1312, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 16.0, "ram_util_percent": 36.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 16.26, "episode_len_mean": 10.37, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 8.13, "policy1": 8.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.0, 28.0, 20.0, -20.0, 24.0, 24.0, 30.0, 24.0, 16.0, 28.0, 12.0, 8.0, 28.0, 18.0, 24.0, 20.0, 16.0, 12.0, 20.0, 14.0, 28.0, 8.0, 24.0, 28.0, 34.0, 28.0, 20.0, 8.0, 12.0, 6.0, 4.0, 26.0, 8.0, 14.0, 18.0, 2.0, 24.0, 24.0, 28.0, 34.0, 34.0, 20.0, -20.0, -20.0, 30.0, 24.0, 28.0, 34.0, 10.0, 28.0, 22.0, 34.0, 30.0, -20.0, 28.0, -20.0, 24.0, 14.0, -20.0, 32.0, 12.0, 34.0, 34.0, 30.0, 30.0, -20.0, 30.0, 32.0, 16.0, 32.0, 28.0, 28.0, -20.0, 30.0, 24.0, 16.0, 20.0, -40.0, 26.0, -20.0, -20.0, -20.0, 28.0, 14.0, 32.0, -20.0, 28.0, 28.0, -20.0, 24.0, 20.0, 16.0, 20.0, 28.0, 28.0, 10.0, 14.0, 24.0, 4.0, 28.0], "episode_lengths": [9, 6, 10, 20, 8, 8, 5, 8, 12, 6, 14, 16, 6, 11, 8, 10, 12, 14, 10, 13, 6, 16, 8, 6, 3, 6, 10, 16, 14, 17, 18, 7, 16, 13, 11, 19, 8, 8, 6, 3, 3, 10, 20, 20, 5, 8, 6, 3, 15, 6, 9, 3, 5, 20, 6, 20, 8, 13, 20, 4, 14, 3, 3, 5, 5, 20, 5, 4, 12, 4, 6, 6, 20, 5, 8, 12, 10, 20, 7, 20, 20, 20, 6, 13, 4, 20, 6, 6, 20, 8, 10, 12, 10, 6, 6, 15, 13, 8, 18, 6], "policy_policy0_reward": [11.0, 14.0, 10.0, -10.0, 12.0, 12.0, 15.0, 12.0, 8.0, 14.0, 6.0, 4.0, 14.0, 9.0, 12.0, 10.0, 8.0, 6.0, 10.0, 7.0, 14.0, 4.0, 12.0, 14.0, 17.0, 14.0, 10.0, 4.0, 6.0, 3.0, 2.0, 13.0, 4.0, 7.0, 9.0, 1.0, 12.0, 12.0, 14.0, 17.0, 17.0, 10.0, -10.0, -10.0, 15.0, 12.0, 14.0, 17.0, 5.0, 14.0, 11.0, 17.0, 15.0, -10.0, 14.0, -10.0, 12.0, 7.0, -10.0, 16.0, 6.0, 17.0, 17.0, 15.0, 15.0, -10.0, 15.0, 16.0, 8.0, 16.0, 14.0, 14.0, -10.0, 15.0, 12.0, 8.0, 10.0, -20.0, 13.0, -10.0, -10.0, -10.0, 14.0, 7.0, 16.0, -10.0, 14.0, 14.0, -10.0, 12.0, 10.0, 8.0, 10.0, 14.0, 14.0, 5.0, 7.0, 12.0, 2.0, 14.0], "policy_policy1_reward": [11.0, 14.0, 10.0, -10.0, 12.0, 12.0, 15.0, 12.0, 8.0, 14.0, 6.0, 4.0, 14.0, 9.0, 12.0, 10.0, 8.0, 6.0, 10.0, 7.0, 14.0, 4.0, 12.0, 14.0, 17.0, 14.0, 10.0, 4.0, 6.0, 3.0, 2.0, 13.0, 4.0, 7.0, 9.0, 1.0, 12.0, 12.0, 14.0, 17.0, 17.0, 10.0, -10.0, -10.0, 15.0, 12.0, 14.0, 17.0, 5.0, 14.0, 11.0, 17.0, 15.0, -10.0, 14.0, -10.0, 12.0, 7.0, -10.0, 16.0, 6.0, 17.0, 17.0, 15.0, 15.0, -10.0, 15.0, 16.0, 8.0, 16.0, 14.0, 14.0, -10.0, 15.0, 12.0, 8.0, 10.0, -20.0, 13.0, -10.0, -10.0, -10.0, 14.0, 7.0, 16.0, -10.0, 14.0, 14.0, -10.0, 12.0, 10.0, 8.0, 10.0, 14.0, 14.0, 5.0, 7.0, 12.0, 2.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28637007791040087, "mean_inference_ms": 1.5307541447135948, "mean_action_processing_ms": 0.10062714193135829, "mean_env_wait_ms": 0.06681183100686658, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13748, "timesteps_this_iter": 32, "agent_timesteps_total": 27496, "timers": {"load_time_ms": 0.42, "load_throughput": 76203.786, "learn_time_ms": 7.433, "learn_throughput": 4305.038, "update_time_ms": 4.596}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.2258806228637695, "min_q": -1.8534749746322632, "max_q": 13.029433250427246, "mean_td_error": -0.47557833790779114, "model": {}}, "td_error": [0.8373870849609375, 0.5682125091552734, -8.175995826721191, -1.5162434577941895, 1.3886234760284424, -1.7592220306396484, -0.33471012115478516, -3.2253055572509766, 1.4500045776367188, 0.8063249588012695, 2.2908172607421875, -1.831568956375122, -0.9408578872680664, -1.7675185203552246, -0.018455326557159424, -3.5321192741394043, -0.33284759521484375, 0.33605724573135376, -2.125469446182251, -0.0764312744140625, -0.4339876174926758, 1.8039298057556152, 0.6901626586914062, 0.10533714294433594, 1.9943184852600098, -2.8009564876556396, 3.5052480697631836, 1.7928235530853271, -2.8186445236206055, -0.5696730613708496, -1.6667098999023438, 1.1389634609222412], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.76727032661438, "min_q": -6.424812316894531, "max_q": 2.8251378536224365, "mean_td_error": -3.20111346244812, "model": {}}, "td_error": [3.391956090927124, 0.3561887741088867, 1.5331239700317383, -9.30567455291748, 0.3967583179473877, -3.840918779373169, 0.43619298934936523, -4.934498310089111, -1.6645240783691406, -2.8363046646118164, 2.673222541809082, 1.1025869846343994, 3.3769638538360596, -13.354059219360352, -9.43356704711914, -4.8271565437316895, 0.005889892578125, 1.1854047775268555, 0.1055300235748291, -0.06698942184448242, -5.549581050872803, -9.768597602844238, -13.233171463012695, 2.471874475479126, -3.8477392196655273, -0.31331729888916016, -5.966094970703125, -2.302654266357422, -9.75240707397461, -1.4325770139694214, -10.269086837768555, -6.772396087646484], "custom_metrics": {}}}, "num_steps_sampled": 13748, "num_agent_steps_sampled": 27496, "num_steps_trained": 26912, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 53824, "last_target_update_ts": 13716, "num_target_updates": 116}, "done": false, "episodes_total": 906, "training_iteration": 42, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-28", "timestamp": 1648811548, "time_this_iter_s": 1.3723478317260742, "time_total_s": 52.92631411552429, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 52.92631411552429, "timesteps_since_restore": 1344, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 14.95, "ram_util_percent": 36.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 14.52, "episode_len_mean": 10.64, "episode_media": {}, "episodes_this_iter": 29, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 7.26, "policy1": 7.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 4.0, 26.0, 8.0, 14.0, 18.0, 2.0, 24.0, 24.0, 28.0, 34.0, 34.0, 20.0, -20.0, -20.0, 30.0, 24.0, 28.0, 34.0, 10.0, 28.0, 22.0, 34.0, 30.0, -20.0, 28.0, -20.0, 24.0, 14.0, -20.0, 32.0, 12.0, 34.0, 34.0, 30.0, 30.0, -20.0, 30.0, 32.0, 16.0, 32.0, 28.0, 28.0, -20.0, 30.0, 24.0, 16.0, 20.0, -40.0, 26.0, -20.0, -20.0, -20.0, 28.0, 14.0, 32.0, -20.0, 28.0, 28.0, -20.0, 24.0, 20.0, 16.0, 20.0, 28.0, 28.0, 10.0, 14.0, 24.0, 4.0, 28.0, 0.0, 24.0, 24.0, 4.0, 28.0, 28.0, -20.0, -20.0, -20.0, 28.0, -20.0, 28.0, 28.0, 34.0, 32.0, 16.0, 34.0, 16.0, -20.0, 4.0, 10.0, -20.0, 30.0, 28.0, 28.0, 32.0, -20.0, 34.0, 34.0], "episode_lengths": [17, 18, 7, 16, 13, 11, 19, 8, 8, 6, 3, 3, 10, 20, 20, 5, 8, 6, 3, 15, 6, 9, 3, 5, 20, 6, 20, 8, 13, 20, 4, 14, 3, 3, 5, 5, 20, 5, 4, 12, 4, 6, 6, 20, 5, 8, 12, 10, 20, 7, 20, 20, 20, 6, 13, 4, 20, 6, 6, 20, 8, 10, 12, 10, 6, 6, 15, 13, 8, 18, 6, 20, 8, 8, 18, 6, 6, 20, 20, 20, 6, 20, 6, 6, 3, 4, 12, 3, 12, 20, 18, 15, 20, 5, 6, 6, 4, 20, 3, 3], "policy_policy0_reward": [3.0, 2.0, 13.0, 4.0, 7.0, 9.0, 1.0, 12.0, 12.0, 14.0, 17.0, 17.0, 10.0, -10.0, -10.0, 15.0, 12.0, 14.0, 17.0, 5.0, 14.0, 11.0, 17.0, 15.0, -10.0, 14.0, -10.0, 12.0, 7.0, -10.0, 16.0, 6.0, 17.0, 17.0, 15.0, 15.0, -10.0, 15.0, 16.0, 8.0, 16.0, 14.0, 14.0, -10.0, 15.0, 12.0, 8.0, 10.0, -20.0, 13.0, -10.0, -10.0, -10.0, 14.0, 7.0, 16.0, -10.0, 14.0, 14.0, -10.0, 12.0, 10.0, 8.0, 10.0, 14.0, 14.0, 5.0, 7.0, 12.0, 2.0, 14.0, 0.0, 12.0, 12.0, 2.0, 14.0, 14.0, -10.0, -10.0, -10.0, 14.0, -10.0, 14.0, 14.0, 17.0, 16.0, 8.0, 17.0, 8.0, -10.0, 2.0, 5.0, -10.0, 15.0, 14.0, 14.0, 16.0, -10.0, 17.0, 17.0], "policy_policy1_reward": [3.0, 2.0, 13.0, 4.0, 7.0, 9.0, 1.0, 12.0, 12.0, 14.0, 17.0, 17.0, 10.0, -10.0, -10.0, 15.0, 12.0, 14.0, 17.0, 5.0, 14.0, 11.0, 17.0, 15.0, -10.0, 14.0, -10.0, 12.0, 7.0, -10.0, 16.0, 6.0, 17.0, 17.0, 15.0, 15.0, -10.0, 15.0, 16.0, 8.0, 16.0, 14.0, 14.0, -10.0, 15.0, 12.0, 8.0, 10.0, -20.0, 13.0, -10.0, -10.0, -10.0, 14.0, 7.0, 16.0, -10.0, 14.0, 14.0, -10.0, 12.0, 10.0, 8.0, 10.0, 14.0, 14.0, 5.0, 7.0, 12.0, 2.0, 14.0, 0.0, 12.0, 12.0, 2.0, 14.0, 14.0, -10.0, -10.0, -10.0, 14.0, -10.0, 14.0, 14.0, 17.0, 16.0, 8.0, 17.0, 8.0, -10.0, 2.0, 5.0, -10.0, 15.0, 14.0, 14.0, 16.0, -10.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2867206452240901, "mean_inference_ms": 1.5295859597791115, "mean_action_processing_ms": 0.10055955000091049, "mean_env_wait_ms": 0.06677252652919444, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14066, "timesteps_this_iter": 32, "agent_timesteps_total": 28132, "timers": {"load_time_ms": 0.428, "load_throughput": 74752.285, "learn_time_ms": 7.477, "learn_throughput": 4279.834, "update_time_ms": 4.743}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.822235107421875, "min_q": -3.306580066680908, "max_q": 11.7588472366333, "mean_td_error": -0.06138947606086731, "model": {}}, "td_error": [0.6472795009613037, 0.3862478733062744, -0.28965091705322266, 1.9418840408325195, 0.11065435409545898, -0.3795192241668701, -1.212303638458252, -3.847262382507324, 0.4978203773498535, -0.3611893653869629, 0.0006861686706542969, -1.2981595993041992, -1.3076605796813965, -0.030425548553466797, 1.173607349395752, -0.49138927459716797, -0.8256101608276367, 0.05142104625701904, 1.7029294967651367, 0.9256117343902588, 3.493900775909424, -0.2598850727081299, -0.9110779762268066, -0.6590719223022461, 1.9830799102783203, -2.1267571449279785, -1.9448814392089844, 0.42293262481689453, 1.3911609649658203, -1.410815715789795, 0.4966466426849365, 0.16533374786376953], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.73522686958313, "min_q": -5.796997547149658, "max_q": 1.487994909286499, "mean_td_error": -1.3381335735321045, "model": {}}, "td_error": [0.7879252433776855, 1.7862739562988281, -11.400957107543945, -6.6407470703125, 1.585337519645691, -0.22477436065673828, 0.016020774841308594, 0.6952347755432129, -0.7763147354125977, -13.553969383239746, 1.5871672630310059, 1.1825166940689087, -8.891563415527344, -5.737030982971191, 1.5904669761657715, 0.6313447952270508, -1.2420639991760254, -0.509831428527832, -5.739232063293457, 0.3067619800567627, 1.4490545988082886, 1.163515567779541, 2.519463539123535, 1.4728260040283203, -1.2985119819641113, -10.79586410522461, 1.926023244857788, 3.266125202178955, 1.1369893550872803, 0.9546492099761963, -0.41162145137786865, 0.34450864791870117], "custom_metrics": {}}}, "num_steps_sampled": 14066, "num_agent_steps_sampled": 28132, "num_steps_trained": 27744, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 55488, "last_target_update_ts": 14060, "num_target_updates": 119}, "done": false, "episodes_total": 935, "training_iteration": 43, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-30", "timestamp": 1648811550, "time_this_iter_s": 1.373180866241455, "time_total_s": 54.29949498176575, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 54.29949498176575, "timesteps_since_restore": 1376, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 14.5, "ram_util_percent": 36.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 13.8, "episode_len_mean": 11.0, "episode_media": {}, "episodes_this_iter": 29, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 6.9, "policy1": 6.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 32.0, 12.0, 34.0, 34.0, 30.0, 30.0, -20.0, 30.0, 32.0, 16.0, 32.0, 28.0, 28.0, -20.0, 30.0, 24.0, 16.0, 20.0, -40.0, 26.0, -20.0, -20.0, -20.0, 28.0, 14.0, 32.0, -20.0, 28.0, 28.0, -20.0, 24.0, 20.0, 16.0, 20.0, 28.0, 28.0, 10.0, 14.0, 24.0, 4.0, 28.0, 0.0, 24.0, 24.0, 4.0, 28.0, 28.0, -20.0, -20.0, -20.0, 28.0, -20.0, 28.0, 28.0, 34.0, 32.0, 16.0, 34.0, 16.0, -20.0, 4.0, 10.0, -20.0, 30.0, 28.0, 28.0, 32.0, -20.0, 34.0, 34.0, 20.0, 34.0, 28.0, 28.0, 20.0, 12.0, 16.0, 16.0, 24.0, 24.0, 20.0, 16.0, -20.0, 0.0, 20.0, 26.0, 34.0, 2.0, -20.0, 4.0, 32.0, 0.0, 20.0, -20.0, 8.0, 28.0, 20.0, 24.0, -20.0], "episode_lengths": [20, 4, 14, 3, 3, 5, 5, 20, 5, 4, 12, 4, 6, 6, 20, 5, 8, 12, 10, 20, 7, 20, 20, 20, 6, 13, 4, 20, 6, 6, 20, 8, 10, 12, 10, 6, 6, 15, 13, 8, 18, 6, 20, 8, 8, 18, 6, 6, 20, 20, 20, 6, 20, 6, 6, 3, 4, 12, 3, 12, 20, 18, 15, 20, 5, 6, 6, 4, 20, 3, 3, 10, 3, 6, 6, 10, 14, 12, 12, 8, 8, 10, 12, 20, 20, 10, 7, 3, 19, 20, 18, 4, 20, 10, 20, 16, 6, 10, 8, 20], "policy_policy0_reward": [-10.0, 16.0, 6.0, 17.0, 17.0, 15.0, 15.0, -10.0, 15.0, 16.0, 8.0, 16.0, 14.0, 14.0, -10.0, 15.0, 12.0, 8.0, 10.0, -20.0, 13.0, -10.0, -10.0, -10.0, 14.0, 7.0, 16.0, -10.0, 14.0, 14.0, -10.0, 12.0, 10.0, 8.0, 10.0, 14.0, 14.0, 5.0, 7.0, 12.0, 2.0, 14.0, 0.0, 12.0, 12.0, 2.0, 14.0, 14.0, -10.0, -10.0, -10.0, 14.0, -10.0, 14.0, 14.0, 17.0, 16.0, 8.0, 17.0, 8.0, -10.0, 2.0, 5.0, -10.0, 15.0, 14.0, 14.0, 16.0, -10.0, 17.0, 17.0, 10.0, 17.0, 14.0, 14.0, 10.0, 6.0, 8.0, 8.0, 12.0, 12.0, 10.0, 8.0, -10.0, 0.0, 10.0, 13.0, 17.0, 1.0, -10.0, 2.0, 16.0, 0.0, 10.0, -10.0, 4.0, 14.0, 10.0, 12.0, -10.0], "policy_policy1_reward": [-10.0, 16.0, 6.0, 17.0, 17.0, 15.0, 15.0, -10.0, 15.0, 16.0, 8.0, 16.0, 14.0, 14.0, -10.0, 15.0, 12.0, 8.0, 10.0, -20.0, 13.0, -10.0, -10.0, -10.0, 14.0, 7.0, 16.0, -10.0, 14.0, 14.0, -10.0, 12.0, 10.0, 8.0, 10.0, 14.0, 14.0, 5.0, 7.0, 12.0, 2.0, 14.0, 0.0, 12.0, 12.0, 2.0, 14.0, 14.0, -10.0, -10.0, -10.0, 14.0, -10.0, 14.0, 14.0, 17.0, 16.0, 8.0, 17.0, 8.0, -10.0, 2.0, 5.0, -10.0, 15.0, 14.0, 14.0, 16.0, -10.0, 17.0, 17.0, 10.0, 17.0, 14.0, 14.0, 10.0, 6.0, 8.0, 8.0, 12.0, 12.0, 10.0, 8.0, -10.0, 0.0, 10.0, 13.0, 17.0, 1.0, -10.0, 2.0, 16.0, 0.0, 10.0, -10.0, 4.0, 14.0, 10.0, 12.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28697836606855825, "mean_inference_ms": 1.5282884765120621, "mean_action_processing_ms": 0.10048085294362034, "mean_env_wait_ms": 0.06671765687274504, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14408, "timesteps_this_iter": 32, "agent_timesteps_total": 28816, "timers": {"load_time_ms": 0.475, "load_throughput": 67344.57, "learn_time_ms": 7.567, "learn_throughput": 4229.062, "update_time_ms": 4.365}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.560966491699219, "min_q": -4.7788496017456055, "max_q": 12.42223834991455, "mean_td_error": -0.3785266578197479, "model": {}}, "td_error": [-1.486548900604248, 0.3176383972167969, -1.2548322677612305, -0.22368526458740234, -3.7788496017456055, 0.038964271545410156, 1.106839656829834, 1.606210708618164, 0.07607841491699219, -1.5110790729522705, -3.370187282562256, 0.8060871362686157, 5.653408050537109, -0.15908241271972656, 0.659900426864624, -0.2731513977050781, 0.4774160385131836, -6.1713457107543945, 1.6973905563354492, -0.7968146800994873, 0.08211827278137207, -0.533814549446106, 0.12545418739318848, -2.551821231842041, -0.1786670684814453, -5.53181266784668, 1.2516499757766724, -0.11497879028320312, 3.7530713081359863, 0.062279701232910156, -1.2269768714904785, -0.663712739944458], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.3187472820281982, "min_q": -5.44455623626709, "max_q": 4.308767318725586, "mean_td_error": -1.895309567451477, "model": {}}, "td_error": [2.899139881134033, 0.2943730354309082, -6.815719127655029, 2.643690824508667, -8.48777961730957, -12.509966850280762, -9.004461288452148, -0.4291372299194336, -0.2065420150756836, -1.1440670490264893, 1.7960646152496338, -1.4804315567016602, -7.848336219787598, -0.5153062343597412, -1.326784610748291, -4.691540241241455, 1.7156767845153809, 0.6872680187225342, -0.574493408203125, 0.8822481632232666, 1.093481183052063, -0.14746856689453125, -6.012077331542969, 0.5324978828430176, 1.9820523262023926, -8.075855255126953, -5.639996528625488, -0.6114757061004639, -1.2362744808197021, 0.3225243091583252, 0.6972513198852539, 0.5615372657775879], "custom_metrics": {}}}, "num_steps_sampled": 14408, "num_agent_steps_sampled": 28816, "num_steps_trained": 28608, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 57216, "last_target_update_ts": 14380, "num_target_updates": 122}, "done": false, "episodes_total": 964, "training_iteration": 44, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-31", "timestamp": 1648811551, "time_this_iter_s": 1.420522689819336, "time_total_s": 55.72001767158508, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 55.72001767158508, "timesteps_since_restore": 1408, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 15.100000000000001, "ram_util_percent": 36.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -20.0, "episode_reward_mean": 13.14, "episode_len_mean": 11.43, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 6.57, "policy1": 6.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.0, -20.0, 28.0, 28.0, -20.0, 24.0, 20.0, 16.0, 20.0, 28.0, 28.0, 10.0, 14.0, 24.0, 4.0, 28.0, 0.0, 24.0, 24.0, 4.0, 28.0, 28.0, -20.0, -20.0, -20.0, 28.0, -20.0, 28.0, 28.0, 34.0, 32.0, 16.0, 34.0, 16.0, -20.0, 4.0, 10.0, -20.0, 30.0, 28.0, 28.0, 32.0, -20.0, 34.0, 34.0, 20.0, 34.0, 28.0, 28.0, 20.0, 12.0, 16.0, 16.0, 24.0, 24.0, 20.0, 16.0, -20.0, 0.0, 20.0, 26.0, 34.0, 2.0, -20.0, 4.0, 32.0, 0.0, 20.0, -20.0, 8.0, 28.0, 20.0, 24.0, -20.0, 28.0, 18.0, 4.0, -20.0, -20.0, -20.0, 28.0, 20.0, 28.0, 12.0, 24.0, -20.0, -20.0, 20.0, -20.0, 28.0, 24.0, 24.0, -20.0, 24.0, 28.0, 32.0, 20.0, 8.0, 20.0, 20.0], "episode_lengths": [4, 20, 6, 6, 20, 8, 10, 12, 10, 6, 6, 15, 13, 8, 18, 6, 20, 8, 8, 18, 6, 6, 20, 20, 20, 6, 20, 6, 6, 3, 4, 12, 3, 12, 20, 18, 15, 20, 5, 6, 6, 4, 20, 3, 3, 10, 3, 6, 6, 10, 14, 12, 12, 8, 8, 10, 12, 20, 20, 10, 7, 3, 19, 20, 18, 4, 20, 10, 20, 16, 6, 10, 8, 20, 6, 11, 18, 20, 20, 20, 6, 10, 6, 14, 8, 20, 20, 10, 20, 6, 8, 8, 20, 8, 6, 4, 10, 16, 10, 10], "policy_policy0_reward": [16.0, -10.0, 14.0, 14.0, -10.0, 12.0, 10.0, 8.0, 10.0, 14.0, 14.0, 5.0, 7.0, 12.0, 2.0, 14.0, 0.0, 12.0, 12.0, 2.0, 14.0, 14.0, -10.0, -10.0, -10.0, 14.0, -10.0, 14.0, 14.0, 17.0, 16.0, 8.0, 17.0, 8.0, -10.0, 2.0, 5.0, -10.0, 15.0, 14.0, 14.0, 16.0, -10.0, 17.0, 17.0, 10.0, 17.0, 14.0, 14.0, 10.0, 6.0, 8.0, 8.0, 12.0, 12.0, 10.0, 8.0, -10.0, 0.0, 10.0, 13.0, 17.0, 1.0, -10.0, 2.0, 16.0, 0.0, 10.0, -10.0, 4.0, 14.0, 10.0, 12.0, -10.0, 14.0, 9.0, 2.0, -10.0, -10.0, -10.0, 14.0, 10.0, 14.0, 6.0, 12.0, -10.0, -10.0, 10.0, -10.0, 14.0, 12.0, 12.0, -10.0, 12.0, 14.0, 16.0, 10.0, 4.0, 10.0, 10.0], "policy_policy1_reward": [16.0, -10.0, 14.0, 14.0, -10.0, 12.0, 10.0, 8.0, 10.0, 14.0, 14.0, 5.0, 7.0, 12.0, 2.0, 14.0, 0.0, 12.0, 12.0, 2.0, 14.0, 14.0, -10.0, -10.0, -10.0, 14.0, -10.0, 14.0, 14.0, 17.0, 16.0, 8.0, 17.0, 8.0, -10.0, 2.0, 5.0, -10.0, 15.0, 14.0, 14.0, 16.0, -10.0, 17.0, 17.0, 10.0, 17.0, 14.0, 14.0, 10.0, 6.0, 8.0, 8.0, 12.0, 12.0, 10.0, 8.0, -10.0, 0.0, 10.0, 13.0, 17.0, 1.0, -10.0, 2.0, 16.0, 0.0, 10.0, -10.0, 4.0, 14.0, 10.0, 12.0, -10.0, 14.0, 9.0, 2.0, -10.0, -10.0, -10.0, 14.0, 10.0, 14.0, 6.0, 12.0, -10.0, -10.0, 10.0, -10.0, 14.0, 12.0, 12.0, -10.0, 12.0, 14.0, 16.0, 10.0, 4.0, 10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2871112651075665, "mean_inference_ms": 1.5270912460202561, "mean_action_processing_ms": 0.10040414244831884, "mean_env_wait_ms": 0.06664963895327901, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14723, "timesteps_this_iter": 32, "agent_timesteps_total": 29446, "timers": {"load_time_ms": 0.424, "load_throughput": 75556.028, "learn_time_ms": 7.087, "learn_throughput": 4515.011, "update_time_ms": 4.323}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 2.7298262119293213, "min_q": -6.844762802124023, "max_q": 11.280315399169922, "mean_td_error": -0.5881629586219788, "model": {}}, "td_error": [1.67216157913208, -0.279803991317749, -1.7829484939575195, -0.9018895626068115, -0.3642911911010742, -2.2780637741088867, -0.6521854400634766, -0.9120477437973022, 0.2535606622695923, -2.3059475421905518, 2.694058895111084, 0.6732387542724609, -0.19723081588745117, 0.004123687744140625, -2.7437520027160645, -0.4313795566558838, -5.3652496337890625, -0.2729630470275879, 0.38364195823669434, 0.36086052656173706, 0.9494009017944336, 3.31756854057312, 1.1625633239746094, 0.6858184337615967, 1.0419425964355469, -0.23875761032104492, 0.4001929759979248, -0.14236736297607422, -0.9401111602783203, 0.603813648223877, 2.1514580249786377, -15.366630554199219], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.2662571668624878, "min_q": -5.938241481781006, "max_q": 9.348431587219238, "mean_td_error": -2.3886420726776123, "model": {}}, "td_error": [-5.68164587020874, 0.2694060802459717, -3.866344451904297, -1.42649507522583, -8.361285209655762, -0.20948004722595215, -1.0278682708740234, -13.364678382873535, -1.5822944641113281, -1.3704841136932373, -10.585105895996094, -0.9494953155517578, -2.011209011077881, -4.004800796508789, -6.015007495880127, -0.7711386680603027, -4.21942138671875, 4.184271812438965, -5.750682353973389, -1.0324463844299316, 2.4746596813201904, -1.604504108428955, -1.3231029510498047, -3.4588241577148438, -1.375622272491455, -0.004494190216064453, -8.561080932617188, 6.449892044067383, 0.878204345703125, 0.8467284440994263, -4.252780914306641, 1.2705817222595215], "custom_metrics": {}}}, "num_steps_sampled": 14723, "num_agent_steps_sampled": 29446, "num_steps_trained": 29440, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 58880, "last_target_update_ts": 14703, "num_target_updates": 125}, "done": false, "episodes_total": 990, "training_iteration": 45, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-33", "timestamp": 1648811553, "time_this_iter_s": 1.3098602294921875, "time_total_s": 57.02987790107727, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 57.02987790107727, "timesteps_since_restore": 1440, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 15.65, "ram_util_percent": 36.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -20.0, "episode_reward_mean": 12.72, "episode_len_mean": 11.44, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 6.36, "policy1": 6.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 28.0, -20.0, -20.0, -20.0, 28.0, -20.0, 28.0, 28.0, 34.0, 32.0, 16.0, 34.0, 16.0, -20.0, 4.0, 10.0, -20.0, 30.0, 28.0, 28.0, 32.0, -20.0, 34.0, 34.0, 20.0, 34.0, 28.0, 28.0, 20.0, 12.0, 16.0, 16.0, 24.0, 24.0, 20.0, 16.0, -20.0, 0.0, 20.0, 26.0, 34.0, 2.0, -20.0, 4.0, 32.0, 0.0, 20.0, -20.0, 8.0, 28.0, 20.0, 24.0, -20.0, 28.0, 18.0, 4.0, -20.0, -20.0, -20.0, 28.0, 20.0, 28.0, 12.0, 24.0, -20.0, -20.0, 20.0, -20.0, 28.0, 24.0, 24.0, -20.0, 24.0, 28.0, 32.0, 20.0, 8.0, 20.0, 20.0, 28.0, 24.0, 22.0, 14.0, -20.0, 28.0, 20.0, 28.0, 20.0, 28.0, 20.0, 14.0, 16.0, 16.0, 24.0, 24.0, -20.0, 28.0, -20.0, -20.0], "episode_lengths": [6, 6, 20, 20, 20, 6, 20, 6, 6, 3, 4, 12, 3, 12, 20, 18, 15, 20, 5, 6, 6, 4, 20, 3, 3, 10, 3, 6, 6, 10, 14, 12, 12, 8, 8, 10, 12, 20, 20, 10, 7, 3, 19, 20, 18, 4, 20, 10, 20, 16, 6, 10, 8, 20, 6, 11, 18, 20, 20, 20, 6, 10, 6, 14, 8, 20, 20, 10, 20, 6, 8, 8, 20, 8, 6, 4, 10, 16, 10, 10, 6, 8, 9, 13, 20, 6, 10, 6, 10, 6, 10, 13, 12, 12, 8, 8, 20, 6, 20, 20], "policy_policy0_reward": [14.0, 14.0, -10.0, -10.0, -10.0, 14.0, -10.0, 14.0, 14.0, 17.0, 16.0, 8.0, 17.0, 8.0, -10.0, 2.0, 5.0, -10.0, 15.0, 14.0, 14.0, 16.0, -10.0, 17.0, 17.0, 10.0, 17.0, 14.0, 14.0, 10.0, 6.0, 8.0, 8.0, 12.0, 12.0, 10.0, 8.0, -10.0, 0.0, 10.0, 13.0, 17.0, 1.0, -10.0, 2.0, 16.0, 0.0, 10.0, -10.0, 4.0, 14.0, 10.0, 12.0, -10.0, 14.0, 9.0, 2.0, -10.0, -10.0, -10.0, 14.0, 10.0, 14.0, 6.0, 12.0, -10.0, -10.0, 10.0, -10.0, 14.0, 12.0, 12.0, -10.0, 12.0, 14.0, 16.0, 10.0, 4.0, 10.0, 10.0, 14.0, 12.0, 11.0, 7.0, -10.0, 14.0, 10.0, 14.0, 10.0, 14.0, 10.0, 7.0, 8.0, 8.0, 12.0, 12.0, -10.0, 14.0, -10.0, -10.0], "policy_policy1_reward": [14.0, 14.0, -10.0, -10.0, -10.0, 14.0, -10.0, 14.0, 14.0, 17.0, 16.0, 8.0, 17.0, 8.0, -10.0, 2.0, 5.0, -10.0, 15.0, 14.0, 14.0, 16.0, -10.0, 17.0, 17.0, 10.0, 17.0, 14.0, 14.0, 10.0, 6.0, 8.0, 8.0, 12.0, 12.0, 10.0, 8.0, -10.0, 0.0, 10.0, 13.0, 17.0, 1.0, -10.0, 2.0, 16.0, 0.0, 10.0, -10.0, 4.0, 14.0, 10.0, 12.0, -10.0, 14.0, 9.0, 2.0, -10.0, -10.0, -10.0, 14.0, 10.0, 14.0, 6.0, 12.0, -10.0, -10.0, 10.0, -10.0, 14.0, 12.0, 12.0, -10.0, 12.0, 14.0, 16.0, 10.0, 4.0, 10.0, 10.0, 14.0, 12.0, 11.0, 7.0, -10.0, 14.0, 10.0, 14.0, 10.0, 14.0, 10.0, 7.0, 8.0, 8.0, 12.0, 12.0, -10.0, 14.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2872137768909232, "mean_inference_ms": 1.5262275954652795, "mean_action_processing_ms": 0.10035384728498734, "mean_env_wait_ms": 0.0666048575404048, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14946, "timesteps_this_iter": 32, "agent_timesteps_total": 29892, "timers": {"load_time_ms": 0.431, "load_throughput": 74206.739, "learn_time_ms": 7.618, "learn_throughput": 4200.828, "update_time_ms": 4.782}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.803211688995361, "min_q": -7.180543422698975, "max_q": 14.319366455078125, "mean_td_error": -0.7187656760215759, "model": {}}, "td_error": [-6.26823091506958, 0.22227191925048828, 1.4613323211669922, -9.224283218383789, -0.14387834072113037, -4.970187187194824, 1.2757244110107422, -0.38747572898864746, -1.0957236289978027, 0.2450876235961914, 0.7298927307128906, -3.9418559074401855, -0.9097681045532227, -2.031810760498047, 0.35564982891082764, 5.319366455078125, -8.091075897216797, 0.8919296264648438, -0.5101261138916016, 0.7428312301635742, -0.2705906629562378, 0.4996818006038666, 0.08530426025390625, 0.14900922775268555, -4.833123207092285, 1.174483299255371, -0.18293094635009766, 6.672507286071777, 0.9161586761474609, -0.12318849563598633, 0.0707857608795166, -0.8282661437988281], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 1.19536554813385, "min_q": -4.875388145446777, "max_q": 5.179014205932617, "mean_td_error": -1.1689929962158203, "model": {}}, "td_error": [-8.73763656616211, 0.4893484115600586, 0.42258691787719727, 0.28411245346069336, 3.3266220092773438, 0.4644155502319336, -0.24760055541992188, 4.114689826965332, 0.7432501316070557, -0.6425809860229492, 1.595344066619873, 1.3770098686218262, -7.732099533081055, -12.578526496887207, -0.1208353042602539, -1.3256453275680542, 1.6595771312713623, -5.083405494689941, -0.10070157051086426, 0.3417320251464844, -4.642021656036377, 0.11432600021362305, -1.7726781368255615, 2.9339544773101807, 0.26203393936157227, -8.555736541748047, -0.2602052688598633, 0.4485774040222168, 0.07358837127685547, -0.6381070613861084, -0.6278061866760254, -2.9933557510375977], "custom_metrics": {}}}, "num_steps_sampled": 14946, "num_agent_steps_sampled": 29892, "num_steps_trained": 30080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 60160, "last_target_update_ts": 14926, "num_target_updates": 127}, "done": false, "episodes_total": 1010, "training_iteration": 46, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-34", "timestamp": 1648811554, "time_this_iter_s": 1.0163898468017578, "time_total_s": 58.04626774787903, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 58.04626774787903, "timesteps_since_restore": 1472, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 14.65, "ram_util_percent": 36.05}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 12.54, "episode_len_mean": 11.83, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 6.27, "policy1": 6.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 28.0, 20.0, 12.0, 16.0, 16.0, 24.0, 24.0, 20.0, 16.0, -20.0, 0.0, 20.0, 26.0, 34.0, 2.0, -20.0, 4.0, 32.0, 0.0, 20.0, -20.0, 8.0, 28.0, 20.0, 24.0, -20.0, 28.0, 18.0, 4.0, -20.0, -20.0, -20.0, 28.0, 20.0, 28.0, 12.0, 24.0, -20.0, -20.0, 20.0, -20.0, 28.0, 24.0, 24.0, -20.0, 24.0, 28.0, 32.0, 20.0, 8.0, 20.0, 20.0, 28.0, 24.0, 22.0, 14.0, -20.0, 28.0, 20.0, 28.0, 20.0, 28.0, 20.0, 14.0, 16.0, 16.0, 24.0, 24.0, -20.0, 28.0, -20.0, -20.0, -20.0, 28.0, 24.0, 24.0, -40.0, 24.0, 10.0, 24.0, 16.0, 28.0, 28.0, 16.0, 16.0, 0.0, 12.0, 24.0, 12.0, 20.0, 0.0, 12.0, 16.0, 20.0, 20.0, 30.0, 32.0, 12.0, -20.0], "episode_lengths": [6, 6, 10, 14, 12, 12, 8, 8, 10, 12, 20, 20, 10, 7, 3, 19, 20, 18, 4, 20, 10, 20, 16, 6, 10, 8, 20, 6, 11, 18, 20, 20, 20, 6, 10, 6, 14, 8, 20, 20, 10, 20, 6, 8, 8, 20, 8, 6, 4, 10, 16, 10, 10, 6, 8, 9, 13, 20, 6, 10, 6, 10, 6, 10, 13, 12, 12, 8, 8, 20, 6, 20, 20, 20, 6, 8, 8, 20, 8, 15, 8, 12, 6, 6, 12, 12, 20, 14, 8, 14, 10, 20, 14, 12, 10, 10, 5, 4, 14, 20], "policy_policy0_reward": [14.0, 14.0, 10.0, 6.0, 8.0, 8.0, 12.0, 12.0, 10.0, 8.0, -10.0, 0.0, 10.0, 13.0, 17.0, 1.0, -10.0, 2.0, 16.0, 0.0, 10.0, -10.0, 4.0, 14.0, 10.0, 12.0, -10.0, 14.0, 9.0, 2.0, -10.0, -10.0, -10.0, 14.0, 10.0, 14.0, 6.0, 12.0, -10.0, -10.0, 10.0, -10.0, 14.0, 12.0, 12.0, -10.0, 12.0, 14.0, 16.0, 10.0, 4.0, 10.0, 10.0, 14.0, 12.0, 11.0, 7.0, -10.0, 14.0, 10.0, 14.0, 10.0, 14.0, 10.0, 7.0, 8.0, 8.0, 12.0, 12.0, -10.0, 14.0, -10.0, -10.0, -10.0, 14.0, 12.0, 12.0, -20.0, 12.0, 5.0, 12.0, 8.0, 14.0, 14.0, 8.0, 8.0, 0.0, 6.0, 12.0, 6.0, 10.0, 0.0, 6.0, 8.0, 10.0, 10.0, 15.0, 16.0, 6.0, -10.0], "policy_policy1_reward": [14.0, 14.0, 10.0, 6.0, 8.0, 8.0, 12.0, 12.0, 10.0, 8.0, -10.0, 0.0, 10.0, 13.0, 17.0, 1.0, -10.0, 2.0, 16.0, 0.0, 10.0, -10.0, 4.0, 14.0, 10.0, 12.0, -10.0, 14.0, 9.0, 2.0, -10.0, -10.0, -10.0, 14.0, 10.0, 14.0, 6.0, 12.0, -10.0, -10.0, 10.0, -10.0, 14.0, 12.0, 12.0, -10.0, 12.0, 14.0, 16.0, 10.0, 4.0, 10.0, 10.0, 14.0, 12.0, 11.0, 7.0, -10.0, 14.0, 10.0, 14.0, 10.0, 14.0, 10.0, 7.0, 8.0, 8.0, 12.0, 12.0, -10.0, 14.0, -10.0, -10.0, -10.0, 14.0, 12.0, 12.0, -20.0, 12.0, 5.0, 12.0, 8.0, 14.0, 14.0, 8.0, 8.0, 0.0, 6.0, 12.0, 6.0, 10.0, 0.0, 6.0, 8.0, 10.0, 10.0, 15.0, 16.0, 6.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.287304177637207, "mean_inference_ms": 1.5248927772037286, "mean_action_processing_ms": 0.10027026874667083, "mean_env_wait_ms": 0.06653895128374876, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15262, "timesteps_this_iter": 32, "agent_timesteps_total": 30524, "timers": {"load_time_ms": 0.413, "load_throughput": 77466.079, "learn_time_ms": 7.202, "learn_throughput": 4442.957, "update_time_ms": 4.653}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.5279979705810547, "min_q": -4.829535961151123, "max_q": 10.201783180236816, "mean_td_error": -1.509223461151123, "model": {}}, "td_error": [-0.6385661363601685, -0.5621349811553955, 2.4051291942596436, -2.3005757331848145, -3.1030025482177734, -1.268606185913086, -1.2072806358337402, -5.994891166687012, -6.231693744659424, 0.1492176055908203, -2.8528060913085938, 4.907222270965576, -3.1774868965148926, -1.648543119430542, 0.27130603790283203, 2.238868236541748, -8.954781532287598, 0.052052974700927734, 0.010720252990722656, 0.5484402179718018, -5.85622501373291, -1.0949091911315918, -8.267931938171387, -0.0830068588256836, -0.3769063949584961, -2.519317150115967, 1.077202558517456, -3.5911569595336914, -1.7195467948913574, 0.6323800086975098, 2.0155606269836426, -1.1538848876953125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -0.8919609785079956, "min_q": -5.0819621086120605, "max_q": 7.911459445953369, "mean_td_error": -0.9073569178581238, "model": {}}, "td_error": [2.3684141635894775, 0.04787898063659668, -2.511899948120117, 2.1454529762268066, 0.21146154403686523, 1.5452260971069336, 0.7084984183311462, 1.1824536323547363, -9.042807579040527, 1.140275478363037, -0.4226851463317871, -10.599267959594727, -2.382549285888672, 0.27947700023651123, 0.05428338050842285, 1.7959120273590088, -10.579289436340332, 0.4285721778869629, 0.8967938423156738, 3.4682490825653076, -2.471803903579712, 0.35864925384521484, -0.023629426956176758, -1.1214473247528076, 0.3489532470703125, 0.7564373016357422, 0.7915387153625488, 0.22346854209899902, 1.0892653465270996, -9.430386543273926, 0.7976255416870117, -1.0885405540466309], "custom_metrics": {}}}, "num_steps_sampled": 15262, "num_agent_steps_sampled": 30524, "num_steps_trained": 30944, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 61888, "last_target_update_ts": 15262, "num_target_updates": 130}, "done": false, "episodes_total": 1037, "training_iteration": 47, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-35", "timestamp": 1648811555, "time_this_iter_s": 1.3539230823516846, "time_total_s": 59.40019083023071, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 59.40019083023071, "timesteps_since_restore": 1504, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 15.75, "ram_util_percent": 36.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 12.7, "episode_len_mean": 11.45, "episode_media": {}, "episodes_this_iter": 30, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 6.35, "policy1": 6.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 28.0, 20.0, 28.0, 12.0, 24.0, -20.0, -20.0, 20.0, -20.0, 28.0, 24.0, 24.0, -20.0, 24.0, 28.0, 32.0, 20.0, 8.0, 20.0, 20.0, 28.0, 24.0, 22.0, 14.0, -20.0, 28.0, 20.0, 28.0, 20.0, 28.0, 20.0, 14.0, 16.0, 16.0, 24.0, 24.0, -20.0, 28.0, -20.0, -20.0, -20.0, 28.0, 24.0, 24.0, -40.0, 24.0, 10.0, 24.0, 16.0, 28.0, 28.0, 16.0, 16.0, 0.0, 12.0, 24.0, 12.0, 20.0, 0.0, 12.0, 16.0, 20.0, 20.0, 30.0, 32.0, 12.0, -20.0, 16.0, 32.0, 0.0, 28.0, 26.0, 28.0, 28.0, 26.0, -20.0, 20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, 28.0, 32.0, 34.0, 30.0, 28.0, 24.0, 8.0, 34.0, 24.0, 28.0, 18.0, 16.0], "episode_lengths": [20, 20, 20, 6, 10, 6, 14, 8, 20, 20, 10, 20, 6, 8, 8, 20, 8, 6, 4, 10, 16, 10, 10, 6, 8, 9, 13, 20, 6, 10, 6, 10, 6, 10, 13, 12, 12, 8, 8, 20, 6, 20, 20, 20, 6, 8, 8, 20, 8, 15, 8, 12, 6, 6, 12, 12, 20, 14, 8, 14, 10, 20, 14, 12, 10, 10, 5, 4, 14, 20, 12, 4, 20, 6, 7, 6, 6, 7, 20, 10, 11, 20, 20, 20, 20, 9, 20, 20, 6, 4, 3, 5, 6, 8, 16, 3, 8, 6, 11, 12], "policy_policy0_reward": [-10.0, -10.0, -10.0, 14.0, 10.0, 14.0, 6.0, 12.0, -10.0, -10.0, 10.0, -10.0, 14.0, 12.0, 12.0, -10.0, 12.0, 14.0, 16.0, 10.0, 4.0, 10.0, 10.0, 14.0, 12.0, 11.0, 7.0, -10.0, 14.0, 10.0, 14.0, 10.0, 14.0, 10.0, 7.0, 8.0, 8.0, 12.0, 12.0, -10.0, 14.0, -10.0, -10.0, -10.0, 14.0, 12.0, 12.0, -20.0, 12.0, 5.0, 12.0, 8.0, 14.0, 14.0, 8.0, 8.0, 0.0, 6.0, 12.0, 6.0, 10.0, 0.0, 6.0, 8.0, 10.0, 10.0, 15.0, 16.0, 6.0, -10.0, 8.0, 16.0, 0.0, 14.0, 13.0, 14.0, 14.0, 13.0, -10.0, 10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, 14.0, 16.0, 17.0, 15.0, 14.0, 12.0, 4.0, 17.0, 12.0, 14.0, 9.0, 8.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 14.0, 10.0, 14.0, 6.0, 12.0, -10.0, -10.0, 10.0, -10.0, 14.0, 12.0, 12.0, -10.0, 12.0, 14.0, 16.0, 10.0, 4.0, 10.0, 10.0, 14.0, 12.0, 11.0, 7.0, -10.0, 14.0, 10.0, 14.0, 10.0, 14.0, 10.0, 7.0, 8.0, 8.0, 12.0, 12.0, -10.0, 14.0, -10.0, -10.0, -10.0, 14.0, 12.0, 12.0, -20.0, 12.0, 5.0, 12.0, 8.0, 14.0, 14.0, 8.0, 8.0, 0.0, 6.0, 12.0, 6.0, 10.0, 0.0, 6.0, 8.0, 10.0, 10.0, 15.0, 16.0, 6.0, -10.0, 8.0, 16.0, 0.0, 14.0, 13.0, 14.0, 14.0, 13.0, -10.0, 10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, 14.0, 16.0, 17.0, 15.0, 14.0, 12.0, 4.0, 17.0, 12.0, 14.0, 9.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2875728264433734, "mean_inference_ms": 1.5241615982849952, "mean_action_processing_ms": 0.10024312342918006, "mean_env_wait_ms": 0.06650573938806308, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15588, "timesteps_this_iter": 32, "agent_timesteps_total": 31176, "timers": {"load_time_ms": 0.446, "load_throughput": 71678.359, "learn_time_ms": 7.943, "learn_throughput": 4028.905, "update_time_ms": 5.147}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.404667854309082, "min_q": -5.193495750427246, "max_q": 11.115815162658691, "mean_td_error": -0.38543206453323364, "model": {}}, "td_error": [0.9576711654663086, 1.0543694496154785, -0.02752208709716797, -2.864744186401367, -5.981538772583008, 0.3283262252807617, -0.10349845886230469, -5.913201332092285, 2.0038297176361084, 0.5828359127044678, -2.6764020919799805, 0.7240533828735352, -1.7813501358032227, 1.6869492530822754, -1.4592936038970947, 1.2429872751235962, 0.9186601638793945, 0.675287127494812, 0.31333351135253906, 2.6715941429138184, -0.25647449493408203, -1.2787485122680664, -1.8373464345932007, -1.00783371925354, -2.021745204925537, 1.051271677017212, 0.44764184951782227, -2.970433235168457, -0.4984922409057617, -1.8643862009048462, 3.5698604583740234, 1.9805136919021606], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.353288173675537, "min_q": -6.040665626525879, "max_q": 5.311114311218262, "mean_td_error": -2.6806633472442627, "model": {}}, "td_error": [-0.8011138439178467, -0.5847773551940918, -10.80953598022461, -9.215502738952637, -0.28677892684936523, 1.563631534576416, 0.587954044342041, 2.565460443496704, 1.2032246589660645, -9.276946067810059, -2.019791603088379, -9.690458297729492, -0.09351158142089844, 1.9805960655212402, 0.5511631965637207, -10.230937957763672, 0.20308208465576172, 1.098902702331543, -0.18336904048919678, -9.522768020629883, 1.9805960655212402, -9.920716285705566, -0.050177574157714844, -6.643385410308838, -11.181166648864746, -2.7892117500305176, 1.841686725616455, 0.3320896625518799, 0.7092866897583008, -0.04508638381958008, -1.632859468460083, -5.420812129974365], "custom_metrics": {}}}, "num_steps_sampled": 15588, "num_agent_steps_sampled": 31176, "num_steps_trained": 31840, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 63680, "last_target_update_ts": 15588, "num_target_updates": 133}, "done": false, "episodes_total": 1067, "training_iteration": 48, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-37", "timestamp": 1648811557, "time_this_iter_s": 1.4866745471954346, "time_total_s": 60.88686537742615, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cda70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cda70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 60.88686537742615, "timesteps_since_restore": 1536, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 18.049999999999997, "ram_util_percent": 36.7}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 15.92, "episode_len_mean": 10.44, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 7.96, "policy1": 7.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, -20.0, 28.0, 20.0, 28.0, 20.0, 28.0, 20.0, 14.0, 16.0, 16.0, 24.0, 24.0, -20.0, 28.0, -20.0, -20.0, -20.0, 28.0, 24.0, 24.0, -40.0, 24.0, 10.0, 24.0, 16.0, 28.0, 28.0, 16.0, 16.0, 0.0, 12.0, 24.0, 12.0, 20.0, 0.0, 12.0, 16.0, 20.0, 20.0, 30.0, 32.0, 12.0, -20.0, 16.0, 32.0, 0.0, 28.0, 26.0, 28.0, 28.0, 26.0, -20.0, 20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, 28.0, 32.0, 34.0, 30.0, 28.0, 24.0, 8.0, 34.0, 24.0, 28.0, 18.0, 16.0, 24.0, 32.0, 28.0, 24.0, 34.0, 20.0, 32.0, 2.0, 30.0, 26.0, 20.0, 24.0, 34.0, 26.0, 10.0, 34.0, 24.0, 30.0, -20.0, 30.0, 26.0, 34.0, 26.0, 4.0, 34.0, 28.0], "episode_lengths": [13, 20, 6, 10, 6, 10, 6, 10, 13, 12, 12, 8, 8, 20, 6, 20, 20, 20, 6, 8, 8, 20, 8, 15, 8, 12, 6, 6, 12, 12, 20, 14, 8, 14, 10, 20, 14, 12, 10, 10, 5, 4, 14, 20, 12, 4, 20, 6, 7, 6, 6, 7, 20, 10, 11, 20, 20, 20, 20, 9, 20, 20, 6, 4, 3, 5, 6, 8, 16, 3, 8, 6, 11, 12, 8, 4, 6, 8, 3, 10, 4, 19, 5, 7, 10, 8, 3, 7, 15, 3, 8, 5, 20, 5, 7, 3, 7, 18, 3, 6], "policy_policy0_reward": [7.0, -10.0, 14.0, 10.0, 14.0, 10.0, 14.0, 10.0, 7.0, 8.0, 8.0, 12.0, 12.0, -10.0, 14.0, -10.0, -10.0, -10.0, 14.0, 12.0, 12.0, -20.0, 12.0, 5.0, 12.0, 8.0, 14.0, 14.0, 8.0, 8.0, 0.0, 6.0, 12.0, 6.0, 10.0, 0.0, 6.0, 8.0, 10.0, 10.0, 15.0, 16.0, 6.0, -10.0, 8.0, 16.0, 0.0, 14.0, 13.0, 14.0, 14.0, 13.0, -10.0, 10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, 14.0, 16.0, 17.0, 15.0, 14.0, 12.0, 4.0, 17.0, 12.0, 14.0, 9.0, 8.0, 12.0, 16.0, 14.0, 12.0, 17.0, 10.0, 16.0, 1.0, 15.0, 13.0, 10.0, 12.0, 17.0, 13.0, 5.0, 17.0, 12.0, 15.0, -10.0, 15.0, 13.0, 17.0, 13.0, 2.0, 17.0, 14.0], "policy_policy1_reward": [7.0, -10.0, 14.0, 10.0, 14.0, 10.0, 14.0, 10.0, 7.0, 8.0, 8.0, 12.0, 12.0, -10.0, 14.0, -10.0, -10.0, -10.0, 14.0, 12.0, 12.0, -20.0, 12.0, 5.0, 12.0, 8.0, 14.0, 14.0, 8.0, 8.0, 0.0, 6.0, 12.0, 6.0, 10.0, 0.0, 6.0, 8.0, 10.0, 10.0, 15.0, 16.0, 6.0, -10.0, 8.0, 16.0, 0.0, 14.0, 13.0, 14.0, 14.0, 13.0, -10.0, 10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, 14.0, 16.0, 17.0, 15.0, 14.0, 12.0, 4.0, 17.0, 12.0, 14.0, 9.0, 8.0, 12.0, 16.0, 14.0, 12.0, 17.0, 10.0, 16.0, 1.0, 15.0, 13.0, 10.0, 12.0, 17.0, 13.0, 5.0, 17.0, 12.0, 15.0, -10.0, 15.0, 13.0, 17.0, 13.0, 2.0, 17.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28801204468045716, "mean_inference_ms": 1.524370861178985, "mean_action_processing_ms": 0.100270953191263, "mean_env_wait_ms": 0.0665225692806265, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15790, "timesteps_this_iter": 32, "agent_timesteps_total": 31580, "timers": {"load_time_ms": 0.421, "load_throughput": 75979.467, "learn_time_ms": 7.325, "learn_throughput": 4368.455, "update_time_ms": 5.082}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.675693511962891, "min_q": -2.9593420028686523, "max_q": 14.233137130737305, "mean_td_error": -0.13954231142997742, "model": {}}, "td_error": [-0.9370412826538086, -1.369354248046875, -2.0208911895751953, -5.445400238037109, 2.4252710342407227, 0.33203768730163574, -6.579209327697754, -3.9847660064697266, 1.1085634231567383, 2.656569004058838, -3.8461556434631348, 0.5638246536254883, 1.5519626140594482, -2.387690544128418, -0.005532264709472656, 3.436338424682617, 7.511578559875488, -1.5030136108398438, 7.346726894378662, -0.27617359161376953, -1.429889440536499, -0.3268303871154785, -3.028158187866211, 0.47462034225463867, 0.7257061004638672, 0.8520393371582031, 2.08651065826416, -1.4271445274353027, -1.5642242431640625, -0.005532264709472656, -0.24009418487548828, 0.839998722076416], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.5525672435760498, "min_q": -6.0404157638549805, "max_q": 5.526458740234375, "mean_td_error": -0.8176873922348022, "model": {}}, "td_error": [0.8822653293609619, 1.6348321437835693, 1.1445870399475098, 1.9952454566955566, 1.418713092803955, -3.900956392288208, -2.5867412090301514, -3.464675188064575, 0.14689016342163086, 3.096569776535034, -11.51435661315918, 0.04957127571105957, 1.3793365955352783, 0.6867187023162842, 1.0687785148620605, 0.16171884536743164, -9.125296592712402, -0.49892520904541016, 1.0858490467071533, -2.103701591491699, 1.0906563997268677, 0.24219369888305664, 0.8802571296691895, 2.507915496826172, 1.137561321258545, -6.204919338226318, -4.656717777252197, -5.245963096618652, 0.7776083946228027, 2.0215024948120117, 0.4044792652130127, -0.6769932508468628], "custom_metrics": {}}}, "num_steps_sampled": 15790, "num_agent_steps_sampled": 31580, "num_steps_trained": 32512, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 65024, "last_target_update_ts": 15690, "num_target_updates": 134}, "done": false, "episodes_total": 1093, "training_iteration": 49, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-38", "timestamp": 1648811558, "time_this_iter_s": 1.0638816356658936, "time_total_s": 61.95074701309204, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e1d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e1d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 61.95074701309204, "timesteps_since_restore": 1568, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 33.9, "ram_util_percent": 37.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -20.0, "episode_reward_mean": 18.8, "episode_len_mean": 9.5, "episode_media": {}, "episodes_this_iter": 28, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 9.4, "policy1": 9.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 16.0, 0.0, 12.0, 24.0, 12.0, 20.0, 0.0, 12.0, 16.0, 20.0, 20.0, 30.0, 32.0, 12.0, -20.0, 16.0, 32.0, 0.0, 28.0, 26.0, 28.0, 28.0, 26.0, -20.0, 20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, 28.0, 32.0, 34.0, 30.0, 28.0, 24.0, 8.0, 34.0, 24.0, 28.0, 18.0, 16.0, 24.0, 32.0, 28.0, 24.0, 34.0, 20.0, 32.0, 2.0, 30.0, 26.0, 20.0, 24.0, 34.0, 26.0, 10.0, 34.0, 24.0, 30.0, -20.0, 30.0, 26.0, 34.0, 26.0, 4.0, 34.0, 28.0, 30.0, 24.0, 28.0, 28.0, 32.0, 12.0, 30.0, 30.0, 28.0, 22.0, 24.0, 28.0, 28.0, 28.0, 18.0, 28.0, 24.0, 28.0, 24.0, 34.0, 24.0, 20.0, 34.0, 34.0, 34.0, 0.0, -20.0, -20.0], "episode_lengths": [12, 12, 20, 14, 8, 14, 10, 20, 14, 12, 10, 10, 5, 4, 14, 20, 12, 4, 20, 6, 7, 6, 6, 7, 20, 10, 11, 20, 20, 20, 20, 9, 20, 20, 6, 4, 3, 5, 6, 8, 16, 3, 8, 6, 11, 12, 8, 4, 6, 8, 3, 10, 4, 19, 5, 7, 10, 8, 3, 7, 15, 3, 8, 5, 20, 5, 7, 3, 7, 18, 3, 6, 5, 8, 6, 6, 4, 14, 5, 5, 6, 9, 8, 6, 6, 6, 11, 6, 8, 6, 8, 3, 8, 10, 3, 3, 3, 20, 20, 20], "policy_policy0_reward": [8.0, 8.0, 0.0, 6.0, 12.0, 6.0, 10.0, 0.0, 6.0, 8.0, 10.0, 10.0, 15.0, 16.0, 6.0, -10.0, 8.0, 16.0, 0.0, 14.0, 13.0, 14.0, 14.0, 13.0, -10.0, 10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, 14.0, 16.0, 17.0, 15.0, 14.0, 12.0, 4.0, 17.0, 12.0, 14.0, 9.0, 8.0, 12.0, 16.0, 14.0, 12.0, 17.0, 10.0, 16.0, 1.0, 15.0, 13.0, 10.0, 12.0, 17.0, 13.0, 5.0, 17.0, 12.0, 15.0, -10.0, 15.0, 13.0, 17.0, 13.0, 2.0, 17.0, 14.0, 15.0, 12.0, 14.0, 14.0, 16.0, 6.0, 15.0, 15.0, 14.0, 11.0, 12.0, 14.0, 14.0, 14.0, 9.0, 14.0, 12.0, 14.0, 12.0, 17.0, 12.0, 10.0, 17.0, 17.0, 17.0, 0.0, -10.0, -10.0], "policy_policy1_reward": [8.0, 8.0, 0.0, 6.0, 12.0, 6.0, 10.0, 0.0, 6.0, 8.0, 10.0, 10.0, 15.0, 16.0, 6.0, -10.0, 8.0, 16.0, 0.0, 14.0, 13.0, 14.0, 14.0, 13.0, -10.0, 10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, 14.0, 16.0, 17.0, 15.0, 14.0, 12.0, 4.0, 17.0, 12.0, 14.0, 9.0, 8.0, 12.0, 16.0, 14.0, 12.0, 17.0, 10.0, 16.0, 1.0, 15.0, 13.0, 10.0, 12.0, 17.0, 13.0, 5.0, 17.0, 12.0, 15.0, -10.0, 15.0, 13.0, 17.0, 13.0, 2.0, 17.0, 14.0, 15.0, 12.0, 14.0, 14.0, 16.0, 6.0, 15.0, 15.0, 14.0, 11.0, 12.0, 14.0, 14.0, 14.0, 9.0, 14.0, 12.0, 14.0, 12.0, 17.0, 12.0, 10.0, 17.0, 17.0, 17.0, 0.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2895404595027859, "mean_inference_ms": 1.5315963803113781, "mean_action_processing_ms": 0.10065537770259325, "mean_env_wait_ms": 0.06678206391415883, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16013, "timesteps_this_iter": 32, "agent_timesteps_total": 32026, "timers": {"load_time_ms": 0.76, "load_throughput": 42122.059, "learn_time_ms": 18.288, "learn_throughput": 1749.766, "update_time_ms": 11.202}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.807441711425781, "min_q": -2.2683351039886475, "max_q": 13.485868453979492, "mean_td_error": -0.19660204648971558, "model": {}}, "td_error": [2.7283787727355957, 0.9432048797607422, 2.9943761825561523, -0.11590290069580078, -1.1870803833007812, 0.35643720626831055, -7.002918243408203, -0.5218572616577148, 0.5480175018310547, 0.33272767066955566, -4.193323135375977, 0.5480175018310547, -0.47031688690185547, 4.728262901306152, -1.0412425994873047, -1.473271369934082, -1.2683351039886475, -0.31861019134521484, 4.206373691558838, -0.17228174209594727, -2.093019485473633, 0.534259557723999, -10.616865158081055, 8.380517959594727, 1.8706235885620117, 3.0060079097747803, -1.4255380630493164, -4.9326324462890625, 0.9249114990234375, -0.13103675842285156, -1.528031826019287, 0.09888362884521484], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -2.0791850090026855, "min_q": -8.264419555664062, "max_q": 8.111879348754883, "mean_td_error": 0.20235919952392578, "model": {}}, "td_error": [0.10530441999435425, 1.6864700317382812, -1.0546412467956543, -0.8881206512451172, 1.6339983940124512, -0.06654906272888184, -8.472803115844727, 1.3933873176574707, -7.219101428985596, 1.6678080558776855, -0.5868263244628906, 0.9838052988052368, -1.4217984676361084, -1.135909080505371, 0.44842529296875, -3.9471702575683594, -0.6474123001098633, 7.383708477020264, 2.4171571731567383, 3.7446744441986084, 6.056949615478516, 2.0272164344787598, -0.3095855712890625, -2.7787184715270996, 4.586510181427002, 5.906142711639404, -5.602686405181885, 0.7614245414733887, -3.584585189819336, 1.7641444206237793, 1.3696136474609375, 0.25466060638427734], "custom_metrics": {}}}, "num_steps_sampled": 16013, "num_agent_steps_sampled": 32026, "num_steps_trained": 33312, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 66624, "last_target_update_ts": 16013, "num_target_updates": 137}, "done": false, "episodes_total": 1121, "training_iteration": 50, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-40", "timestamp": 1648811560, "time_this_iter_s": 2.002195119857788, "time_total_s": 63.95294213294983, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 63.95294213294983, "timesteps_since_restore": 1600, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 50.53333333333333, "ram_util_percent": 38.96666666666666}}
{"episode_reward_max": 34.0, "episode_reward_min": -20.0, "episode_reward_mean": 24.2, "episode_len_mean": 7.4, "episode_media": {}, "episodes_this_iter": 33, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 12.1, "policy1": 12.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 28.0, 32.0, 34.0, 30.0, 28.0, 24.0, 8.0, 34.0, 24.0, 28.0, 18.0, 16.0, 24.0, 32.0, 28.0, 24.0, 34.0, 20.0, 32.0, 2.0, 30.0, 26.0, 20.0, 24.0, 34.0, 26.0, 10.0, 34.0, 24.0, 30.0, -20.0, 30.0, 26.0, 34.0, 26.0, 4.0, 34.0, 28.0, 30.0, 24.0, 28.0, 28.0, 32.0, 12.0, 30.0, 30.0, 28.0, 22.0, 24.0, 28.0, 28.0, 28.0, 18.0, 28.0, 24.0, 28.0, 24.0, 34.0, 24.0, 20.0, 34.0, 34.0, 34.0, 0.0, -20.0, -20.0, 32.0, 30.0, 32.0, 30.0, 34.0, 28.0, 28.0, 34.0, 34.0, 34.0, 28.0, 28.0, 24.0, 32.0, 34.0, 34.0, 34.0, 32.0, 30.0, 12.0, 28.0, -20.0, 34.0, 24.0, 28.0, 24.0, 4.0, 32.0, 18.0, 20.0, 34.0, 28.0, 28.0], "episode_lengths": [20, 6, 4, 3, 5, 6, 8, 16, 3, 8, 6, 11, 12, 8, 4, 6, 8, 3, 10, 4, 19, 5, 7, 10, 8, 3, 7, 15, 3, 8, 5, 20, 5, 7, 3, 7, 18, 3, 6, 5, 8, 6, 6, 4, 14, 5, 5, 6, 9, 8, 6, 6, 6, 11, 6, 8, 6, 8, 3, 8, 10, 3, 3, 3, 20, 20, 20, 4, 5, 4, 5, 3, 6, 6, 3, 3, 3, 6, 6, 8, 4, 3, 3, 3, 4, 5, 14, 6, 20, 3, 8, 6, 8, 18, 4, 11, 10, 3, 6, 6], "policy_policy0_reward": [-10.0, 14.0, 16.0, 17.0, 15.0, 14.0, 12.0, 4.0, 17.0, 12.0, 14.0, 9.0, 8.0, 12.0, 16.0, 14.0, 12.0, 17.0, 10.0, 16.0, 1.0, 15.0, 13.0, 10.0, 12.0, 17.0, 13.0, 5.0, 17.0, 12.0, 15.0, -10.0, 15.0, 13.0, 17.0, 13.0, 2.0, 17.0, 14.0, 15.0, 12.0, 14.0, 14.0, 16.0, 6.0, 15.0, 15.0, 14.0, 11.0, 12.0, 14.0, 14.0, 14.0, 9.0, 14.0, 12.0, 14.0, 12.0, 17.0, 12.0, 10.0, 17.0, 17.0, 17.0, 0.0, -10.0, -10.0, 16.0, 15.0, 16.0, 15.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 14.0, 14.0, 12.0, 16.0, 17.0, 17.0, 17.0, 16.0, 15.0, 6.0, 14.0, -10.0, 17.0, 12.0, 14.0, 12.0, 2.0, 16.0, 9.0, 10.0, 17.0, 14.0, 14.0], "policy_policy1_reward": [-10.0, 14.0, 16.0, 17.0, 15.0, 14.0, 12.0, 4.0, 17.0, 12.0, 14.0, 9.0, 8.0, 12.0, 16.0, 14.0, 12.0, 17.0, 10.0, 16.0, 1.0, 15.0, 13.0, 10.0, 12.0, 17.0, 13.0, 5.0, 17.0, 12.0, 15.0, -10.0, 15.0, 13.0, 17.0, 13.0, 2.0, 17.0, 14.0, 15.0, 12.0, 14.0, 14.0, 16.0, 6.0, 15.0, 15.0, 14.0, 11.0, 12.0, 14.0, 14.0, 14.0, 9.0, 14.0, 12.0, 14.0, 12.0, 17.0, 12.0, 10.0, 17.0, 17.0, 17.0, 0.0, -10.0, -10.0, 16.0, 15.0, 16.0, 15.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 14.0, 14.0, 12.0, 16.0, 17.0, 17.0, 17.0, 16.0, 15.0, 6.0, 14.0, -10.0, 17.0, 12.0, 14.0, 12.0, 2.0, 16.0, 9.0, 10.0, 17.0, 14.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29162311850178524, "mean_inference_ms": 1.541002497975902, "mean_action_processing_ms": 0.10115775687587839, "mean_env_wait_ms": 0.06712436336199197, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16220, "timesteps_this_iter": 32, "agent_timesteps_total": 32440, "timers": {"load_time_ms": 0.444, "load_throughput": 72047.736, "learn_time_ms": 7.891, "learn_throughput": 4055.296, "update_time_ms": 4.896}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.462939739227295, "min_q": -3.7431609630584717, "max_q": 14.911155700683594, "mean_td_error": -0.2638028860092163, "model": {}}, "td_error": [1.3579421043395996, 0.995579719543457, 0.09968376159667969, 0.6066546440124512, 5.6588521003723145, -1.0351171493530273, -3.3780040740966797, 5.602871894836426, 1.837228775024414, 0.2887873649597168, -2.7604074478149414, -1.6089000701904297, -0.6836013793945312, -1.3950912952423096, 0.19051361083984375, -0.7810754776000977, -0.8843927383422852, -0.9188785552978516, 0.15692520141601562, 0.09612178802490234, -1.425337314605713, 0.9959602355957031, 0.3227238655090332, -2.21345853805542, -0.8192930221557617, -10.757095336914062, -0.8103604316711426, -0.681912899017334, 0.9137845039367676, 1.6874266862869263, 0.28008365631103516, 0.6200942993164062], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -1.3759241104125977, "min_q": -8.251031875610352, "max_q": 8.726675033569336, "mean_td_error": -1.2030023336410522, "model": {}}, "td_error": [2.0434956550598145, -1.618384838104248, -0.5457520484924316, 1.76762056350708, -0.06456232070922852, -1.508500099182129, -2.4865665435791016, 13.61139965057373, 3.861374616622925, -1.5415525436401367, -3.313420295715332, -12.238165855407715, 1.6715376377105713, 2.6844305992126465, 1.637277603149414, -3.4442496299743652, -5.397979259490967, -3.7195687294006348, 2.097209930419922, 0.49698877334594727, -9.895252227783203, -5.5880937576293945, 1.2762093544006348, 3.684291362762451, 0.30396509170532227, -0.2762925624847412, 8.346724510192871, -9.544992446899414, -4.297271728515625, -4.142982006072998, -1.545972466468811, -10.809040069580078], "custom_metrics": {}}}, "num_steps_sampled": 16220, "num_agent_steps_sampled": 32440, "num_steps_trained": 34144, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 68288, "last_target_update_ts": 16220, "num_target_updates": 139}, "done": false, "episodes_total": 1154, "training_iteration": 51, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-41", "timestamp": 1648811561, "time_this_iter_s": 1.2636713981628418, "time_total_s": 65.21661353111267, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e17a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e17a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 65.21661353111267, "timesteps_since_restore": 1632, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 70.35, "ram_util_percent": 43.349999999999994}}
{"episode_reward_max": 34.0, "episode_reward_min": -20.0, "episode_reward_mean": 25.44, "episode_len_mean": 6.78, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 12.72, "policy1": 12.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 26.0, 4.0, 34.0, 28.0, 30.0, 24.0, 28.0, 28.0, 32.0, 12.0, 30.0, 30.0, 28.0, 22.0, 24.0, 28.0, 28.0, 28.0, 18.0, 28.0, 24.0, 28.0, 24.0, 34.0, 24.0, 20.0, 34.0, 34.0, 34.0, 0.0, -20.0, -20.0, 32.0, 30.0, 32.0, 30.0, 34.0, 28.0, 28.0, 34.0, 34.0, 34.0, 28.0, 28.0, 24.0, 32.0, 34.0, 34.0, 34.0, 32.0, 30.0, 12.0, 28.0, -20.0, 34.0, 24.0, 28.0, 24.0, 4.0, 32.0, 18.0, 20.0, 34.0, 28.0, 28.0, 28.0, 34.0, 20.0, 24.0, 34.0, 34.0, 30.0, 34.0, 28.0, 34.0, 34.0, 26.0, 34.0, 34.0, 28.0, 34.0, 30.0, 34.0, 12.0, 34.0, 28.0, 34.0, 24.0, 28.0, 32.0, 22.0, 34.0, 30.0, 30.0, 28.0, 28.0, -20.0, 20.0, -20.0], "episode_lengths": [3, 7, 18, 3, 6, 5, 8, 6, 6, 4, 14, 5, 5, 6, 9, 8, 6, 6, 6, 11, 6, 8, 6, 8, 3, 8, 10, 3, 3, 3, 20, 20, 20, 4, 5, 4, 5, 3, 6, 6, 3, 3, 3, 6, 6, 8, 4, 3, 3, 3, 4, 5, 14, 6, 20, 3, 8, 6, 8, 18, 4, 11, 10, 3, 6, 6, 6, 3, 10, 8, 3, 3, 5, 3, 6, 3, 3, 7, 3, 3, 6, 3, 5, 3, 14, 3, 6, 3, 8, 6, 4, 9, 3, 5, 5, 6, 6, 20, 10, 20], "policy_policy0_reward": [17.0, 13.0, 2.0, 17.0, 14.0, 15.0, 12.0, 14.0, 14.0, 16.0, 6.0, 15.0, 15.0, 14.0, 11.0, 12.0, 14.0, 14.0, 14.0, 9.0, 14.0, 12.0, 14.0, 12.0, 17.0, 12.0, 10.0, 17.0, 17.0, 17.0, 0.0, -10.0, -10.0, 16.0, 15.0, 16.0, 15.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 14.0, 14.0, 12.0, 16.0, 17.0, 17.0, 17.0, 16.0, 15.0, 6.0, 14.0, -10.0, 17.0, 12.0, 14.0, 12.0, 2.0, 16.0, 9.0, 10.0, 17.0, 14.0, 14.0, 14.0, 17.0, 10.0, 12.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 17.0, 13.0, 17.0, 17.0, 14.0, 17.0, 15.0, 17.0, 6.0, 17.0, 14.0, 17.0, 12.0, 14.0, 16.0, 11.0, 17.0, 15.0, 15.0, 14.0, 14.0, -10.0, 10.0, -10.0], "policy_policy1_reward": [17.0, 13.0, 2.0, 17.0, 14.0, 15.0, 12.0, 14.0, 14.0, 16.0, 6.0, 15.0, 15.0, 14.0, 11.0, 12.0, 14.0, 14.0, 14.0, 9.0, 14.0, 12.0, 14.0, 12.0, 17.0, 12.0, 10.0, 17.0, 17.0, 17.0, 0.0, -10.0, -10.0, 16.0, 15.0, 16.0, 15.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 14.0, 14.0, 12.0, 16.0, 17.0, 17.0, 17.0, 16.0, 15.0, 6.0, 14.0, -10.0, 17.0, 12.0, 14.0, 12.0, 2.0, 16.0, 9.0, 10.0, 17.0, 14.0, 14.0, 14.0, 17.0, 10.0, 12.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 17.0, 13.0, 17.0, 17.0, 14.0, 17.0, 15.0, 17.0, 6.0, 17.0, 14.0, 17.0, 12.0, 14.0, 16.0, 11.0, 17.0, 15.0, 15.0, 14.0, 14.0, -10.0, 10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2937845117928825, "mean_inference_ms": 1.5502483526233477, "mean_action_processing_ms": 0.10163323305039036, "mean_env_wait_ms": 0.06746440016750764, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16431, "timesteps_this_iter": 32, "agent_timesteps_total": 32862, "timers": {"load_time_ms": 0.443, "load_throughput": 72284.429, "learn_time_ms": 7.644, "learn_throughput": 4186.298, "update_time_ms": 4.816}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.9572954177856445, "min_q": -2.4572298526763916, "max_q": 14.403688430786133, "mean_td_error": -0.19558580219745636, "model": {}}, "td_error": [1.1262693405151367, -0.026673316955566406, -0.47998082637786865, 0.92584228515625, 0.16986513137817383, -2.946906089782715, -0.30875730514526367, -1.2368669509887695, 1.3586540222167969, 0.11144161224365234, -0.05416369438171387, 0.9652094841003418, -0.3878188133239746, 0.6041953563690186, 1.57499361038208, 0.15722274780273438, 1.7714333534240723, -1.8535293340682983, -1.5226778984069824, 1.7162081003189087, 2.3270580768585205, 0.9955348968505859, 0.05624115467071533, -0.19939041137695312, -6.467367172241211, -6.574897766113281, -0.41767752170562744, 0.7232675552368164, 0.9579260349273682, -0.7620522975921631, 0.18226861953735352, 1.2563819885253906], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 0.41161566972732544, "min_q": -6.368435859680176, "max_q": 9.190836906433105, "mean_td_error": -0.2111327201128006, "model": {}}, "td_error": [-11.104029655456543, 4.073240280151367, -1.0891149044036865, 3.36374831199646, 6.850821018218994, -0.791964054107666, 2.518324851989746, 2.5996944904327393, -0.4854888916015625, -0.38802409172058105, 0.4670572280883789, -0.3871030807495117, -0.47988224029541016, 1.4217939376831055, -4.354001045227051, -9.565430641174316, -4.420350074768066, -2.0868515968322754, -7.501439094543457, 0.8189349174499512, 2.0069527626037598, 0.8053407669067383, 0.3796815872192383, 0.9345178604125977, 0.540104866027832, -1.8315675258636475, 0.8807430267333984, 4.117216110229492, 2.3580660820007324, 2.11541748046875, -0.2275245189666748, 1.704869270324707], "custom_metrics": {}}}, "num_steps_sampled": 16431, "num_agent_steps_sampled": 32862, "num_steps_trained": 34912, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 69824, "last_target_update_ts": 16431, "num_target_updates": 141}, "done": false, "episodes_total": 1188, "training_iteration": 52, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-42", "timestamp": 1648811562, "time_this_iter_s": 1.1299867630004883, "time_total_s": 66.34660029411316, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 66.34660029411316, "timesteps_since_restore": 1664, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 27.450000000000003, "ram_util_percent": 44.35}}
{"episode_reward_max": 34.0, "episode_reward_min": -20.0, "episode_reward_mean": 21.06, "episode_len_mean": 8.17, "episode_media": {}, "episodes_this_iter": 14, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 10.53, "policy1": 10.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.0, 24.0, 28.0, 28.0, 28.0, 18.0, 28.0, 24.0, 28.0, 24.0, 34.0, 24.0, 20.0, 34.0, 34.0, 34.0, 0.0, -20.0, -20.0, 32.0, 30.0, 32.0, 30.0, 34.0, 28.0, 28.0, 34.0, 34.0, 34.0, 28.0, 28.0, 24.0, 32.0, 34.0, 34.0, 34.0, 32.0, 30.0, 12.0, 28.0, -20.0, 34.0, 24.0, 28.0, 24.0, 4.0, 32.0, 18.0, 20.0, 34.0, 28.0, 28.0, 28.0, 34.0, 20.0, 24.0, 34.0, 34.0, 30.0, 34.0, 28.0, 34.0, 34.0, 26.0, 34.0, 34.0, 28.0, 34.0, 30.0, 34.0, 12.0, 34.0, 28.0, 34.0, 24.0, 28.0, 32.0, 22.0, 34.0, 30.0, 30.0, 28.0, 28.0, -20.0, 20.0, -20.0, -20.0, 4.0, 6.0, -20.0, 4.0, 28.0, -20.0, 30.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0], "episode_lengths": [9, 8, 6, 6, 6, 11, 6, 8, 6, 8, 3, 8, 10, 3, 3, 3, 20, 20, 20, 4, 5, 4, 5, 3, 6, 6, 3, 3, 3, 6, 6, 8, 4, 3, 3, 3, 4, 5, 14, 6, 20, 3, 8, 6, 8, 18, 4, 11, 10, 3, 6, 6, 6, 3, 10, 8, 3, 3, 5, 3, 6, 3, 3, 7, 3, 3, 6, 3, 5, 3, 14, 3, 6, 3, 8, 6, 4, 9, 3, 5, 5, 6, 6, 20, 10, 20, 20, 18, 17, 20, 18, 6, 20, 5, 20, 20, 20, 11, 20, 20], "policy_policy0_reward": [11.0, 12.0, 14.0, 14.0, 14.0, 9.0, 14.0, 12.0, 14.0, 12.0, 17.0, 12.0, 10.0, 17.0, 17.0, 17.0, 0.0, -10.0, -10.0, 16.0, 15.0, 16.0, 15.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 14.0, 14.0, 12.0, 16.0, 17.0, 17.0, 17.0, 16.0, 15.0, 6.0, 14.0, -10.0, 17.0, 12.0, 14.0, 12.0, 2.0, 16.0, 9.0, 10.0, 17.0, 14.0, 14.0, 14.0, 17.0, 10.0, 12.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 17.0, 13.0, 17.0, 17.0, 14.0, 17.0, 15.0, 17.0, 6.0, 17.0, 14.0, 17.0, 12.0, 14.0, 16.0, 11.0, 17.0, 15.0, 15.0, 14.0, 14.0, -10.0, 10.0, -10.0, -10.0, 2.0, 3.0, -10.0, 2.0, 14.0, -10.0, 15.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0], "policy_policy1_reward": [11.0, 12.0, 14.0, 14.0, 14.0, 9.0, 14.0, 12.0, 14.0, 12.0, 17.0, 12.0, 10.0, 17.0, 17.0, 17.0, 0.0, -10.0, -10.0, 16.0, 15.0, 16.0, 15.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 14.0, 14.0, 12.0, 16.0, 17.0, 17.0, 17.0, 16.0, 15.0, 6.0, 14.0, -10.0, 17.0, 12.0, 14.0, 12.0, 2.0, 16.0, 9.0, 10.0, 17.0, 14.0, 14.0, 14.0, 17.0, 10.0, 12.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 17.0, 13.0, 17.0, 17.0, 14.0, 17.0, 15.0, 17.0, 6.0, 17.0, 14.0, 17.0, 12.0, 14.0, 16.0, 11.0, 17.0, 15.0, 15.0, 14.0, 14.0, -10.0, 10.0, -10.0, -10.0, 2.0, 3.0, -10.0, 2.0, 14.0, -10.0, 15.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29428644798873976, "mean_inference_ms": 1.5520120843494825, "mean_action_processing_ms": 0.10173098448935189, "mean_env_wait_ms": 0.06753932520070621, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16666, "timesteps_this_iter": 32, "agent_timesteps_total": 33332, "timers": {"load_time_ms": 0.449, "load_throughput": 71312.751, "learn_time_ms": 7.94, "learn_throughput": 4030.429, "update_time_ms": 5.258}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.382848262786865, "min_q": -4.405240058898926, "max_q": 14.372072219848633, "mean_td_error": -1.0041651725769043, "model": {}}, "td_error": [-2.8905792236328125, 1.0245399475097656, -8.555474281311035, 0.4991464614868164, -4.516040802001953, -2.6707096099853516, -1.6971111297607422, 0.7747335433959961, 0.7109451293945312, 1.3670203685760498, 1.4866418838500977, -1.2192420959472656, 0.6306781768798828, 1.5075035095214844, 1.1189937591552734, 1.5075035095214844, -0.3115987777709961, -1.8194036483764648, 0.2308816909790039, -2.908825397491455, 0.41158342361450195, 6.06217098236084, 0.32111072540283203, -0.09832382202148438, -2.8905792236328125, 0.055617332458496094, -0.7672688961029053, 1.2654399871826172, -6.16157865524292, -8.390425682067871, 1.4866437911987305, -7.697277069091797], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 0.3258320689201355, "min_q": -5.285489082336426, "max_q": 10.013548851013184, "mean_td_error": -1.3488945960998535, "model": {}}, "td_error": [-3.2445597648620605, -3.4090635776519775, 0.48046016693115234, -1.1711554527282715, 2.243058204650879, -1.8839905261993408, -0.9833104014396667, 1.1164007186889648, 0.21097326278686523, -1.376558780670166, -9.905862808227539, -0.9653408527374268, -11.923354148864746, 1.7537736892700195, -0.8490090370178223, 3.435697317123413, 4.749736309051514, 0.5014071464538574, -0.442962646484375, -5.579370498657227, -0.5263404846191406, -6.918893814086914, -2.020286798477173, -4.448228359222412, 0.8516864776611328, -10.37072467803955, -5.298084259033203, 6.813422203063965, 3.410719871520996, 1.1854324340820312, 1.0135488510131836, 0.3861508369445801], "custom_metrics": {}}}, "num_steps_sampled": 16666, "num_agent_steps_sampled": 33332, "num_steps_trained": 35360, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 70720, "last_target_update_ts": 16666, "num_target_updates": 143}, "done": false, "episodes_total": 1202, "training_iteration": 53, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-43", "timestamp": 1648811563, "time_this_iter_s": 0.9503152370452881, "time_total_s": 67.29691553115845, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d15f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d15f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 67.29691553115845, "timesteps_since_restore": 1696, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 24.9, "ram_util_percent": 44.7}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 18.6, "episode_len_mean": 8.9, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 9.3, "policy1": 9.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 32.0, 30.0, 32.0, 30.0, 34.0, 28.0, 28.0, 34.0, 34.0, 34.0, 28.0, 28.0, 24.0, 32.0, 34.0, 34.0, 34.0, 32.0, 30.0, 12.0, 28.0, -20.0, 34.0, 24.0, 28.0, 24.0, 4.0, 32.0, 18.0, 20.0, 34.0, 28.0, 28.0, 28.0, 34.0, 20.0, 24.0, 34.0, 34.0, 30.0, 34.0, 28.0, 34.0, 34.0, 26.0, 34.0, 34.0, 28.0, 34.0, 30.0, 34.0, 12.0, 34.0, 28.0, 34.0, 24.0, 28.0, 32.0, 22.0, 34.0, 30.0, 30.0, 28.0, 28.0, -20.0, 20.0, -20.0, -20.0, 4.0, 6.0, -20.0, 4.0, 28.0, -20.0, 30.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, 20.0, -20.0, 8.0, 24.0, 24.0, 20.0, 28.0, 16.0, 22.0, -20.0, 24.0, 24.0, 24.0, 28.0], "episode_lengths": [20, 4, 5, 4, 5, 3, 6, 6, 3, 3, 3, 6, 6, 8, 4, 3, 3, 3, 4, 5, 14, 6, 20, 3, 8, 6, 8, 18, 4, 11, 10, 3, 6, 6, 6, 3, 10, 8, 3, 3, 5, 3, 6, 3, 3, 7, 3, 3, 6, 3, 5, 3, 14, 3, 6, 3, 8, 6, 4, 9, 3, 5, 5, 6, 6, 20, 10, 20, 20, 18, 17, 20, 18, 6, 20, 5, 20, 20, 20, 11, 20, 20, 20, 20, 20, 8, 10, 20, 16, 8, 8, 10, 6, 12, 9, 20, 8, 8, 8, 6], "policy_policy0_reward": [-10.0, 16.0, 15.0, 16.0, 15.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 14.0, 14.0, 12.0, 16.0, 17.0, 17.0, 17.0, 16.0, 15.0, 6.0, 14.0, -10.0, 17.0, 12.0, 14.0, 12.0, 2.0, 16.0, 9.0, 10.0, 17.0, 14.0, 14.0, 14.0, 17.0, 10.0, 12.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 17.0, 13.0, 17.0, 17.0, 14.0, 17.0, 15.0, 17.0, 6.0, 17.0, 14.0, 17.0, 12.0, 14.0, 16.0, 11.0, 17.0, 15.0, 15.0, 14.0, 14.0, -10.0, 10.0, -10.0, -10.0, 2.0, 3.0, -10.0, 2.0, 14.0, -10.0, 15.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, 10.0, -10.0, 4.0, 12.0, 12.0, 10.0, 14.0, 8.0, 11.0, -10.0, 12.0, 12.0, 12.0, 14.0], "policy_policy1_reward": [-10.0, 16.0, 15.0, 16.0, 15.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 14.0, 14.0, 12.0, 16.0, 17.0, 17.0, 17.0, 16.0, 15.0, 6.0, 14.0, -10.0, 17.0, 12.0, 14.0, 12.0, 2.0, 16.0, 9.0, 10.0, 17.0, 14.0, 14.0, 14.0, 17.0, 10.0, 12.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 17.0, 13.0, 17.0, 17.0, 14.0, 17.0, 15.0, 17.0, 6.0, 17.0, 14.0, 17.0, 12.0, 14.0, 16.0, 11.0, 17.0, 15.0, 15.0, 14.0, 14.0, -10.0, 10.0, -10.0, -10.0, 2.0, 3.0, -10.0, 2.0, 14.0, -10.0, 15.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, 10.0, -10.0, 4.0, 12.0, 12.0, 10.0, 14.0, 8.0, 11.0, -10.0, 12.0, 12.0, 12.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29470759809212127, "mean_inference_ms": 1.552795235701696, "mean_action_processing_ms": 0.10178187146753208, "mean_env_wait_ms": 0.0675890354490216, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16883, "timesteps_this_iter": 32, "agent_timesteps_total": 33766, "timers": {"load_time_ms": 0.432, "load_throughput": 74112.495, "learn_time_ms": 7.994, "learn_throughput": 4003.213, "update_time_ms": 5.096}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.219884872436523, "min_q": -3.105072021484375, "max_q": 14.268936157226562, "mean_td_error": 0.4170728623867035, "model": {}}, "td_error": [0.6218364238739014, -0.7600817680358887, -2.412848949432373, -0.9045944213867188, 0.7393178939819336, 0.36957693099975586, -1.3775173425674438, 1.5945072174072266, 0.22357681393623352, 10.393625259399414, -7.574875831604004, 1.205141544342041, 10.13946533203125, -0.9986690282821655, 0.3996410369873047, 1.212803840637207, 0.5763381719589233, 0.6701993942260742, 0.05562639236450195, -0.8730716705322266, 2.4451520442962646, 1.0389480590820312, -0.6201949119567871, -0.5343080759048462, -1.1478066444396973, 0.5783090591430664, 0.7050290107727051, -0.5677752494812012, -0.007003068923950195, -0.44966793060302734, -2.6200428009033203, 1.2256956100463867], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 2.7566542625427246, "min_q": -3.7708864212036133, "max_q": 6.703402996063232, "mean_td_error": -1.3481581211090088, "model": {}}, "td_error": [5.2767133712768555, -3.5370359420776367, -6.505163192749023, -4.063497543334961, 2.402080535888672, -7.45257043838501, 2.98708176612854, -2.7717785835266113, -2.642279624938965, -4.748019218444824, -7.1745805740356445, -1.6948471069335938, -3.608783006668091, -0.10599994659423828, 2.040800094604492, -2.129735231399536, 1.5919768810272217, 2.094273090362549, -0.7568902969360352, 0.1878366470336914, -7.134574890136719, 0.8476378917694092, 0.4629850387573242, 1.1771178245544434, 1.559697151184082, -1.9040024280548096, 0.18959999084472656, 6.141495704650879, -8.576974868774414, 0.4544243812561035, -7.890705108642578, 2.142658233642578], "custom_metrics": {}}}, "num_steps_sampled": 16883, "num_agent_steps_sampled": 33766, "num_steps_trained": 35936, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 71872, "last_target_update_ts": 16883, "num_target_updates": 145}, "done": false, "episodes_total": 1220, "training_iteration": 54, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-44", "timestamp": 1648811564, "time_this_iter_s": 0.9955880641937256, "time_total_s": 68.29250359535217, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 68.29250359535217, "timesteps_since_restore": 1728, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 25.55, "ram_util_percent": 45.15}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 17.58, "episode_len_mean": 9.51, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 8.79, "policy1": 8.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, 28.0, 24.0, 4.0, 32.0, 18.0, 20.0, 34.0, 28.0, 28.0, 28.0, 34.0, 20.0, 24.0, 34.0, 34.0, 30.0, 34.0, 28.0, 34.0, 34.0, 26.0, 34.0, 34.0, 28.0, 34.0, 30.0, 34.0, 12.0, 34.0, 28.0, 34.0, 24.0, 28.0, 32.0, 22.0, 34.0, 30.0, 30.0, 28.0, 28.0, -20.0, 20.0, -20.0, -20.0, 4.0, 6.0, -20.0, 4.0, 28.0, -20.0, 30.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, 20.0, -20.0, 8.0, 24.0, 24.0, 20.0, 28.0, 16.0, 22.0, -20.0, 24.0, 24.0, 24.0, 28.0, 28.0, 24.0, 20.0, -20.0, 24.0, 28.0, 16.0, 28.0, 24.0, 24.0, 28.0, 20.0, 24.0, 24.0, 24.0, 28.0, 28.0, 24.0, 28.0, 16.0, 28.0, 28.0, 20.0, 8.0], "episode_lengths": [8, 6, 8, 18, 4, 11, 10, 3, 6, 6, 6, 3, 10, 8, 3, 3, 5, 3, 6, 3, 3, 7, 3, 3, 6, 3, 5, 3, 14, 3, 6, 3, 8, 6, 4, 9, 3, 5, 5, 6, 6, 20, 10, 20, 20, 18, 17, 20, 18, 6, 20, 5, 20, 20, 20, 11, 20, 20, 20, 20, 20, 8, 10, 20, 16, 8, 8, 10, 6, 12, 9, 20, 8, 8, 8, 6, 6, 8, 10, 20, 8, 6, 12, 6, 8, 8, 6, 10, 8, 8, 8, 6, 6, 8, 6, 12, 6, 6, 10, 16], "policy_policy0_reward": [12.0, 14.0, 12.0, 2.0, 16.0, 9.0, 10.0, 17.0, 14.0, 14.0, 14.0, 17.0, 10.0, 12.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 17.0, 13.0, 17.0, 17.0, 14.0, 17.0, 15.0, 17.0, 6.0, 17.0, 14.0, 17.0, 12.0, 14.0, 16.0, 11.0, 17.0, 15.0, 15.0, 14.0, 14.0, -10.0, 10.0, -10.0, -10.0, 2.0, 3.0, -10.0, 2.0, 14.0, -10.0, 15.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, 10.0, -10.0, 4.0, 12.0, 12.0, 10.0, 14.0, 8.0, 11.0, -10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 10.0, -10.0, 12.0, 14.0, 8.0, 14.0, 12.0, 12.0, 14.0, 10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 14.0, 14.0, 10.0, 4.0], "policy_policy1_reward": [12.0, 14.0, 12.0, 2.0, 16.0, 9.0, 10.0, 17.0, 14.0, 14.0, 14.0, 17.0, 10.0, 12.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 17.0, 13.0, 17.0, 17.0, 14.0, 17.0, 15.0, 17.0, 6.0, 17.0, 14.0, 17.0, 12.0, 14.0, 16.0, 11.0, 17.0, 15.0, 15.0, 14.0, 14.0, -10.0, 10.0, -10.0, -10.0, 2.0, 3.0, -10.0, 2.0, 14.0, -10.0, 15.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, 10.0, -10.0, 4.0, 12.0, 12.0, 10.0, 14.0, 8.0, 11.0, -10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 10.0, -10.0, 12.0, 14.0, 8.0, 14.0, 12.0, 12.0, 14.0, 10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 14.0, 14.0, 10.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2951213464493543, "mean_inference_ms": 1.5535304357914113, "mean_action_processing_ms": 0.10183180199911675, "mean_env_wait_ms": 0.06764849027274698, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17091, "timesteps_this_iter": 32, "agent_timesteps_total": 34182, "timers": {"load_time_ms": 0.459, "load_throughput": 69676.441, "learn_time_ms": 7.723, "learn_throughput": 4143.443, "update_time_ms": 4.589}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.432084083557129, "min_q": -3.530015230178833, "max_q": 15.45350456237793, "mean_td_error": -0.012468785047531128, "model": {}}, "td_error": [-8.293327331542969, 5.80470609664917, 1.9145889282226562, 0.07049942016601562, 1.602156639099121, -0.45995163917541504, 0.8072357177734375, 1.076700210571289, -0.22041893005371094, 0.006555080413818359, -1.1156611442565918, -1.793342113494873, -0.17561817169189453, 2.761673927307129, -0.7680683135986328, 0.09579324722290039, 0.6887388229370117, 3.0686354637145996, -1.8762016296386719, -0.6019749641418457, 3.6379594802856445, 0.4929618835449219, -0.22041893005371094, -0.07169342041015625, -2.8442578315734863, 0.8259488344192505, -0.40506744384765625, 0.3409123420715332, -1.3456707000732422, -2.518014907836914, -1.0319039821624756, 0.14752483367919922], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 1.6330909729003906, "min_q": -4.910667419433594, "max_q": 8.242813110351562, "mean_td_error": -1.4774748086929321, "model": {}}, "td_error": [-0.28835248947143555, 0.9977849721908569, -1.7864718437194824, -4.069815635681152, -1.1232883930206299, 1.548048973083496, 0.16927337646484375, -1.8666024208068848, -2.042508125305176, -0.24204611778259277, -0.0536503791809082, -8.756244659423828, 0.4324682950973511, -12.301375389099121, -10.330900192260742, -1.0661931037902832, 0.0513068288564682, 0.363018274307251, 0.28389930725097656, -0.29331016540527344, -0.018489480018615723, -10.048830032348633, -4.2896881103515625, 1.0636358261108398, 4.193096160888672, -0.5705053806304932, 1.887976884841919, 0.5662679672241211, -0.3584693968296051, 1.2001086473464966, 0.16927242279052734, -0.6986101865768433], "custom_metrics": {}}}, "num_steps_sampled": 17091, "num_agent_steps_sampled": 34182, "num_steps_trained": 36704, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 73408, "last_target_update_ts": 16991, "num_target_updates": 146}, "done": false, "episodes_total": 1244, "training_iteration": 55, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-46", "timestamp": 1648811566, "time_this_iter_s": 1.1363534927368164, "time_total_s": 69.42885708808899, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 69.42885708808899, "timesteps_since_restore": 1760, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 25.9, "ram_util_percent": 45.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 16.06, "episode_len_mean": 10.27, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 8.03, "policy1": 8.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 34.0, 30.0, 34.0, 12.0, 34.0, 28.0, 34.0, 24.0, 28.0, 32.0, 22.0, 34.0, 30.0, 30.0, 28.0, 28.0, -20.0, 20.0, -20.0, -20.0, 4.0, 6.0, -20.0, 4.0, 28.0, -20.0, 30.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, 20.0, -20.0, 8.0, 24.0, 24.0, 20.0, 28.0, 16.0, 22.0, -20.0, 24.0, 24.0, 24.0, 28.0, 28.0, 24.0, 20.0, -20.0, 24.0, 28.0, 16.0, 28.0, 24.0, 24.0, 28.0, 20.0, 24.0, 24.0, 24.0, 28.0, 28.0, 24.0, 28.0, 16.0, 28.0, 28.0, 20.0, 8.0, 24.0, 28.0, 28.0, 12.0, 20.0, 24.0, 28.0, 16.0, 20.0, 24.0, 28.0, 16.0, 14.0, 12.0, 24.0, 24.0, 28.0, 20.0, 24.0, 34.0, 16.0, 28.0, 24.0, 0.0], "episode_lengths": [6, 3, 5, 3, 14, 3, 6, 3, 8, 6, 4, 9, 3, 5, 5, 6, 6, 20, 10, 20, 20, 18, 17, 20, 18, 6, 20, 5, 20, 20, 20, 11, 20, 20, 20, 20, 20, 8, 10, 20, 16, 8, 8, 10, 6, 12, 9, 20, 8, 8, 8, 6, 6, 8, 10, 20, 8, 6, 12, 6, 8, 8, 6, 10, 8, 8, 8, 6, 6, 8, 6, 12, 6, 6, 10, 16, 8, 6, 6, 14, 10, 8, 6, 12, 10, 8, 6, 12, 13, 14, 8, 8, 6, 10, 8, 3, 12, 6, 8, 20], "policy_policy0_reward": [14.0, 17.0, 15.0, 17.0, 6.0, 17.0, 14.0, 17.0, 12.0, 14.0, 16.0, 11.0, 17.0, 15.0, 15.0, 14.0, 14.0, -10.0, 10.0, -10.0, -10.0, 2.0, 3.0, -10.0, 2.0, 14.0, -10.0, 15.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, 10.0, -10.0, 4.0, 12.0, 12.0, 10.0, 14.0, 8.0, 11.0, -10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 10.0, -10.0, 12.0, 14.0, 8.0, 14.0, 12.0, 12.0, 14.0, 10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 14.0, 14.0, 10.0, 4.0, 12.0, 14.0, 14.0, 6.0, 10.0, 12.0, 14.0, 8.0, 10.0, 12.0, 14.0, 8.0, 7.0, 6.0, 12.0, 12.0, 14.0, 10.0, 12.0, 17.0, 8.0, 14.0, 12.0, 0.0], "policy_policy1_reward": [14.0, 17.0, 15.0, 17.0, 6.0, 17.0, 14.0, 17.0, 12.0, 14.0, 16.0, 11.0, 17.0, 15.0, 15.0, 14.0, 14.0, -10.0, 10.0, -10.0, -10.0, 2.0, 3.0, -10.0, 2.0, 14.0, -10.0, 15.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, 10.0, -10.0, 4.0, 12.0, 12.0, 10.0, 14.0, 8.0, 11.0, -10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 10.0, -10.0, 12.0, 14.0, 8.0, 14.0, 12.0, 12.0, 14.0, 10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 14.0, 14.0, 10.0, 4.0, 12.0, 14.0, 14.0, 6.0, 10.0, 12.0, 14.0, 8.0, 10.0, 12.0, 14.0, 8.0, 7.0, 6.0, 12.0, 12.0, 14.0, 10.0, 12.0, 17.0, 8.0, 14.0, 12.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2956136612280942, "mean_inference_ms": 1.5550158343482756, "mean_action_processing_ms": 0.10194160681730985, "mean_env_wait_ms": 0.06773685862336318, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17313, "timesteps_this_iter": 32, "agent_timesteps_total": 34626, "timers": {"load_time_ms": 0.47, "load_throughput": 68041.026, "learn_time_ms": 8.409, "learn_throughput": 3805.663, "update_time_ms": 5.542}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.170221328735352, "min_q": -3.422757387161255, "max_q": 13.40310001373291, "mean_td_error": -0.09920435398817062, "model": {}}, "td_error": [-0.5848994255065918, 0.6916465759277344, -1.5377264022827148, -1.0648188591003418, 0.19574713706970215, 4.445509910583496, -2.1890344619750977, 0.4593207836151123, 0.951705813407898, -0.7470493316650391, -0.26104736328125, 0.4194068908691406, 0.7250556945800781, -1.1262128353118896, 5.226324558258057, -6.605856418609619, -0.3266773223876953, -1.845083475112915, 2.5479021072387695, 0.36830687522888184, -1.2837913036346436, -2.0595388412475586, -0.07408428192138672, 1.3983888626098633, -4.52716064453125, 0.34910154342651367, -1.0422601699829102, 0.3393564224243164, 1.0309829711914062, 0.1776270866394043, 1.1361980438232422, 1.6381206512451172], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 1.3864071369171143, "min_q": -7.325531005859375, "max_q": 13.458907127380371, "mean_td_error": -2.518073558807373, "model": {}}, "td_error": [-1.4104396104812622, -2.549757480621338, -0.635554313659668, -1.5592594146728516, -1.7660131454467773, -0.08377832174301147, -1.6553339958190918, 1.9974855184555054, -1.211167812347412, -9.526695251464844, 0.16079294681549072, -10.125951766967773, 1.3646162748336792, -7.970319747924805, -5.169095516204834, 1.3094053268432617, -1.4864797592163086, -14.164751052856445, 1.468261480331421, -0.859958827495575, -4.122740268707275, -2.0584301948547363, -1.8440017700195312, 0.20809125900268555, -1.5592594146728516, -10.392132759094238, -0.9037761688232422, 0.008565068244934082, -0.8681028485298157, 1.5349609851837158, -0.977332592010498, -5.730195999145508], "custom_metrics": {}}}, "num_steps_sampled": 17313, "num_agent_steps_sampled": 34626, "num_steps_trained": 37440, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 74880, "last_target_update_ts": 17313, "num_target_updates": 149}, "done": false, "episodes_total": 1268, "training_iteration": 56, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-47", "timestamp": 1648811567, "time_this_iter_s": 1.2358372211456299, "time_total_s": 70.66469430923462, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 70.66469430923462, "timesteps_since_restore": 1792, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 32.75, "ram_util_percent": 46.05}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 17.32, "episode_len_mean": 10.04, "episode_media": {}, "episodes_this_iter": 25, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 8.66, "policy1": 8.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, -20.0, 30.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, 20.0, -20.0, 8.0, 24.0, 24.0, 20.0, 28.0, 16.0, 22.0, -20.0, 24.0, 24.0, 24.0, 28.0, 28.0, 24.0, 20.0, -20.0, 24.0, 28.0, 16.0, 28.0, 24.0, 24.0, 28.0, 20.0, 24.0, 24.0, 24.0, 28.0, 28.0, 24.0, 28.0, 16.0, 28.0, 28.0, 20.0, 8.0, 24.0, 28.0, 28.0, 12.0, 20.0, 24.0, 28.0, 16.0, 20.0, 24.0, 28.0, 16.0, 14.0, 12.0, 24.0, 24.0, 28.0, 20.0, 24.0, 34.0, 16.0, 28.0, 24.0, 0.0, 8.0, 34.0, 24.0, 24.0, 12.0, 14.0, 30.0, 16.0, 16.0, 24.0, 16.0, 28.0, 20.0, 28.0, 20.0, 20.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 24.0, 24.0, 24.0], "episode_lengths": [6, 20, 5, 20, 20, 20, 11, 20, 20, 20, 20, 20, 8, 10, 20, 16, 8, 8, 10, 6, 12, 9, 20, 8, 8, 8, 6, 6, 8, 10, 20, 8, 6, 12, 6, 8, 8, 6, 10, 8, 8, 8, 6, 6, 8, 6, 12, 6, 6, 10, 16, 8, 6, 6, 14, 10, 8, 6, 12, 10, 8, 6, 12, 13, 14, 8, 8, 6, 10, 8, 3, 12, 6, 8, 20, 16, 3, 8, 8, 14, 13, 5, 12, 12, 8, 12, 6, 10, 6, 10, 10, 6, 6, 8, 6, 6, 6, 8, 8, 8], "policy_policy0_reward": [14.0, -10.0, 15.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, 10.0, -10.0, 4.0, 12.0, 12.0, 10.0, 14.0, 8.0, 11.0, -10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 10.0, -10.0, 12.0, 14.0, 8.0, 14.0, 12.0, 12.0, 14.0, 10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 14.0, 14.0, 10.0, 4.0, 12.0, 14.0, 14.0, 6.0, 10.0, 12.0, 14.0, 8.0, 10.0, 12.0, 14.0, 8.0, 7.0, 6.0, 12.0, 12.0, 14.0, 10.0, 12.0, 17.0, 8.0, 14.0, 12.0, 0.0, 4.0, 17.0, 12.0, 12.0, 6.0, 7.0, 15.0, 8.0, 8.0, 12.0, 8.0, 14.0, 10.0, 14.0, 10.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 12.0], "policy_policy1_reward": [14.0, -10.0, 15.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, 10.0, -10.0, 4.0, 12.0, 12.0, 10.0, 14.0, 8.0, 11.0, -10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 10.0, -10.0, 12.0, 14.0, 8.0, 14.0, 12.0, 12.0, 14.0, 10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 14.0, 14.0, 10.0, 4.0, 12.0, 14.0, 14.0, 6.0, 10.0, 12.0, 14.0, 8.0, 10.0, 12.0, 14.0, 8.0, 7.0, 6.0, 12.0, 12.0, 14.0, 10.0, 12.0, 17.0, 8.0, 14.0, 12.0, 0.0, 4.0, 17.0, 12.0, 12.0, 6.0, 7.0, 15.0, 8.0, 8.0, 12.0, 8.0, 14.0, 10.0, 14.0, 10.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29633409809476724, "mean_inference_ms": 1.558005124589077, "mean_action_processing_ms": 0.10214481981586733, "mean_env_wait_ms": 0.06787873766153711, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17528, "timesteps_this_iter": 32, "agent_timesteps_total": 35056, "timers": {"load_time_ms": 0.505, "load_throughput": 63319.209, "learn_time_ms": 8.59, "learn_throughput": 3725.176, "update_time_ms": 5.435}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.216938018798828, "min_q": -3.185342311859131, "max_q": 13.034096717834473, "mean_td_error": -0.2077731043100357, "model": {}}, "td_error": [0.44060492515563965, -0.4939088821411133, 2.569580554962158, -1.4014396667480469, -0.007640361785888672, -0.22235870361328125, -0.3692607879638672, -8.279866218566895, 0.9418172836303711, 0.08059382438659668, 0.5963599681854248, 0.11658477783203125, -2.801603078842163, 0.36686134338378906, 0.8504495620727539, 1.0178351402282715, -0.4965829849243164, 0.16049671173095703, -0.9858074188232422, 0.8765459060668945, 1.205019474029541, -0.2297825813293457, 1.0772770643234253, -0.04731273651123047, 0.24697017669677734, -0.14688396453857422, -1.0682873725891113, 0.5381555557250977, 0.17711448669433594, -0.3692607879638672, -0.8669338226318359, -0.12407684326171875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 1.1940202713012695, "min_q": -8.705415725708008, "max_q": 9.343738555908203, "mean_td_error": -0.244537353515625, "model": {}}, "td_error": [6.162216663360596, 0.19879531860351562, 2.9926974773406982, -10.153226852416992, -0.9854335784912109, -0.4159212112426758, -0.5242655277252197, -4.22235631942749, 0.5890161991119385, -0.1348276138305664, 0.054621219635009766, 0.9745454788208008, -6.464040279388428, 2.2503774166107178, 1.2870512008666992, -0.6088895797729492, -2.5909180641174316, -1.3197989463806152, 0.6267776489257812, 0.9951677322387695, 1.132154941558838, 6.446371078491211, -0.12527823448181152, 1.6981937885284424, 1.536851406097412, 0.6308431625366211, -2.619138717651367, 2.013667583465576, 2.10965633392334, -0.09322309494018555, 2.815509796142578, -12.082392692565918], "custom_metrics": {}}}, "num_steps_sampled": 17528, "num_agent_steps_sampled": 35056, "num_steps_trained": 38208, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 76416, "last_target_update_ts": 17528, "num_target_updates": 151}, "done": false, "episodes_total": 1293, "training_iteration": 57, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-48", "timestamp": 1648811568, "time_this_iter_s": 1.3498713970184326, "time_total_s": 72.01456570625305, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cda70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cda70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 72.01456570625305, "timesteps_since_restore": 1824, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 31.15, "ram_util_percent": 46.55}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 21.0, "episode_len_mean": 9.1, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 10.5, "policy1": 10.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.0, -20.0, 24.0, 24.0, 24.0, 28.0, 28.0, 24.0, 20.0, -20.0, 24.0, 28.0, 16.0, 28.0, 24.0, 24.0, 28.0, 20.0, 24.0, 24.0, 24.0, 28.0, 28.0, 24.0, 28.0, 16.0, 28.0, 28.0, 20.0, 8.0, 24.0, 28.0, 28.0, 12.0, 20.0, 24.0, 28.0, 16.0, 20.0, 24.0, 28.0, 16.0, 14.0, 12.0, 24.0, 24.0, 28.0, 20.0, 24.0, 34.0, 16.0, 28.0, 24.0, 0.0, 8.0, 34.0, 24.0, 24.0, 12.0, 14.0, 30.0, 16.0, 16.0, 24.0, 16.0, 28.0, 20.0, 28.0, 20.0, 20.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 24.0, 24.0, 24.0, 24.0, 8.0, 20.0, 28.0, 24.0, 16.0, 18.0, 28.0, -40.0, 28.0, 20.0, 16.0, 24.0, 16.0, 24.0, 28.0, 30.0, 20.0, 16.0, 24.0, 16.0], "episode_lengths": [9, 20, 8, 8, 8, 6, 6, 8, 10, 20, 8, 6, 12, 6, 8, 8, 6, 10, 8, 8, 8, 6, 6, 8, 6, 12, 6, 6, 10, 16, 8, 6, 6, 14, 10, 8, 6, 12, 10, 8, 6, 12, 13, 14, 8, 8, 6, 10, 8, 3, 12, 6, 8, 20, 16, 3, 8, 8, 14, 13, 5, 12, 12, 8, 12, 6, 10, 6, 10, 10, 6, 6, 8, 6, 6, 6, 8, 8, 8, 8, 16, 10, 6, 8, 12, 11, 6, 20, 6, 10, 12, 8, 12, 8, 6, 5, 10, 12, 8, 12], "policy_policy0_reward": [11.0, -10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 10.0, -10.0, 12.0, 14.0, 8.0, 14.0, 12.0, 12.0, 14.0, 10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 14.0, 14.0, 10.0, 4.0, 12.0, 14.0, 14.0, 6.0, 10.0, 12.0, 14.0, 8.0, 10.0, 12.0, 14.0, 8.0, 7.0, 6.0, 12.0, 12.0, 14.0, 10.0, 12.0, 17.0, 8.0, 14.0, 12.0, 0.0, 4.0, 17.0, 12.0, 12.0, 6.0, 7.0, 15.0, 8.0, 8.0, 12.0, 8.0, 14.0, 10.0, 14.0, 10.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 12.0, 12.0, 4.0, 10.0, 14.0, 12.0, 8.0, 9.0, 14.0, -20.0, 14.0, 10.0, 8.0, 12.0, 8.0, 12.0, 14.0, 15.0, 10.0, 8.0, 12.0, 8.0], "policy_policy1_reward": [11.0, -10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 10.0, -10.0, 12.0, 14.0, 8.0, 14.0, 12.0, 12.0, 14.0, 10.0, 12.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 14.0, 14.0, 10.0, 4.0, 12.0, 14.0, 14.0, 6.0, 10.0, 12.0, 14.0, 8.0, 10.0, 12.0, 14.0, 8.0, 7.0, 6.0, 12.0, 12.0, 14.0, 10.0, 12.0, 17.0, 8.0, 14.0, 12.0, 0.0, 4.0, 17.0, 12.0, 12.0, 6.0, 7.0, 15.0, 8.0, 8.0, 12.0, 8.0, 14.0, 10.0, 14.0, 10.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 12.0, 12.0, 4.0, 10.0, 14.0, 12.0, 8.0, 9.0, 14.0, -20.0, 14.0, 10.0, 8.0, 12.0, 8.0, 12.0, 14.0, 15.0, 10.0, 8.0, 12.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29709308203961415, "mean_inference_ms": 1.5614999813913721, "mean_action_processing_ms": 0.10238347949649476, "mean_env_wait_ms": 0.06804051218004459, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17734, "timesteps_this_iter": 32, "agent_timesteps_total": 35468, "timers": {"load_time_ms": 0.483, "load_throughput": 66303.279, "learn_time_ms": 8.295, "learn_throughput": 3857.751, "update_time_ms": 5.153}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.959346771240234, "min_q": -3.13037371635437, "max_q": 13.083006858825684, "mean_td_error": -0.4045462906360626, "model": {}}, "td_error": [0.13582134246826172, -1.2202162742614746, -3.606572389602661, 3.6320719718933105, -1.4628114700317383, -1.2327601909637451, -1.946859359741211, -0.3401479721069336, -1.411271095275879, -1.3453278541564941, -0.9715986251831055, -1.5844900608062744, -3.8222408294677734, -2.1906862258911133, -0.8754472732543945, 2.0102202892303467, -1.4543638229370117, -0.7155437469482422, 0.6857843399047852, 0.5834236145019531, -1.677642822265625, -0.5228610038757324, -1.4264662265777588, 4.216644763946533, -0.9107460975646973, 0.8315465450286865, 0.04757307469844818, -0.5122823715209961, -1.1090736389160156, 5.054481029510498, 1.018789291381836, -0.8224287033081055], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 0.3347713053226471, "min_q": -5.726581573486328, "max_q": 6.843070983886719, "mean_td_error": -0.9045981168746948, "model": {}}, "td_error": [1.2388620376586914, -2.679663896560669, 0.8234412670135498, -0.12885046005249023, -0.6189179420471191, -0.8418617248535156, -10.76026725769043, 1.2678139209747314, 0.5136480331420898, -0.06582045555114746, -3.5656352043151855, -0.26587915420532227, -0.021110057830810547, -0.01557159423828125, -0.7658758163452148, 1.8060131072998047, -0.7941536903381348, 5.195387840270996, -2.4822213649749756, 0.6335070133209229, 3.2117013931274414, -13.420732498168945, 0.8802237510681152, 0.40737462043762207, 0.07809925079345703, 2.691758155822754, 1.028653621673584, 0.631312370300293, -0.5024893283843994, 0.7995936870574951, -12.696825981140137, -0.5286521911621094], "custom_metrics": {}}}, "num_steps_sampled": 17734, "num_agent_steps_sampled": 35468, "num_steps_trained": 38880, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 77760, "last_target_update_ts": 17734, "num_target_updates": 153}, "done": false, "episodes_total": 1314, "training_iteration": 58, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-50", "timestamp": 1648811570, "time_this_iter_s": 1.230454683303833, "time_total_s": 73.24502038955688, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 73.24502038955688, "timesteps_since_restore": 1856, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 27.0, "ram_util_percent": 46.9}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 21.34, "episode_len_mean": 9.13, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 10.67, "policy1": 10.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, 28.0, 16.0, 28.0, 28.0, 20.0, 8.0, 24.0, 28.0, 28.0, 12.0, 20.0, 24.0, 28.0, 16.0, 20.0, 24.0, 28.0, 16.0, 14.0, 12.0, 24.0, 24.0, 28.0, 20.0, 24.0, 34.0, 16.0, 28.0, 24.0, 0.0, 8.0, 34.0, 24.0, 24.0, 12.0, 14.0, 30.0, 16.0, 16.0, 24.0, 16.0, 28.0, 20.0, 28.0, 20.0, 20.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 24.0, 24.0, 24.0, 24.0, 8.0, 20.0, 28.0, 24.0, 16.0, 18.0, 28.0, -40.0, 28.0, 20.0, 16.0, 24.0, 16.0, 24.0, 28.0, 30.0, 20.0, 16.0, 24.0, 16.0, 28.0, 12.0, 28.0, 28.0, 22.0, 20.0, 20.0, 28.0, 28.0, 24.0, 26.0, 28.0, 16.0, 0.0, 28.0, 8.0, 24.0, 28.0, 20.0, 12.0, 28.0, 24.0, 28.0], "episode_lengths": [8, 6, 12, 6, 6, 10, 16, 8, 6, 6, 14, 10, 8, 6, 12, 10, 8, 6, 12, 13, 14, 8, 8, 6, 10, 8, 3, 12, 6, 8, 20, 16, 3, 8, 8, 14, 13, 5, 12, 12, 8, 12, 6, 10, 6, 10, 10, 6, 6, 8, 6, 6, 6, 8, 8, 8, 8, 16, 10, 6, 8, 12, 11, 6, 20, 6, 10, 12, 8, 12, 8, 6, 5, 10, 12, 8, 12, 6, 14, 6, 6, 9, 10, 10, 6, 6, 8, 7, 6, 12, 20, 6, 16, 8, 6, 10, 14, 6, 8, 6], "policy_policy0_reward": [12.0, 14.0, 8.0, 14.0, 14.0, 10.0, 4.0, 12.0, 14.0, 14.0, 6.0, 10.0, 12.0, 14.0, 8.0, 10.0, 12.0, 14.0, 8.0, 7.0, 6.0, 12.0, 12.0, 14.0, 10.0, 12.0, 17.0, 8.0, 14.0, 12.0, 0.0, 4.0, 17.0, 12.0, 12.0, 6.0, 7.0, 15.0, 8.0, 8.0, 12.0, 8.0, 14.0, 10.0, 14.0, 10.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 12.0, 12.0, 4.0, 10.0, 14.0, 12.0, 8.0, 9.0, 14.0, -20.0, 14.0, 10.0, 8.0, 12.0, 8.0, 12.0, 14.0, 15.0, 10.0, 8.0, 12.0, 8.0, 14.0, 6.0, 14.0, 14.0, 11.0, 10.0, 10.0, 14.0, 14.0, 12.0, 13.0, 14.0, 8.0, 0.0, 14.0, 4.0, 12.0, 14.0, 10.0, 6.0, 14.0, 12.0, 14.0], "policy_policy1_reward": [12.0, 14.0, 8.0, 14.0, 14.0, 10.0, 4.0, 12.0, 14.0, 14.0, 6.0, 10.0, 12.0, 14.0, 8.0, 10.0, 12.0, 14.0, 8.0, 7.0, 6.0, 12.0, 12.0, 14.0, 10.0, 12.0, 17.0, 8.0, 14.0, 12.0, 0.0, 4.0, 17.0, 12.0, 12.0, 6.0, 7.0, 15.0, 8.0, 8.0, 12.0, 8.0, 14.0, 10.0, 14.0, 10.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 12.0, 12.0, 4.0, 10.0, 14.0, 12.0, 8.0, 9.0, 14.0, -20.0, 14.0, 10.0, 8.0, 12.0, 8.0, 12.0, 14.0, 15.0, 10.0, 8.0, 12.0, 8.0, 14.0, 6.0, 14.0, 14.0, 11.0, 10.0, 10.0, 14.0, 14.0, 12.0, 13.0, 14.0, 8.0, 0.0, 14.0, 4.0, 12.0, 14.0, 10.0, 6.0, 14.0, 12.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2981119697679372, "mean_inference_ms": 1.5667227500413226, "mean_action_processing_ms": 0.10275110301095663, "mean_env_wait_ms": 0.06827219329134347, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17940, "timesteps_this_iter": 32, "agent_timesteps_total": 35880, "timers": {"load_time_ms": 0.501, "load_throughput": 63843.28, "learn_time_ms": 8.697, "learn_throughput": 3679.547, "update_time_ms": 5.584}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.819456100463867, "min_q": -1.029129981994629, "max_q": 13.083127975463867, "mean_td_error": 0.21133002638816833, "model": {}}, "td_error": [3.694247007369995, 0.26891088485717773, 0.4276008605957031, 0.1891622543334961, 1.3777570724487305, -0.7260608673095703, 2.0053505897521973, -0.3770461082458496, 0.6364288330078125, -0.5645952224731445, -0.06352043151855469, -0.8402187824249268, -0.01973581314086914, -0.5658993721008301, -0.6531624794006348, -0.25387096405029297, -0.34146928787231445, 0.8317060470581055, -0.32889747619628906, 0.8151745796203613, 0.45256567001342773, -0.9800806045532227, -1.5714197158813477, 0.0844278335571289, -0.2647209167480469, 1.7753400802612305, 0.8123431205749512, 0.005320072174072266, 0.3373537063598633, -0.7587395906448364, 1.5551602840423584, -0.19685125350952148], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -0.09871359169483185, "min_q": -5.65101432800293, "max_q": 8.373828887939453, "mean_td_error": -1.449919581413269, "model": {}}, "td_error": [1.4605391025543213, 1.6070234775543213, 0.5805063247680664, 1.117841124534607, 0.3172929286956787, -0.34821534156799316, 3.3362843990325928, -11.220874786376953, 1.2033967971801758, -4.4788432121276855, -8.982181549072266, -1.5916118621826172, 1.342432975769043, -7.331896781921387, -3.6134538650512695, -0.6261711120605469, -3.7119691371917725, 0.8461751937866211, 0.11026906967163086, -2.2937397956848145, 0.5703773498535156, -1.4706021547317505, 0.39682793617248535, -0.6030421257019043, -0.19189214706420898, 1.8725974559783936, -0.5382671356201172, -3.948723316192627, 0.667442798614502, -3.4201979637145996, 1.5532832145690918, -9.008035659790039], "custom_metrics": {}}}, "num_steps_sampled": 17940, "num_agent_steps_sampled": 35880, "num_steps_trained": 39616, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 79232, "last_target_update_ts": 17840, "num_target_updates": 154}, "done": false, "episodes_total": 1337, "training_iteration": 59, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-51", "timestamp": 1648811571, "time_this_iter_s": 1.3451156616210938, "time_total_s": 74.59013605117798, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 74.59013605117798, "timesteps_since_restore": 1888, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 27.95, "ram_util_percent": 47.35}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 21.66, "episode_len_mean": 8.97, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 10.83, "policy1": 10.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 24.0, 34.0, 16.0, 28.0, 24.0, 0.0, 8.0, 34.0, 24.0, 24.0, 12.0, 14.0, 30.0, 16.0, 16.0, 24.0, 16.0, 28.0, 20.0, 28.0, 20.0, 20.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 24.0, 24.0, 24.0, 24.0, 8.0, 20.0, 28.0, 24.0, 16.0, 18.0, 28.0, -40.0, 28.0, 20.0, 16.0, 24.0, 16.0, 24.0, 28.0, 30.0, 20.0, 16.0, 24.0, 16.0, 28.0, 12.0, 28.0, 28.0, 22.0, 20.0, 20.0, 28.0, 28.0, 24.0, 26.0, 28.0, 16.0, 0.0, 28.0, 8.0, 24.0, 28.0, 20.0, 12.0, 28.0, 24.0, 28.0, 34.0, 24.0, 24.0, 24.0, 28.0, 20.0, 20.0, 24.0, 12.0, 16.0, 28.0, 20.0, 24.0, 24.0, 24.0, 24.0, 24.0, 16.0, 16.0, 20.0, 28.0, 28.0, 24.0, 28.0], "episode_lengths": [10, 8, 3, 12, 6, 8, 20, 16, 3, 8, 8, 14, 13, 5, 12, 12, 8, 12, 6, 10, 6, 10, 10, 6, 6, 8, 6, 6, 6, 8, 8, 8, 8, 16, 10, 6, 8, 12, 11, 6, 20, 6, 10, 12, 8, 12, 8, 6, 5, 10, 12, 8, 12, 6, 14, 6, 6, 9, 10, 10, 6, 6, 8, 7, 6, 12, 20, 6, 16, 8, 6, 10, 14, 6, 8, 6, 3, 8, 8, 8, 6, 10, 10, 8, 14, 12, 6, 10, 8, 8, 8, 8, 8, 12, 12, 10, 6, 6, 8, 6], "policy_policy0_reward": [10.0, 12.0, 17.0, 8.0, 14.0, 12.0, 0.0, 4.0, 17.0, 12.0, 12.0, 6.0, 7.0, 15.0, 8.0, 8.0, 12.0, 8.0, 14.0, 10.0, 14.0, 10.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 12.0, 12.0, 4.0, 10.0, 14.0, 12.0, 8.0, 9.0, 14.0, -20.0, 14.0, 10.0, 8.0, 12.0, 8.0, 12.0, 14.0, 15.0, 10.0, 8.0, 12.0, 8.0, 14.0, 6.0, 14.0, 14.0, 11.0, 10.0, 10.0, 14.0, 14.0, 12.0, 13.0, 14.0, 8.0, 0.0, 14.0, 4.0, 12.0, 14.0, 10.0, 6.0, 14.0, 12.0, 14.0, 17.0, 12.0, 12.0, 12.0, 14.0, 10.0, 10.0, 12.0, 6.0, 8.0, 14.0, 10.0, 12.0, 12.0, 12.0, 12.0, 12.0, 8.0, 8.0, 10.0, 14.0, 14.0, 12.0, 14.0], "policy_policy1_reward": [10.0, 12.0, 17.0, 8.0, 14.0, 12.0, 0.0, 4.0, 17.0, 12.0, 12.0, 6.0, 7.0, 15.0, 8.0, 8.0, 12.0, 8.0, 14.0, 10.0, 14.0, 10.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 12.0, 12.0, 12.0, 4.0, 10.0, 14.0, 12.0, 8.0, 9.0, 14.0, -20.0, 14.0, 10.0, 8.0, 12.0, 8.0, 12.0, 14.0, 15.0, 10.0, 8.0, 12.0, 8.0, 14.0, 6.0, 14.0, 14.0, 11.0, 10.0, 10.0, 14.0, 14.0, 12.0, 13.0, 14.0, 8.0, 0.0, 14.0, 4.0, 12.0, 14.0, 10.0, 6.0, 14.0, 12.0, 14.0, 17.0, 12.0, 12.0, 12.0, 14.0, 10.0, 10.0, 12.0, 6.0, 8.0, 14.0, 10.0, 12.0, 12.0, 12.0, 12.0, 12.0, 8.0, 8.0, 10.0, 14.0, 14.0, 12.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.299227347610346, "mean_inference_ms": 1.5724869367755148, "mean_action_processing_ms": 0.10316287676870323, "mean_env_wait_ms": 0.06853742682214783, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18143, "timesteps_this_iter": 32, "agent_timesteps_total": 36286, "timers": {"load_time_ms": 0.467, "load_throughput": 68558.884, "learn_time_ms": 8.425, "learn_throughput": 3798.242, "update_time_ms": 5.16}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.863918304443359, "min_q": -1.5953967571258545, "max_q": 14.35421085357666, "mean_td_error": -0.6560170650482178, "model": {}}, "td_error": [1.7223451137542725, -0.30898475646972656, -0.6181426048278809, 1.4546289443969727, 1.7295594215393066, -7.672802448272705, -7.169171333312988, 1.208481788635254, -3.233645439147949, -1.0552361011505127, -5.776455879211426, 1.116994857788086, 0.34273576736450195, 0.6602575182914734, 6.401299476623535, -0.1153407096862793, -0.024332880973815918, -1.5341285467147827, -1.3088531494140625, -0.45594120025634766, -0.33890438079833984, -5.593825340270996, -0.5496988296508789, 1.6294193267822266, 2.1399316787719727, -1.2191519737243652, -2.3913612365722656, -0.45511651039123535, 1.9566785097122192, 0.2152566909790039, -0.24843978881835938, -1.5006017684936523], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 0.2789691388607025, "min_q": -5.648548126220703, "max_q": 7.243971824645996, "mean_td_error": -0.8740787506103516, "model": {}}, "td_error": [-4.648548126220703, -0.6210261583328247, 1.3183555603027344, 0.40909361839294434, -1.756028175354004, 2.7965612411499023, 2.037313222885132, -2.617095470428467, -3.1810622215270996, -10.549897193908691, 3.0825977325439453, 2.1897337436676025, -0.8986709117889404, -1.9379397630691528, -2.506948471069336, -1.4991695880889893, 0.7285786867141724, -0.18758392333984375, -0.0016694068908691406, -2.119597911834717, 0.42606544494628906, 0.3412129878997803, -0.24431204795837402, -1.4018995761871338, -0.6320617198944092, 0.1818704605102539, 1.4568679332733154, -0.8263604640960693, -10.54007339477539, -0.8986709117889404, 2.461848497390747, 1.6679952144622803], "custom_metrics": {}}}, "num_steps_sampled": 18143, "num_agent_steps_sampled": 36286, "num_steps_trained": 40352, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 80704, "last_target_update_ts": 18059, "num_target_updates": 156}, "done": false, "episodes_total": 1361, "training_iteration": 60, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-52", "timestamp": 1648811572, "time_this_iter_s": 1.263570785522461, "time_total_s": 75.85370683670044, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 75.85370683670044, "timesteps_since_restore": 1920, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 32.55, "ram_util_percent": 47.9}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": 22.28, "episode_len_mean": 8.66, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 11.14, "policy1": 11.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 28.0, 28.0, 24.0, 24.0, 24.0, 24.0, 8.0, 20.0, 28.0, 24.0, 16.0, 18.0, 28.0, -40.0, 28.0, 20.0, 16.0, 24.0, 16.0, 24.0, 28.0, 30.0, 20.0, 16.0, 24.0, 16.0, 28.0, 12.0, 28.0, 28.0, 22.0, 20.0, 20.0, 28.0, 28.0, 24.0, 26.0, 28.0, 16.0, 0.0, 28.0, 8.0, 24.0, 28.0, 20.0, 12.0, 28.0, 24.0, 28.0, 34.0, 24.0, 24.0, 24.0, 28.0, 20.0, 20.0, 24.0, 12.0, 16.0, 28.0, 20.0, 24.0, 24.0, 24.0, 24.0, 24.0, 16.0, 16.0, 20.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 16.0, 24.0, 24.0, 24.0, 20.0, 20.0, 20.0, 20.0, 24.0, 20.0, 28.0, 20.0, 22.0, 24.0, 28.0, 20.0, 24.0, 28.0, 28.0, 20.0], "episode_lengths": [6, 6, 6, 8, 8, 8, 8, 16, 10, 6, 8, 12, 11, 6, 20, 6, 10, 12, 8, 12, 8, 6, 5, 10, 12, 8, 12, 6, 14, 6, 6, 9, 10, 10, 6, 6, 8, 7, 6, 12, 20, 6, 16, 8, 6, 10, 14, 6, 8, 6, 3, 8, 8, 8, 6, 10, 10, 8, 14, 12, 6, 10, 8, 8, 8, 8, 8, 12, 12, 10, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 12, 8, 8, 8, 10, 10, 10, 10, 8, 10, 6, 10, 9, 8, 6, 10, 8, 6, 6, 10], "policy_policy0_reward": [14.0, 14.0, 14.0, 12.0, 12.0, 12.0, 12.0, 4.0, 10.0, 14.0, 12.0, 8.0, 9.0, 14.0, -20.0, 14.0, 10.0, 8.0, 12.0, 8.0, 12.0, 14.0, 15.0, 10.0, 8.0, 12.0, 8.0, 14.0, 6.0, 14.0, 14.0, 11.0, 10.0, 10.0, 14.0, 14.0, 12.0, 13.0, 14.0, 8.0, 0.0, 14.0, 4.0, 12.0, 14.0, 10.0, 6.0, 14.0, 12.0, 14.0, 17.0, 12.0, 12.0, 12.0, 14.0, 10.0, 10.0, 12.0, 6.0, 8.0, 14.0, 10.0, 12.0, 12.0, 12.0, 12.0, 12.0, 8.0, 8.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 8.0, 12.0, 12.0, 12.0, 10.0, 10.0, 10.0, 10.0, 12.0, 10.0, 14.0, 10.0, 11.0, 12.0, 14.0, 10.0, 12.0, 14.0, 14.0, 10.0], "policy_policy1_reward": [14.0, 14.0, 14.0, 12.0, 12.0, 12.0, 12.0, 4.0, 10.0, 14.0, 12.0, 8.0, 9.0, 14.0, -20.0, 14.0, 10.0, 8.0, 12.0, 8.0, 12.0, 14.0, 15.0, 10.0, 8.0, 12.0, 8.0, 14.0, 6.0, 14.0, 14.0, 11.0, 10.0, 10.0, 14.0, 14.0, 12.0, 13.0, 14.0, 8.0, 0.0, 14.0, 4.0, 12.0, 14.0, 10.0, 6.0, 14.0, 12.0, 14.0, 17.0, 12.0, 12.0, 12.0, 14.0, 10.0, 10.0, 12.0, 6.0, 8.0, 14.0, 10.0, 12.0, 12.0, 12.0, 12.0, 12.0, 8.0, 8.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 8.0, 12.0, 12.0, 12.0, 10.0, 10.0, 10.0, 10.0, 12.0, 10.0, 14.0, 10.0, 11.0, 12.0, 14.0, 10.0, 12.0, 14.0, 14.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3003873266821111, "mean_inference_ms": 1.5784159122059938, "mean_action_processing_ms": 0.1036055238051836, "mean_env_wait_ms": 0.06882411056326132, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18352, "timesteps_this_iter": 32, "agent_timesteps_total": 36704, "timers": {"load_time_ms": 0.443, "load_throughput": 72307.794, "learn_time_ms": 7.946, "learn_throughput": 4027.297, "update_time_ms": 5.012}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.374861717224121, "min_q": -1.0155357122421265, "max_q": 13.792872428894043, "mean_td_error": -0.35099470615386963, "model": {}}, "td_error": [0.01391744613647461, -0.5628538131713867, -0.1057748794555664, -0.5628538131713867, -0.04739999771118164, 0.023990631103515625, 0.008523225784301758, -0.34377384185791016, -5.835738182067871, -0.28447389602661133, 4.455207824707031, 0.22814178466796875, 0.052158355712890625, -1.5603370666503906, -10.015535354614258, -0.44523048400878906, -0.5628538131713867, 0.019909381866455078, 1.3637008666992188, -0.03960895538330078, 1.0186262130737305, -1.1978187561035156, -1.713846206665039, -0.3292481303215027, -0.3729586601257324, -1.168992042541504, -0.634058952331543, -1.5585498809814453, -0.6029024124145508, 9.918265342712402, 0.21547424793243408, -0.6049368381500244], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 0.7515801191329956, "min_q": -4.44191312789917, "max_q": 7.324360370635986, "mean_td_error": -1.6873914003372192, "model": {}}, "td_error": [3.361985921859741, -3.7357869148254395, 2.8060238361358643, 2.8320631980895996, -1.4016324281692505, -4.545082092285156, -1.0995590686798096, 0.35466837882995605, -2.4290518760681152, 0.9316183924674988, 0.4206554889678955, 4.063557147979736, -9.81298542022705, -1.869168996810913, -3.043583869934082, 2.190187931060791, -0.5794124603271484, -5.967268943786621, 0.6171503067016602, -10.687239646911621, -0.6825003623962402, -1.0802128314971924, 0.5458869934082031, -9.509075164794922, -0.921994686126709, -1.8940691947937012, 2.3579776287078857, -1.727758765220642, -10.687239646911621, -3.959367036819458, 0.17430686950683594, 0.9803850650787354], "custom_metrics": {}}}, "num_steps_sampled": 18352, "num_agent_steps_sampled": 36704, "num_steps_trained": 41184, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 82368, "last_target_update_ts": 18263, "num_target_updates": 158}, "done": false, "episodes_total": 1387, "training_iteration": 61, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-54", "timestamp": 1648811574, "time_this_iter_s": 1.3407471179962158, "time_total_s": 77.19445395469666, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83efe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83efe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 77.19445395469666, "timesteps_since_restore": 1952, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 35.55, "ram_util_percent": 48.150000000000006}}
{"episode_reward_max": 34.0, "episode_reward_min": 0.0, "episode_reward_mean": 23.28, "episode_len_mean": 8.36, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 11.64, "policy1": 11.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 28.0, 12.0, 28.0, 28.0, 22.0, 20.0, 20.0, 28.0, 28.0, 24.0, 26.0, 28.0, 16.0, 0.0, 28.0, 8.0, 24.0, 28.0, 20.0, 12.0, 28.0, 24.0, 28.0, 34.0, 24.0, 24.0, 24.0, 28.0, 20.0, 20.0, 24.0, 12.0, 16.0, 28.0, 20.0, 24.0, 24.0, 24.0, 24.0, 24.0, 16.0, 16.0, 20.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 16.0, 24.0, 24.0, 24.0, 20.0, 20.0, 20.0, 20.0, 24.0, 20.0, 28.0, 20.0, 22.0, 24.0, 28.0, 20.0, 24.0, 28.0, 28.0, 20.0, 28.0, 28.0, 28.0, 20.0, 24.0, 24.0, 24.0, 16.0, 28.0, 24.0, 24.0, 28.0, 16.0, 20.0, 28.0, 28.0, 16.0, 28.0, 24.0, 24.0, 24.0, 28.0, 24.0, 24.0, 28.0, 20.0], "episode_lengths": [12, 6, 14, 6, 6, 9, 10, 10, 6, 6, 8, 7, 6, 12, 20, 6, 16, 8, 6, 10, 14, 6, 8, 6, 3, 8, 8, 8, 6, 10, 10, 8, 14, 12, 6, 10, 8, 8, 8, 8, 8, 12, 12, 10, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 12, 8, 8, 8, 10, 10, 10, 10, 8, 10, 6, 10, 9, 8, 6, 10, 8, 6, 6, 10, 6, 6, 6, 10, 8, 8, 8, 12, 6, 8, 8, 6, 12, 10, 6, 6, 12, 6, 8, 8, 8, 6, 8, 8, 6, 10], "policy_policy0_reward": [8.0, 14.0, 6.0, 14.0, 14.0, 11.0, 10.0, 10.0, 14.0, 14.0, 12.0, 13.0, 14.0, 8.0, 0.0, 14.0, 4.0, 12.0, 14.0, 10.0, 6.0, 14.0, 12.0, 14.0, 17.0, 12.0, 12.0, 12.0, 14.0, 10.0, 10.0, 12.0, 6.0, 8.0, 14.0, 10.0, 12.0, 12.0, 12.0, 12.0, 12.0, 8.0, 8.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 8.0, 12.0, 12.0, 12.0, 10.0, 10.0, 10.0, 10.0, 12.0, 10.0, 14.0, 10.0, 11.0, 12.0, 14.0, 10.0, 12.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 10.0, 12.0, 12.0, 12.0, 8.0, 14.0, 12.0, 12.0, 14.0, 8.0, 10.0, 14.0, 14.0, 8.0, 14.0, 12.0, 12.0, 12.0, 14.0, 12.0, 12.0, 14.0, 10.0], "policy_policy1_reward": [8.0, 14.0, 6.0, 14.0, 14.0, 11.0, 10.0, 10.0, 14.0, 14.0, 12.0, 13.0, 14.0, 8.0, 0.0, 14.0, 4.0, 12.0, 14.0, 10.0, 6.0, 14.0, 12.0, 14.0, 17.0, 12.0, 12.0, 12.0, 14.0, 10.0, 10.0, 12.0, 6.0, 8.0, 14.0, 10.0, 12.0, 12.0, 12.0, 12.0, 12.0, 8.0, 8.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 8.0, 12.0, 12.0, 12.0, 10.0, 10.0, 10.0, 10.0, 12.0, 10.0, 14.0, 10.0, 11.0, 12.0, 14.0, 10.0, 12.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 10.0, 12.0, 12.0, 12.0, 8.0, 14.0, 12.0, 12.0, 14.0, 8.0, 10.0, 14.0, 14.0, 8.0, 14.0, 12.0, 12.0, 12.0, 14.0, 12.0, 12.0, 14.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30151251968848364, "mean_inference_ms": 1.5834544547619362, "mean_action_processing_ms": 0.10399932076830652, "mean_env_wait_ms": 0.06906751183208366, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18558, "timesteps_this_iter": 32, "agent_timesteps_total": 37116, "timers": {"load_time_ms": 0.483, "load_throughput": 66237.836, "learn_time_ms": 8.011, "learn_throughput": 3994.67, "update_time_ms": 4.868}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.176314353942871, "min_q": -1.8163902759552002, "max_q": 14.388236045837402, "mean_td_error": 0.49485981464385986, "model": {}}, "td_error": [0.8039312362670898, 1.875650405883789, 0.10837554931640625, -0.21106243133544922, 0.07729148864746094, 0.20067119598388672, -0.5483837127685547, 0.5539035797119141, -0.037848472595214844, -1.3414030075073242, 1.054764747619629, 6.878635883331299, 0.5104860067367554, 0.21394872665405273, 0.8038263320922852, -1.4005064964294434, -1.3823490142822266, -0.32323360443115234, 0.06357622146606445, -0.037848472595214844, 1.2726860046386719, -0.32891273498535156, -0.5355734825134277, -0.36513757705688477, 0.44350600242614746, 0.9129128456115723, 0.9239833354949951, 0.40580177307128906, 0.07325363159179688, 3.5868539810180664, 0.1975780725479126, 1.3861356973648071], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 2.25783634185791, "min_q": -5.478352069854736, "max_q": 12.18112850189209, "mean_td_error": -0.8244170546531677, "model": {}}, "td_error": [4.206325531005859, -0.7755645513534546, -0.41754150390625, -1.0217432975769043, -9.184494972229004, 0.7833585739135742, -7.369344234466553, -0.5777339935302734, -9.987996101379395, 0.7850885391235352, 0.6374473571777344, 2.1370925903320312, 1.4783427715301514, -0.1889629364013672, 8.993916511535645, -7.7292375564575195, 6.572575092315674, -2.2588634490966797, -0.47407007217407227, -1.9333620071411133, -0.36723852157592773, -1.7245796918869019, -4.421043395996094, 0.09465956687927246, -9.273765563964844, 0.1911630630493164, -1.1994094848632812, -0.42412662506103516, 0.5726007223129272, 3.8296055793762207, 1.446866512298584, 1.2186899185180664], "custom_metrics": {}}}, "num_steps_sampled": 18558, "num_agent_steps_sampled": 37116, "num_steps_trained": 42016, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 84032, "last_target_update_ts": 18466, "num_target_updates": 160}, "done": false, "episodes_total": 1413, "training_iteration": 62, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-55", "timestamp": 1648811575, "time_this_iter_s": 1.3142211437225342, "time_total_s": 78.50867509841919, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 78.50867509841919, "timesteps_since_restore": 1984, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 28.15, "ram_util_percent": 48.349999999999994}}
{"episode_reward_max": 28.0, "episode_reward_min": 8.0, "episode_reward_mean": 23.66, "episode_len_mean": 8.17, "episode_media": {}, "episodes_this_iter": 25, "policy_reward_min": {"policy0": 4.0, "policy1": 4.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": 11.83, "policy1": 11.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, 24.0, 24.0, 28.0, 20.0, 20.0, 24.0, 12.0, 16.0, 28.0, 20.0, 24.0, 24.0, 24.0, 24.0, 24.0, 16.0, 16.0, 20.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 16.0, 24.0, 24.0, 24.0, 20.0, 20.0, 20.0, 20.0, 24.0, 20.0, 28.0, 20.0, 22.0, 24.0, 28.0, 20.0, 24.0, 28.0, 28.0, 20.0, 28.0, 28.0, 28.0, 20.0, 24.0, 24.0, 24.0, 16.0, 28.0, 24.0, 24.0, 28.0, 16.0, 20.0, 28.0, 28.0, 16.0, 28.0, 24.0, 24.0, 24.0, 28.0, 24.0, 24.0, 28.0, 20.0, 28.0, 28.0, 20.0, 16.0, 28.0, 28.0, 24.0, 28.0, 20.0, 24.0, 28.0, 24.0, 24.0, 28.0, 28.0, 24.0, 28.0, 16.0, 16.0, 24.0, 28.0, 24.0, 28.0, 24.0, 8.0], "episode_lengths": [8, 8, 8, 6, 10, 10, 8, 14, 12, 6, 10, 8, 8, 8, 8, 8, 12, 12, 10, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 12, 8, 8, 8, 10, 10, 10, 10, 8, 10, 6, 10, 9, 8, 6, 10, 8, 6, 6, 10, 6, 6, 6, 10, 8, 8, 8, 12, 6, 8, 8, 6, 12, 10, 6, 6, 12, 6, 8, 8, 8, 6, 8, 8, 6, 10, 6, 6, 10, 12, 6, 6, 8, 6, 10, 8, 6, 8, 8, 6, 6, 8, 6, 12, 12, 8, 6, 8, 6, 8, 16], "policy_policy0_reward": [12.0, 12.0, 12.0, 14.0, 10.0, 10.0, 12.0, 6.0, 8.0, 14.0, 10.0, 12.0, 12.0, 12.0, 12.0, 12.0, 8.0, 8.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 8.0, 12.0, 12.0, 12.0, 10.0, 10.0, 10.0, 10.0, 12.0, 10.0, 14.0, 10.0, 11.0, 12.0, 14.0, 10.0, 12.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 10.0, 12.0, 12.0, 12.0, 8.0, 14.0, 12.0, 12.0, 14.0, 8.0, 10.0, 14.0, 14.0, 8.0, 14.0, 12.0, 12.0, 12.0, 14.0, 12.0, 12.0, 14.0, 10.0, 14.0, 14.0, 10.0, 8.0, 14.0, 14.0, 12.0, 14.0, 10.0, 12.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 8.0, 12.0, 14.0, 12.0, 14.0, 12.0, 4.0], "policy_policy1_reward": [12.0, 12.0, 12.0, 14.0, 10.0, 10.0, 12.0, 6.0, 8.0, 14.0, 10.0, 12.0, 12.0, 12.0, 12.0, 12.0, 8.0, 8.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 8.0, 12.0, 12.0, 12.0, 10.0, 10.0, 10.0, 10.0, 12.0, 10.0, 14.0, 10.0, 11.0, 12.0, 14.0, 10.0, 12.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 10.0, 12.0, 12.0, 12.0, 8.0, 14.0, 12.0, 12.0, 14.0, 8.0, 10.0, 14.0, 14.0, 8.0, 14.0, 12.0, 12.0, 12.0, 14.0, 12.0, 12.0, 14.0, 10.0, 14.0, 14.0, 10.0, 8.0, 14.0, 14.0, 12.0, 14.0, 10.0, 12.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 8.0, 12.0, 14.0, 12.0, 14.0, 12.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30242723560978274, "mean_inference_ms": 1.5871844969532827, "mean_action_processing_ms": 0.10429348552793329, "mean_env_wait_ms": 0.06924612724767513, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18760, "timesteps_this_iter": 32, "agent_timesteps_total": 37520, "timers": {"load_time_ms": 0.443, "load_throughput": 72210.539, "learn_time_ms": 8.577, "learn_throughput": 3730.851, "update_time_ms": 5.509}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.68745756149292, "min_q": -0.715386688709259, "max_q": 14.049308776855469, "mean_td_error": -0.9691265225410461, "model": {}}, "td_error": [-0.12962836027145386, 1.1043787002563477, -10.109774589538574, -1.5504283905029297, 1.0528631210327148, 0.2590665817260742, 0.22005939483642578, -2.7162623405456543, -0.7231111526489258, -0.20028230547904968, -0.49864864349365234, -0.606459379196167, -1.7596588134765625, -0.1559295654296875, 0.034171104431152344, -0.6477456092834473, -0.785346508026123, -1.1150245666503906, -0.7015495300292969, -0.4046030044555664, -0.2703433036804199, -0.616663932800293, 0.378997802734375, -4.353728294372559, -1.127901554107666, -5.834453582763672, -0.06635570526123047, 0.6741452217102051, -0.9814834594726562, -0.5670208930969238, 0.403106689453125, 0.7835655212402344], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 1.2022371292114258, "min_q": -6.545531272888184, "max_q": 14.201276779174805, "mean_td_error": 0.17638495564460754, "model": {}}, "td_error": [7.445141792297363, 1.7743024826049805, 0.24266529083251953, 2.784543037414551, 1.4762639999389648, -0.24293732643127441, -4.156278610229492, -5.182251930236816, -0.3070969581604004, 0.4923279285430908, -9.029733657836914, -1.2883944511413574, -0.38103675842285156, -14.271564483642578, 6.957592010498047, 0.830939769744873, 5.991272926330566, -1.612617015838623, 0.6250267028808594, 1.0448408126831055, -0.22762060165405273, 5.840394020080566, -2.086252212524414, 2.852451801300049, 2.9010181427001953, 0.7294578552246094, 3.0633180141448975, 0.9235095977783203, 2.7170143127441406, -0.8726499080657959, -0.5609629154205322, -2.82836651802063], "custom_metrics": {}}}, "num_steps_sampled": 18760, "num_agent_steps_sampled": 37520, "num_steps_trained": 42816, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 85632, "last_target_update_ts": 18678, "num_target_updates": 162}, "done": false, "episodes_total": 1438, "training_iteration": 63, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-56", "timestamp": 1648811576, "time_this_iter_s": 1.2945663928985596, "time_total_s": 79.80324149131775, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cdd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cdd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 79.80324149131775, "timesteps_since_restore": 2016, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 28.35, "ram_util_percent": 48.55}}
{"episode_reward_max": 32.0, "episode_reward_min": 8.0, "episode_reward_mean": 24.06, "episode_len_mean": 7.97, "episode_media": {}, "episodes_this_iter": 28, "policy_reward_min": {"policy0": 4.0, "policy1": 4.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": 12.03, "policy1": 12.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 16.0, 24.0, 24.0, 24.0, 20.0, 20.0, 20.0, 20.0, 24.0, 20.0, 28.0, 20.0, 22.0, 24.0, 28.0, 20.0, 24.0, 28.0, 28.0, 20.0, 28.0, 28.0, 28.0, 20.0, 24.0, 24.0, 24.0, 16.0, 28.0, 24.0, 24.0, 28.0, 16.0, 20.0, 28.0, 28.0, 16.0, 28.0, 24.0, 24.0, 24.0, 28.0, 24.0, 24.0, 28.0, 20.0, 28.0, 28.0, 20.0, 16.0, 28.0, 28.0, 24.0, 28.0, 20.0, 24.0, 28.0, 24.0, 24.0, 28.0, 28.0, 24.0, 28.0, 16.0, 16.0, 24.0, 28.0, 24.0, 28.0, 24.0, 8.0, 28.0, 28.0, 28.0, 26.0, 20.0, 28.0, 20.0, 28.0, 24.0, 28.0, 12.0, 24.0, 28.0, 24.0, 12.0, 12.0, 28.0, 30.0, 28.0, 24.0, 28.0, 24.0, 28.0, 24.0, 32.0, 24.0, 32.0, 28.0], "episode_lengths": [6, 12, 8, 8, 8, 10, 10, 10, 10, 8, 10, 6, 10, 9, 8, 6, 10, 8, 6, 6, 10, 6, 6, 6, 10, 8, 8, 8, 12, 6, 8, 8, 6, 12, 10, 6, 6, 12, 6, 8, 8, 8, 6, 8, 8, 6, 10, 6, 6, 10, 12, 6, 6, 8, 6, 10, 8, 6, 8, 8, 6, 6, 8, 6, 12, 12, 8, 6, 8, 6, 8, 16, 6, 6, 6, 7, 10, 6, 10, 6, 8, 6, 14, 8, 6, 8, 14, 14, 6, 5, 6, 8, 6, 8, 6, 8, 4, 8, 4, 6], "policy_policy0_reward": [14.0, 8.0, 12.0, 12.0, 12.0, 10.0, 10.0, 10.0, 10.0, 12.0, 10.0, 14.0, 10.0, 11.0, 12.0, 14.0, 10.0, 12.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 10.0, 12.0, 12.0, 12.0, 8.0, 14.0, 12.0, 12.0, 14.0, 8.0, 10.0, 14.0, 14.0, 8.0, 14.0, 12.0, 12.0, 12.0, 14.0, 12.0, 12.0, 14.0, 10.0, 14.0, 14.0, 10.0, 8.0, 14.0, 14.0, 12.0, 14.0, 10.0, 12.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 8.0, 12.0, 14.0, 12.0, 14.0, 12.0, 4.0, 14.0, 14.0, 14.0, 13.0, 10.0, 14.0, 10.0, 14.0, 12.0, 14.0, 6.0, 12.0, 14.0, 12.0, 6.0, 6.0, 14.0, 15.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 16.0, 12.0, 16.0, 14.0], "policy_policy1_reward": [14.0, 8.0, 12.0, 12.0, 12.0, 10.0, 10.0, 10.0, 10.0, 12.0, 10.0, 14.0, 10.0, 11.0, 12.0, 14.0, 10.0, 12.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 10.0, 12.0, 12.0, 12.0, 8.0, 14.0, 12.0, 12.0, 14.0, 8.0, 10.0, 14.0, 14.0, 8.0, 14.0, 12.0, 12.0, 12.0, 14.0, 12.0, 12.0, 14.0, 10.0, 14.0, 14.0, 10.0, 8.0, 14.0, 14.0, 12.0, 14.0, 10.0, 12.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 8.0, 12.0, 14.0, 12.0, 14.0, 12.0, 4.0, 14.0, 14.0, 14.0, 13.0, 10.0, 14.0, 10.0, 14.0, 12.0, 14.0, 6.0, 12.0, 14.0, 12.0, 6.0, 6.0, 14.0, 15.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 16.0, 12.0, 16.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3034937284016015, "mean_inference_ms": 1.5915908725243613, "mean_action_processing_ms": 0.10461529866246515, "mean_env_wait_ms": 0.06943279442274837, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18970, "timesteps_this_iter": 32, "agent_timesteps_total": 37940, "timers": {"load_time_ms": 0.424, "load_throughput": 75500.775, "learn_time_ms": 8.115, "learn_throughput": 3943.451, "update_time_ms": 4.922}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.286779403686523, "min_q": -0.8009614944458008, "max_q": 15.372146606445312, "mean_td_error": -0.09715217351913452, "model": {}}, "td_error": [1.8552579879760742, 2.259833812713623, 0.15624046325683594, -0.5230283737182617, -0.047287940979003906, -0.5267810821533203, -0.27927494049072266, -0.2956380844116211, -5.409335136413574, -1.359766960144043, -0.3384275436401367, -0.628511905670166, -0.403389573097229, -1.4926685094833374, -0.5048961639404297, -2.149806499481201, -0.8331880569458008, 1.4587621688842773, -0.792056679725647, 0.9389315843582153, 10.978562355041504, 0.19542312622070312, 1.0972137451171875, -0.49390125274658203, -0.5601119995117188, 0.19136571884155273, -0.36428070068359375, -0.8104944229125977, -3.196981430053711, -0.3012552261352539, -0.4968118667602539, -0.43256568908691406], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 1.5203388929367065, "min_q": -6.349626541137695, "max_q": 9.309679985046387, "mean_td_error": -1.0946354866027832, "model": {}}, "td_error": [-8.80882453918457, 3.228870153427124, 1.0633540153503418, -6.742218971252441, 2.065758228302002, -2.636392116546631, 1.3846498727798462, -4.875837326049805, -1.0130691528320312, -2.529601573944092, 0.7158946990966797, -4.904904365539551, -1.736320972442627, 2.269395351409912, -0.6841349601745605, -2.5033090114593506, -3.19334077835083, 1.4090018272399902, -3.447848320007324, 0.9363927841186523, -1.9603502750396729, 3.6869921684265137, -1.2490899562835693, -0.6514269113540649, 0.5971775054931641, -2.8533945083618164, 1.0633540153503418, -2.3751628398895264, 0.32314562797546387, -2.7903892993927, -0.0008547306060791016, 1.184150218963623], "custom_metrics": {}}}, "num_steps_sampled": 18970, "num_agent_steps_sampled": 37940, "num_steps_trained": 43712, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 87424, "last_target_update_ts": 18895, "num_target_updates": 164}, "done": false, "episodes_total": 1466, "training_iteration": 64, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-58", "timestamp": 1648811578, "time_this_iter_s": 1.4802961349487305, "time_total_s": 81.28353762626648, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 81.28353762626648, "timesteps_since_restore": 2048, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 37.3, "ram_util_percent": 49.099999999999994}}
{"episode_reward_max": 34.0, "episode_reward_min": 8.0, "episode_reward_mean": 25.32, "episode_len_mean": 7.34, "episode_media": {}, "episodes_this_iter": 33, "policy_reward_min": {"policy0": 4.0, "policy1": 4.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 12.66, "policy1": 12.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 20.0, 28.0, 28.0, 16.0, 28.0, 24.0, 24.0, 24.0, 28.0, 24.0, 24.0, 28.0, 20.0, 28.0, 28.0, 20.0, 16.0, 28.0, 28.0, 24.0, 28.0, 20.0, 24.0, 28.0, 24.0, 24.0, 28.0, 28.0, 24.0, 28.0, 16.0, 16.0, 24.0, 28.0, 24.0, 28.0, 24.0, 8.0, 28.0, 28.0, 28.0, 26.0, 20.0, 28.0, 20.0, 28.0, 24.0, 28.0, 12.0, 24.0, 28.0, 24.0, 12.0, 12.0, 28.0, 30.0, 28.0, 24.0, 28.0, 24.0, 28.0, 24.0, 32.0, 24.0, 32.0, 28.0, 28.0, 28.0, 24.0, 28.0, 24.0, 16.0, 28.0, 20.0, 34.0, 24.0, 28.0, 28.0, 28.0, 28.0, 26.0, 32.0, 32.0, 34.0, 34.0, 24.0, 28.0, 28.0, 28.0, 24.0, 16.0, 20.0, 28.0, 28.0, 30.0, 30.0, 28.0, 34.0, 34.0], "episode_lengths": [12, 10, 6, 6, 12, 6, 8, 8, 8, 6, 8, 8, 6, 10, 6, 6, 10, 12, 6, 6, 8, 6, 10, 8, 6, 8, 8, 6, 6, 8, 6, 12, 12, 8, 6, 8, 6, 8, 16, 6, 6, 6, 7, 10, 6, 10, 6, 8, 6, 14, 8, 6, 8, 14, 14, 6, 5, 6, 8, 6, 8, 6, 8, 4, 8, 4, 6, 6, 6, 8, 6, 8, 12, 6, 10, 3, 8, 6, 6, 6, 6, 7, 4, 4, 3, 3, 8, 6, 6, 6, 8, 12, 10, 6, 6, 5, 5, 6, 3, 3], "policy_policy0_reward": [8.0, 10.0, 14.0, 14.0, 8.0, 14.0, 12.0, 12.0, 12.0, 14.0, 12.0, 12.0, 14.0, 10.0, 14.0, 14.0, 10.0, 8.0, 14.0, 14.0, 12.0, 14.0, 10.0, 12.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 8.0, 12.0, 14.0, 12.0, 14.0, 12.0, 4.0, 14.0, 14.0, 14.0, 13.0, 10.0, 14.0, 10.0, 14.0, 12.0, 14.0, 6.0, 12.0, 14.0, 12.0, 6.0, 6.0, 14.0, 15.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 16.0, 12.0, 16.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 8.0, 14.0, 10.0, 17.0, 12.0, 14.0, 14.0, 14.0, 14.0, 13.0, 16.0, 16.0, 17.0, 17.0, 12.0, 14.0, 14.0, 14.0, 12.0, 8.0, 10.0, 14.0, 14.0, 15.0, 15.0, 14.0, 17.0, 17.0], "policy_policy1_reward": [8.0, 10.0, 14.0, 14.0, 8.0, 14.0, 12.0, 12.0, 12.0, 14.0, 12.0, 12.0, 14.0, 10.0, 14.0, 14.0, 10.0, 8.0, 14.0, 14.0, 12.0, 14.0, 10.0, 12.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 14.0, 8.0, 8.0, 12.0, 14.0, 12.0, 14.0, 12.0, 4.0, 14.0, 14.0, 14.0, 13.0, 10.0, 14.0, 10.0, 14.0, 12.0, 14.0, 6.0, 12.0, 14.0, 12.0, 6.0, 6.0, 14.0, 15.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 16.0, 12.0, 16.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 8.0, 14.0, 10.0, 17.0, 12.0, 14.0, 14.0, 14.0, 14.0, 13.0, 16.0, 16.0, 17.0, 17.0, 12.0, 14.0, 14.0, 14.0, 12.0, 8.0, 10.0, 14.0, 14.0, 15.0, 15.0, 14.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30474037068448145, "mean_inference_ms": 1.5960877463599161, "mean_action_processing_ms": 0.10493827518681646, "mean_env_wait_ms": 0.06962307843643276, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19178, "timesteps_this_iter": 32, "agent_timesteps_total": 38356, "timers": {"load_time_ms": 0.442, "load_throughput": 72467.862, "learn_time_ms": 7.899, "learn_throughput": 4050.951, "update_time_ms": 4.955}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.883481502532959, "min_q": 0.18412208557128906, "max_q": 15.04576301574707, "mean_td_error": -0.197745218873024, "model": {}}, "td_error": [-4.431184768676758, 0.03798413276672363, 0.16109466552734375, -0.8272563219070435, -1.1309711933135986, 0.7453069686889648, -0.09439706802368164, 0.504967212677002, -0.11276721954345703, -0.24153518676757812, 0.5470218658447266, 0.5765738487243652, -0.8224716186523438, -1.329559326171875, -0.9395961761474609, -0.2384967803955078, 0.3255472183227539, 1.4139947891235352, 0.3675041198730469, -3.1289501190185547, 0.1595158576965332, -0.5283231735229492, 0.7481508255004883, 0.009037971496582031, -1.9776298999786377, 5.078370571136475, 0.19531726837158203, -0.6921039819717407, 1.3554201126098633, 0.21757793426513672, -0.4265627861022949, -1.8494272232055664], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 2.9490365982055664, "min_q": -6.486073017120361, "max_q": 15.715214729309082, "mean_td_error": 0.20379284024238586, "model": {}}, "td_error": [-0.48457956314086914, -0.8996162414550781, -2.2961180210113525, -2.5685296058654785, -0.3092341423034668, 2.033534526824951, 0.1369032859802246, 0.3716416358947754, 2.5578160285949707, -2.5221705436706543, -2.2664318084716797, 2.6228227615356445, -2.644998550415039, -2.9162909984588623, -2.8234543800354004, 3.7384235858917236, 0.3567342758178711, 2.208946466445923, -2.3112564086914062, 0.275226354598999, -4.367236137390137, 2.5578160285949707, 5.156329154968262, 6.1906867027282715, 0.5441830158233643, -0.5397405624389648, 1.7964526414871216, -1.9050779342651367, -1.6063168048858643, 2.9728195667266846, -1.039224624633789, 4.5013108253479], "custom_metrics": {}}}, "num_steps_sampled": 19178, "num_agent_steps_sampled": 38356, "num_steps_trained": 44672, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 89344, "last_target_update_ts": 19102, "num_target_updates": 166}, "done": false, "episodes_total": 1499, "training_iteration": 65, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-12-59", "timestamp": 1648811579, "time_this_iter_s": 1.407209873199463, "time_total_s": 82.69074749946594, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 82.69074749946594, "timesteps_since_restore": 2080, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 37.15, "ram_util_percent": 49.85}}
{"episode_reward_max": 34.0, "episode_reward_min": 8.0, "episode_reward_mean": 26.52, "episode_len_mean": 6.74, "episode_media": {}, "episodes_this_iter": 33, "policy_reward_min": {"policy0": 4.0, "policy1": 4.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 13.26, "policy1": 13.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, 28.0, 24.0, 28.0, 24.0, 8.0, 28.0, 28.0, 28.0, 26.0, 20.0, 28.0, 20.0, 28.0, 24.0, 28.0, 12.0, 24.0, 28.0, 24.0, 12.0, 12.0, 28.0, 30.0, 28.0, 24.0, 28.0, 24.0, 28.0, 24.0, 32.0, 24.0, 32.0, 28.0, 28.0, 28.0, 24.0, 28.0, 24.0, 16.0, 28.0, 20.0, 34.0, 24.0, 28.0, 28.0, 28.0, 28.0, 26.0, 32.0, 32.0, 34.0, 34.0, 24.0, 28.0, 28.0, 28.0, 24.0, 16.0, 20.0, 28.0, 28.0, 30.0, 30.0, 28.0, 34.0, 34.0, 34.0, 34.0, 28.0, 24.0, 20.0, 30.0, 26.0, 12.0, 30.0, 32.0, 24.0, 26.0, 12.0, 24.0, 28.0, 24.0, 34.0, 34.0, 34.0, 34.0, 30.0, 28.0, 24.0, 22.0, 24.0, 34.0, 28.0, 34.0, 34.0, 20.0, 28.0, 34.0, 28.0], "episode_lengths": [8, 6, 8, 6, 8, 16, 6, 6, 6, 7, 10, 6, 10, 6, 8, 6, 14, 8, 6, 8, 14, 14, 6, 5, 6, 8, 6, 8, 6, 8, 4, 8, 4, 6, 6, 6, 8, 6, 8, 12, 6, 10, 3, 8, 6, 6, 6, 6, 7, 4, 4, 3, 3, 8, 6, 6, 6, 8, 12, 10, 6, 6, 5, 5, 6, 3, 3, 3, 3, 6, 8, 10, 5, 7, 14, 5, 4, 8, 7, 14, 8, 6, 8, 3, 3, 3, 3, 5, 6, 8, 9, 8, 3, 6, 3, 3, 10, 6, 3, 6], "policy_policy0_reward": [12.0, 14.0, 12.0, 14.0, 12.0, 4.0, 14.0, 14.0, 14.0, 13.0, 10.0, 14.0, 10.0, 14.0, 12.0, 14.0, 6.0, 12.0, 14.0, 12.0, 6.0, 6.0, 14.0, 15.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 16.0, 12.0, 16.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 8.0, 14.0, 10.0, 17.0, 12.0, 14.0, 14.0, 14.0, 14.0, 13.0, 16.0, 16.0, 17.0, 17.0, 12.0, 14.0, 14.0, 14.0, 12.0, 8.0, 10.0, 14.0, 14.0, 15.0, 15.0, 14.0, 17.0, 17.0, 17.0, 17.0, 14.0, 12.0, 10.0, 15.0, 13.0, 6.0, 15.0, 16.0, 12.0, 13.0, 6.0, 12.0, 14.0, 12.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 12.0, 11.0, 12.0, 17.0, 14.0, 17.0, 17.0, 10.0, 14.0, 17.0, 14.0], "policy_policy1_reward": [12.0, 14.0, 12.0, 14.0, 12.0, 4.0, 14.0, 14.0, 14.0, 13.0, 10.0, 14.0, 10.0, 14.0, 12.0, 14.0, 6.0, 12.0, 14.0, 12.0, 6.0, 6.0, 14.0, 15.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 16.0, 12.0, 16.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 8.0, 14.0, 10.0, 17.0, 12.0, 14.0, 14.0, 14.0, 14.0, 13.0, 16.0, 16.0, 17.0, 17.0, 12.0, 14.0, 14.0, 14.0, 12.0, 8.0, 10.0, 14.0, 14.0, 15.0, 15.0, 14.0, 17.0, 17.0, 17.0, 17.0, 14.0, 12.0, 10.0, 15.0, 13.0, 6.0, 15.0, 16.0, 12.0, 13.0, 6.0, 12.0, 14.0, 12.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 12.0, 11.0, 12.0, 17.0, 14.0, 17.0, 17.0, 10.0, 14.0, 17.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3059767146779621, "mean_inference_ms": 1.5999611104206202, "mean_action_processing_ms": 0.1052154508427445, "mean_env_wait_ms": 0.06979603923298155, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19382, "timesteps_this_iter": 32, "agent_timesteps_total": 38764, "timers": {"load_time_ms": 0.462, "load_throughput": 69313.018, "learn_time_ms": 7.928, "learn_throughput": 4036.429, "update_time_ms": 5.003}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.975105285644531, "min_q": 1.140122413635254, "max_q": 16.284128189086914, "mean_td_error": -0.1541382074356079, "model": {}}, "td_error": [0.07731819152832031, -0.5054183006286621, -0.02882838249206543, 0.10416030883789062, 0.5951786041259766, 0.9249563217163086, 1.0743083953857422, -0.01121377944946289, 0.47177886962890625, -1.5644638538360596, 1.402113914489746, 0.625361442565918, -0.3030662536621094, 0.14871501922607422, -0.4754800796508789, -0.322329044342041, -1.296792984008789, 0.009386062622070312, -0.9568977355957031, 0.03615617752075195, -2.0560994148254395, -0.46720361709594727, -0.4084053039550781, 0.4126706123352051, 1.0833330154418945, -0.805019736289978, 0.4848661422729492, -0.5958328247070312, -0.4983487129211426, 0.19962692260742188, 0.10798454284667969, -2.394937515258789], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.1313588619232178, "min_q": -3.6826181411743164, "max_q": 11.108977317810059, "mean_td_error": -1.7177213430404663, "model": {}}, "td_error": [-0.04365992546081543, -1.2386293411254883, -0.5148043632507324, -6.603738784790039, 1.6191396713256836, -7.506748199462891, -0.6163130402565002, -10.696632385253906, -1.2386293411254883, 1.691007375717163, -8.197066307067871, -2.0138258934020996, 0.20394229888916016, 0.37969350814819336, -4.372673034667969, -3.9263410568237305, -5.712527275085449, -2.247084617614746, 2.862989902496338, 1.283177137374878, 0.5212481021881104, -9.4964017868042, -0.8794737458229065, 4.953874588012695, 0.429457426071167, -2.9447221755981445, -3.958866596221924, -0.5495905876159668, 2.891362190246582, 0.4901564121246338, 0.4584522247314453, 0.006142616271972656], "custom_metrics": {}}}, "num_steps_sampled": 19382, "num_agent_steps_sampled": 38764, "num_steps_trained": 45536, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 91072, "last_target_update_ts": 19311, "num_target_updates": 168}, "done": false, "episodes_total": 1532, "training_iteration": 66, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-01", "timestamp": 1648811581, "time_this_iter_s": 1.3204903602600098, "time_total_s": 84.01123785972595, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 84.01123785972595, "timesteps_since_restore": 2112, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 37.45, "ram_util_percent": 50.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -20.0, "episode_reward_mean": 28.7, "episode_len_mean": 5.55, "episode_media": {}, "episodes_this_iter": 42, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 14.35, "policy1": 14.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 24.0, 28.0, 28.0, 28.0, 28.0, 26.0, 32.0, 32.0, 34.0, 34.0, 24.0, 28.0, 28.0, 28.0, 24.0, 16.0, 20.0, 28.0, 28.0, 30.0, 30.0, 28.0, 34.0, 34.0, 34.0, 34.0, 28.0, 24.0, 20.0, 30.0, 26.0, 12.0, 30.0, 32.0, 24.0, 26.0, 12.0, 24.0, 28.0, 24.0, 34.0, 34.0, 34.0, 34.0, 30.0, 28.0, 24.0, 22.0, 24.0, 34.0, 28.0, 34.0, 34.0, 20.0, 28.0, 34.0, 28.0, 32.0, 34.0, 28.0, 32.0, 32.0, 32.0, -20.0, 34.0, 34.0, 32.0, 34.0, 30.0, 24.0, 28.0, 32.0, 34.0, 34.0, 28.0, 28.0, 30.0, 32.0, 26.0, 24.0, 32.0, 34.0, 32.0, 32.0, 30.0, 28.0, 34.0, 28.0, 26.0, 34.0, 32.0, 32.0, 34.0, 34.0, 34.0, 30.0, 28.0, 32.0, 30.0], "episode_lengths": [3, 8, 6, 6, 6, 6, 7, 4, 4, 3, 3, 8, 6, 6, 6, 8, 12, 10, 6, 6, 5, 5, 6, 3, 3, 3, 3, 6, 8, 10, 5, 7, 14, 5, 4, 8, 7, 14, 8, 6, 8, 3, 3, 3, 3, 5, 6, 8, 9, 8, 3, 6, 3, 3, 10, 6, 3, 6, 4, 3, 6, 4, 4, 4, 20, 3, 3, 4, 3, 5, 8, 6, 4, 3, 3, 6, 6, 5, 4, 7, 8, 4, 3, 4, 4, 5, 6, 3, 6, 7, 3, 4, 4, 3, 3, 3, 5, 6, 4, 5], "policy_policy0_reward": [17.0, 12.0, 14.0, 14.0, 14.0, 14.0, 13.0, 16.0, 16.0, 17.0, 17.0, 12.0, 14.0, 14.0, 14.0, 12.0, 8.0, 10.0, 14.0, 14.0, 15.0, 15.0, 14.0, 17.0, 17.0, 17.0, 17.0, 14.0, 12.0, 10.0, 15.0, 13.0, 6.0, 15.0, 16.0, 12.0, 13.0, 6.0, 12.0, 14.0, 12.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 12.0, 11.0, 12.0, 17.0, 14.0, 17.0, 17.0, 10.0, 14.0, 17.0, 14.0, 16.0, 17.0, 14.0, 16.0, 16.0, 16.0, -10.0, 17.0, 17.0, 16.0, 17.0, 15.0, 12.0, 14.0, 16.0, 17.0, 17.0, 14.0, 14.0, 15.0, 16.0, 13.0, 12.0, 16.0, 17.0, 16.0, 16.0, 15.0, 14.0, 17.0, 14.0, 13.0, 17.0, 16.0, 16.0, 17.0, 17.0, 17.0, 15.0, 14.0, 16.0, 15.0], "policy_policy1_reward": [17.0, 12.0, 14.0, 14.0, 14.0, 14.0, 13.0, 16.0, 16.0, 17.0, 17.0, 12.0, 14.0, 14.0, 14.0, 12.0, 8.0, 10.0, 14.0, 14.0, 15.0, 15.0, 14.0, 17.0, 17.0, 17.0, 17.0, 14.0, 12.0, 10.0, 15.0, 13.0, 6.0, 15.0, 16.0, 12.0, 13.0, 6.0, 12.0, 14.0, 12.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 12.0, 11.0, 12.0, 17.0, 14.0, 17.0, 17.0, 10.0, 14.0, 17.0, 14.0, 16.0, 17.0, 14.0, 16.0, 16.0, 16.0, -10.0, 17.0, 17.0, 16.0, 17.0, 15.0, 12.0, 14.0, 16.0, 17.0, 17.0, 14.0, 14.0, 15.0, 16.0, 13.0, 12.0, 16.0, 17.0, 16.0, 16.0, 15.0, 14.0, 17.0, 14.0, 13.0, 17.0, 16.0, 16.0, 17.0, 17.0, 17.0, 15.0, 14.0, 16.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3074565466258487, "mean_inference_ms": 1.603275286694374, "mean_action_processing_ms": 0.10548311660384196, "mean_env_wait_ms": 0.06995852774814504, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19587, "timesteps_this_iter": 32, "agent_timesteps_total": 39174, "timers": {"load_time_ms": 0.447, "load_throughput": 71655.399, "learn_time_ms": 8.779, "learn_throughput": 3645.052, "update_time_ms": 5.265}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.256479263305664, "min_q": 0.4118225574493408, "max_q": 15.669973373413086, "mean_td_error": 0.44779521226882935, "model": {}}, "td_error": [0.7203903198242188, 0.39427661895751953, 1.1949377059936523, 8.323280334472656, 1.119537353515625, 1.4118225574493408, -1.098175048828125, 5.1656951904296875, -0.6596870422363281, 1.312546730041504, -1.4346728324890137, 0.1048583984375, 0.1224355697631836, -0.03799247741699219, 0.8270487785339355, -0.16554641723632812, -0.9330282211303711, -0.28777408599853516, -1.2684650421142578, -0.7761516571044922, 0.16418170928955078, -0.152008056640625, -0.1971416473388672, -0.1712017059326172, 0.5236868858337402, -0.7923393249511719, 0.15474414825439453, -0.99261474609375, -0.4518299102783203, 0.1112823486328125, 2.170046806335449, -0.07269573211669922], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.420986175537109, "min_q": -4.206921577453613, "max_q": 12.884946823120117, "mean_td_error": -1.0940501689910889, "model": {}}, "td_error": [-2.0369977951049805, -0.38043975830078125, -3.366722583770752, -9.328753471374512, 0.33479034900665283, 0.4223494529724121, -5.331357002258301, 0.26362133026123047, 0.5719280242919922, 1.607990026473999, -2.526865005493164, 2.04817533493042, -3.008024215698242, -2.706448554992676, 7.725852966308594, -0.9560337066650391, 1.3509459495544434, 0.45163244009017944, 4.803621768951416, 2.1279473304748535, -3.9386978149414062, 1.0464428663253784, -3.7658801078796387, -1.012568473815918, -5.255143165588379, -1.159377098083496, -1.3442773818969727, -5.718869686126709, -1.012568473815918, -0.7654037475585938, -2.0542731285095215, -2.0962023735046387], "custom_metrics": {}}}, "num_steps_sampled": 19587, "num_agent_steps_sampled": 39174, "num_steps_trained": 46592, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 93184, "last_target_update_ts": 19531, "num_target_updates": 170}, "done": false, "episodes_total": 1574, "training_iteration": 67, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-02", "timestamp": 1648811582, "time_this_iter_s": 1.5388493537902832, "time_total_s": 85.55008721351624, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c09e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c09e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 85.55008721351624, "timesteps_since_restore": 2144, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 37.03333333333333, "ram_util_percent": 51.13333333333333}}
{"episode_reward_max": 34.0, "episode_reward_min": -20.0, "episode_reward_mean": 30.28, "episode_len_mean": 4.76, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 15.14, "policy1": 15.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, 22.0, 24.0, 34.0, 28.0, 34.0, 34.0, 20.0, 28.0, 34.0, 28.0, 32.0, 34.0, 28.0, 32.0, 32.0, 32.0, -20.0, 34.0, 34.0, 32.0, 34.0, 30.0, 24.0, 28.0, 32.0, 34.0, 34.0, 28.0, 28.0, 30.0, 32.0, 26.0, 24.0, 32.0, 34.0, 32.0, 32.0, 30.0, 28.0, 34.0, 28.0, 26.0, 34.0, 32.0, 32.0, 34.0, 34.0, 34.0, 30.0, 28.0, 32.0, 30.0, 30.0, 34.0, 34.0, 34.0, 32.0, 28.0, 34.0, 34.0, 34.0, 32.0, 28.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 10.0, 34.0, 34.0, 34.0, 34.0, 24.0, 34.0, 20.0, 32.0, 30.0, 34.0, 34.0, 34.0, 30.0, 30.0, 20.0, 24.0, 34.0, 32.0, 34.0, 30.0, 34.0, 34.0, 30.0, 34.0, 34.0, 30.0], "episode_lengths": [8, 9, 8, 3, 6, 3, 3, 10, 6, 3, 6, 4, 3, 6, 4, 4, 4, 20, 3, 3, 4, 3, 5, 8, 6, 4, 3, 3, 6, 6, 5, 4, 7, 8, 4, 3, 4, 4, 5, 6, 3, 6, 7, 3, 4, 4, 3, 3, 3, 5, 6, 4, 5, 5, 3, 3, 3, 4, 6, 3, 3, 3, 4, 6, 3, 3, 6, 3, 3, 3, 5, 3, 3, 15, 3, 3, 3, 3, 8, 3, 10, 4, 5, 3, 3, 3, 5, 5, 10, 8, 3, 4, 3, 5, 3, 3, 5, 3, 3, 5], "policy_policy0_reward": [12.0, 11.0, 12.0, 17.0, 14.0, 17.0, 17.0, 10.0, 14.0, 17.0, 14.0, 16.0, 17.0, 14.0, 16.0, 16.0, 16.0, -10.0, 17.0, 17.0, 16.0, 17.0, 15.0, 12.0, 14.0, 16.0, 17.0, 17.0, 14.0, 14.0, 15.0, 16.0, 13.0, 12.0, 16.0, 17.0, 16.0, 16.0, 15.0, 14.0, 17.0, 14.0, 13.0, 17.0, 16.0, 16.0, 17.0, 17.0, 17.0, 15.0, 14.0, 16.0, 15.0, 15.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 5.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 10.0, 16.0, 15.0, 17.0, 17.0, 17.0, 15.0, 15.0, 10.0, 12.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 15.0, 17.0, 17.0, 15.0], "policy_policy1_reward": [12.0, 11.0, 12.0, 17.0, 14.0, 17.0, 17.0, 10.0, 14.0, 17.0, 14.0, 16.0, 17.0, 14.0, 16.0, 16.0, 16.0, -10.0, 17.0, 17.0, 16.0, 17.0, 15.0, 12.0, 14.0, 16.0, 17.0, 17.0, 14.0, 14.0, 15.0, 16.0, 13.0, 12.0, 16.0, 17.0, 16.0, 16.0, 15.0, 14.0, 17.0, 14.0, 13.0, 17.0, 16.0, 16.0, 17.0, 17.0, 17.0, 15.0, 14.0, 16.0, 15.0, 15.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 5.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 10.0, 16.0, 15.0, 17.0, 17.0, 17.0, 15.0, 15.0, 10.0, 12.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 15.0, 17.0, 17.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3090358645140902, "mean_inference_ms": 1.6059155591321896, "mean_action_processing_ms": 0.10570139869429865, "mean_env_wait_ms": 0.07008398224926168, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19793, "timesteps_this_iter": 32, "agent_timesteps_total": 39586, "timers": {"load_time_ms": 0.435, "load_throughput": 73507.71, "learn_time_ms": 7.677, "learn_throughput": 4168.032, "update_time_ms": 4.599}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.262767791748047, "min_q": 0.08326327800750732, "max_q": 15.729447364807129, "mean_td_error": 0.13093534111976624, "model": {}}, "td_error": [12.124531745910645, -1.1452091932296753, -0.30754804611206055, -1.2964491844177246, 0.5312614440917969, -1.0767297744750977, 1.5697822570800781, -3.8500289916992188, -0.0614008903503418, 0.2889575958251953, -0.10874128341674805, 7.176943302154541, 0.1862344741821289, -0.731532096862793, 5.030573844909668, -0.1577317714691162, -2.94014835357666, -0.35619020462036133, -0.8997020721435547, -0.30303239822387695, 0.5445461273193359, -0.16282224655151367, -0.6331043243408203, -2.795424461364746, -0.3776860237121582, -1.6189746856689453, -0.5644912719726562, -0.5587468147277832, -1.0767297744750977, -0.6985769271850586, -0.8433194160461426, -0.6985797882080078], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 2.560438394546509, "min_q": -4.641538143157959, "max_q": 12.16688346862793, "mean_td_error": -0.7971627712249756, "model": {}}, "td_error": [-0.9852063655853271, 1.678200602531433, -6.864818096160889, -1.7841322422027588, -6.94249963760376, -1.5238113403320312, 3.5401790142059326, -2.127696990966797, 0.9586338996887207, -0.6464502811431885, 0.24788933992385864, -4.015048980712891, 2.170675277709961, 2.0284156799316406, 1.233414649963379, 2.8248562812805176, -1.3194751739501953, 1.4644920825958252, 0.3946564197540283, 0.1849040985107422, -0.5139141082763672, 0.409304141998291, 3.070551872253418, 0.7812948226928711, 0.8302723169326782, -7.700305461883545, -0.6217994689941406, -2.386885166168213, -2.999873161315918, -5.835753917694092, 0.7595438957214355, -1.8188238143920898], "custom_metrics": {}}}, "num_steps_sampled": 19793, "num_agent_steps_sampled": 39586, "num_steps_trained": 47552, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 95104, "last_target_update_ts": 19738, "num_target_updates": 172}, "done": false, "episodes_total": 1621, "training_iteration": 68, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-04", "timestamp": 1648811584, "time_this_iter_s": 1.3973803520202637, "time_total_s": 86.9474675655365, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 86.9474675655365, "timesteps_since_restore": 2176, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 32.2, "ram_util_percent": 51.55}}
{"episode_reward_max": 34.0, "episode_reward_min": 10.0, "episode_reward_mean": 30.78, "episode_len_mean": 4.61, "episode_media": {}, "episodes_this_iter": 41, "policy_reward_min": {"policy0": 5.0, "policy1": 5.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 15.39, "policy1": 15.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 26.0, 34.0, 32.0, 32.0, 34.0, 34.0, 34.0, 30.0, 28.0, 32.0, 30.0, 30.0, 34.0, 34.0, 34.0, 32.0, 28.0, 34.0, 34.0, 34.0, 32.0, 28.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 10.0, 34.0, 34.0, 34.0, 34.0, 24.0, 34.0, 20.0, 32.0, 30.0, 34.0, 34.0, 34.0, 30.0, 30.0, 20.0, 24.0, 34.0, 32.0, 34.0, 30.0, 34.0, 34.0, 30.0, 34.0, 34.0, 30.0, 30.0, 32.0, 32.0, 28.0, 34.0, 28.0, 34.0, 28.0, 34.0, 24.0, 26.0, 34.0, 32.0, 34.0, 16.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 32.0, 26.0, 34.0, 30.0, 24.0, 30.0, 24.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0], "episode_lengths": [6, 7, 3, 4, 4, 3, 3, 3, 5, 6, 4, 5, 5, 3, 3, 3, 4, 6, 3, 3, 3, 4, 6, 3, 3, 6, 3, 3, 3, 5, 3, 3, 15, 3, 3, 3, 3, 8, 3, 10, 4, 5, 3, 3, 3, 5, 5, 10, 8, 3, 4, 3, 5, 3, 3, 5, 3, 3, 5, 5, 4, 4, 6, 3, 6, 3, 6, 3, 8, 7, 3, 4, 3, 12, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 4, 7, 3, 5, 8, 5, 8, 6, 6, 8, 6, 6, 6, 6, 6], "policy_policy0_reward": [14.0, 13.0, 17.0, 16.0, 16.0, 17.0, 17.0, 17.0, 15.0, 14.0, 16.0, 15.0, 15.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 5.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 10.0, 16.0, 15.0, 17.0, 17.0, 17.0, 15.0, 15.0, 10.0, 12.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 15.0, 17.0, 17.0, 15.0, 15.0, 16.0, 16.0, 14.0, 17.0, 14.0, 17.0, 14.0, 17.0, 12.0, 13.0, 17.0, 16.0, 17.0, 8.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 16.0, 13.0, 17.0, 15.0, 12.0, 15.0, 12.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0], "policy_policy1_reward": [14.0, 13.0, 17.0, 16.0, 16.0, 17.0, 17.0, 17.0, 15.0, 14.0, 16.0, 15.0, 15.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 5.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 10.0, 16.0, 15.0, 17.0, 17.0, 17.0, 15.0, 15.0, 10.0, 12.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 15.0, 17.0, 17.0, 15.0, 15.0, 16.0, 16.0, 14.0, 17.0, 14.0, 17.0, 14.0, 17.0, 12.0, 13.0, 17.0, 16.0, 17.0, 8.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 16.0, 13.0, 17.0, 15.0, 12.0, 15.0, 12.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31022791968542274, "mean_inference_ms": 1.6074164915592206, "mean_action_processing_ms": 0.10581892845796352, "mean_env_wait_ms": 0.07015497317461185, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19995, "timesteps_this_iter": 32, "agent_timesteps_total": 39990, "timers": {"load_time_ms": 0.475, "load_throughput": 67358.089, "learn_time_ms": 8.217, "learn_throughput": 3894.218, "update_time_ms": 4.904}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.476887702941895, "min_q": 0.35790711641311646, "max_q": 14.688674926757812, "mean_td_error": -0.12881313264369965, "model": {}}, "td_error": [-0.35702985525131226, -0.2395305633544922, -1.827132225036621, 0.1931591033935547, -0.20899581909179688, 0.18173980712890625, -0.3417854309082031, -0.5731334686279297, -0.009480476379394531, 0.39090490341186523, -0.6871747970581055, -0.0416107177734375, -0.7753777503967285, 0.2448277473449707, -0.19082927703857422, -1.0135173797607422, 7.1646575927734375, 0.0156707763671875, -0.4637784957885742, -2.9780759811401367, -0.1312570571899414, 0.3501768112182617, 0.18802762031555176, 0.5277537107467651, -0.6600770950317383, -0.0567169189453125, -1.302382469177246, -1.0476064682006836, 0.01909637451171875, -0.9867620468139648, 0.09306716918945312, 0.4011526107788086], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.662408828735352, "min_q": -0.7577354311943054, "max_q": 11.105071067810059, "mean_td_error": 0.7244890928268433, "model": {}}, "td_error": [3.090876579284668, -5.898165702819824, 4.6309967041015625, -5.898617744445801, 4.000465393066406, 2.859415054321289, -3.8743104934692383, 4.418239593505859, 3.848227024078369, 1.77951979637146, 0.08532661199569702, -1.4830305576324463, 6.251387119293213, 1.701873779296875, 2.1260435581207275, -0.4612569808959961, -1.7352790832519531, 3.941408634185791, 0.5694856643676758, 0.25675392150878906, -4.289999485015869, 3.295257568359375, -2.4870080947875977, -1.9968504905700684, -0.08514595031738281, -4.1805267333984375, 8.30717945098877, 4.546582221984863, 3.3076283931732178, 6.7782440185546875, -9.757735252380371, -0.463334321975708], "custom_metrics": {}}}, "num_steps_sampled": 19995, "num_agent_steps_sampled": 39990, "num_steps_trained": 48512, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 97024, "last_target_update_ts": 19945, "num_target_updates": 174}, "done": false, "episodes_total": 1662, "training_iteration": 69, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-05", "timestamp": 1648811585, "time_this_iter_s": 1.3529305458068848, "time_total_s": 88.30039811134338, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cdd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cdd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 88.30039811134338, "timesteps_since_restore": 2208, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 28.85, "ram_util_percent": 51.6}}
{"episode_reward_max": 34.0, "episode_reward_min": 12.0, "episode_reward_mean": 29.52, "episode_len_mean": 5.24, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 6.0, "policy1": 6.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 14.76, "policy1": 14.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 24.0, 34.0, 20.0, 32.0, 30.0, 34.0, 34.0, 34.0, 30.0, 30.0, 20.0, 24.0, 34.0, 32.0, 34.0, 30.0, 34.0, 34.0, 30.0, 34.0, 34.0, 30.0, 30.0, 32.0, 32.0, 28.0, 34.0, 28.0, 34.0, 28.0, 34.0, 24.0, 26.0, 34.0, 32.0, 34.0, 16.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 32.0, 26.0, 34.0, 30.0, 24.0, 30.0, 24.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 30.0, 28.0, 20.0, 24.0, 28.0, 28.0, 28.0, 24.0, 34.0, 34.0, 34.0, 12.0, 34.0, 34.0, 30.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0, 24.0, 24.0, 30.0, 16.0, 24.0, 30.0, 30.0, 34.0, 30.0, 22.0, 34.0, 30.0], "episode_lengths": [3, 3, 3, 8, 3, 10, 4, 5, 3, 3, 3, 5, 5, 10, 8, 3, 4, 3, 5, 3, 3, 5, 3, 3, 5, 5, 4, 4, 6, 3, 6, 3, 6, 3, 8, 7, 3, 4, 3, 12, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 4, 7, 3, 5, 8, 5, 8, 6, 6, 8, 6, 6, 6, 6, 6, 6, 5, 6, 10, 8, 6, 6, 6, 8, 3, 3, 3, 14, 3, 3, 5, 8, 6, 6, 6, 6, 6, 8, 8, 5, 12, 8, 5, 5, 3, 5, 9, 3, 5], "policy_policy0_reward": [17.0, 17.0, 17.0, 12.0, 17.0, 10.0, 16.0, 15.0, 17.0, 17.0, 17.0, 15.0, 15.0, 10.0, 12.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 15.0, 17.0, 17.0, 15.0, 15.0, 16.0, 16.0, 14.0, 17.0, 14.0, 17.0, 14.0, 17.0, 12.0, 13.0, 17.0, 16.0, 17.0, 8.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 16.0, 13.0, 17.0, 15.0, 12.0, 15.0, 12.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 14.0, 10.0, 12.0, 14.0, 14.0, 14.0, 12.0, 17.0, 17.0, 17.0, 6.0, 17.0, 17.0, 15.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 15.0, 8.0, 12.0, 15.0, 15.0, 17.0, 15.0, 11.0, 17.0, 15.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 12.0, 17.0, 10.0, 16.0, 15.0, 17.0, 17.0, 17.0, 15.0, 15.0, 10.0, 12.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 15.0, 17.0, 17.0, 15.0, 15.0, 16.0, 16.0, 14.0, 17.0, 14.0, 17.0, 14.0, 17.0, 12.0, 13.0, 17.0, 16.0, 17.0, 8.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 16.0, 13.0, 17.0, 15.0, 12.0, 15.0, 12.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 14.0, 10.0, 12.0, 14.0, 14.0, 14.0, 12.0, 17.0, 17.0, 17.0, 6.0, 17.0, 17.0, 15.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 15.0, 8.0, 12.0, 15.0, 15.0, 17.0, 15.0, 11.0, 17.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3110765610566885, "mean_inference_ms": 1.6086142237996517, "mean_action_processing_ms": 0.10591998769382563, "mean_env_wait_ms": 0.07022296796199161, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20204, "timesteps_this_iter": 32, "agent_timesteps_total": 40408, "timers": {"load_time_ms": 0.441, "load_throughput": 72585.435, "learn_time_ms": 8.026, "learn_throughput": 3987.135, "update_time_ms": 5.019}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.835210800170898, "min_q": 1.4538906812667847, "max_q": 16.447742462158203, "mean_td_error": 0.36630475521087646, "model": {}}, "td_error": [0.39189577102661133, -0.2056121826171875, 0.25525569915771484, 0.15714263916015625, 0.7758417129516602, -1.252023696899414, 0.0024394989013671875, -0.6430091857910156, -0.2124767303466797, -0.4377899169921875, 0.11780929565429688, -0.25320911407470703, 1.3585538864135742, 4.930269718170166, 0.4046158790588379, 1.335352897644043, 1.1954690217971802, 0.5856361389160156, 0.04886579513549805, 1.9033315181732178, 0.3567934036254883, -0.7823400497436523, 0.04593658447265625, 2.352637529373169, 0.5853142738342285, 0.3971834182739258, -0.038739681243896484, -1.1515116691589355, 0.10651016235351562, 0.26036834716796875, -0.6673851013183594, -0.20137405395507812], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.871673107147217, "min_q": -3.6450295448303223, "max_q": 8.921527862548828, "mean_td_error": 0.03666354715824127, "model": {}}, "td_error": [-1.8459515571594238, -0.6980404853820801, 3.637944221496582, 2.39996600151062, -0.16794109344482422, -1.6429202556610107, -0.09728527069091797, -0.04179859161376953, 2.3215575218200684, 0.649592399597168, 1.5139780044555664, 2.3638405799865723, -6.457941055297852, -5.288530349731445, -1.0872416496276855, 0.8814067840576172, -0.44091570377349854, 0.40541017055511475, -2.1555848121643066, 0.5599377155303955, 0.10097503662109375, -0.09728527069091797, 0.5799260139465332, 1.356006145477295, 3.3423593044281006, 1.599403977394104, 6.798655033111572, -10.19432544708252, 4.817028045654297, 1.1704552173614502, -7.6663818359375, 4.556935787200928], "custom_metrics": {}}}, "num_steps_sampled": 20204, "num_agent_steps_sampled": 40408, "num_steps_trained": 49440, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 98880, "last_target_update_ts": 20149, "num_target_updates": 176}, "done": false, "episodes_total": 1696, "training_iteration": 70, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-07", "timestamp": 1648811587, "time_this_iter_s": 1.3529770374298096, "time_total_s": 89.6533751487732, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c4cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 89.6533751487732, "timesteps_since_restore": 2240, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 29.85, "ram_util_percent": 51.650000000000006}}
{"episode_reward_max": 34.0, "episode_reward_min": 12.0, "episode_reward_mean": 27.94, "episode_len_mean": 6.03, "episode_media": {}, "episodes_this_iter": 29, "policy_reward_min": {"policy0": 6.0, "policy1": 6.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 13.97, "policy1": 13.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 28.0, 34.0, 28.0, 34.0, 24.0, 26.0, 34.0, 32.0, 34.0, 16.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 32.0, 26.0, 34.0, 30.0, 24.0, 30.0, 24.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 30.0, 28.0, 20.0, 24.0, 28.0, 28.0, 28.0, 24.0, 34.0, 34.0, 34.0, 12.0, 34.0, 34.0, 30.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0, 24.0, 24.0, 30.0, 16.0, 24.0, 30.0, 30.0, 34.0, 30.0, 22.0, 34.0, 30.0, 20.0, 32.0, 18.0, 24.0, 32.0, 24.0, 22.0, 32.0, 24.0, 30.0, 28.0, 22.0, 28.0, 16.0, 28.0, 28.0, 22.0, 24.0, 32.0, 24.0, 16.0, 34.0, 22.0, 34.0, 26.0, 24.0, 28.0, 24.0, 20.0], "episode_lengths": [3, 6, 3, 6, 3, 8, 7, 3, 4, 3, 12, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 4, 7, 3, 5, 8, 5, 8, 6, 6, 8, 6, 6, 6, 6, 6, 6, 5, 6, 10, 8, 6, 6, 6, 8, 3, 3, 3, 14, 3, 3, 5, 8, 6, 6, 6, 6, 6, 8, 8, 5, 12, 8, 5, 5, 3, 5, 9, 3, 5, 10, 4, 11, 8, 4, 8, 9, 4, 8, 5, 6, 9, 6, 12, 6, 6, 9, 8, 4, 8, 12, 3, 9, 3, 7, 8, 6, 8, 10], "policy_policy0_reward": [17.0, 14.0, 17.0, 14.0, 17.0, 12.0, 13.0, 17.0, 16.0, 17.0, 8.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 16.0, 13.0, 17.0, 15.0, 12.0, 15.0, 12.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 14.0, 10.0, 12.0, 14.0, 14.0, 14.0, 12.0, 17.0, 17.0, 17.0, 6.0, 17.0, 17.0, 15.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 15.0, 8.0, 12.0, 15.0, 15.0, 17.0, 15.0, 11.0, 17.0, 15.0, 10.0, 16.0, 9.0, 12.0, 16.0, 12.0, 11.0, 16.0, 12.0, 15.0, 14.0, 11.0, 14.0, 8.0, 14.0, 14.0, 11.0, 12.0, 16.0, 12.0, 8.0, 17.0, 11.0, 17.0, 13.0, 12.0, 14.0, 12.0, 10.0], "policy_policy1_reward": [17.0, 14.0, 17.0, 14.0, 17.0, 12.0, 13.0, 17.0, 16.0, 17.0, 8.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 16.0, 13.0, 17.0, 15.0, 12.0, 15.0, 12.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 14.0, 10.0, 12.0, 14.0, 14.0, 14.0, 12.0, 17.0, 17.0, 17.0, 6.0, 17.0, 17.0, 15.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 15.0, 8.0, 12.0, 15.0, 15.0, 17.0, 15.0, 11.0, 17.0, 15.0, 10.0, 16.0, 9.0, 12.0, 16.0, 12.0, 11.0, 16.0, 12.0, 15.0, 14.0, 11.0, 14.0, 8.0, 14.0, 14.0, 11.0, 12.0, 16.0, 12.0, 8.0, 17.0, 11.0, 17.0, 13.0, 12.0, 14.0, 12.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3118131970939276, "mean_inference_ms": 1.6098911689025937, "mean_action_processing_ms": 0.10606117785578223, "mean_env_wait_ms": 0.07030258590025724, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20415, "timesteps_this_iter": 32, "agent_timesteps_total": 40830, "timers": {"load_time_ms": 0.46, "load_throughput": 69557.28, "learn_time_ms": 8.014, "learn_throughput": 3992.935, "update_time_ms": 5.447}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.947872638702393, "min_q": -0.338188111782074, "max_q": 15.439508438110352, "mean_td_error": 0.10491228848695755, "model": {}}, "td_error": [-0.5089826583862305, -0.5816688537597656, -0.0679931640625, 0.05449104309082031, -0.5614986419677734, -0.2887706756591797, -1.03509521484375, -0.6424789428710938, 0.04021286964416504, 0.04011821746826172, -0.707331657409668, 0.5178866386413574, 1.2994623184204102, -0.9095849990844727, -0.009015321731567383, 1.2840609550476074, 0.27066612243652344, 0.6737060546875, 1.3358614444732666, -0.49512767791748047, 0.38880300521850586, 1.0676383972167969, 0.47278690338134766, -2.086620330810547, 0.18179750442504883, 0.661811888217926, 4.992288589477539, 0.961369514465332, -2.559103488922119, -0.2565007209777832, -0.0987081527709961, -0.07728767395019531], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.381767749786377, "min_q": -3.2642977237701416, "max_q": 15.52804183959961, "mean_td_error": 0.8126038312911987, "model": {}}, "td_error": [-3.2748053073883057, 2.014803409576416, -4.2399821281433105, -2.8458175659179688, -0.39669036865234375, 0.06050682067871094, 0.24859929084777832, -1.8089609146118164, 5.689053535461426, 4.223875045776367, -1.2481870651245117, 5.209537029266357, 2.655498504638672, 1.0474739074707031, -1.1298532485961914, -2.0757036209106445, 1.7503528594970703, 6.083371162414551, -0.02546405792236328, 0.11208152770996094, 1.4922809600830078, -2.2642977237701416, 3.4035935401916504, 3.6697511672973633, 4.6581573486328125, -2.9891176223754883, -0.44025516510009766, -6.477663040161133, 1.3242878913879395, 5.053379058837891, 0.9345083236694336, 5.589008808135986], "custom_metrics": {}}}, "num_steps_sampled": 20415, "num_agent_steps_sampled": 40830, "num_steps_trained": 50304, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 100608, "last_target_update_ts": 20361, "num_target_updates": 178}, "done": false, "episodes_total": 1725, "training_iteration": 71, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-08", "timestamp": 1648811588, "time_this_iter_s": 1.320296287536621, "time_total_s": 90.97367143630981, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83efc20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83efc20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 90.97367143630981, "timesteps_since_restore": 2272, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 30.45, "ram_util_percent": 51.7}}
{"episode_reward_max": 34.0, "episode_reward_min": 12.0, "episode_reward_mean": 27.66, "episode_len_mean": 6.17, "episode_media": {}, "episodes_this_iter": 39, "policy_reward_min": {"policy0": 6.0, "policy1": 6.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 13.83, "policy1": 13.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 20.0, 24.0, 28.0, 28.0, 28.0, 24.0, 34.0, 34.0, 34.0, 12.0, 34.0, 34.0, 30.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0, 24.0, 24.0, 30.0, 16.0, 24.0, 30.0, 30.0, 34.0, 30.0, 22.0, 34.0, 30.0, 20.0, 32.0, 18.0, 24.0, 32.0, 24.0, 22.0, 32.0, 24.0, 30.0, 28.0, 22.0, 28.0, 16.0, 28.0, 28.0, 22.0, 24.0, 32.0, 24.0, 16.0, 34.0, 22.0, 34.0, 26.0, 24.0, 28.0, 24.0, 20.0, 30.0, 24.0, 34.0, 20.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 30.0, 30.0, 28.0, 32.0, 34.0, 28.0, 32.0, 16.0, 30.0, 32.0, 32.0, 28.0, 24.0, 34.0, 28.0, 30.0, 32.0, 32.0, 28.0, 32.0, 32.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [6, 10, 8, 6, 6, 6, 8, 3, 3, 3, 14, 3, 3, 5, 8, 6, 6, 6, 6, 6, 8, 8, 5, 12, 8, 5, 5, 3, 5, 9, 3, 5, 10, 4, 11, 8, 4, 8, 9, 4, 8, 5, 6, 9, 6, 12, 6, 6, 9, 8, 4, 8, 12, 3, 9, 3, 7, 8, 6, 8, 10, 5, 8, 3, 10, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 4, 3, 6, 4, 12, 5, 4, 4, 6, 8, 3, 6, 5, 4, 4, 6, 4, 4, 3, 3, 3, 3], "policy_policy0_reward": [14.0, 10.0, 12.0, 14.0, 14.0, 14.0, 12.0, 17.0, 17.0, 17.0, 6.0, 17.0, 17.0, 15.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 15.0, 8.0, 12.0, 15.0, 15.0, 17.0, 15.0, 11.0, 17.0, 15.0, 10.0, 16.0, 9.0, 12.0, 16.0, 12.0, 11.0, 16.0, 12.0, 15.0, 14.0, 11.0, 14.0, 8.0, 14.0, 14.0, 11.0, 12.0, 16.0, 12.0, 8.0, 17.0, 11.0, 17.0, 13.0, 12.0, 14.0, 12.0, 10.0, 15.0, 12.0, 17.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 14.0, 16.0, 17.0, 14.0, 16.0, 8.0, 15.0, 16.0, 16.0, 14.0, 12.0, 17.0, 14.0, 15.0, 16.0, 16.0, 14.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [14.0, 10.0, 12.0, 14.0, 14.0, 14.0, 12.0, 17.0, 17.0, 17.0, 6.0, 17.0, 17.0, 15.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 15.0, 8.0, 12.0, 15.0, 15.0, 17.0, 15.0, 11.0, 17.0, 15.0, 10.0, 16.0, 9.0, 12.0, 16.0, 12.0, 11.0, 16.0, 12.0, 15.0, 14.0, 11.0, 14.0, 8.0, 14.0, 14.0, 11.0, 12.0, 16.0, 12.0, 8.0, 17.0, 11.0, 17.0, 13.0, 12.0, 14.0, 12.0, 10.0, 15.0, 12.0, 17.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 14.0, 16.0, 17.0, 14.0, 16.0, 8.0, 15.0, 16.0, 16.0, 14.0, 12.0, 17.0, 14.0, 15.0, 16.0, 16.0, 14.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3128001118405171, "mean_inference_ms": 1.6117727129794879, "mean_action_processing_ms": 0.10627150293667474, "mean_env_wait_ms": 0.0704246368047442, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20623, "timesteps_this_iter": 32, "agent_timesteps_total": 41246, "timers": {"load_time_ms": 0.436, "load_throughput": 73330.999, "learn_time_ms": 7.731, "learn_throughput": 4139.367, "update_time_ms": 5.096}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.680543899536133, "min_q": 0.9329595565795898, "max_q": 15.053099632263184, "mean_td_error": -0.38952094316482544, "model": {}}, "td_error": [-0.9950294494628906, 0.8134307861328125, -1.6627788543701172, -2.704890251159668, 0.9831571578979492, -1.3374052047729492, -0.7214250564575195, 0.2575645446777344, 1.3816585540771484, 0.45206165313720703, 0.21668720245361328, 0.5905747413635254, -2.02071475982666, -0.15984773635864258, -1.996908187866211, -2.369533061981201, -0.1663517951965332, -1.1163411140441895, -0.47478199005126953, 0.20377039909362793, -1.3887052536010742, -1.0207839012145996, 0.19977855682373047, 0.08094310760498047, 0.21668720245361328, 0.5840463638305664, 1.8264970779418945, 0.23713111877441406, -0.014070510864257812, -1.1103367805480957, 0.09837722778320312, -1.347132682800293], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.2841973304748535, "min_q": -2.9582290649414062, "max_q": 17.484375, "mean_td_error": 0.4499543011188507, "model": {}}, "td_error": [-2.0946359634399414, 0.27030104398727417, -1.9950635433197021, 2.455322265625, 4.753739833831787, 1.7086000442504883, -1.0515542030334473, 1.533437967300415, 2.6175918579101562, -0.506210446357727, 1.962998390197754, -1.2065844535827637, -3.8510007858276367, -3.040576219558716, -2.3289778232574463, -2.6964259147644043, 10.192612648010254, 6.500936508178711, -7.3748602867126465, -2.0946359634399414, 0.20297199487686157, 6.934296131134033, 0.3775300979614258, -0.862645149230957, 1.5520548820495605, 0.5456584692001343, 1.816612958908081, 6.824821472167969, 1.596616506576538, 6.81456995010376, -3.0159990787506104, -12.142966270446777], "custom_metrics": {}}}, "num_steps_sampled": 20623, "num_agent_steps_sampled": 41246, "num_steps_trained": 51392, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 102784, "last_target_update_ts": 20575, "num_target_updates": 180}, "done": false, "episodes_total": 1764, "training_iteration": 72, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-10", "timestamp": 1648811590, "time_this_iter_s": 1.4911880493164062, "time_total_s": 92.46485948562622, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d15f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d15f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 92.46485948562622, "timesteps_since_restore": 2304, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 30.2, "ram_util_percent": 51.7}}
{"episode_reward_max": 34.0, "episode_reward_min": 12.0, "episode_reward_mean": 27.58, "episode_len_mean": 6.21, "episode_media": {}, "episodes_this_iter": 32, "policy_reward_min": {"policy0": 6.0, "policy1": 6.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 13.79, "policy1": 13.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 32.0, 18.0, 24.0, 32.0, 24.0, 22.0, 32.0, 24.0, 30.0, 28.0, 22.0, 28.0, 16.0, 28.0, 28.0, 22.0, 24.0, 32.0, 24.0, 16.0, 34.0, 22.0, 34.0, 26.0, 24.0, 28.0, 24.0, 20.0, 30.0, 24.0, 34.0, 20.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 30.0, 30.0, 28.0, 32.0, 34.0, 28.0, 32.0, 16.0, 30.0, 32.0, 32.0, 28.0, 24.0, 34.0, 28.0, 30.0, 32.0, 32.0, 28.0, 32.0, 32.0, 34.0, 34.0, 34.0, 34.0, 30.0, 24.0, 24.0, 32.0, 28.0, 24.0, 12.0, 28.0, 28.0, 24.0, 24.0, 28.0, 28.0, 24.0, 24.0, 20.0, 24.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 28.0, 28.0, 24.0, 28.0, 28.0, 34.0, 28.0, 24.0, 28.0], "episode_lengths": [10, 4, 11, 8, 4, 8, 9, 4, 8, 5, 6, 9, 6, 12, 6, 6, 9, 8, 4, 8, 12, 3, 9, 3, 7, 8, 6, 8, 10, 5, 8, 3, 10, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 4, 3, 6, 4, 12, 5, 4, 4, 6, 8, 3, 6, 5, 4, 4, 6, 4, 4, 3, 3, 3, 3, 5, 8, 8, 4, 6, 8, 14, 6, 6, 8, 8, 6, 6, 8, 8, 10, 8, 3, 3, 3, 3, 3, 5, 6, 6, 8, 6, 6, 3, 6, 8, 6], "policy_policy0_reward": [10.0, 16.0, 9.0, 12.0, 16.0, 12.0, 11.0, 16.0, 12.0, 15.0, 14.0, 11.0, 14.0, 8.0, 14.0, 14.0, 11.0, 12.0, 16.0, 12.0, 8.0, 17.0, 11.0, 17.0, 13.0, 12.0, 14.0, 12.0, 10.0, 15.0, 12.0, 17.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 14.0, 16.0, 17.0, 14.0, 16.0, 8.0, 15.0, 16.0, 16.0, 14.0, 12.0, 17.0, 14.0, 15.0, 16.0, 16.0, 14.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 15.0, 12.0, 12.0, 16.0, 14.0, 12.0, 6.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 12.0, 10.0, 12.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 14.0, 12.0, 14.0, 14.0, 17.0, 14.0, 12.0, 14.0], "policy_policy1_reward": [10.0, 16.0, 9.0, 12.0, 16.0, 12.0, 11.0, 16.0, 12.0, 15.0, 14.0, 11.0, 14.0, 8.0, 14.0, 14.0, 11.0, 12.0, 16.0, 12.0, 8.0, 17.0, 11.0, 17.0, 13.0, 12.0, 14.0, 12.0, 10.0, 15.0, 12.0, 17.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 14.0, 16.0, 17.0, 14.0, 16.0, 8.0, 15.0, 16.0, 16.0, 14.0, 12.0, 17.0, 14.0, 15.0, 16.0, 16.0, 14.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 15.0, 12.0, 12.0, 16.0, 14.0, 12.0, 6.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 12.0, 10.0, 12.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 14.0, 12.0, 14.0, 14.0, 17.0, 14.0, 12.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31358121259609406, "mean_inference_ms": 1.6130863858888767, "mean_action_processing_ms": 0.10642599008504273, "mean_env_wait_ms": 0.07051387820366627, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20825, "timesteps_this_iter": 32, "agent_timesteps_total": 41650, "timers": {"load_time_ms": 0.501, "load_throughput": 63809.893, "learn_time_ms": 8.108, "learn_throughput": 3946.791, "update_time_ms": 4.992}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.358534336090088, "min_q": -0.22826313972473145, "max_q": 15.674467086791992, "mean_td_error": -0.16151192784309387, "model": {}}, "td_error": [0.5207157135009766, -0.6218056678771973, -0.059123992919921875, -0.6528725624084473, -0.496030330657959, 0.5083231925964355, -0.7530879974365234, -0.7218475341796875, -2.0820131301879883, 1.3541221618652344, -0.0627431869506836, 0.8613967895507812, -0.9298772811889648, 0.7157981395721436, -0.17180109024047852, -0.29992008209228516, -0.9791240692138672, 2.4161624908447266, -0.8847670555114746, -1.4363269805908203, -0.22550392150878906, -0.49411678314208984, -0.07047224044799805, 0.14209938049316406, 1.349700927734375, -0.28108787536621094, -0.18979167938232422, -0.8540127277374268, 1.1143484115600586, -1.0575008392333984, -1.6381263732910156, 0.810904860496521], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.8402366638183594, "min_q": -1.5705492496490479, "max_q": 13.143468856811523, "mean_td_error": 0.902080774307251, "model": {}}, "td_error": [1.1674423217773438, -0.9943351745605469, -9.095398902893066, -1.4188629388809204, -0.5922746658325195, 1.3063266277313232, 3.1247572898864746, 2.0072154998779297, 0.24323558807373047, 1.5286779403686523, 1.016557216644287, 0.0537685751914978, 6.973562717437744, 1.325360655784607, 2.46591854095459, 1.083939790725708, 6.378136157989502, 2.799912214279175, 0.14496922492980957, 0.08333969116210938, 1.575514793395996, 0.9812994599342346, 0.9231832027435303, 0.1649717092514038, 0.3391064405441284, 3.1677637100219727, 2.221457004547119, 0.5166401863098145, -1.6591724157333374, 0.6086856722831726, -0.21504351496696472, 0.6399314403533936], "custom_metrics": {}}}, "num_steps_sampled": 20825, "num_agent_steps_sampled": 41650, "num_steps_trained": 52288, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 104576, "last_target_update_ts": 20782, "num_target_updates": 182}, "done": false, "episodes_total": 1796, "training_iteration": 73, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-11", "timestamp": 1648811591, "time_this_iter_s": 1.273188591003418, "time_total_s": 93.73804807662964, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 93.73804807662964, "timesteps_since_restore": 2336, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 30.9, "ram_util_percent": 51.75}}
{"episode_reward_max": 34.0, "episode_reward_min": 6.0, "episode_reward_mean": 28.04, "episode_len_mean": 5.98, "episode_media": {}, "episodes_this_iter": 32, "policy_reward_min": {"policy0": 3.0, "policy1": 3.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 14.02, "policy1": 14.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 30.0, 30.0, 28.0, 32.0, 34.0, 28.0, 32.0, 16.0, 30.0, 32.0, 32.0, 28.0, 24.0, 34.0, 28.0, 30.0, 32.0, 32.0, 28.0, 32.0, 32.0, 34.0, 34.0, 34.0, 34.0, 30.0, 24.0, 24.0, 32.0, 28.0, 24.0, 12.0, 28.0, 28.0, 24.0, 24.0, 28.0, 28.0, 24.0, 24.0, 20.0, 24.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 28.0, 28.0, 24.0, 28.0, 28.0, 34.0, 28.0, 24.0, 28.0, 24.0, 24.0, 28.0, 28.0, 24.0, 30.0, 24.0, 34.0, 22.0, 32.0, 16.0, 30.0, 22.0, 18.0, 34.0, 30.0, 30.0, 28.0, 30.0, 30.0, 30.0, 30.0, 34.0, 26.0, 34.0, 26.0, 6.0, 34.0, 30.0, 26.0, 34.0, 24.0], "episode_lengths": [10, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 4, 3, 6, 4, 12, 5, 4, 4, 6, 8, 3, 6, 5, 4, 4, 6, 4, 4, 3, 3, 3, 3, 5, 8, 8, 4, 6, 8, 14, 6, 6, 8, 8, 6, 6, 8, 8, 10, 8, 3, 3, 3, 3, 3, 5, 6, 6, 8, 6, 6, 3, 6, 8, 6, 8, 8, 6, 6, 8, 5, 8, 3, 9, 4, 12, 5, 9, 11, 3, 5, 5, 6, 5, 5, 5, 5, 3, 7, 3, 7, 17, 3, 5, 7, 3, 8], "policy_policy0_reward": [10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 14.0, 16.0, 17.0, 14.0, 16.0, 8.0, 15.0, 16.0, 16.0, 14.0, 12.0, 17.0, 14.0, 15.0, 16.0, 16.0, 14.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 15.0, 12.0, 12.0, 16.0, 14.0, 12.0, 6.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 12.0, 10.0, 12.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 14.0, 12.0, 14.0, 14.0, 17.0, 14.0, 12.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 15.0, 12.0, 17.0, 11.0, 16.0, 8.0, 15.0, 11.0, 9.0, 17.0, 15.0, 15.0, 14.0, 15.0, 15.0, 15.0, 15.0, 17.0, 13.0, 17.0, 13.0, 3.0, 17.0, 15.0, 13.0, 17.0, 12.0], "policy_policy1_reward": [10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 14.0, 16.0, 17.0, 14.0, 16.0, 8.0, 15.0, 16.0, 16.0, 14.0, 12.0, 17.0, 14.0, 15.0, 16.0, 16.0, 14.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 15.0, 12.0, 12.0, 16.0, 14.0, 12.0, 6.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 12.0, 10.0, 12.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 14.0, 12.0, 14.0, 14.0, 17.0, 14.0, 12.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 15.0, 12.0, 17.0, 11.0, 16.0, 8.0, 15.0, 11.0, 9.0, 17.0, 15.0, 15.0, 14.0, 15.0, 15.0, 15.0, 15.0, 17.0, 13.0, 17.0, 13.0, 3.0, 17.0, 15.0, 13.0, 17.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3143301964331058, "mean_inference_ms": 1.61402018905317, "mean_action_processing_ms": 0.10651914583227377, "mean_env_wait_ms": 0.0705829915071555, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21029, "timesteps_this_iter": 32, "agent_timesteps_total": 42058, "timers": {"load_time_ms": 0.471, "load_throughput": 67896.463, "learn_time_ms": 7.694, "learn_throughput": 4159.236, "update_time_ms": 4.732}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.503571033477783, "min_q": -1.6695919036865234, "max_q": 15.605137825012207, "mean_td_error": -0.1668790578842163, "model": {}}, "td_error": [-0.042363643646240234, 2.4024460315704346, -2.0495529174804688, -2.300631523132324, 0.2927737236022949, 0.20853519439697266, -0.7211768627166748, 0.5228853225708008, 0.0068781375885009766, 0.16663789749145508, -0.015906810760498047, -0.6643996238708496, -0.5206918716430664, -1.0853424072265625, -2.1455984115600586, 2.0560474395751953, -2.4838714599609375, 0.3787667751312256, -0.43286705017089844, -1.1924371719360352, 0.5090117454528809, 0.07056903839111328, -0.30730271339416504, 2.7622339725494385, -1.3790504932403564, -1.8788766860961914, -2.3927364349365234, -1.5983715057373047, 7.7669453620910645, -1.163304328918457, 0.04756426811218262, -0.15694189071655273], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 2.909548282623291, "min_q": -1.7437701225280762, "max_q": 12.612784385681152, "mean_td_error": 0.2633117139339447, "model": {}}, "td_error": [0.22028225660324097, 7.307440757751465, 3.729853868484497, -0.21559596061706543, -0.13625997304916382, 1.4609034061431885, 0.48714756965637207, 1.5459508895874023, 4.123631000518799, 2.1511917114257812, -5.9415998458862305, 0.8255490064620972, -1.8398470878601074, 2.2247633934020996, 0.831043004989624, 3.188655376434326, 0.2903628349304199, 1.4490703344345093, -1.3393607139587402, 0.6370006799697876, -3.195767402648926, 0.832127571105957, 0.540334165096283, 0.1633879542350769, -0.2224695086479187, 1.2663002014160156, -1.6681013107299805, -0.10442161560058594, 3.0406882762908936, -6.110316276550293, 1.776876449584961, -8.89284610748291], "custom_metrics": {}}}, "num_steps_sampled": 21029, "num_agent_steps_sampled": 42058, "num_steps_trained": 53120, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 106240, "last_target_update_ts": 21003, "num_target_updates": 184}, "done": false, "episodes_total": 1828, "training_iteration": 74, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-12", "timestamp": 1648811592, "time_this_iter_s": 1.2094988822937012, "time_total_s": 94.94754695892334, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 94.94754695892334, "timesteps_since_restore": 2368, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 30.8, "ram_util_percent": 51.75}}
{"episode_reward_max": 34.0, "episode_reward_min": -20.0, "episode_reward_mean": 28.3, "episode_len_mean": 5.75, "episode_media": {}, "episodes_this_iter": 42, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 14.15, "policy1": 14.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, 28.0, 28.0, 24.0, 24.0, 28.0, 28.0, 24.0, 24.0, 20.0, 24.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 28.0, 28.0, 24.0, 28.0, 28.0, 34.0, 28.0, 24.0, 28.0, 24.0, 24.0, 28.0, 28.0, 24.0, 30.0, 24.0, 34.0, 22.0, 32.0, 16.0, 30.0, 22.0, 18.0, 34.0, 30.0, 30.0, 28.0, 30.0, 30.0, 30.0, 30.0, 34.0, 26.0, 34.0, 26.0, 6.0, 34.0, 30.0, 26.0, 34.0, 24.0, 30.0, 30.0, 24.0, 34.0, 34.0, 34.0, 34.0, 22.0, 32.0, 26.0, 34.0, 34.0, 34.0, 28.0, 24.0, 30.0, 24.0, -20.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 26.0, 32.0, 24.0, 34.0, 26.0, 30.0, 32.0, 30.0, 34.0, 34.0, 30.0, 28.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [14, 6, 6, 8, 8, 6, 6, 8, 8, 10, 8, 3, 3, 3, 3, 3, 5, 6, 6, 8, 6, 6, 3, 6, 8, 6, 8, 8, 6, 6, 8, 5, 8, 3, 9, 4, 12, 5, 9, 11, 3, 5, 5, 6, 5, 5, 5, 5, 3, 7, 3, 7, 17, 3, 5, 7, 3, 8, 5, 5, 8, 3, 3, 3, 3, 9, 4, 7, 3, 3, 3, 6, 8, 5, 8, 20, 6, 3, 3, 3, 3, 3, 7, 4, 8, 3, 7, 5, 4, 5, 3, 3, 5, 6, 3, 6, 3, 3, 3, 3], "policy_policy0_reward": [6.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 12.0, 10.0, 12.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 14.0, 12.0, 14.0, 14.0, 17.0, 14.0, 12.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 15.0, 12.0, 17.0, 11.0, 16.0, 8.0, 15.0, 11.0, 9.0, 17.0, 15.0, 15.0, 14.0, 15.0, 15.0, 15.0, 15.0, 17.0, 13.0, 17.0, 13.0, 3.0, 17.0, 15.0, 13.0, 17.0, 12.0, 15.0, 15.0, 12.0, 17.0, 17.0, 17.0, 17.0, 11.0, 16.0, 13.0, 17.0, 17.0, 17.0, 14.0, 12.0, 15.0, 12.0, -10.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 13.0, 16.0, 12.0, 17.0, 13.0, 15.0, 16.0, 15.0, 17.0, 17.0, 15.0, 14.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [6.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 12.0, 10.0, 12.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 14.0, 12.0, 14.0, 14.0, 17.0, 14.0, 12.0, 14.0, 12.0, 12.0, 14.0, 14.0, 12.0, 15.0, 12.0, 17.0, 11.0, 16.0, 8.0, 15.0, 11.0, 9.0, 17.0, 15.0, 15.0, 14.0, 15.0, 15.0, 15.0, 15.0, 17.0, 13.0, 17.0, 13.0, 3.0, 17.0, 15.0, 13.0, 17.0, 12.0, 15.0, 15.0, 12.0, 17.0, 17.0, 17.0, 17.0, 11.0, 16.0, 13.0, 17.0, 17.0, 17.0, 14.0, 12.0, 15.0, 12.0, -10.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 13.0, 16.0, 12.0, 17.0, 13.0, 15.0, 16.0, 15.0, 17.0, 17.0, 15.0, 14.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3154080837292871, "mean_inference_ms": 1.615429259491334, "mean_action_processing_ms": 0.10665213919515835, "mean_env_wait_ms": 0.07066873676446297, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21237, "timesteps_this_iter": 32, "agent_timesteps_total": 42474, "timers": {"load_time_ms": 0.472, "load_throughput": 67831.267, "learn_time_ms": 7.866, "learn_throughput": 4068.239, "update_time_ms": 5.038}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.312295913696289, "min_q": -0.30488771200180054, "max_q": 15.462348937988281, "mean_td_error": -0.3234519064426422, "model": {}}, "td_error": [-0.2168288230895996, 0.4463810920715332, -0.9778423309326172, 0.2245950698852539, 2.0940816402435303, -1.0858750343322754, -5.53102970123291, -1.9597446918487549, 0.05946159362792969, 1.0672252178192139, -3.0751352310180664, -0.6140785217285156, 1.2684760093688965, -2.2208101749420166, 10.726341247558594, -4.505936145782471, 0.2959229350090027, -0.4026670455932617, -0.8660035133361816, 0.31194496154785156, -1.4072661399841309, -0.5594902038574219, -1.1280403137207031, -1.4202985763549805, -1.1672277450561523, -1.502359390258789, -0.10090017318725586, 0.2278919219970703, 1.6152877807617188, -0.5331916809082031, 0.35549354553222656, 0.23116207122802734], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.871696472167969, "min_q": -1.5675872564315796, "max_q": 9.624334335327148, "mean_td_error": -0.44173941016197205, "model": {}}, "td_error": [0.8773007392883301, -2.35398006439209, -0.1859297752380371, 3.5215773582458496, -2.35398006439209, -4.587647438049316, 1.7292245626449585, 6.910491466522217, -1.3191535472869873, -1.0564974546432495, -1.1922472715377808, 0.22824633121490479, 5.159908294677734, 0.0934152603149414, -3.6779677867889404, 1.8222932815551758, -4.641506195068359, -0.11300373077392578, 0.8012781143188477, -0.11163294315338135, -5.5305633544921875, -4.516155242919922, 0.845792293548584, 0.5193226337432861, -4.6719489097595215, -0.17501068115234375, 0.8773007392883301, 1.8524856567382812, -2.35398006439209, 1.2694902420043945, -2.147426128387451, 0.34484338760375977], "custom_metrics": {}}}, "num_steps_sampled": 21237, "num_agent_steps_sampled": 42474, "num_steps_trained": 54080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 108160, "last_target_update_ts": 21210, "num_target_updates": 186}, "done": false, "episodes_total": 1870, "training_iteration": 75, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-14", "timestamp": 1648811594, "time_this_iter_s": 1.4230594635009766, "time_total_s": 96.37060642242432, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c04d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c04d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 96.37060642242432, "timesteps_since_restore": 2400, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 28.65, "ram_util_percent": 51.8}}
{"episode_reward_max": 34.0, "episode_reward_min": -20.0, "episode_reward_mean": 28.46, "episode_len_mean": 5.67, "episode_media": {}, "episodes_this_iter": 33, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 14.23, "policy1": 14.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 22.0, 32.0, 16.0, 30.0, 22.0, 18.0, 34.0, 30.0, 30.0, 28.0, 30.0, 30.0, 30.0, 30.0, 34.0, 26.0, 34.0, 26.0, 6.0, 34.0, 30.0, 26.0, 34.0, 24.0, 30.0, 30.0, 24.0, 34.0, 34.0, 34.0, 34.0, 22.0, 32.0, 26.0, 34.0, 34.0, 34.0, 28.0, 24.0, 30.0, 24.0, -20.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 26.0, 32.0, 24.0, 34.0, 26.0, 30.0, 32.0, 30.0, 34.0, 34.0, 30.0, 28.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 30.0, 34.0, 34.0, 28.0, 24.0, 28.0, 34.0, 28.0, 28.0, 20.0, 34.0, 28.0, 34.0, 28.0, 24.0, 28.0, 28.0, 34.0, 24.0, 28.0, 20.0, 30.0, 28.0, 28.0, 28.0, 24.0, 28.0, 16.0, 28.0, 20.0, 20.0], "episode_lengths": [3, 9, 4, 12, 5, 9, 11, 3, 5, 5, 6, 5, 5, 5, 5, 3, 7, 3, 7, 17, 3, 5, 7, 3, 8, 5, 5, 8, 3, 3, 3, 3, 9, 4, 7, 3, 3, 3, 6, 8, 5, 8, 20, 6, 3, 3, 3, 3, 3, 7, 4, 8, 3, 7, 5, 4, 5, 3, 3, 5, 6, 3, 6, 3, 3, 3, 3, 3, 5, 5, 3, 3, 6, 8, 6, 3, 6, 6, 10, 3, 6, 3, 6, 8, 6, 6, 3, 8, 6, 10, 5, 6, 6, 6, 8, 6, 12, 6, 10, 10], "policy_policy0_reward": [17.0, 11.0, 16.0, 8.0, 15.0, 11.0, 9.0, 17.0, 15.0, 15.0, 14.0, 15.0, 15.0, 15.0, 15.0, 17.0, 13.0, 17.0, 13.0, 3.0, 17.0, 15.0, 13.0, 17.0, 12.0, 15.0, 15.0, 12.0, 17.0, 17.0, 17.0, 17.0, 11.0, 16.0, 13.0, 17.0, 17.0, 17.0, 14.0, 12.0, 15.0, 12.0, -10.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 13.0, 16.0, 12.0, 17.0, 13.0, 15.0, 16.0, 15.0, 17.0, 17.0, 15.0, 14.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 15.0, 17.0, 17.0, 14.0, 12.0, 14.0, 17.0, 14.0, 14.0, 10.0, 17.0, 14.0, 17.0, 14.0, 12.0, 14.0, 14.0, 17.0, 12.0, 14.0, 10.0, 15.0, 14.0, 14.0, 14.0, 12.0, 14.0, 8.0, 14.0, 10.0, 10.0], "policy_policy1_reward": [17.0, 11.0, 16.0, 8.0, 15.0, 11.0, 9.0, 17.0, 15.0, 15.0, 14.0, 15.0, 15.0, 15.0, 15.0, 17.0, 13.0, 17.0, 13.0, 3.0, 17.0, 15.0, 13.0, 17.0, 12.0, 15.0, 15.0, 12.0, 17.0, 17.0, 17.0, 17.0, 11.0, 16.0, 13.0, 17.0, 17.0, 17.0, 14.0, 12.0, 15.0, 12.0, -10.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 13.0, 16.0, 12.0, 17.0, 13.0, 15.0, 16.0, 15.0, 17.0, 17.0, 15.0, 14.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 15.0, 17.0, 17.0, 14.0, 12.0, 14.0, 17.0, 14.0, 14.0, 10.0, 17.0, 14.0, 17.0, 14.0, 12.0, 14.0, 14.0, 17.0, 12.0, 14.0, 10.0, 15.0, 14.0, 14.0, 14.0, 12.0, 14.0, 8.0, 14.0, 10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3162254639392451, "mean_inference_ms": 1.6166696868414057, "mean_action_processing_ms": 0.1067636301524303, "mean_env_wait_ms": 0.07073572521359471, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21441, "timesteps_this_iter": 32, "agent_timesteps_total": 42882, "timers": {"load_time_ms": 0.477, "load_throughput": 67142.435, "learn_time_ms": 7.977, "learn_throughput": 4011.565, "update_time_ms": 4.956}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.325174331665039, "min_q": -1.1182719469070435, "max_q": 16.29791259765625, "mean_td_error": 0.09705697000026703, "model": {}}, "td_error": [-1.39630126953125, -0.5595707893371582, -2.132963180541992, 0.5043792724609375, 0.5370597839355469, 6.458488464355469, -0.27076244354248047, -0.31754112243652344, -0.31719112396240234, -0.2644209861755371, 0.33908987045288086, 0.1685352325439453, 1.2583274841308594, -0.24292516708374023, -0.01659679412841797, -0.4085540771484375, -0.13939571380615234, -3.452627182006836, -0.1938610076904297, 6.407473564147949, -0.1112823486328125, -0.8330001831054688, -0.06607532501220703, -1.7736902236938477, -0.5993757247924805, 0.16223859786987305, 0.28830814361572266, 4.716252326965332, -0.7915573120117188, 0.6173734664916992, -4.040184020996094, -0.4238276481628418], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 4.976679801940918, "min_q": -3.7428138256073, "max_q": 13.669734001159668, "mean_td_error": -1.439708948135376, "model": {}}, "td_error": [-6.091716766357422, 5.112511157989502, -0.6392207145690918, -2.2813308238983154, 4.350647926330566, 0.6320614814758301, -6.729547500610352, -5.204668045043945, -1.5733556747436523, -3.793231964111328, 2.4365081787109375, -4.641223430633545, -5.008582592010498, 1.1016154289245605, -1.2818975448608398, -1.8862075805664062, 6.915591716766357, 2.1499733924865723, 2.329143524169922, 0.898280143737793, -6.007368087768555, -9.700469017028809, -5.706388473510742, -1.9152231216430664, 0.429152250289917, 1.7996540069580078, 1.2703938484191895, 0.27064037322998047, 0.20017147064208984, -7.360480308532715, -4.57969856262207, -1.566425085067749], "custom_metrics": {}}}, "num_steps_sampled": 21441, "num_agent_steps_sampled": 42882, "num_steps_trained": 54944, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 109888, "last_target_update_ts": 21421, "num_target_updates": 188}, "done": false, "episodes_total": 1903, "training_iteration": 76, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-15", "timestamp": 1648811595, "time_this_iter_s": 1.2775428295135498, "time_total_s": 97.64814925193787, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 97.64814925193787, "timesteps_since_restore": 2432, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 29.7, "ram_util_percent": 51.8}}
{"episode_reward_max": 34.0, "episode_reward_min": 16.0, "episode_reward_mean": 30.6, "episode_len_mean": 4.7, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"policy0": 8.0, "policy1": 8.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 15.3, "policy1": 15.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.0, 30.0, 32.0, 30.0, 34.0, 34.0, 30.0, 28.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 30.0, 34.0, 34.0, 28.0, 24.0, 28.0, 34.0, 28.0, 28.0, 20.0, 34.0, 28.0, 34.0, 28.0, 24.0, 28.0, 28.0, 34.0, 24.0, 28.0, 20.0, 30.0, 28.0, 28.0, 28.0, 24.0, 28.0, 16.0, 28.0, 20.0, 20.0, 34.0, 34.0, 34.0, 30.0, 34.0, 32.0, 16.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 32.0, 32.0, 24.0, 34.0, 32.0, 34.0, 34.0, 28.0, 34.0, 34.0, 32.0, 34.0, 34.0, 30.0, 30.0, 34.0, 34.0, 34.0, 34.0, 30.0, 24.0, 34.0, 34.0, 28.0, 28.0, 34.0, 34.0, 34.0, 32.0], "episode_lengths": [7, 5, 4, 5, 3, 3, 5, 6, 3, 6, 3, 3, 3, 3, 3, 5, 5, 3, 3, 6, 8, 6, 3, 6, 6, 10, 3, 6, 3, 6, 8, 6, 6, 3, 8, 6, 10, 5, 6, 6, 6, 8, 6, 12, 6, 10, 10, 3, 3, 3, 5, 3, 4, 12, 3, 6, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 4, 3, 3, 3, 3, 4, 4, 8, 3, 4, 3, 3, 6, 3, 3, 4, 3, 3, 5, 5, 3, 3, 3, 3, 5, 8, 3, 3, 6, 6, 3, 3, 3, 4], "policy_policy0_reward": [13.0, 15.0, 16.0, 15.0, 17.0, 17.0, 15.0, 14.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 15.0, 17.0, 17.0, 14.0, 12.0, 14.0, 17.0, 14.0, 14.0, 10.0, 17.0, 14.0, 17.0, 14.0, 12.0, 14.0, 14.0, 17.0, 12.0, 14.0, 10.0, 15.0, 14.0, 14.0, 14.0, 12.0, 14.0, 8.0, 14.0, 10.0, 10.0, 17.0, 17.0, 17.0, 15.0, 17.0, 16.0, 8.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 12.0, 17.0, 16.0, 17.0, 17.0, 14.0, 17.0, 17.0, 16.0, 17.0, 17.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 12.0, 17.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 16.0], "policy_policy1_reward": [13.0, 15.0, 16.0, 15.0, 17.0, 17.0, 15.0, 14.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 15.0, 17.0, 17.0, 14.0, 12.0, 14.0, 17.0, 14.0, 14.0, 10.0, 17.0, 14.0, 17.0, 14.0, 12.0, 14.0, 14.0, 17.0, 12.0, 14.0, 10.0, 15.0, 14.0, 14.0, 14.0, 12.0, 14.0, 8.0, 14.0, 10.0, 10.0, 17.0, 17.0, 17.0, 15.0, 17.0, 16.0, 8.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 12.0, 17.0, 16.0, 17.0, 17.0, 14.0, 17.0, 17.0, 16.0, 17.0, 17.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 12.0, 17.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3175730037408183, "mean_inference_ms": 1.6180091194835202, "mean_action_processing_ms": 0.1068787420732274, "mean_env_wait_ms": 0.0708132462857851, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21648, "timesteps_this_iter": 32, "agent_timesteps_total": 43296, "timers": {"load_time_ms": 0.45, "load_throughput": 71153.967, "learn_time_ms": 7.628, "learn_throughput": 4194.946, "update_time_ms": 4.731}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.205068588256836, "min_q": 0.15830233693122864, "max_q": 14.854663848876953, "mean_td_error": -0.2790055572986603, "model": {}}, "td_error": [0.733433723449707, 1.0377826690673828, -1.7251510620117188, -1.919205665588379, -0.7445049285888672, 0.7473821640014648, 0.1312544345855713, -1.297006607055664, -0.5068659782409668, 0.6399192810058594, -0.2861485481262207, -0.4612545967102051, 0.2853221893310547, -0.6841549873352051, 0.5282993316650391, 0.908022403717041, 0.3181781768798828, -2.5043296813964844, -0.7659530639648438, 0.9814767837524414, -1.2378506660461426, -1.0144519805908203, -1.122208595275879, 0.24211883544921875, 0.10986804962158203, -0.5831880569458008, 0.7386770248413086, 0.36234569549560547, 1.0681977272033691, -1.1802124977111816, -1.2089424133300781, -0.5190272331237793], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.2970006465911865, "min_q": -2.334031820297241, "max_q": 11.064752578735352, "mean_td_error": 0.16944903135299683, "model": {}}, "td_error": [7.017557144165039, -5.797111988067627, 0.32001519203186035, 0.40915966033935547, -1.0080451965332031, 3.4452929496765137, 1.425682544708252, 1.1357108354568481, -0.6750116348266602, -2.156243324279785, 2.970900058746338, -3.3246426582336426, -0.12473106384277344, 2.191995620727539, -0.3379087448120117, -1.9533720016479492, 6.099756717681885, -6.5639848709106445, -1.1553840637207031, 1.13353431224823, -0.5340447425842285, 1.209038257598877, -0.5785446166992188, -0.28803837299346924, -0.8679993152618408, 0.2035360336303711, 4.952288627624512, -0.56524658203125, -3.7621865272521973, 0.5976715087890625, 0.2782268524169922, 1.724496841430664], "custom_metrics": {}}}, "num_steps_sampled": 21648, "num_agent_steps_sampled": 43296, "num_steps_trained": 56000, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 112000, "last_target_update_ts": 21629, "num_target_updates": 190}, "done": false, "episodes_total": 1956, "training_iteration": 77, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-16", "timestamp": 1648811596, "time_this_iter_s": 1.4168529510498047, "time_total_s": 99.06500220298767, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 99.06500220298767, "timesteps_since_restore": 2464, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 30.05, "ram_util_percent": 51.8}}
{"episode_reward_max": 34.0, "episode_reward_min": 18.0, "episode_reward_mean": 32.52, "episode_len_mean": 3.74, "episode_media": {}, "episodes_this_iter": 57, "policy_reward_min": {"policy0": 9.0, "policy1": 9.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.26, "policy1": 16.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 32.0, 32.0, 24.0, 34.0, 32.0, 34.0, 34.0, 28.0, 34.0, 34.0, 32.0, 34.0, 34.0, 30.0, 30.0, 34.0, 34.0, 34.0, 34.0, 30.0, 24.0, 34.0, 34.0, 28.0, 28.0, 34.0, 34.0, 34.0, 32.0, 18.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 32.0, 30.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 32.0, 30.0, 34.0, 28.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 28.0, 34.0, 20.0], "episode_lengths": [3, 3, 3, 3, 3, 5, 3, 3, 3, 4, 3, 3, 3, 3, 4, 4, 8, 3, 4, 3, 3, 6, 3, 3, 4, 3, 3, 5, 5, 3, 3, 3, 3, 5, 8, 3, 3, 6, 6, 3, 3, 3, 4, 11, 3, 3, 3, 3, 6, 3, 3, 3, 3, 4, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 5, 4, 5, 3, 6, 5, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 6, 3, 10], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 12.0, 17.0, 16.0, 17.0, 17.0, 14.0, 17.0, 17.0, 16.0, 17.0, 17.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 12.0, 17.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 16.0, 9.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 16.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 16.0, 15.0, 17.0, 14.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 10.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 12.0, 17.0, 16.0, 17.0, 17.0, 14.0, 17.0, 17.0, 16.0, 17.0, 17.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 12.0, 17.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 16.0, 9.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 16.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 16.0, 15.0, 17.0, 14.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31913854195639063, "mean_inference_ms": 1.618973944847217, "mean_action_processing_ms": 0.10697469861563082, "mean_env_wait_ms": 0.07088742158808362, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21860, "timesteps_this_iter": 32, "agent_timesteps_total": 43720, "timers": {"load_time_ms": 0.434, "load_throughput": 73746.004, "learn_time_ms": 7.953, "learn_throughput": 4023.639, "update_time_ms": 4.63}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.81682825088501, "min_q": -2.269033670425415, "max_q": 13.746150970458984, "mean_td_error": -0.2084493339061737, "model": {}}, "td_error": [0.43277931213378906, -0.36921072006225586, 0.553380012512207, 1.095445156097412, -1.3824377059936523, -0.2669558525085449, 7.668928146362305, -0.049345970153808594, -0.02456808090209961, -0.21499180793762207, -0.7917861938476562, 0.12484860420227051, -1.6607723236083984, -1.567475438117981, -1.0196094512939453, -1.4788265228271484, -0.8897190093994141, 0.05545949935913086, 0.1514376401901245, -0.7482504844665527, -4.429797172546387, -0.4886007308959961, 0.3734760284423828, -0.3593564033508301, -0.32161617279052734, -0.6469182968139648, 0.4996764659881592, 0.7423582077026367, -0.8015408515930176, -0.48210620880126953, -0.02591419219970703, -0.34836912155151367], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 3.1304030418395996, "min_q": -5.428798675537109, "max_q": 7.18994140625, "mean_td_error": -1.079691767692566, "model": {}}, "td_error": [-4.5433549880981445, -8.807720184326172, -5.43277645111084, 4.5945305824279785, 4.0701141357421875, 3.5339250564575195, 0.8363032341003418, -4.706472396850586, -2.290132522583008, 2.7509219646453857, -3.012117862701416, -1.864206314086914, 0.05314350128173828, -2.3735103607177734, 0.006383419036865234, -0.13196563720703125, 0.8748655319213867, -0.10262775421142578, 1.7364697456359863, -4.839619159698486, -1.5939130783081055, -3.297687530517578, -2.2235970497131348, -0.14467763900756836, -1.0768065452575684, -1.893470048904419, 1.2850892543792725, -1.0578923225402832, -4.8244452476501465, -3.4476332664489746, 3.488011598587036, -0.11526870727539062], "custom_metrics": {}}}, "num_steps_sampled": 21860, "num_agent_steps_sampled": 43720, "num_steps_trained": 57088, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 114176, "last_target_update_ts": 21833, "num_target_updates": 192}, "done": false, "episodes_total": 2013, "training_iteration": 78, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-18", "timestamp": 1648811598, "time_this_iter_s": 1.5096712112426758, "time_total_s": 100.57467341423035, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 100.57467341423035, "timesteps_since_restore": 2496, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 29.450000000000003, "ram_util_percent": 51.8}}
{"episode_reward_max": 34.0, "episode_reward_min": 18.0, "episode_reward_mean": 31.6, "episode_len_mean": 4.2, "episode_media": {}, "episodes_this_iter": 42, "policy_reward_min": {"policy0": 9.0, "policy1": 9.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 15.8, "policy1": 15.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.0, 18.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 32.0, 30.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 32.0, 30.0, 34.0, 28.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 28.0, 34.0, 20.0, 24.0, 24.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 28.0, 30.0, 26.0, 28.0, 26.0, 30.0, 26.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 30.0, 34.0, 30.0, 34.0, 34.0, 34.0, 32.0, 28.0, 34.0, 32.0, 28.0, 32.0, 34.0, 34.0, 20.0, 34.0, 34.0, 28.0, 34.0, 28.0, 24.0], "episode_lengths": [4, 11, 3, 3, 3, 3, 6, 3, 3, 3, 3, 4, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 5, 4, 5, 3, 6, 5, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 6, 3, 10, 8, 8, 5, 5, 5, 5, 5, 5, 6, 5, 7, 6, 7, 5, 7, 3, 3, 3, 3, 3, 6, 5, 3, 5, 3, 3, 3, 4, 6, 3, 4, 6, 4, 3, 3, 10, 3, 3, 6, 3, 6, 8], "policy_policy0_reward": [16.0, 9.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 16.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 16.0, 15.0, 17.0, 14.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 10.0, 12.0, 12.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 14.0, 15.0, 13.0, 14.0, 13.0, 15.0, 13.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 16.0, 14.0, 16.0, 17.0, 17.0, 10.0, 17.0, 17.0, 14.0, 17.0, 14.0, 12.0], "policy_policy1_reward": [16.0, 9.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 16.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 16.0, 15.0, 17.0, 14.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 10.0, 12.0, 12.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 14.0, 15.0, 13.0, 14.0, 13.0, 15.0, 13.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 16.0, 14.0, 16.0, 17.0, 17.0, 10.0, 17.0, 17.0, 14.0, 17.0, 14.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32013987243165554, "mean_inference_ms": 1.6195741156714902, "mean_action_processing_ms": 0.10704152351625154, "mean_env_wait_ms": 0.07092928064184231, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22064, "timesteps_this_iter": 32, "agent_timesteps_total": 44128, "timers": {"load_time_ms": 0.472, "load_throughput": 67776.462, "learn_time_ms": 7.865, "learn_throughput": 4068.597, "update_time_ms": 4.759}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.354221820831299, "min_q": 0.4920024871826172, "max_q": 15.522562026977539, "mean_td_error": -0.045736730098724365, "model": {}}, "td_error": [-0.5751967430114746, 0.21486377716064453, -0.32870960235595703, -0.0419459342956543, -2.4615602493286133, -1.0564088821411133, 0.48065662384033203, -0.3006591796875, -1.5064725875854492, -0.9864768981933594, -1.0295639038085938, 0.8988723754882812, -2.200185775756836, 0.32279109954833984, 0.20127391815185547, 0.2847633361816406, 0.05946063995361328, -2.0898990631103516, 7.533926963806152, 3.74222469329834, 0.5847814679145813, 0.22269582748413086, -0.9280819892883301, -0.21150875091552734, -0.007755279541015625, 0.16702795028686523, -0.2574448585510254, -1.0295639038085938, 0.034827232360839844, 0.029471397399902344, -1.5221831798553467, 0.2924041748046875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.926427841186523, "min_q": -0.639380931854248, "max_q": 10.930511474609375, "mean_td_error": 0.4359127879142761, "model": {}}, "td_error": [0.48170197010040283, 3.222548007965088, 1.723313331604004, -2.5127716064453125, -1.0459775924682617, 1.6322975158691406, -1.917797565460205, -0.680689811706543, 0.47133445739746094, 2.386496067047119, -8.324291229248047, -0.3343930244445801, 0.28605127334594727, 4.073087692260742, -1.9328193664550781, 0.6366500854492188, 3.132079601287842, 1.4373518228530884, 0.9740467071533203, 5.538736820220947, 4.205394268035889, 2.839911460876465, -5.074687957763672, -4.2748260498046875, 2.366231918334961, -2.104482650756836, 3.5710654258728027, -1.338183879852295, 1.7732598781585693, -1.669637680053711, 0.8828363418579102, 3.52537202835083], "custom_metrics": {}}}, "num_steps_sampled": 22064, "num_agent_steps_sampled": 44128, "num_steps_trained": 58112, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 116224, "last_target_update_ts": 22041, "num_target_updates": 194}, "done": false, "episodes_total": 2055, "training_iteration": 79, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-19", "timestamp": 1648811599, "time_this_iter_s": 1.372680425643921, "time_total_s": 101.94735383987427, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 101.94735383987427, "timesteps_since_restore": 2528, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 29.8, "ram_util_percent": 51.9}}
{"episode_reward_max": 34.0, "episode_reward_min": 20.0, "episode_reward_mean": 30.98, "episode_len_mean": 4.51, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 15.49, "policy1": 15.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 28.0, 34.0, 20.0, 24.0, 24.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 28.0, 30.0, 26.0, 28.0, 26.0, 30.0, 26.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 30.0, 34.0, 30.0, 34.0, 34.0, 34.0, 32.0, 28.0, 34.0, 32.0, 28.0, 32.0, 34.0, 34.0, 20.0, 34.0, 34.0, 28.0, 34.0, 28.0, 24.0, 28.0, 34.0, 34.0, 28.0, 32.0, 24.0, 28.0, 24.0, 28.0, 28.0, 28.0, 24.0, 28.0, 28.0, 26.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 30.0, 34.0, 34.0, 30.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 30.0, 34.0, 34.0, 30.0], "episode_lengths": [3, 3, 3, 3, 3, 5, 3, 6, 3, 10, 8, 8, 5, 5, 5, 5, 5, 5, 6, 5, 7, 6, 7, 5, 7, 3, 3, 3, 3, 3, 6, 5, 3, 5, 3, 3, 3, 4, 6, 3, 4, 6, 4, 3, 3, 10, 3, 3, 6, 3, 6, 8, 6, 3, 3, 6, 4, 8, 6, 8, 6, 6, 6, 8, 6, 6, 7, 3, 3, 3, 3, 3, 3, 5, 3, 5, 3, 3, 3, 3, 5, 3, 5, 3, 3, 5, 5, 3, 3, 3, 3, 3, 3, 3, 4, 3, 5, 3, 3, 5], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 10.0, 12.0, 12.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 14.0, 15.0, 13.0, 14.0, 13.0, 15.0, 13.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 16.0, 14.0, 16.0, 17.0, 17.0, 10.0, 17.0, 17.0, 14.0, 17.0, 14.0, 12.0, 14.0, 17.0, 17.0, 14.0, 16.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 13.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 15.0, 17.0, 17.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 15.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 10.0, 12.0, 12.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 14.0, 15.0, 13.0, 14.0, 13.0, 15.0, 13.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 16.0, 14.0, 16.0, 17.0, 17.0, 10.0, 17.0, 17.0, 14.0, 17.0, 14.0, 12.0, 14.0, 17.0, 17.0, 14.0, 16.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 13.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 15.0, 17.0, 17.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3211486061492673, "mean_inference_ms": 1.6205457403472496, "mean_action_processing_ms": 0.1071266817292066, "mean_env_wait_ms": 0.07098048890832917, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22269, "timesteps_this_iter": 32, "agent_timesteps_total": 44538, "timers": {"load_time_ms": 0.445, "load_throughput": 71885.667, "learn_time_ms": 8.018, "learn_throughput": 3990.929, "update_time_ms": 4.8}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.911890983581543, "min_q": -0.4576166272163391, "max_q": 17.056406021118164, "mean_td_error": 0.4856548011302948, "model": {}}, "td_error": [-2.236508369445801, 0.9630508422851562, -0.7182083129882812, 3.4678263664245605, -0.8707489967346191, 0.04495811462402344, 0.3175983428955078, -0.1250830888748169, -1.6916260719299316, -2.860349655151367, -1.3880501985549927, -0.13100004196166992, 0.33719921112060547, -0.1399383544921875, 0.010306835174560547, 0.4639015197753906, 6.459228515625, 0.15037822723388672, -0.6256246566772461, 0.4639015197753906, 5.601463317871094, -0.06811332702636719, 0.1604173183441162, -1.4000201225280762, -0.31860971450805664, -0.1399383544921875, 0.28503698110580444, -0.07464933395385742, -0.44527435302734375, 0.6460781097412109, 9.74653148651123, -0.34317970275878906], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.3889288902282715, "min_q": -2.339702606201172, "max_q": 20.045127868652344, "mean_td_error": -0.5186055898666382, "model": {}}, "td_error": [5.065629959106445, 1.3193449974060059, -0.9302191734313965, 6.047595500946045, -1.9407014846801758, -4.071327209472656, -6.202388763427734, 0.5985206365585327, -1.141493558883667, -6.202388763427734, -11.2514009475708, -0.7717577219009399, 3.1210145950317383, 1.9804532527923584, 5.065629959106445, -1.6315221786499023, -7.818828582763672, 1.4250364303588867, 6.7373857498168945, -1.2596893310546875, 0.2450246810913086, 2.4819297790527344, 2.882101535797119, 0.10798168182373047, -3.701901435852051, -4.085248947143555, 4.081119537353516, -0.2085096836090088, -6.202388763427734, -0.8040821552276611, -0.11438274383544922, 0.5840826034545898], "custom_metrics": {}}}, "num_steps_sampled": 22269, "num_agent_steps_sampled": 44538, "num_steps_trained": 59168, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 118336, "last_target_update_ts": 22250, "num_target_updates": 196}, "done": false, "episodes_total": 2103, "training_iteration": 80, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-21", "timestamp": 1648811601, "time_this_iter_s": 1.4771230220794678, "time_total_s": 103.42447686195374, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 103.42447686195374, "timesteps_since_restore": 2560, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 32.0, "ram_util_percent": 51.9}}
{"episode_reward_max": 34.0, "episode_reward_min": -20.0, "episode_reward_mean": 31.7, "episode_len_mean": 4.05, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 15.85, "policy1": 15.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 28.0, 32.0, 24.0, 28.0, 24.0, 28.0, 28.0, 28.0, 24.0, 28.0, 28.0, 26.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 30.0, 34.0, 34.0, 30.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 30.0, 34.0, 34.0, 30.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 32.0, 30.0, 30.0, 34.0, 30.0, 34.0, 34.0, 34.0, 26.0, 30.0, 34.0, 34.0, -20.0, 34.0, 28.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 6, 4, 8, 6, 8, 6, 6, 6, 8, 6, 6, 7, 3, 3, 3, 3, 3, 3, 5, 3, 5, 3, 3, 3, 3, 5, 3, 5, 3, 3, 5, 5, 3, 3, 3, 3, 3, 3, 3, 4, 3, 5, 3, 3, 5, 3, 6, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 5, 3, 3, 3, 7, 5, 3, 3, 20, 3, 6, 5, 3, 3, 3, 3, 3, 4, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 14.0, 16.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 13.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 15.0, 17.0, 17.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 16.0, 15.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 13.0, 15.0, 17.0, 17.0, -10.0, 17.0, 14.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 14.0, 16.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 13.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 15.0, 17.0, 17.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 16.0, 15.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 13.0, 15.0, 17.0, 17.0, -10.0, 17.0, 14.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3224956838144617, "mean_inference_ms": 1.6217056163847154, "mean_action_processing_ms": 0.10723695563589644, "mean_env_wait_ms": 0.07104367132435316, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22475, "timesteps_this_iter": 32, "agent_timesteps_total": 44950, "timers": {"load_time_ms": 0.461, "load_throughput": 69478.066, "learn_time_ms": 7.678, "learn_throughput": 4167.981, "update_time_ms": 4.585}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.9667863845825195, "min_q": -1.8876585960388184, "max_q": 17.210390090942383, "mean_td_error": -0.2250121533870697, "model": {}}, "td_error": [2.286433219909668, 0.16330432891845703, -1.0159659385681152, 1.2604036331176758, -0.6172332763671875, 0.27574634552001953, 0.16020828485488892, -0.3352651596069336, -2.42257022857666, 1.2352523803710938, -0.12061834335327148, -0.7982597351074219, -0.7990579605102539, -0.3170013427734375, -0.2188258171081543, 0.6569223403930664, -2.6664295196533203, 0.06737327575683594, -0.3485746383666992, -1.5532832145690918, 0.34277963638305664, 0.4141664505004883, -1.2143373489379883, 0.09066581726074219, -0.8636749982833862, -0.43158721923828125, -0.032625675201416016, -0.012827873229980469, -0.06120133399963379, 0.3856801986694336, 0.09066581726074219, -0.8006505966186523], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.441816329956055, "min_q": -3.1021223068237305, "max_q": 16.740385055541992, "mean_td_error": -0.5715498328208923, "model": {}}, "td_error": [3.762202739715576, 2.8164525032043457, -1.578317403793335, -1.8075695037841797, -0.3475837707519531, -5.547926425933838, -1.9254961013793945, 2.8258328437805176, -0.15941238403320312, -0.047382354736328125, 0.6675443649291992, -3.6569366455078125, -0.15088462829589844, -1.2436962127685547, 1.6070938110351562, -0.7946810126304626, -1.9254961013793945, -1.8842926025390625, 5.508498668670654, -1.422743320465088, -0.1492772102355957, 1.7334346771240234, -1.9254961013793945, -1.8842926025390625, -5.143163204193115, -0.4675273895263672, -0.6602697372436523, -1.9254961013793945, -0.9190883636474609, -2.8047666549682617, 0.17527008056640625, 0.9858712553977966], "custom_metrics": {}}}, "num_steps_sampled": 22475, "num_agent_steps_sampled": 44950, "num_steps_trained": 60128, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 120256, "last_target_update_ts": 22469, "num_target_updates": 198}, "done": false, "episodes_total": 2156, "training_iteration": 81, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-22", "timestamp": 1648811602, "time_this_iter_s": 1.3304500579833984, "time_total_s": 104.75492691993713, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83deef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83deef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 104.75492691993713, "timesteps_since_restore": 2592, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 29.1, "ram_util_percent": 51.9}}
{"episode_reward_max": 34.0, "episode_reward_min": -20.0, "episode_reward_mean": 32.14, "episode_len_mean": 3.83, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.07, "policy1": 16.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 30.0, 34.0, 30.0, 34.0, 34.0, 34.0, 26.0, 30.0, 34.0, 34.0, -20.0, 34.0, 28.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 26.0, 34.0, 34.0, 34.0, 30.0, 28.0, 34.0, 30.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 20.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 24.0, 34.0, 28.0], "episode_lengths": [5, 5, 3, 5, 3, 3, 3, 7, 5, 3, 3, 20, 3, 6, 5, 3, 3, 3, 3, 3, 4, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 7, 3, 3, 3, 5, 6, 3, 5, 3, 3, 3, 5, 3, 3, 3, 3, 5, 3, 3, 10, 3, 3, 3, 3, 4, 3, 3, 6, 3, 3, 3, 3, 3, 4, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 8, 3, 6], "policy_policy0_reward": [15.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 13.0, 15.0, 17.0, 17.0, -10.0, 17.0, 14.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 13.0, 17.0, 17.0, 17.0, 15.0, 14.0, 17.0, 15.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 10.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 14.0], "policy_policy1_reward": [15.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 13.0, 15.0, 17.0, 17.0, -10.0, 17.0, 14.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 13.0, 17.0, 17.0, 17.0, 15.0, 14.0, 17.0, 15.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 10.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3237100552881944, "mean_inference_ms": 1.6219957663160052, "mean_action_processing_ms": 0.1072851922404735, "mean_env_wait_ms": 0.07107700281515263, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22684, "timesteps_this_iter": 32, "agent_timesteps_total": 45368, "timers": {"load_time_ms": 0.473, "load_throughput": 67711.496, "learn_time_ms": 7.822, "learn_throughput": 4091.28, "update_time_ms": 5.041}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.997303009033203, "min_q": -2.415780782699585, "max_q": 17.05537223815918, "mean_td_error": 0.1611904501914978, "model": {}}, "td_error": [0.08132076263427734, 0.4536857604980469, 0.48641324043273926, -0.6228733062744141, -0.3916759490966797, -0.34851741790771484, 0.2766728401184082, 1.1870386600494385, -1.5412979125976562, 0.2693452835083008, 0.07235336303710938, -0.4670381546020508, -0.4526076316833496, 0.22468852996826172, 0.1823892593383789, -1.4936599731445312, 0.23797130584716797, 0.15347766876220703, 2.807076930999756, -1.7399177551269531, 1.1619939804077148, -0.7222042083740234, 2.3219361305236816, -0.10902023315429688, 2.7651913166046143, -0.12975692749023438, -0.6592617034912109, 0.9298152923583984, -0.0705265998840332, -0.2593727111816406, 0.40097713470458984, 0.15347766876220703], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.3167009353637695, "min_q": -1.952476978302002, "max_q": 17.75103187561035, "mean_td_error": -1.0694944858551025, "model": {}}, "td_error": [-0.8557977676391602, 0.41619420051574707, -2.1379590034484863, -1.3706340789794922, -1.7987031936645508, 0.36784446239471436, 2.6204452514648438, -1.9615812301635742, 0.3043365478515625, -0.8460788726806641, -0.7594671249389648, -4.387308597564697, 1.889746904373169, -5.715149879455566, -9.467567443847656, -1.119431972503662, -0.8170757293701172, -1.7042837142944336, -0.8455209732055664, 3.2003378868103027, -0.8867321014404297, -1.3706340789794922, -1.346311092376709, -0.30434513092041016, -1.8887073993682861, -1.3706340789794922, -2.7612123489379883, 0.2508573532104492, -1.262467861175537, -3.1907429695129395, 1.1630010604858398, 3.731760025024414], "custom_metrics": {}}}, "num_steps_sampled": 22684, "num_agent_steps_sampled": 45368, "num_steps_trained": 61152, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 122304, "last_target_update_ts": 22684, "num_target_updates": 200}, "done": false, "episodes_total": 2212, "training_iteration": 82, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-24", "timestamp": 1648811604, "time_this_iter_s": 1.3976819515228271, "time_total_s": 106.15260887145996, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 106.15260887145996, "timesteps_since_restore": 2624, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 30.45, "ram_util_percent": 51.9}}
{"episode_reward_max": 34.0, "episode_reward_min": 20.0, "episode_reward_mean": 32.48, "episode_len_mean": 3.76, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.24, "policy1": 16.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 28.0, 34.0, 30.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 20.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 24.0, 34.0, 28.0, 28.0, 30.0, 28.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 28.0, 30.0, 34.0, 34.0, 32.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 24.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 20.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [5, 6, 3, 5, 3, 3, 3, 5, 3, 3, 3, 3, 5, 3, 3, 10, 3, 3, 3, 3, 4, 3, 3, 6, 3, 3, 3, 3, 3, 4, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 8, 3, 6, 6, 5, 6, 4, 3, 3, 3, 3, 3, 5, 3, 6, 5, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 6, 3, 8, 3, 3, 3, 3, 6, 3, 3, 10, 3, 3, 4, 3, 3, 3, 5, 3, 3, 4, 3, 3, 3, 3], "policy_policy0_reward": [15.0, 14.0, 17.0, 15.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 10.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 14.0, 14.0, 15.0, 14.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 14.0, 15.0, 17.0, 17.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 12.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 10.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [15.0, 14.0, 17.0, 15.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 10.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 14.0, 14.0, 15.0, 14.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 14.0, 15.0, 17.0, 17.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 12.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 10.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32494550147226176, "mean_inference_ms": 1.6232245340451095, "mean_action_processing_ms": 0.10738468374903036, "mean_env_wait_ms": 0.07113515641529315, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22888, "timesteps_this_iter": 32, "agent_timesteps_total": 45776, "timers": {"load_time_ms": 0.509, "load_throughput": 62891.958, "learn_time_ms": 8.003, "learn_throughput": 3998.598, "update_time_ms": 5.217}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.385726928710938, "min_q": -2.8984358310699463, "max_q": 18.153427124023438, "mean_td_error": 0.07320526987314224, "model": {}}, "td_error": [-0.9920825958251953, 0.2517080307006836, 6.462223529815674, 0.3876309394836426, 0.7045370936393738, 1.516413927078247, -0.24174880981445312, 0.7952461242675781, -0.12504816055297852, 0.09737205505371094, 0.12129592895507812, 0.15307998657226562, 0.16364574432373047, 0.14957237243652344, 0.07587766647338867, -2.302678108215332, -2.439734935760498, -0.6199188232421875, -3.216216564178467, 2.6034059524536133, 1.7373809814453125, -1.8984358310699463, -0.09498405456542969, -8.374421119689941, 0.11840629577636719, 0.29791831970214844, -0.7686805725097656, 0.4488067626953125, -0.9920825958251953, 5.683136463165283, 1.2637357711791992, 1.377206802368164], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.128003120422363, "min_q": -3.066546678543091, "max_q": 17.159061431884766, "mean_td_error": -0.5562587380409241, "model": {}}, "td_error": [-3.7136428356170654, -1.8088603019714355, 0.4962770938873291, -0.19455790519714355, -1.4409966468811035, 1.1402583122253418, -0.9573101997375488, -0.8048057556152344, 1.374826431274414, -2.738163471221924, -0.32472801208496094, -2.0726113319396973, -2.3605189323425293, 1.1352043151855469, -0.39556407928466797, -2.662341833114624, -0.5421743392944336, -3.1342010498046875, -0.3773384094238281, 1.5008974075317383, 1.5949959754943848, 0.0140380859375, -1.5762853622436523, -0.12908411026000977, 4.167886734008789, -2.0633506774902344, -0.417391300201416, -0.5109639167785645, -1.2314395904541016, -1.8088657855987549, 1.6326985359191895, 0.407834529876709], "custom_metrics": {}}}, "num_steps_sampled": 22888, "num_agent_steps_sampled": 45776, "num_steps_trained": 62208, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 124416, "last_target_update_ts": 22888, "num_target_updates": 202}, "done": false, "episodes_total": 2266, "training_iteration": 83, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-25", "timestamp": 1648811605, "time_this_iter_s": 1.5133256912231445, "time_total_s": 107.6659345626831, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 107.6659345626831, "timesteps_since_restore": 2656, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 29.25, "ram_util_percent": 51.9}}
{"episode_reward_max": 34.0, "episode_reward_min": 20.0, "episode_reward_mean": 32.64, "episode_len_mean": 3.68, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.32, "policy1": 16.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 28.0, 30.0, 34.0, 34.0, 32.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 24.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 20.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 28.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 24.0, 34.0, 34.0, 32.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 24.0, 34.0, 32.0, 32.0, 32.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 30.0, 32.0], "episode_lengths": [3, 6, 5, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 6, 3, 8, 3, 3, 3, 3, 6, 3, 3, 10, 3, 3, 4, 3, 3, 3, 5, 3, 3, 4, 3, 3, 3, 3, 3, 3, 5, 3, 3, 5, 3, 3, 3, 6, 3, 6, 3, 3, 3, 3, 8, 3, 3, 4, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 8, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 5, 6, 3, 3, 3, 3, 3, 5, 3, 3, 5, 4], "policy_policy0_reward": [17.0, 14.0, 15.0, 17.0, 17.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 12.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 10.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 14.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 15.0, 16.0], "policy_policy1_reward": [17.0, 14.0, 15.0, 17.0, 17.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 12.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 10.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 14.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 15.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32622568175414896, "mean_inference_ms": 1.6245550141780476, "mean_action_processing_ms": 0.10749004696855628, "mean_env_wait_ms": 0.07120470889638338, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23093, "timesteps_this_iter": 32, "agent_timesteps_total": 46186, "timers": {"load_time_ms": 0.432, "load_throughput": 73994.006, "learn_time_ms": 7.813, "learn_throughput": 4095.925, "update_time_ms": 4.724}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.587900161743164, "min_q": -1.1282275915145874, "max_q": 17.954763412475586, "mean_td_error": 0.5853536128997803, "model": {}}, "td_error": [0.5534372329711914, 2.571685791015625, -0.9133791923522949, 1.7665376663208008, -1.3393478393554688, -0.8060331344604492, -0.2962827682495117, 0.18906211853027344, 0.15654945373535156, -0.20860671997070312, 0.8844575881958008, 1.7329607009887695, 0.41181373596191406, -0.141448974609375, 1.305710792541504, -0.5701084136962891, 0.6118731498718262, 0.6495094299316406, 3.8793015480041504, 0.41196250915527344, 0.6849203109741211, 0.7756056785583496, 6.2134294509887695, -0.22080087661743164, 0.18906211853027344, 0.6760311126708984, -1.5765039920806885, 0.9171714782714844, 0.010465383529663086, -0.13332867622375488, 0.15654563903808594, 0.18906402587890625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.373875617980957, "min_q": 0.8200201392173767, "max_q": 18.588369369506836, "mean_td_error": 0.09505121409893036, "model": {}}, "td_error": [-1.808415412902832, -0.9097886085510254, -1.1593666076660156, 1.1556153297424316, 2.2954463958740234, -1.3401756286621094, 2.845637321472168, -2.7818546295166016, 2.142599105834961, 1.5172414779663086, -0.4216804504394531, -9.698529243469238, 0.3976407051086426, -0.8425865173339844, 3.0469954013824463, -0.2464752197265625, 2.4304327964782715, -1.2240276336669922, -4.729231834411621, 0.5209898948669434, -1.5389232635498047, 1.2926344871520996, 7.094795227050781, -0.6074681282043457, -0.3103170394897461, 2.1839518547058105, -3.1708784103393555, 2.5753390789031982, -0.12739086151123047, 5.69577693939209, -0.30764293670654297, -0.928706169128418], "custom_metrics": {}}}, "num_steps_sampled": 23093, "num_agent_steps_sampled": 46186, "num_steps_trained": 63296, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 126592, "last_target_update_ts": 23093, "num_target_updates": 204}, "done": false, "episodes_total": 2322, "training_iteration": 84, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-27", "timestamp": 1648811607, "time_this_iter_s": 1.4661922454833984, "time_total_s": 109.1321268081665, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 109.1321268081665, "timesteps_since_restore": 2688, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 29.8, "ram_util_percent": 51.9}}
{"episode_reward_max": 34.0, "episode_reward_min": 24.0, "episode_reward_mean": 33.1, "episode_len_mean": 3.45, "episode_media": {}, "episodes_this_iter": 61, "policy_reward_min": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.55, "policy1": 16.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 32.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 24.0, 34.0, 32.0, 32.0, 32.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 30.0, 32.0, 34.0, 32.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 30.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 32.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 32.0, 34.0, 34.0, 28.0], "episode_lengths": [3, 3, 4, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 8, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 5, 6, 3, 3, 3, 3, 3, 5, 3, 3, 5, 4, 3, 4, 3, 3, 3, 5, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 5, 4, 3, 3, 3, 3, 3, 3, 3, 6, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 6], "policy_policy0_reward": [17.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 15.0, 16.0, 17.0, 16.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 15.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 16.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 17.0, 17.0, 14.0], "policy_policy1_reward": [17.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 15.0, 16.0, 17.0, 16.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 15.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 16.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 17.0, 17.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32752679517992767, "mean_inference_ms": 1.62495719571128, "mean_action_processing_ms": 0.10752515386899424, "mean_env_wait_ms": 0.07124155579377846, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23299, "timesteps_this_iter": 32, "agent_timesteps_total": 46598, "timers": {"load_time_ms": 0.443, "load_throughput": 72179.472, "learn_time_ms": 7.792, "learn_throughput": 4106.527, "update_time_ms": 4.59}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.437082290649414, "min_q": 1.375173807144165, "max_q": 16.175939559936523, "mean_td_error": -0.15453627705574036, "model": {}}, "td_error": [0.013670921325683594, 6.759568214416504, 0.17554569244384766, 1.943960189819336, 4.325903415679932, -0.5839719772338867, -0.7755351066589355, 0.05939674377441406, 2.1973400115966797, 0.8678405284881592, -0.15387248992919922, 0.1306743621826172, -1.3626985549926758, -2.411665439605713, -2.3226466178894043, -0.12443804740905762, -0.3816800117492676, -0.9962148666381836, 0.5395040512084961, -1.184514045715332, -1.3556480407714844, -1.950998306274414, -1.0745906829833984, -1.264296531677246, -1.243788719177246, -0.5123114585876465, 0.2036292552947998, -0.4926908016204834, -0.613739013671875, -0.7661995887756348, -1.9540958404541016, -0.6365985870361328], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.25727653503418, "min_q": -4.165997505187988, "max_q": 16.888498306274414, "mean_td_error": -0.10045847296714783, "model": {}}, "td_error": [-0.2894577980041504, -0.3868122100830078, -1.2581825256347656, 2.1124706268310547, -0.38201141357421875, 1.7357654571533203, -0.560287356376648, -9.62346076965332, 3.905740737915039, -0.4122614860534668, 0.05578470230102539, 2.4792604446411133, -6.460629463195801, -1.551164150238037, -0.1649036407470703, 1.9948348999023438, -0.8001624345779419, 0.6659793853759766, 7.404946804046631, -8.142922401428223, 0.3081660270690918, -0.4107975959777832, -1.1575183868408203, -0.6966300010681152, 0.17443203926086426, -0.6547138690948486, 2.390043258666992, 1.1238422393798828, 2.480093002319336, -1.6472549438476562, 1.5025193691253662, 3.0506210327148438], "custom_metrics": {}}}, "num_steps_sampled": 23299, "num_agent_steps_sampled": 46598, "num_steps_trained": 64416, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 128832, "last_target_update_ts": 23299, "num_target_updates": 206}, "done": false, "episodes_total": 2383, "training_iteration": 85, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-28", "timestamp": 1648811608, "time_this_iter_s": 1.4706780910491943, "time_total_s": 110.6028048992157, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 110.6028048992157, "timesteps_since_restore": 2720, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 29.766666666666666, "ram_util_percent": 51.96666666666667}}
{"episode_reward_max": 34.0, "episode_reward_min": 24.0, "episode_reward_mean": 33.1, "episode_len_mean": 3.45, "episode_media": {}, "episodes_this_iter": 59, "policy_reward_min": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.55, "policy1": 16.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 32.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 32.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 28.0, 34.0, 24.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 28.0, 28.0, 30.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 30.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 6, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 6, 3, 3, 3, 6, 3, 8, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 5, 3, 3, 3, 3, 6, 6, 5, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 16.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 14.0, 17.0, 12.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 15.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 15.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 16.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 14.0, 17.0, 12.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 15.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 15.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32890184169998593, "mean_inference_ms": 1.626041665909014, "mean_action_processing_ms": 0.10760174314177653, "mean_env_wait_ms": 0.07129446146289337, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23506, "timesteps_this_iter": 32, "agent_timesteps_total": 47012, "timers": {"load_time_ms": 0.51, "load_throughput": 62797.795, "learn_time_ms": 8.518, "learn_throughput": 3756.917, "update_time_ms": 5.388}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.6880950927734375, "min_q": 0.47741472721099854, "max_q": 18.013113021850586, "mean_td_error": -0.020867682993412018, "model": {}}, "td_error": [-0.809389591217041, -0.7824668884277344, -2.5116405487060547, -0.23265838623046875, 4.311681747436523, 0.32550549507141113, 4.4841742515563965, 0.30559349060058594, 0.3843822479248047, 0.20838594436645508, -1.6796345710754395, 4.11464786529541, -0.18735122680664062, -0.6126556396484375, -0.6722822189331055, -0.18735122680664062, -1.2421083450317383, -0.453566312789917, -0.628199577331543, 4.1078386306762695, -1.6496009826660156, 0.15622568130493164, -0.18735122680664062, 0.09863948822021484, -0.9959716796875, -0.21497535705566406, -0.7391400337219238, -2.1645116806030273, -1.1404201984405518, -2.0853238105773926, -0.1127920150756836, 0.12455081939697266], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.802111625671387, "min_q": -4.514614105224609, "max_q": 16.621475219726562, "mean_td_error": 0.1868899166584015, "model": {}}, "td_error": [6.070484638214111, -0.4333651065826416, 0.036273956298828125, -1.6352310180664062, 3.043728828430176, -5.812510967254639, 0.16201114654541016, 0.1700420379638672, 2.2342405319213867, -2.5438709259033203, -0.03900146484375, 2.332139730453491, 2.254426956176758, -0.9619617462158203, -0.3158559799194336, -3.119013786315918, 1.8141660690307617, 1.3062396049499512, -1.626223087310791, -1.6352310180664062, 1.4677619934082031, -1.6352310180664062, 2.6169302463531494, -0.5592613220214844, 3.555988073348999, -0.4761016368865967, 3.178042411804199, -0.818049430847168, -6.047779560089111, -1.6352310180664062, 2.1061484813690186, 2.9257707595825195], "custom_metrics": {}}}, "num_steps_sampled": 23506, "num_agent_steps_sampled": 47012, "num_steps_trained": 65472, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 130944, "last_target_update_ts": 23506, "num_target_updates": 208}, "done": false, "episodes_total": 2442, "training_iteration": 86, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-30", "timestamp": 1648811610, "time_this_iter_s": 1.5130720138549805, "time_total_s": 112.11587691307068, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 112.11587691307068, "timesteps_since_restore": 2752, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 30.25, "ram_util_percent": 52.0}}
{"episode_reward_max": 34.0, "episode_reward_min": 28.0, "episode_reward_mean": 33.24, "episode_len_mean": 3.38, "episode_media": {}, "episodes_this_iter": 62, "policy_reward_min": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.62, "policy1": 16.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 28.0, 28.0, 30.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 30.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 32.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 32.0, 30.0, 34.0, 34.0, 34.0, 34.0, 32.0, 30.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 6, 6, 5, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 3, 3, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 5, 3, 3, 3, 3, 3, 3, 6, 4, 3, 4, 3, 3, 3, 3, 5, 3, 3, 4, 5, 3, 3, 3, 3, 4, 5, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 4, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 15.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 15.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 16.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 16.0, 15.0, 17.0, 17.0, 17.0, 17.0, 16.0, 15.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 15.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 15.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 16.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 16.0, 15.0, 17.0, 17.0, 17.0, 17.0, 16.0, 15.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3303432319044649, "mean_inference_ms": 1.6267886656947126, "mean_action_processing_ms": 0.10765698186127885, "mean_env_wait_ms": 0.07134391682523161, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23716, "timesteps_this_iter": 32, "agent_timesteps_total": 47432, "timers": {"load_time_ms": 0.453, "load_throughput": 70562.919, "learn_time_ms": 7.793, "learn_throughput": 4106.112, "update_time_ms": 4.652}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.640707015991211, "min_q": 0.323991596698761, "max_q": 18.77777099609375, "mean_td_error": 0.08181273192167282, "model": {}}, "td_error": [-0.7303094863891602, -0.26807355880737305, -0.6351927518844604, 2.208329200744629, 0.5103485584259033, 0.15008187294006348, 0.19244766235351562, -1.393235206604004, 1.6058597564697266, 1.3574821949005127, -1.3592510223388672, 0.14061641693115234, -3.4146642684936523, 0.19244766235351562, 3.6303186416625977, 6.468090057373047, -0.4157733917236328, 0.36281776428222656, -0.6692981719970703, -1.9288268089294434, 0.0033440589904785156, -0.42255210876464844, 0.1061549186706543, 0.3692188262939453, 0.20522642135620117, 0.11147761344909668, -0.2348041534423828, 0.1894674301147461, 0.9168539047241211, -2.4849491119384766, -2.1712913513183594, 0.025645732879638672], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 5.135588645935059, "min_q": -7.437999248504639, "max_q": 18.305553436279297, "mean_td_error": 0.30595338344573975, "model": {}}, "td_error": [-0.26171207427978516, -1.1946730613708496, -1.190972089767456, 2.200897455215454, -0.18072509765625, -4.168178558349609, 0.4548196792602539, 3.472907304763794, 2.406320810317993, 1.6261043548583984, -0.9823122024536133, -1.2576904296875, -0.46326351165771484, -2.269348621368408, -0.6917181015014648, -0.26171207427978516, 0.045589447021484375, 2.8534505367279053, 3.614518880844116, -1.2980117797851562, -2.239177703857422, -3.467480421066284, -2.1706008911132812, -0.6582586765289307, 0.9770269393920898, 4.682209014892578, 0.5930061340332031, 3.8835411071777344, -1.0294303894042969, 4.870439052581787, 1.0154962539672852, 0.8794479370117188], "custom_metrics": {}}}, "num_steps_sampled": 23716, "num_agent_steps_sampled": 47432, "num_steps_trained": 66624, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 133248, "last_target_update_ts": 23716, "num_target_updates": 210}, "done": false, "episodes_total": 2504, "training_iteration": 87, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-32", "timestamp": 1648811612, "time_this_iter_s": 1.5002903938293457, "time_total_s": 113.61616730690002, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 113.61616730690002, "timesteps_since_restore": 2784, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 30.7, "ram_util_percent": 52.0}}
{"episode_reward_max": 34.0, "episode_reward_min": 24.0, "episode_reward_mean": 33.6, "episode_len_mean": 3.2, "episode_media": {}, "episodes_this_iter": 66, "policy_reward_min": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.8, "policy1": 16.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 32.0, 30.0, 34.0, 34.0, 34.0, 34.0, 32.0, 30.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 24.0], "episode_lengths": [3, 3, 3, 5, 3, 3, 4, 5, 3, 3, 3, 3, 4, 5, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 8], "policy_policy0_reward": [17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 16.0, 15.0, 17.0, 17.0, 17.0, 17.0, 16.0, 15.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 12.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 16.0, 15.0, 17.0, 17.0, 17.0, 17.0, 16.0, 15.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33182561668251465, "mean_inference_ms": 1.6275507553080042, "mean_action_processing_ms": 0.10770727159532513, "mean_env_wait_ms": 0.0713827253316231, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23922, "timesteps_this_iter": 32, "agent_timesteps_total": 47844, "timers": {"load_time_ms": 0.46, "load_throughput": 69499.652, "learn_time_ms": 8.031, "learn_throughput": 3984.626, "update_time_ms": 4.825}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.316680908203125, "min_q": -1.099614143371582, "max_q": 17.916112899780273, "mean_td_error": 0.2790350914001465, "model": {}}, "td_error": [0.6786251068115234, 4.672301769256592, -0.11521148681640625, 0.15774250030517578, 0.5844459533691406, 0.006391048431396484, 0.746953010559082, 0.4242095947265625, 0.6123561859130859, 2.6713991165161133, 0.7258844375610352, -0.49133872985839844, -0.1809253692626953, -0.5517673492431641, 0.21921443939208984, 1.7211108207702637, -0.23856687545776367, -0.09961414337158203, 1.8221054077148438, -0.49239158630371094, 2.6713991165161133, -0.6484613418579102, -1.506540060043335, 0.5844459533691406, -2.6935482025146484, -0.5327177047729492, -0.7429180145263672, 0.5015921592712402, -0.7791862487792969, -1.564845085144043, 0.18253421783447266, 0.5844440460205078], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.472101211547852, "min_q": -3.069643497467041, "max_q": 17.33386993408203, "mean_td_error": -0.11907714605331421, "model": {}}, "td_error": [-2.8698205947875977, 0.46380615234375, -4.866130352020264, 0.712395429611206, -0.4246654510498047, -0.07837772369384766, 6.534517288208008, -0.3134498596191406, 1.1503734588623047, -0.5010280609130859, -0.7806596755981445, -2.308919906616211, -3.4397776126861572, -1.1070778369903564, 1.28391695022583, -1.931687355041504, 1.4000908136367798, 0.4177945852279663, 0.5139627456665039, 1.5591421127319336, 1.1367073059082031, 0.46380615234375, -1.399118423461914, 0.5139627456665039, 0.3586387634277344, -0.384307861328125, 2.0574746131896973, 0.42048192024230957, -0.3897109627723694, 0.43379735946655273, -1.7509794235229492, -0.6856260299682617], "custom_metrics": {}}}, "num_steps_sampled": 23922, "num_agent_steps_sampled": 47844, "num_steps_trained": 67712, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 135424, "last_target_update_ts": 23922, "num_target_updates": 212}, "done": false, "episodes_total": 2570, "training_iteration": 88, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-33", "timestamp": 1648811613, "time_this_iter_s": 1.5092558860778809, "time_total_s": 115.1254231929779, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 115.1254231929779, "timesteps_since_restore": 2816, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 28.75, "ram_util_percent": 52.0}}
{"episode_reward_max": 34.0, "episode_reward_min": 24.0, "episode_reward_mean": 33.4, "episode_len_mean": 3.3, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.7, "policy1": 16.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 24.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 30.0, 34.0, 34.0, 34.0, 30.0, 32.0, 34.0, 28.0, 32.0, 32.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 32.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 5, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 4, 3, 5, 3, 3, 3, 5, 4, 3, 6, 4, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 6, 3, 3, 3, 4, 5, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 17.0, 15.0, 16.0, 17.0, 14.0, 16.0, 16.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 16.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 12.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 15.0, 17.0, 17.0, 17.0, 15.0, 16.0, 17.0, 14.0, 16.0, 16.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 16.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33305002326143535, "mean_inference_ms": 1.6282826975092575, "mean_action_processing_ms": 0.10775047330237579, "mean_env_wait_ms": 0.07142816149285086, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24126, "timesteps_this_iter": 32, "agent_timesteps_total": 48252, "timers": {"load_time_ms": 0.438, "load_throughput": 73095.375, "learn_time_ms": 7.85, "learn_throughput": 4076.679, "update_time_ms": 4.796}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.447014808654785, "min_q": -1.4427158832550049, "max_q": 17.926000595092773, "mean_td_error": 0.559939980506897, "model": {}}, "td_error": [3.131734848022461, 0.2007509469985962, -0.05959892272949219, 0.6357696056365967, -0.12665939331054688, -0.07212221622467041, 0.9645061492919922, -0.5683994293212891, -0.8068647384643555, 0.15129899978637695, -0.20803546905517578, -0.09315252304077148, 2.827566623687744, 1.2333769798278809, 0.29176807403564453, 1.652174949645996, 2.661372184753418, 0.12114334106445312, 0.5751810073852539, 1.966343641281128, 0.32679176330566406, 2.4499239921569824, -0.05959892272949219, 0.061859130859375, 0.1951894760131836, 0.7399110794067383, -0.06748104095458984, -0.12665939331054688, 0.5308403968811035, 0.5779333114624023, 0.09029054641723633, -1.2790756225585938], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.473569869995117, "min_q": -3.9714272022247314, "max_q": 19.04592514038086, "mean_td_error": 0.8897042870521545, "model": {}}, "td_error": [0.7983808517456055, -1.9458808898925781, 8.543083190917969, 0.9959118366241455, 2.367086410522461, 5.7888407707214355, -4.5416741371154785, 6.945137977600098, 3.4347381591796875, 0.7608699798583984, -1.6226658821105957, -1.2761168479919434, 1.337667465209961, 2.7319486141204834, -2.516589641571045, -0.8647007942199707, -1.2527923583984375, -3.87799072265625, 0.7983808517456055, 5.496135711669922, 3.378876209259033, 2.707362651824951, 1.4161701202392578, -1.9160571098327637, -0.5950632095336914, 1.6926475763320923, -2.2657928466796875, 7.2692718505859375, 2.716917037963867, 1.337667465209961, -2.3417575359344482, -7.029475212097168], "custom_metrics": {}}}, "num_steps_sampled": 24126, "num_agent_steps_sampled": 48252, "num_steps_trained": 68800, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 137600, "last_target_update_ts": 24126, "num_target_updates": 214}, "done": false, "episodes_total": 2630, "training_iteration": 89, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-35", "timestamp": 1648811615, "time_this_iter_s": 1.464447021484375, "time_total_s": 116.58987021446228, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83de5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83de5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 116.58987021446228, "timesteps_since_restore": 2848, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 31.15, "ram_util_percent": 52.1}}
{"episode_reward_max": 34.0, "episode_reward_min": 26.0, "episode_reward_mean": 33.2, "episode_len_mean": 3.4, "episode_media": {}, "episodes_this_iter": 61, "policy_reward_min": {"policy0": 13.0, "policy1": 13.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.6, "policy1": 16.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 32.0, 34.0, 28.0, 32.0, 32.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 32.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 32.0, 28.0, 34.0, 34.0, 34.0, 26.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [5, 4, 3, 6, 4, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 6, 3, 3, 3, 4, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 4, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 6, 3, 3, 3, 3, 3, 3, 4, 4, 6, 3, 3, 3, 7, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3], "policy_policy0_reward": [15.0, 16.0, 17.0, 14.0, 16.0, 16.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 16.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 14.0, 17.0, 17.0, 17.0, 13.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [15.0, 16.0, 17.0, 14.0, 16.0, 16.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 16.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 14.0, 17.0, 17.0, 17.0, 13.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33426351445692576, "mean_inference_ms": 1.6287939641225488, "mean_action_processing_ms": 0.10777606411340834, "mean_env_wait_ms": 0.07146306298638944, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24332, "timesteps_this_iter": 32, "agent_timesteps_total": 48664, "timers": {"load_time_ms": 0.489, "load_throughput": 65440.14, "learn_time_ms": 7.908, "learn_throughput": 4046.774, "update_time_ms": 5.101}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.441871643066406, "min_q": 0.8215368986129761, "max_q": 18.087295532226562, "mean_td_error": 0.00913470983505249, "model": {}}, "td_error": [1.4573628902435303, 0.5746574401855469, 0.5746574401855469, -0.27515125274658203, -0.07477188110351562, 2.080082416534424, 0.0012340545654296875, -1.974686622619629, 0.545966625213623, -0.8052225112915039, 0.0012340545654296875, 0.1984882354736328, 1.819253921508789, 0.11284637451171875, -2.2936134338378906, 0.029491424560546875, -0.8432035446166992, 0.04238605499267578, 0.04238605499267578, -0.6411275863647461, -1.6510400772094727, 0.0012340545654296875, -1.3151718378067017, 0.9169015884399414, 0.38797950744628906, -0.5388519763946533, -0.3394460678100586, 1.1496086120605469, 0.9831395149230957, -0.9300093650817871, 1.0544624328613281, 0.0012340545654296875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.304978370666504, "min_q": -2.747962474822998, "max_q": 16.631977081298828, "mean_td_error": 0.21301162242889404, "model": {}}, "td_error": [8.179071426391602, 4.491464614868164, 2.349849224090576, -1.7048664093017578, -0.09224319458007812, -3.612544059753418, 3.2159652709960938, -3.8787364959716797, -1.1289281845092773, 0.2936187982559204, 3.167597770690918, -1.2883796691894531, -3.6612465381622314, 5.253652572631836, -2.152000904083252, -1.9050073623657227, 6.210606098175049, -1.2376213073730469, -3.7243916988372803, 1.6462478637695312, -1.8150653839111328, 0.49448585510253906, -0.20781707763671875, 5.4369707107543945, -2.1024012565612793, -2.1124868392944336, -1.3729991912841797, -0.6840982437133789, 0.6707534790039062, 0.30538153648376465, -1.2866599559783936, -0.9317994117736816], "custom_metrics": {}}}, "num_steps_sampled": 24332, "num_agent_steps_sampled": 48664, "num_steps_trained": 69888, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 139776, "last_target_update_ts": 24332, "num_target_updates": 216}, "done": false, "episodes_total": 2691, "training_iteration": 90, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-36", "timestamp": 1648811616, "time_this_iter_s": 1.4789960384368896, "time_total_s": 118.06886625289917, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 118.06886625289917, "timesteps_since_restore": 2880, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 30.03333333333333, "ram_util_percent": 52.1}}
{"episode_reward_max": 34.0, "episode_reward_min": 26.0, "episode_reward_mean": 33.5, "episode_len_mean": 3.25, "episode_media": {}, "episodes_this_iter": 66, "policy_reward_min": {"policy0": 13.0, "policy1": 13.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.75, "policy1": 16.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 32.0, 28.0, 34.0, 34.0, 34.0, 26.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 6, 3, 3, 3, 3, 3, 3, 4, 4, 6, 3, 3, 3, 7, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 5, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 14.0, 17.0, 17.0, 17.0, 13.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 14.0, 17.0, 17.0, 17.0, 13.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3356591547967507, "mean_inference_ms": 1.629524258353783, "mean_action_processing_ms": 0.10781528280737288, "mean_env_wait_ms": 0.07150076850582762, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24539, "timesteps_this_iter": 32, "agent_timesteps_total": 49078, "timers": {"load_time_ms": 0.51, "load_throughput": 62786.045, "learn_time_ms": 8.572, "learn_throughput": 3733.134, "update_time_ms": 5.636}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.164862632751465, "min_q": -1.424133062362671, "max_q": 17.566038131713867, "mean_td_error": 0.10577689111232758, "model": {}}, "td_error": [-0.43822574615478516, -0.8052158355712891, -1.3734626770019531, -2.038503646850586, -1.1090078353881836, 0.003635406494140625, 1.291231393814087, -1.2893266677856445, -0.08600234985351562, 0.8471236228942871, -0.5652103424072266, 1.4551239013671875, -0.011960744857788086, 6.220047950744629, 0.16656494140625, 0.9225964546203613, -0.1028141975402832, 0.7151966094970703, -2.240117073059082, 6.061898708343506, -0.15170717239379883, -0.15532732009887695, 0.9202404022216797, 0.0005784034729003906, 0.7109546661376953, 0.11649703979492188, -0.3170948028564453, 0.2113027572631836, -0.6930546760559082, -0.06241416931152344, 1.415842056274414, -6.234528541564941], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.008376121520996, "min_q": -4.511992931365967, "max_q": 16.982017517089844, "mean_td_error": -0.7278022766113281, "model": {}}, "td_error": [-1.6802072525024414, 0.46565818786621094, -0.28914785385131836, -2.618419885635376, 0.9065485000610352, 1.8873682022094727, -1.4753257036209106, -5.347143173217773, 2.205141067504883, -7.930107116699219, -0.41321420669555664, 3.2001938819885254, 3.7431929111480713, -8.341022491455078, -2.8239879608154297, 0.8873543739318848, -2.1982693672180176, -0.5336380004882812, -0.008962631225585938, -0.6217641830444336, -1.6802072525024414, -1.6802072525024414, -1.0403814315795898, -1.1698846817016602, 1.6963205337524414, 1.4014520645141602, -0.5336380004882812, 5.302595138549805, -0.7942752838134766, -0.7942752838134766, -0.018948078155517578, -2.9924721717834473], "custom_metrics": {}}}, "num_steps_sampled": 24539, "num_agent_steps_sampled": 49078, "num_steps_trained": 70976, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 141952, "last_target_update_ts": 24539, "num_target_updates": 218}, "done": false, "episodes_total": 2757, "training_iteration": 91, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-38", "timestamp": 1648811618, "time_this_iter_s": 1.5137856006622314, "time_total_s": 119.5826518535614, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 119.5826518535614, "timesteps_since_restore": 2912, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 31.25, "ram_util_percent": 52.1}}
{"episode_reward_max": 34.0, "episode_reward_min": 24.0, "episode_reward_mean": 33.0, "episode_len_mean": 3.5, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.5, "policy1": 16.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 28.0, 24.0, 28.0, 28.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 5, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 8, 6, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33671326706862587, "mean_inference_ms": 1.630312733548974, "mean_action_processing_ms": 0.10787869511323116, "mean_env_wait_ms": 0.07154967183670656, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24743, "timesteps_this_iter": 32, "agent_timesteps_total": 49486, "timers": {"load_time_ms": 0.454, "load_throughput": 70492.504, "learn_time_ms": 7.599, "learn_throughput": 4210.977, "update_time_ms": 4.467}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.325776100158691, "min_q": -0.7876037359237671, "max_q": 17.847232818603516, "mean_td_error": 0.582602858543396, "model": {}}, "td_error": [-0.3426036834716797, 0.17209815979003906, 2.3681888580322266, 7.922430992126465, 0.4463958740234375, -0.3319535255432129, -0.07016539573669434, -0.05052375793457031, -0.047827720642089844, -0.12899351119995117, 1.0588431358337402, 0.4267888069152832, 4.922347545623779, -0.35712623596191406, -1.488752841949463, 0.12726974487304688, -0.29911231994628906, 2.8535547256469727, -0.06061267852783203, 1.1833887100219727, -0.8613572120666504, 0.12653636932373047, -0.3862428665161133, -0.35483741760253906, 0.12776947021484375, -3.812506675720215, 0.016384124755859375, -1.6906166076660156, 8.461501121520996, 0.7258633375167847, -2.363898754119873, 0.3510608673095703], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.019104480743408, "min_q": -4.2503180503845215, "max_q": 16.188493728637695, "mean_td_error": -1.5237650871276855, "model": {}}, "td_error": [-1.9578886032104492, -1.0136666297912598, -1.9578886032104492, -1.573770523071289, -2.0347752571105957, 1.9710615873336792, -10.799199104309082, 4.112383842468262, -1.3597874641418457, -0.9472231864929199, -0.8378396034240723, -0.23295879364013672, 1.3244346380233765, -2.996654510498047, -2.366166114807129, -0.6642374992370605, -2.4585442543029785, -1.8788399696350098, -1.9578886032104492, 2.7176809310913086, 2.324404239654541, -2.855674982070923, -0.009453535079956055, -5.342354774475098, 2.8891382217407227, -1.5562691688537598, -9.908591270446777, -0.5864048004150391, -5.298784255981445, -1.3445491790771484, -0.5864028930664062, -1.573770523071289], "custom_metrics": {}}}, "num_steps_sampled": 24743, "num_agent_steps_sampled": 49486, "num_steps_trained": 72064, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 144128, "last_target_update_ts": 24743, "num_target_updates": 220}, "done": false, "episodes_total": 2810, "training_iteration": 92, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-39", "timestamp": 1648811619, "time_this_iter_s": 1.5002412796020508, "time_total_s": 121.08289313316345, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83efe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83efe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 121.08289313316345, "timesteps_since_restore": 2944, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 29.75, "ram_util_percent": 52.1}}
{"episode_reward_max": 34.0, "episode_reward_min": 28.0, "episode_reward_mean": 33.4, "episode_len_mean": 3.3, "episode_media": {}, "episodes_this_iter": 66, "policy_reward_min": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.7, "policy1": 16.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33814722009992937, "mean_inference_ms": 1.6310610948856166, "mean_action_processing_ms": 0.10793989542075107, "mean_env_wait_ms": 0.07160489162207463, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24946, "timesteps_this_iter": 32, "agent_timesteps_total": 49892, "timers": {"load_time_ms": 0.45, "load_throughput": 71044.743, "learn_time_ms": 7.85, "learn_throughput": 4076.456, "update_time_ms": 4.623}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.89968490600586, "min_q": 4.335968494415283, "max_q": 17.709346771240234, "mean_td_error": 0.11890405416488647, "model": {}}, "td_error": [1.5044937133789062, 1.153768539428711, -0.622706413269043, 0.21969032287597656, 0.9166755676269531, -0.41528940200805664, 0.1199941635131836, 1.2851448059082031, 0.9925575256347656, 2.8976874351501465, -0.13885879516601562, 0.33184385299682617, -1.8967194557189941, -1.499063491821289, 0.9771461486816406, 0.6379070281982422, 0.08871078491210938, -1.4590225219726562, -3.420344352722168, -0.1351299285888672, 0.14759540557861328, 0.17311477661132812, 1.6578092575073242, 0.1981372833251953, -0.16268634796142578, 0.48392772674560547, -0.0650339126586914, -0.18089866638183594, -0.06406116485595703, 0.249053955078125, 0.45847606658935547, -0.6289901733398438], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 6.94856071472168, "min_q": -3.4905450344085693, "max_q": 16.797372817993164, "mean_td_error": 0.7534406781196594, "model": {}}, "td_error": [6.117037773132324, -1.314401388168335, 0.3709850311279297, 5.023008346557617, 2.053171157836914, -0.8449782133102417, -0.7363128662109375, 6.079611778259277, 6.117037773132324, -1.8832443952560425, 1.5205501317977905, -0.3869197368621826, -1.7906206846237183, 2.0485925674438477, -2.3563175201416016, 0.09350967407226562, -0.7504119873046875, 1.0174651145935059, 6.041965484619141, -1.682175636291504, -3.686166286468506, -3.528371810913086, -0.5397109985351562, -1.1157166957855225, 2.607417106628418, -0.23552751541137695, -0.8213949203491211, 0.42075252532958984, 1.256948709487915, 6.153326034545898, -1.2808027267456055, 0.14179611206054688], "custom_metrics": {}}}, "num_steps_sampled": 24946, "num_agent_steps_sampled": 49892, "num_steps_trained": 73152, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 146304, "last_target_update_ts": 24849, "num_target_updates": 221}, "done": false, "episodes_total": 2876, "training_iteration": 93, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-41", "timestamp": 1648811621, "time_this_iter_s": 1.4839863777160645, "time_total_s": 122.56687951087952, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010e5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010e5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 122.56687951087952, "timesteps_since_restore": 2976, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 31.4, "ram_util_percent": 52.150000000000006}}
{"episode_reward_max": 34.0, "episode_reward_min": 32.0, "episode_reward_mean": 33.98, "episode_len_mean": 3.01, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.99, "policy1": 16.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33963834122090186, "mean_inference_ms": 1.6318473750383589, "mean_action_processing_ms": 0.1080031201505348, "mean_env_wait_ms": 0.07165160380178615, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25150, "timesteps_this_iter": 32, "agent_timesteps_total": 50300, "timers": {"load_time_ms": 0.444, "load_throughput": 72148.432, "learn_time_ms": 8.105, "learn_throughput": 3948.161, "update_time_ms": 5.014}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.407682418823242, "min_q": -2.134502410888672, "max_q": 17.47691535949707, "mean_td_error": 0.06286823749542236, "model": {}}, "td_error": [0.056301116943359375, 2.25924015045166, -0.11838626861572266, -0.2757568359375, -0.284912109375, -0.11732673645019531, 0.29251527786254883, 0.10895252227783203, -0.04439735412597656, -1.4186639785766602, 3.814697265625e-06, 1.8732671737670898, 3.814697265625e-06, -0.06687402725219727, -0.16828536987304688, -3.8950061798095703, 0.641803503036499, -0.284912109375, 0.060498714447021484, 0.40332603454589844, 1.3651390075683594, 0.015478134155273438, 1.1539387702941895, 0.10184669494628906, 1.0206718444824219, 0.11256599426269531, -1.6266404390335083, 0.016803741455078125, -0.7086629867553711, 0.0951080322265625, -0.21152067184448242, 1.6556644439697266], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 7.679932594299316, "min_q": -1.5310686826705933, "max_q": 16.082042694091797, "mean_td_error": 0.19918453693389893, "model": {}}, "td_error": [-1.615971565246582, 2.7264633178710938, -0.23694515228271484, -2.4404540061950684, 0.5574417114257812, 3.9038753509521484, -0.8303422927856445, 2.2338242530822754, -2.6133174896240234, 0.7235579490661621, -0.6168332099914551, 0.3711061477661133, 3.657095432281494, 0.30679893493652344, -1.9958629608154297, -1.1911964416503906, 1.9980782270431519, 1.577380657196045, -5.177985191345215, 2.0571746826171875, -1.7502551078796387, 4.3324103355407715, -1.085758090019226, 4.59625244140625, -0.49694061279296875, -3.2179675102233887, -0.6190476417541504, 6.204056739807129, -1.860173225402832, -1.173445701599121, -2.7674026489257812, 0.8182878494262695], "custom_metrics": {}}}, "num_steps_sampled": 25150, "num_agent_steps_sampled": 50300, "num_steps_trained": 74240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 148480, "last_target_update_ts": 25054, "num_target_updates": 223}, "done": false, "episodes_total": 2944, "training_iteration": 94, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-42", "timestamp": 1648811622, "time_this_iter_s": 1.5077135562896729, "time_total_s": 124.07459306716919, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83efd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83efd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 124.07459306716919, "timesteps_since_restore": 3008, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 30.0, "ram_util_percent": 52.2}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34104154809797094, "mean_inference_ms": 1.632330795084715, "mean_action_processing_ms": 0.10804862857572817, "mean_env_wait_ms": 0.07168420820163408, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25354, "timesteps_this_iter": 32, "agent_timesteps_total": 50708, "timers": {"load_time_ms": 0.446, "load_throughput": 71747.329, "learn_time_ms": 7.738, "learn_throughput": 4135.273, "update_time_ms": 4.724}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.423425674438477, "min_q": -1.2448276281356812, "max_q": 18.5786190032959, "mean_td_error": 0.3592503070831299, "model": {}}, "td_error": [0.5054130554199219, -0.40598011016845703, 0.3334636688232422, 0.43670129776000977, -0.08565235137939453, -1.1369552612304688, 0.04150247573852539, -0.5495893955230713, 0.3439464569091797, 1.9966068267822266, -0.0961465835571289, -0.42555809020996094, 0.260040283203125, 1.1260128021240234, 0.3426685333251953, 0.04545021057128906, -0.5246410369873047, 1.8979902267456055, 1.7101140022277832, -0.07274532318115234, -0.0847015380859375, -0.0847015380859375, 5.723439693450928, -0.9472079277038574, -0.06074333190917969, -0.07274532318115234, -0.0847015380859375, 0.813140869140625, 0.07826900482177734, 0.6841564178466797, 0.6427097320556641, -0.8535468578338623], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.891578674316406, "min_q": -2.569880723953247, "max_q": 17.79526710510254, "mean_td_error": -1.1664892435073853, "model": {}}, "td_error": [-9.873409271240234, -3.415907859802246, -0.7968974113464355, 0.5461034774780273, -1.8477792739868164, -3.415907859802246, 0.9699301719665527, -11.569880485534668, -3.415907859802246, 0.9760217666625977, -0.37683963775634766, -0.4319477081298828, 2.7036523818969727, 0.1753530502319336, 0.24148178100585938, -3.098517417907715, -0.8910427093505859, -7.131518363952637, -3.415907859802246, 2.60500431060791, -1.5329718589782715, -2.4787168502807617, -0.11592864990234375, 2.270273208618164, 0.7025337219238281, 1.876772403717041, -1.008965015411377, -0.915614128112793, 5.092276573181152, -0.9994268417358398, 0.5461025238037109, 0.6999263763427734], "custom_metrics": {}}}, "num_steps_sampled": 25354, "num_agent_steps_sampled": 50708, "num_steps_trained": 75328, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 150656, "last_target_update_ts": 25258, "num_target_updates": 225}, "done": false, "episodes_total": 3012, "training_iteration": 95, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-44", "timestamp": 1648811624, "time_this_iter_s": 1.4767773151397705, "time_total_s": 125.55137038230896, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010eb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010eb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 125.55137038230896, "timesteps_since_restore": 3040, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 30.266666666666666, "ram_util_percent": 52.20000000000001}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34240689838592026, "mean_inference_ms": 1.632805893772509, "mean_action_processing_ms": 0.10808291314077936, "mean_env_wait_ms": 0.07171583865410326, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25558, "timesteps_this_iter": 32, "agent_timesteps_total": 51116, "timers": {"load_time_ms": 0.446, "load_throughput": 71716.659, "learn_time_ms": 7.959, "learn_throughput": 4020.601, "update_time_ms": 4.799}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.338350296020508, "min_q": -1.248018503189087, "max_q": 17.770977020263672, "mean_td_error": -0.07421077787876129, "model": {}}, "td_error": [-0.38555145263671875, -0.7278804779052734, -0.38555145263671875, -0.17071008682250977, -0.23134613037109375, 0.19666099548339844, 0.11194324493408203, 0.8832083940505981, 0.21654224395751953, 0.19666099548339844, 0.41108834743499756, -0.8146228790283203, 0.3941354751586914, 0.33590126037597656, -0.6088371276855469, -0.07835578918457031, 0.11035346984863281, -1.3178844451904297, 0.01770496368408203, 0.7753152847290039, -0.1723489761352539, -0.3833599090576172, 1.498457431793213, 0.12398433685302734, -0.9800128936767578, -0.5856094360351562, -0.30042362213134766, -0.38358497619628906, 0.11035346984863281, -0.11520004272460938, 0.8445110321044922, -0.9602861404418945], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.924810409545898, "min_q": -1.5988733768463135, "max_q": 17.920373916625977, "mean_td_error": -0.31998398900032043, "model": {}}, "td_error": [1.538956642150879, -2.1369895935058594, -1.8791775703430176, -2.183651924133301, 0.4184086322784424, 0.01854419708251953, 0.10687446594238281, -1.981790542602539, 0.9371155500411987, -2.2912368774414062, 2.2915897369384766, -0.4374732971191406, -4.6196770668029785, -0.07604408264160156, -0.3032724857330322, -2.2912368774414062, 1.1873821020126343, -1.8778138160705566, -0.23100852966308594, 0.9519062042236328, 1.3030743598937988, -1.5929145812988281, -2.2160444259643555, 0.10687446594238281, -0.7400251626968384, 3.3875503540039062, 2.643723487854004, 2.643723487854004, -0.9101433753967285, 0.1776561737060547, -2.291238784790039, 0.10687065124511719], "custom_metrics": {}}}, "num_steps_sampled": 25558, "num_agent_steps_sampled": 51116, "num_steps_trained": 76416, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 152832, "last_target_update_ts": 25462, "num_target_updates": 227}, "done": false, "episodes_total": 3080, "training_iteration": 96, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-45", "timestamp": 1648811625, "time_this_iter_s": 1.4788506031036377, "time_total_s": 127.0302209854126, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 127.0302209854126, "timesteps_since_restore": 3072, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 30.0, "ram_util_percent": 52.25}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.343721781026958, "mean_inference_ms": 1.6331164501880497, "mean_action_processing_ms": 0.10810985953279836, "mean_env_wait_ms": 0.07173426860889301, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25762, "timesteps_this_iter": 32, "agent_timesteps_total": 51524, "timers": {"load_time_ms": 0.423, "load_throughput": 75730.818, "learn_time_ms": 7.422, "learn_throughput": 4311.787, "update_time_ms": 4.605}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.299798011779785, "min_q": 2.836411952972412, "max_q": 17.685327529907227, "mean_td_error": 0.15181942284107208, "model": {}}, "td_error": [-0.663994312286377, 1.758523941040039, -0.8526992797851562, -1.0925846099853516, 0.6279845237731934, -2.2789440155029297, 0.38678932189941406, 0.856877326965332, 2.063039779663086, 1.2514925003051758, 1.839402198791504, 1.0465121269226074, -0.6739768981933594, 0.4401431083679199, 0.09041404724121094, 1.0898165702819824, -0.2997150421142578, -0.2504005432128906, -0.6739768981933594, 0.6488876342773438, -0.2997150421142578, 0.38678932189941406, -0.5014190673828125, -0.7701921463012695, -0.7928495407104492, 1.3920507431030273, -0.4156055450439453, 0.2899904251098633, -0.2997150421142578, -0.39783477783203125, 0.6974468231201172, 0.25568389892578125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.851680755615234, "min_q": -2.3862056732177734, "max_q": 18.122119903564453, "mean_td_error": 0.5819141864776611, "model": {}}, "td_error": [-2.641035556793213, -0.45777034759521484, 3.3092308044433594, 2.2845773696899414, -0.7533669471740723, -0.45777034759521484, 0.28173255920410156, 2.980393171310425, 0.28173255920410156, 0.9291889667510986, 2.7474613189697266, 0.0004673004150390625, -0.45777034759521484, -1.3769187927246094, 3.3092308044433594, -0.5470271110534668, 0.40226078033447266, 0.3290867805480957, -0.45777034759521484, -0.5286350250244141, 2.3819379806518555, -0.48127079010009766, -2.020106315612793, 4.0995378494262695, -0.5190029144287109, 0.28173255920410156, 4.203096866607666, -0.4454253911972046, 0.34348487854003906, -0.4881610870361328, -0.7381601333618164, 2.826292037963867], "custom_metrics": {}}}, "num_steps_sampled": 25762, "num_agent_steps_sampled": 51524, "num_steps_trained": 77504, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 155008, "last_target_update_ts": 25666, "num_target_updates": 229}, "done": false, "episodes_total": 3148, "training_iteration": 97, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-47", "timestamp": 1648811627, "time_this_iter_s": 1.4511752128601074, "time_total_s": 128.4813961982727, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 128.4813961982727, "timesteps_since_restore": 3104, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 30.8, "ram_util_percent": 52.3}}
{"episode_reward_max": 34.0, "episode_reward_min": 32.0, "episode_reward_mean": 33.88, "episode_len_mean": 3.06, "episode_media": {}, "episodes_this_iter": 66, "policy_reward_min": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.94, "policy1": 16.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34488114305670226, "mean_inference_ms": 1.6330913485118301, "mean_action_processing_ms": 0.10811087436473628, "mean_env_wait_ms": 0.0717361794403284, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25966, "timesteps_this_iter": 32, "agent_timesteps_total": 51932, "timers": {"load_time_ms": 0.444, "load_throughput": 72094.176, "learn_time_ms": 7.415, "learn_throughput": 4315.294, "update_time_ms": 4.754}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.20468521118164, "min_q": 2.0992326736450195, "max_q": 17.18553352355957, "mean_td_error": -0.378124475479126, "model": {}}, "td_error": [0.14053058624267578, -0.43143653869628906, -0.1893024444580078, -0.5519256591796875, -2.0222153663635254, -0.33851099014282227, -1.0572710037231445, -0.1812124252319336, -0.1947951316833496, 0.9139566421508789, -0.3907604217529297, -0.7726316452026367, 0.22774457931518555, -2.2759621143341064, -5.172881126403809, 1.8913592100143433, 1.0676398277282715, 1.252962589263916, -0.3907604217529297, -0.5441951751708984, -0.5597925186157227, 0.7602710723876953, 0.40465545654296875, 5.278876304626465, -0.43143653869628906, -0.43143653869628906, 0.42479705810546875, -0.5568327903747559, -9.050495147705078, 2.3506383895874023, -0.3809370994567871, -0.8886241912841797], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.6758451461792, "min_q": -1.191933274269104, "max_q": 17.459678649902344, "mean_td_error": -0.06376908719539642, "model": {}}, "td_error": [-4.416545867919922, 2.1554336547851562, 0.7815084457397461, -0.29082489013671875, 2.4656496047973633, 5.684493541717529, -1.2942085266113281, -0.7147645950317383, -2.3853530883789062, -0.4175891876220703, 1.953801155090332, 1.5877819061279297, 1.800100326538086, -0.7147645950317383, -2.2292609214782715, -1.4781789779663086, -0.5986447334289551, -1.6278605461120605, 0.5011844635009766, -1.807440996170044, 0.11540025472640991, -0.358245849609375, 0.37185096740722656, -0.14791631698608398, -0.358245849609375, 2.1554336547851562, -1.3588368892669678, 3.7551209926605225, -0.4175891876220703, -3.6197457313537598, -0.4175872802734375, -0.7147655487060547], "custom_metrics": {}}}, "num_steps_sampled": 25966, "num_agent_steps_sampled": 51932, "num_steps_trained": 78656, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 157312, "last_target_update_ts": 25870, "num_target_updates": 231}, "done": false, "episodes_total": 3214, "training_iteration": 98, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-48", "timestamp": 1648811628, "time_this_iter_s": 1.474266767501831, "time_total_s": 129.95566296577454, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 129.95566296577454, "timesteps_since_restore": 3136, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 29.15, "ram_util_percent": 52.3}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3461608479286437, "mean_inference_ms": 1.63351863696774, "mean_action_processing_ms": 0.10816098055030145, "mean_env_wait_ms": 0.0717660709818024, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26170, "timesteps_this_iter": 32, "agent_timesteps_total": 52340, "timers": {"load_time_ms": 0.503, "load_throughput": 63586.189, "learn_time_ms": 7.947, "learn_throughput": 4026.85, "update_time_ms": 4.727}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.712922096252441, "min_q": -1.1367013454437256, "max_q": 17.2282772064209, "mean_td_error": 0.37599605321884155, "model": {}}, "td_error": [1.168513298034668, 0.34929466247558594, 0.22263622283935547, -0.4088134765625, -0.6567449569702148, -0.4088134765625, -1.2215690612792969, -2.7415194511413574, -0.13670134544372559, -0.5908184051513672, 8.147773742675781, 1.3471708297729492, -0.3751811981201172, 1.4368867874145508, -0.1960926055908203, -0.41155433654785156, 0.13188886642456055, 0.1331954002380371, -0.03806352615356445, -1.4320054054260254, -0.7580118179321289, 2.422231435775757, -0.13430070877075195, -0.6610965728759766, 0.7715091705322266, 6.836296081542969, -0.4656534194946289, -0.39882564544677734, 0.796666145324707, -0.594700813293457, 0.23931026458740234, -0.3410320281982422], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.025615692138672, "min_q": -0.6494414210319519, "max_q": 17.577266693115234, "mean_td_error": 0.48486390709877014, "model": {}}, "td_error": [-3.2666337490081787, -1.4463963508605957, 0.8510071039199829, -0.35138988494873047, 2.9348278045654297, 2.55739688873291, 0.8099184036254883, 2.0658349990844727, 2.8416833877563477, 3.775570869445801, 2.8416833877563477, 3.8926329612731934, -2.0319161415100098, 4.665323257446289, -5.849040985107422, 1.2289457321166992, 2.2816667556762695, 3.139484167098999, -0.35138988494873047, 2.8416833877563477, 1.0213568210601807, 0.8481637239456177, -3.296082019805908, -0.4016227722167969, 1.1671605110168457, -0.3417072296142578, -0.08906745910644531, -2.780449390411377, -0.2118387222290039, 3.359595775604248, -1.5463271141052246, -5.644426345825195], "custom_metrics": {}}}, "num_steps_sampled": 26170, "num_agent_steps_sampled": 52340, "num_steps_trained": 79744, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 159488, "last_target_update_ts": 26074, "num_target_updates": 233}, "done": false, "episodes_total": 3282, "training_iteration": 99, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-50", "timestamp": 1648811630, "time_this_iter_s": 1.4922840595245361, "time_total_s": 131.44794702529907, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83cd950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 131.44794702529907, "timesteps_since_restore": 3168, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 28.25, "ram_util_percent": 52.3}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34755457022592273, "mean_inference_ms": 1.6344783820735262, "mean_action_processing_ms": 0.1082521599017287, "mean_env_wait_ms": 0.0718156653651699, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26374, "timesteps_this_iter": 32, "agent_timesteps_total": 52748, "timers": {"load_time_ms": 0.427, "load_throughput": 74948.474, "learn_time_ms": 7.74, "learn_throughput": 4134.585, "update_time_ms": 4.568}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.501140594482422, "min_q": -0.06949537992477417, "max_q": 17.47286605834961, "mean_td_error": 0.5065920352935791, "model": {}}, "td_error": [1.6919927597045898, 0.6779727935791016, 0.6779727935791016, 1.0108261108398438, 0.12317276000976562, 0.05347251892089844, 0.7452206611633301, 0.18864059448242188, 1.0168406963348389, 0.7753286361694336, -0.5202713012695312, 0.4356050491333008, -0.4389982223510742, 0.12317276000976562, 0.15291309356689453, -0.5600643157958984, -0.4389982223510742, 0.732903003692627, -0.2419910430908203, 0.13410472869873047, -1.9642763137817383, 1.8148860931396484, 0.15564966201782227, 0.010412216186523438, 0.552928626537323, 8.635231018066406, 1.7104873657226562, -0.5683364868164062, 0.44861412048339844, -0.44048595428466797, -0.2419910430908203, -0.2419910430908203], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.138473510742188, "min_q": -3.772608757019043, "max_q": 17.731401443481445, "mean_td_error": 0.5823052525520325, "model": {}}, "td_error": [-1.6083803176879883, 1.9690656661987305, 1.9115357398986816, 0.3185558319091797, 4.678977012634277, 0.8033464550971985, -0.2124338150024414, 0.5106306076049805, 4.7439093589782715, -1.2901310920715332, -1.8278188705444336, -5.002774238586426, 4.821300506591797, -0.29604530334472656, 5.256839752197266, 1.5621719360351562, 3.459132194519043, 5.256839752197266, -3.514202117919922, -0.29604530334472656, 0.30617761611938477, -0.9858450889587402, 3.282194137573242, -1.4857969284057617, -0.4894218444824219, -0.92279052734375, -0.8672218322753906, 2.185011863708496, -0.4146559238433838, -0.4894218444824219, -1.0574731826782227, -1.671463966369629], "custom_metrics": {}}}, "num_steps_sampled": 26374, "num_agent_steps_sampled": 52748, "num_steps_trained": 80832, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 161664, "last_target_update_ts": 26278, "num_target_updates": 235}, "done": false, "episodes_total": 3350, "training_iteration": 100, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-52", "timestamp": 1648811632, "time_this_iter_s": 1.5261006355285645, "time_total_s": 132.97404766082764, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 132.97404766082764, "timesteps_since_restore": 3200, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 31.866666666666664, "ram_util_percent": 52.333333333333336}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3488799969659897, "mean_inference_ms": 1.6354338577258596, "mean_action_processing_ms": 0.10832503361232863, "mean_env_wait_ms": 0.07186402782038391, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26578, "timesteps_this_iter": 32, "agent_timesteps_total": 53156, "timers": {"load_time_ms": 0.426, "load_throughput": 75200.43, "learn_time_ms": 8.201, "learn_throughput": 3901.848, "update_time_ms": 5.106}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.530974388122559, "min_q": 0.42860138416290283, "max_q": 17.72183609008789, "mean_td_error": 0.48184671998023987, "model": {}}, "td_error": [1.0078125, -0.27774858474731445, 3.0248947143554688, 0.1631631851196289, 0.12409496307373047, 0.029710769653320312, 7.901755332946777, -0.3892698287963867, -0.039746761322021484, 0.24426841735839844, 0.3893766403198242, -0.07900524139404297, -2.073810577392578, -0.07980632781982422, -0.16565704345703125, 0.5316219329833984, 0.14463329315185547, -1.8981785774230957, 0.9058851003646851, 3.694070816040039, 2.7685515880584717, 0.14463329315185547, -0.2535057067871094, 0.1631631851196289, -0.18399429321289062, 0.19756507873535156, -0.010345458984375, 0.029710769653320312, -1.2078351974487305, 0.24426841735839844, 0.24426841735839844, 0.12454986572265625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.394281387329102, "min_q": -1.9425381422042847, "max_q": 17.691856384277344, "mean_td_error": 0.05424024909734726, "model": {}}, "td_error": [-1.4718937873840332, 1.8636131286621094, 0.504788875579834, -1.9598286151885986, -0.7062034606933594, -1.5574913024902344, -4.9662322998046875, -3.63895320892334, 7.035458564758301, -4.476388931274414, -0.5735139846801758, 1.342167854309082, -0.11786937713623047, -0.08477020263671875, 6.379411220550537, -0.08477020263671875, 0.1758289337158203, 0.770482063293457, 1.342167854309082, 3.865893602371216, -2.0934956073760986, 1.2870080471038818, -0.35178279876708984, -0.6840572357177734, -0.6118330955505371, -0.08477020263671875, -0.02092158794403076, 0.171478271484375, -1.5574913024902344, -0.35178279876708984, 0.27067458629608154, 2.12076473236084], "custom_metrics": {}}}, "num_steps_sampled": 26578, "num_agent_steps_sampled": 53156, "num_steps_trained": 81920, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 163840, "last_target_update_ts": 26482, "num_target_updates": 237}, "done": false, "episodes_total": 3418, "training_iteration": 101, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-53", "timestamp": 1648811633, "time_this_iter_s": 1.5097424983978271, "time_total_s": 134.48379015922546, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 134.48379015922546, "timesteps_since_restore": 3232, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 29.85, "ram_util_percent": 52.4}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3500659613630738, "mean_inference_ms": 1.6356518279826966, "mean_action_processing_ms": 0.10833652486327564, "mean_env_wait_ms": 0.07189112131301911, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26782, "timesteps_this_iter": 32, "agent_timesteps_total": 53564, "timers": {"load_time_ms": 0.472, "load_throughput": 67824.412, "learn_time_ms": 7.394, "learn_throughput": 4327.58, "update_time_ms": 4.496}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.432519912719727, "min_q": 3.476055145263672, "max_q": 17.840282440185547, "mean_td_error": 0.10497783869504929, "model": {}}, "td_error": [-1.094869613647461, -0.07267570495605469, -0.20101118087768555, -0.5071282386779785, 0.7454538345336914, 0.33957815170288086, -1.3115243911743164, -1.3390159606933594, -2.012603759765625, -0.48386192321777344, 4.476055145263672, -0.3043403625488281, 0.5544857978820801, 0.5664348602294922, -0.20093202590942383, 1.7081565856933594, 0.25905704498291016, -0.23699188232421875, 2.777095079421997, -0.3224163055419922, 0.11425590515136719, -1.0458641052246094, -0.23699188232421875, 1.1884946823120117, 2.48746395111084, -1.1178524494171143, 0.6505670547485352, -1.0812444686889648, 0.13609933853149414, 0.3588685989379883, -0.10477733612060547, -1.3286738395690918], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.895263671875, "min_q": 0.3020334243774414, "max_q": 17.478899002075195, "mean_td_error": 0.21830391883850098, "model": {}}, "td_error": [0.0031723976135253906, -0.3807544708251953, -2.2674479484558105, 0.03590869903564453, -4.609165191650391, -0.19971942901611328, -0.5252718925476074, 0.03590869903564453, -0.5197982788085938, 0.8490171432495117, 0.03590869903564453, -0.7876186370849609, 6.168485641479492, -0.12864017486572266, 0.03590869903564453, -0.7876186370849609, -0.7876186370849609, 8.097996711730957, -0.3807544708251953, 2.89290189743042, -0.7876186370849609, 0.03590869903564453, -0.5197982788085938, 0.7878987193107605, -0.3807544708251953, -5.2933549880981445, 0.03590869903564453, -0.9843850135803223, 5.628276824951172, -1.3001317977905273, 2.979801654815674, 0.003173351287841797], "custom_metrics": {}}}, "num_steps_sampled": 26782, "num_agent_steps_sampled": 53564, "num_steps_trained": 83008, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 166016, "last_target_update_ts": 26686, "num_target_updates": 239}, "done": false, "episodes_total": 3486, "training_iteration": 102, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-55", "timestamp": 1648811635, "time_this_iter_s": 1.4367523193359375, "time_total_s": 135.9205424785614, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020126c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020126c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 135.9205424785614, "timesteps_since_restore": 3264, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 31.200000000000003, "ram_util_percent": 52.45}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35131806252035874, "mean_inference_ms": 1.6361899003426148, "mean_action_processing_ms": 0.10835974302870381, "mean_env_wait_ms": 0.07192604847887782, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26986, "timesteps_this_iter": 32, "agent_timesteps_total": 53972, "timers": {"load_time_ms": 0.461, "load_throughput": 69416.979, "learn_time_ms": 7.644, "learn_throughput": 4186.259, "update_time_ms": 4.534}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.943889617919922, "min_q": 0.12374550104141235, "max_q": 17.295101165771484, "mean_td_error": -0.388279527425766, "model": {}}, "td_error": [-1.742478847503662, -0.502021312713623, 0.18077468872070312, -0.3865475654602051, -0.5629310607910156, -0.834630012512207, 0.15426158905029297, -0.7392129898071289, -1.9873477220535278, -0.03402423858642578, -3.1824722290039062, -0.8813831806182861, 0.32616984844207764, -0.4333033561706543, -0.014356136322021484, 0.3069782257080078, 0.24672842025756836, -0.5648183822631836, -0.7392129898071289, -1.020406723022461, 0.08776092529296875, 0.5971317291259766, 0.17406845092773438, 0.0033588409423828125, -0.6059966087341309, 0.40296268463134766, 0.15426158905029297, 0.08776092529296875, 0.08776092529296875, -0.5629310607910156, -0.03513145446777344, -0.4057178497314453], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.078071594238281, "min_q": -1.352363109588623, "max_q": 17.997093200683594, "mean_td_error": -0.04667957127094269, "model": {}}, "td_error": [-1.061161994934082, -0.0886392593383789, 0.4847431182861328, -1.0158824920654297, -0.6954231262207031, -1.061161994934082, 0.29358863830566406, -0.11572074890136719, 3.1683244705200195, -0.6803603172302246, 0.4847431182861328, 0.28052473068237305, -1.7669782638549805, -0.7214088439941406, 2.6204776763916016, 3.4340391159057617, -0.8613882064819336, -0.5638303756713867, -1.5631904602050781, 2.0192313194274902, 2.234856128692627, 1.3257341384887695, -1.2790932655334473, 3.058211326599121, 0.29358863830566406, -1.420485496520996, -2.417954206466675, -2.9761581420898438, -6.292162895202637, 1.6254863739013672, 0.323455810546875, 1.4402494430541992], "custom_metrics": {}}}, "num_steps_sampled": 26986, "num_agent_steps_sampled": 53972, "num_steps_trained": 84096, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 168192, "last_target_update_ts": 26890, "num_target_updates": 241}, "done": false, "episodes_total": 3554, "training_iteration": 103, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-56", "timestamp": 1648811636, "time_this_iter_s": 1.5088317394256592, "time_total_s": 137.42937421798706, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 137.42937421798706, "timesteps_since_restore": 3296, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 32.7, "ram_util_percent": 52.8}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35215135587426666, "mean_inference_ms": 1.6374956568839099, "mean_action_processing_ms": 0.10845034432713514, "mean_env_wait_ms": 0.07198366288550752, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27088, "timesteps_this_iter": 32, "agent_timesteps_total": 54176, "timers": {"load_time_ms": 0.581, "load_throughput": 55124.745, "learn_time_ms": 9.425, "learn_throughput": 3395.304, "update_time_ms": 5.792}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.474883079528809, "min_q": -1.475502371788025, "max_q": 18.193946838378906, "mean_td_error": 0.1826658397912979, "model": {}}, "td_error": [0.22196102142333984, -0.3013334274291992, 0.22196102142333984, 0.07051277160644531, -1.500623106956482, 0.49413585662841797, 3.185387134552002, 1.85725736618042, -0.611720085144043, -0.3960585594177246, -2.8608474731445312, -0.8406696319580078, 0.22196102142333984, -0.17005586624145508, 2.6127171516418457, -0.6555924415588379, 0.3250770568847656, 0.3250770568847656, -0.002434253692626953, -2.8608474731445312, 0.22196102142333984, -0.3013334274291992, 5.316021919250488, 0.052608489990234375, 0.22196102142333984, 0.6492195129394531, 2.348269462585449, 0.11438846588134766, -0.8107552528381348, -1.4474921226501465, 0.07408809661865234, 0.07050514221191406], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.591805458068848, "min_q": 0.11606212705373764, "max_q": 17.242877960205078, "mean_td_error": 0.7796016931533813, "model": {}}, "td_error": [-0.7435474395751953, 4.627030849456787, -1.1898269653320312, -0.22982215881347656, 3.4311885833740234, -0.22982215881347656, 2.7749459743499756, -0.768627405166626, -0.32929039001464844, -0.9355449676513672, -0.36289215087890625, 0.3580284118652344, -0.6305723190307617, -0.6945114135742188, 0.6936918497085571, -0.2778778076171875, -0.7435474395751953, -0.32929039001464844, -1.6852455139160156, -0.4275388717651367, 6.611001491546631, 5.510506629943848, 1.093918800354004, -0.32929039001464844, 3.929536819458008, -1.1898269653320312, -0.7512493133544922, 3.5751571655273438, 1.4500470161437988, -2.268850326538086, 5.752928733825684, -0.7435512542724609], "custom_metrics": {}}}, "num_steps_sampled": 27088, "num_agent_steps_sampled": 54176, "num_steps_trained": 84640, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 169280, "last_target_update_ts": 26992, "num_target_updates": 242}, "done": false, "episodes_total": 3588, "training_iteration": 104, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-57", "timestamp": 1648811637, "time_this_iter_s": 0.9589691162109375, "time_total_s": 138.388343334198, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010e4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010e4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 138.388343334198, "timesteps_since_restore": 3328, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 38.05, "ram_util_percent": 53.3}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3530012389772418, "mean_inference_ms": 1.6394324834983092, "mean_action_processing_ms": 0.10859099938220648, "mean_env_wait_ms": 0.07206550798699918, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27190, "timesteps_this_iter": 32, "agent_timesteps_total": 54380, "timers": {"load_time_ms": 0.453, "load_throughput": 70678.108, "learn_time_ms": 8.698, "learn_throughput": 3678.861, "update_time_ms": 5.016}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.6011381149292, "min_q": -1.1519358158111572, "max_q": 17.468461990356445, "mean_td_error": -0.4879900813102722, "model": {}}, "td_error": [-0.30939579010009766, 0.4030733108520508, -1.5125517845153809, 0.13742494583129883, -0.30939579010009766, -0.5296783447265625, -0.5238962173461914, -0.7414164543151855, -1.9585390090942383, -0.694981575012207, -0.4945964813232422, -0.5296783447265625, -0.340484619140625, -2.014134168624878, -0.5296783447265625, -0.30939579010009766, -0.8003406524658203, -0.5698914527893066, 0.6433773040771484, -1.5420856475830078, -0.694981575012207, -0.30939579010009766, -0.2624235153198242, 0.486447811126709, -0.5296783447265625, -0.5296783447265625, -1.2668046951293945, 0.05321669578552246, -0.694981575012207, -1.7676770687103271, 0.8401994705200195, 1.5863385200500488], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 11.110322952270508, "min_q": -1.1972721815109253, "max_q": 18.074859619140625, "mean_td_error": 0.9204657077789307, "model": {}}, "td_error": [0.16351032257080078, -0.24782180786132812, -1.194112777709961, -0.6173677444458008, 2.253371477127075, -1.0596911907196045, 0.16351032257080078, 3.722379684448242, -1.0998954772949219, -0.5037765502929688, -1.1598596572875977, 2.802227020263672, 3.722231864929199, 6.85423469543457, 1.5901923179626465, 0.3186483383178711, 0.0004425048828125, 2.802227020263672, -0.5037765502929688, -2.6378633975982666, 5.222322463989258, -2.233898162841797, -0.18990516662597656, -0.5037765502929688, -0.7759475708007812, 0.6147851943969727, 3.375718116760254, 7.427083969116211, -1.671910285949707, 3.2762928009033203, 0.04910564422607422, -0.5037784576416016], "custom_metrics": {}}}, "num_steps_sampled": 27190, "num_agent_steps_sampled": 54380, "num_steps_trained": 85184, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 170368, "last_target_update_ts": 27094, "num_target_updates": 243}, "done": false, "episodes_total": 3622, "training_iteration": 105, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-13-58", "timestamp": 1648811638, "time_this_iter_s": 1.0076274871826172, "time_total_s": 139.39597082138062, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010e710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010e710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 139.39597082138062, "timesteps_since_restore": 3360, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 44.4, "ram_util_percent": 53.9}}
{"episode_reward_max": 34.0, "episode_reward_min": 28.0, "episode_reward_mean": 33.88, "episode_len_mean": 3.06, "episode_media": {}, "episodes_this_iter": 66, "policy_reward_min": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.94, "policy1": 16.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35608452267645985, "mean_inference_ms": 1.6473441921825316, "mean_action_processing_ms": 0.10906988912332727, "mean_env_wait_ms": 0.0723180354461312, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27394, "timesteps_this_iter": 32, "agent_timesteps_total": 54788, "timers": {"load_time_ms": 0.976, "load_throughput": 32773.601, "learn_time_ms": 14.974, "learn_throughput": 2137.058, "update_time_ms": 12.424}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.352800369262695, "min_q": 1.4363470077514648, "max_q": 18.397287368774414, "mean_td_error": 0.1370566487312317, "model": {}}, "td_error": [0.5709223747253418, 0.43103599548339844, -0.06715583801269531, 0.45772552490234375, -0.6518914699554443, 0.4334087371826172, 0.011240959167480469, -0.29571533203125, 0.45772552490234375, 1.6446046829223633, 0.38999176025390625, 0.05527973175048828, 0.4537992477416992, -0.3125772476196289, 1.224705696105957, -0.3125772476196289, -1.0210990905761719, -0.6605806350708008, 0.004054069519042969, -0.3364238739013672, 0.06642532348632812, -0.06715583801269531, -0.06715583801269531, 0.4320392608642578, 0.004054069519042969, 0.7966756820678711, 0.45772552490234375, -0.5029773712158203, 0.32715606689453125, 0.042858123779296875, 0.4577293395996094, -0.03803539276123047], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.605175971984863, "min_q": 3.7980446815490723, "max_q": 18.485319137573242, "mean_td_error": 0.5122687220573425, "model": {}}, "td_error": [2.5408029556274414, -0.1880359649658203, 3.138598918914795, 1.451223373413086, 2.779444694519043, 2.198126792907715, -1.0757436752319336, 2.468513011932373, -1.3330268859863281, -1.219679832458496, 0.31786537170410156, -0.5299539566040039, -0.6670026779174805, -1.5454139709472656, -1.153080940246582, -3.916576385498047, 2.358950138092041, -0.13956260681152344, 2.977375030517578, -1.1046504974365234, 0.31786537170410156, 0.4495120048522949, -1.219679832458496, 2.1867246627807617, 2.1867246627807617, 0.21520042419433594, 0.4271240234375, 0.6164565086364746, -1.3586063385009766, 2.4682698249816895, 0.4776005744934082, 2.2672338485717773], "custom_metrics": {}}}, "num_steps_sampled": 27394, "num_agent_steps_sampled": 54788, "num_steps_trained": 86272, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 172544, "last_target_update_ts": 27298, "num_target_updates": 245}, "done": false, "episodes_total": 3688, "training_iteration": 106, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-01", "timestamp": 1648811641, "time_this_iter_s": 2.2647926807403564, "time_total_s": 141.66076350212097, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83de0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83de0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 141.66076350212097, "timesteps_since_restore": 3392, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 54.775000000000006, "ram_util_percent": 55.025}}
{"episode_reward_max": 34.0, "episode_reward_min": 28.0, "episode_reward_mean": 33.88, "episode_len_mean": 3.06, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.94, "policy1": 16.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35789634500377693, "mean_inference_ms": 1.6534437885889788, "mean_action_processing_ms": 0.10966814602534627, "mean_env_wait_ms": 0.07248106336922847, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27496, "timesteps_this_iter": 32, "agent_timesteps_total": 54992, "timers": {"load_time_ms": 0.701, "load_throughput": 45664.714, "learn_time_ms": 9.907, "learn_throughput": 3229.967, "update_time_ms": 5.891}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 12.950725555419922, "min_q": 6.284754753112793, "max_q": 18.060821533203125, "mean_td_error": 0.06979347765445709, "model": {}}, "td_error": [-0.5427494049072266, -0.5555925369262695, 0.8595232963562012, 0.7689228057861328, -0.5056180953979492, -0.02195453643798828, -0.5427494049072266, 0.22693538665771484, -0.2780427932739258, 1.9723210334777832, -0.7883052825927734, -0.35310935974121094, 0.6866827011108398, -0.015544891357421875, 2.08819580078125, -0.5553646087646484, -0.6796627044677734, 0.5494112968444824, -0.02195453643798828, -0.19718694686889648, -0.45250892639160156, -0.4968833923339844, -0.12873268127441406, -0.5335073471069336, -0.5553646087646484, -1.1286611557006836, 1.3997068405151367, 0.4873948097229004, 0.7663755416870117, 0.81890869140625, -0.02195453643798828, -0.015539169311523438], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.50581169128418, "min_q": 1.586151361465454, "max_q": 16.913673400878906, "mean_td_error": -0.8255926370620728, "model": {}}, "td_error": [2.245245933532715, -0.6927556991577148, 0.22058725357055664, -0.8353462219238281, -3.752537727355957, -0.5235633850097656, -0.3873419761657715, -2.637270927429199, 3.4736223220825195, -1.9403071403503418, -0.5235633850097656, -1.3200740814208984, -1.6602869033813477, -2.4533519744873047, 0.014066696166992188, -0.1674365997314453, -1.1682848930358887, -0.7482600212097168, -0.8907618522644043, -1.1853046417236328, -0.919830322265625, -1.7476224899291992, 0.5958347320556641, -0.060637474060058594, 0.34731626510620117, -0.9639432430267334, -0.16632366180419922, -2.575615882873535, -2.544626235961914, -1.4032135009765625, -1.1275463104248047, -0.919830322265625], "custom_metrics": {}}}, "num_steps_sampled": 27496, "num_agent_steps_sampled": 54992, "num_steps_trained": 86816, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 173632, "last_target_update_ts": 27400, "num_target_updates": 246}, "done": false, "episodes_total": 3722, "training_iteration": 107, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-02", "timestamp": 1648811642, "time_this_iter_s": 1.5910544395446777, "time_total_s": 143.25181794166565, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c00e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c00e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 143.25181794166565, "timesteps_since_restore": 3424, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 93.1, "ram_util_percent": 59.099999999999994}}
{"episode_reward_max": 34.0, "episode_reward_min": 28.0, "episode_reward_mean": 33.88, "episode_len_mean": 3.06, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.94, "policy1": 16.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.35911356092072455, "mean_inference_ms": 1.6577352106535925, "mean_action_processing_ms": 0.11030233653512318, "mean_env_wait_ms": 0.07260997570249803, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27598, "timesteps_this_iter": 32, "agent_timesteps_total": 55196, "timers": {"load_time_ms": 0.557, "load_throughput": 57451.3, "learn_time_ms": 9.693, "learn_throughput": 3301.188, "update_time_ms": 6.191}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 11.590156555175781, "min_q": 5.24210262298584, "max_q": 18.01028823852539, "mean_td_error": 0.3434363007545471, "model": {}}, "td_error": [-0.1647047996520996, -0.21584320068359375, -0.3149385452270508, 0.4017186164855957, 0.17939424514770508, 0.8448257446289062, -0.10042476654052734, 0.43752479553222656, -0.10042476654052734, -0.09553718566894531, -0.26399993896484375, -0.36623668670654297, -0.09553718566894531, 0.7300243377685547, -0.16072654724121094, 0.007832527160644531, -0.16072654724121094, -0.08647918701171875, 0.201324462890625, 0.2815389633178711, 0.7264471054077148, -0.10042476654052734, -0.43198108673095703, -0.9514427185058594, 10.97131633758545, -0.32175445556640625, -0.16072654724121094, -0.012675285339355469, -0.014011859893798828, -0.0017271041870117188, 0.42387962341308594, -0.09554100036621094], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.094032287597656, "min_q": -1.378782868385315, "max_q": 17.5616455078125, "mean_td_error": 0.37497302889823914, "model": {}}, "td_error": [0.5707368850708008, -0.6454334259033203, -0.796471118927002, -0.031113147735595703, -0.6919412612915039, -0.37878286838531494, -0.24799728393554688, -0.6397037506103516, 1.489288330078125, -1.2441725730895996, -0.2556133270263672, 1.4214801788330078, -0.24799728393554688, -0.08195877075195312, 1.3834590911865234, -0.08195877075195312, -0.01727581024169922, 0.7428503036499023, -0.6454334259033203, -2.1352033615112305, 9.73957633972168, -0.35723114013671875, 3.0718371868133545, 5.003528118133545, -0.19594621658325195, 1.3465995788574219, -0.2556133270263672, -1.16111421585083, -0.4031505584716797, 0.5273904800415039, -1.4132637977600098, -1.3702340126037598], "custom_metrics": {}}}, "num_steps_sampled": 27598, "num_agent_steps_sampled": 55196, "num_steps_trained": 87360, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 174720, "last_target_update_ts": 27502, "num_target_updates": 247}, "done": false, "episodes_total": 3756, "training_iteration": 108, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-03", "timestamp": 1648811643, "time_this_iter_s": 0.9664218425750732, "time_total_s": 144.21823978424072, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 144.21823978424072, "timesteps_since_restore": 3456, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 43.15, "ram_util_percent": 60.25}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3607144357418804, "mean_inference_ms": 1.6627432752163585, "mean_action_processing_ms": 0.11098512895735273, "mean_env_wait_ms": 0.0727764631775522, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27700, "timesteps_this_iter": 32, "agent_timesteps_total": 55400, "timers": {"load_time_ms": 0.557, "load_throughput": 57402.159, "learn_time_ms": 9.254, "learn_throughput": 3457.892, "update_time_ms": 6.147}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 11.765886306762695, "min_q": -0.10661345720291138, "max_q": 17.834718704223633, "mean_td_error": 0.33204108476638794, "model": {}}, "td_error": [0.3916454315185547, 0.5067678093910217, -0.4892559051513672, 0.35164642333984375, 1.2759952545166016, 0.45061492919921875, 1.8242759704589844, 3.159999370574951, 0.3400764465332031, -0.04437065124511719, -0.10126304626464844, 0.12268352508544922, -0.6933803558349609, -1.7024028301239014, 0.2650637626647949, 0.17450714111328125, 0.6055793762207031, 2.0712461471557617, -0.04437065124511719, 0.24678421020507812, -0.2075214385986328, 0.24678421020507812, -0.28658199310302734, -1.0679197311401367, 0.4002809524536133, -0.07530784606933594, 1.6953601837158203, -0.022580623626708984, 0.7636756896972656, -0.10126304626464844, -0.044368743896484375, 0.6129155158996582], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.165305137634277, "min_q": -1.1933177709579468, "max_q": 18.127397537231445, "mean_td_error": -0.14629031717777252, "model": {}}, "td_error": [1.4618124961853027, 0.3398113250732422, 0.6450357437133789, -2.205717086791992, -10.193317413330078, -1.0651297569274902, 0.3398113250732422, 1.0319409370422363, 0.3398113250732422, -0.2813100814819336, 2.906001329421997, 0.4641914367675781, -0.6964199542999268, -2.454315662384033, -0.5587034225463867, -0.4537630081176758, -0.5637063980102539, -0.4537630081176758, -0.38248443603515625, -3.145510673522949, 0.9158935546875, -0.38248443603515625, 0.05479109287261963, 1.720895767211914, 0.6450357437133789, 0.7162790298461914, -1.1026268005371094, 0.6450357437133789, 1.979194164276123, 1.5818309783935547, 3.1307783126831055, 0.3398113250732422], "custom_metrics": {}}}, "num_steps_sampled": 27700, "num_agent_steps_sampled": 55400, "num_steps_trained": 87904, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 175808, "last_target_update_ts": 27604, "num_target_updates": 248}, "done": false, "episodes_total": 3790, "training_iteration": 109, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-04", "timestamp": 1648811644, "time_this_iter_s": 0.9414052963256836, "time_total_s": 145.1596450805664, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 145.1596450805664, "timesteps_since_restore": 3488, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 40.7, "ram_util_percent": 60.7}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3618686369475026, "mean_inference_ms": 1.6654727210929492, "mean_action_processing_ms": 0.11130816673309213, "mean_env_wait_ms": 0.07289495896931025, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27802, "timesteps_this_iter": 32, "agent_timesteps_total": 55604, "timers": {"load_time_ms": 0.579, "load_throughput": 55249.548, "learn_time_ms": 9.803, "learn_throughput": 3264.209, "update_time_ms": 6.732}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.378530502319336, "min_q": 1.9687581062316895, "max_q": 18.628419876098633, "mean_td_error": 0.6709671020507812, "model": {}}, "td_error": [0.1782855987548828, -0.5234365463256836, 0.7511472702026367, 2.6003379821777344, 0.22408103942871094, 0.1782855987548828, -0.15840625762939453, 0.16165447235107422, 0.02858257293701172, 0.4256572723388672, 0.6349494457244873, -0.1006622314453125, -0.19133996963500977, 0.4256572723388672, 0.15778255462646484, 0.546051025390625, 1.07293701171875, 6.9959917068481445, 0.8940753936767578, 0.9629697799682617, -0.33585166931152344, 0.3210258483886719, -1.10498046875, 0.2665553092956543, -0.1006622314453125, 0.6413958072662354, 3.082613706588745, 2.7964158058166504, 0.7203407287597656, -0.03969144821166992, -0.2191004753112793, 0.1782855987548828], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.823736190795898, "min_q": -2.8259477615356445, "max_q": 18.132497787475586, "mean_td_error": -0.30599263310432434, "model": {}}, "td_error": [0.6770620346069336, 3.487238645553589, -3.6108932495117188, -2.297567367553711, -0.7363457679748535, -1.249654769897461, 0.18018817901611328, -1.0655336380004883, -1.0655336380004883, 1.7337379455566406, -0.17928504943847656, 0.18018817901611328, -1.0655336380004883, -0.9164533615112305, -0.6645717620849609, -0.17928504943847656, -0.8043098449707031, -0.13896560668945312, 0.8209238052368164, -0.9478626251220703, -1.365659236907959, -0.7630167007446289, 0.15665817260742188, -0.3182675838470459, 1.5770692825317383, 1.5770692825317383, -0.9164533615112305, -1.572946548461914, -2.391481399536133, 2.003739356994629, -1.2847900390625, 1.348771095275879], "custom_metrics": {}}}, "num_steps_sampled": 27802, "num_agent_steps_sampled": 55604, "num_steps_trained": 88448, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 176896, "last_target_update_ts": 27706, "num_target_updates": 249}, "done": false, "episodes_total": 3824, "training_iteration": 110, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-06", "timestamp": 1648811646, "time_this_iter_s": 0.982140064239502, "time_total_s": 146.1417851448059, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020126440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020126440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 146.1417851448059, "timesteps_since_restore": 3520, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 40.900000000000006, "ram_util_percent": 61.099999999999994}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36463818631121375, "mean_inference_ms": 1.6725590033001878, "mean_action_processing_ms": 0.11183635853587298, "mean_env_wait_ms": 0.07319662092175179, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28006, "timesteps_this_iter": 32, "agent_timesteps_total": 56012, "timers": {"load_time_ms": 0.683, "load_throughput": 46839.2, "learn_time_ms": 10.632, "learn_throughput": 3009.778, "update_time_ms": 7.021}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.728208541870117, "min_q": 2.3994948863983154, "max_q": 18.113245010375977, "mean_td_error": 0.4734596610069275, "model": {}}, "td_error": [0.4753098487854004, 0.7502470016479492, -0.6772093772888184, -0.034951210021972656, 2.0293121337890625, 0.2321786880493164, -0.15713024139404297, -0.034951210021972656, -0.034951210021972656, 0.03040313720703125, -0.5768413543701172, 0.9327106475830078, 0.054927825927734375, 0.03342294692993164, -5.008996963500977, -0.034951210021972656, -0.0013914108276367188, 2.350078582763672, 0.3150815963745117, -0.09434986114501953, 0.4291839599609375, 2.417572021484375, 0.4172029495239258, 8.417230606079102, -0.5768413543701172, 0.24263954162597656, 0.24263954162597656, 0.24263954162597656, 2.1892781257629395, 0.24263954162597656, 0.02579498291015625, 0.31278228759765625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 11.526248931884766, "min_q": -0.9019485712051392, "max_q": 17.963077545166016, "mean_td_error": 0.6368125677108765, "model": {}}, "td_error": [1.4879703521728516, -1.6159441471099854, 2.266388416290283, -6.7431511878967285, 1.1404180526733398, 0.15920448303222656, -2.934390068054199, 3.9804468154907227, 0.07934188842773438, -0.306782603263855, 0.5801496505737305, -0.2766456604003906, 4.377141952514648, -0.9773797988891602, 1.8534822463989258, 1.9573183059692383, 3.841749668121338, -0.4578971862792969, 0.7191877365112305, 1.6054542064666748, 1.2258920669555664, -0.40357112884521484, 2.2488603591918945, -0.2766456604003906, 0.36028480529785156, 2.3864402770996094, 0.33936309814453125, 3.7339649200439453, -2.6118381023406982, 2.11968994140625, 0.3602886199951172, 0.1592082977294922], "custom_metrics": {}}}, "num_steps_sampled": 28006, "num_agent_steps_sampled": 56012, "num_steps_trained": 89536, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 179072, "last_target_update_ts": 27910, "num_target_updates": 251}, "done": false, "episodes_total": 3892, "training_iteration": 111, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-08", "timestamp": 1648811648, "time_this_iter_s": 1.9835398197174072, "time_total_s": 148.12532496452332, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83de440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83de440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 148.12532496452332, "timesteps_since_restore": 3552, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 43.05, "ram_util_percent": 61.849999999999994}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3657401103863824, "mean_inference_ms": 1.675419250849766, "mean_action_processing_ms": 0.11204242174610482, "mean_env_wait_ms": 0.07331385273664319, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28108, "timesteps_this_iter": 32, "agent_timesteps_total": 56216, "timers": {"load_time_ms": 0.507, "load_throughput": 63090.029, "learn_time_ms": 9.064, "learn_throughput": 3530.466, "update_time_ms": 6.611}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.657224655151367, "min_q": 3.011199951171875, "max_q": 17.385129928588867, "mean_td_error": 0.0009992346167564392, "model": {}}, "td_error": [-0.7053308486938477, 0.25134754180908203, -0.20735645294189453, 0.04904460906982422, -0.6141281127929688, 0.27573156356811523, 0.1704273223876953, -0.3779125213623047, -0.3434467315673828, -0.47039270401000977, 0.15756607055664062, 0.13898849487304688, -0.15821456909179688, -0.9191045761108398, -0.033893585205078125, 0.8633623123168945, -0.16917657852172852, -0.5491247177124023, 1.0369648933410645, 0.43325138092041016, 0.12759780883789062, 0.2152576446533203, -0.6141281127929688, 1.279144287109375, 0.043999671936035156, -0.9678754806518555, 0.04904460906982422, 0.012782573699951172, 0.27179646492004395, 2.1163291931152344, -0.5267238616943359, -0.8038520812988281], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.637535095214844, "min_q": 0.8121001124382019, "max_q": 17.298158645629883, "mean_td_error": 0.3082689642906189, "model": {}}, "td_error": [-0.38214778900146484, 2.3676741123199463, -0.4677896499633789, -0.4500904083251953, 0.09386634826660156, 0.10965442657470703, -0.8606686592102051, 0.8748822212219238, 0.04534721374511719, -0.4500904083251953, 0.09386634826660156, -1.9004740715026855, 0.04534721374511719, -1.7289867401123047, -0.38214778900146484, 3.7318084239959717, 0.04534721374511719, -0.38214778900146484, 3.717219352722168, -0.7990455627441406, -0.4500904083251953, -0.11753082275390625, -0.38214778900146484, 2.6448025703430176, 2.942615509033203, -0.11753082275390625, -0.8179749250411987, -1.2863678932189941, 1.3607679605484009, -0.38214778900146484, 3.2663207054138184, -0.11753273010253906], "custom_metrics": {}}}, "num_steps_sampled": 28108, "num_agent_steps_sampled": 56216, "num_steps_trained": 90080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 180160, "last_target_update_ts": 28012, "num_target_updates": 252}, "done": false, "episodes_total": 3926, "training_iteration": 112, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-09", "timestamp": 1648811649, "time_this_iter_s": 0.9571988582611084, "time_total_s": 149.08252382278442, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 149.08252382278442, "timesteps_since_restore": 3584, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 39.55, "ram_util_percent": 62.2}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3673610629412745, "mean_inference_ms": 1.6784697680265905, "mean_action_processing_ms": 0.11227103353146595, "mean_env_wait_ms": 0.07343256609443138, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28312, "timesteps_this_iter": 32, "agent_timesteps_total": 56624, "timers": {"load_time_ms": 0.483, "load_throughput": 66214.962, "learn_time_ms": 8.346, "learn_throughput": 3834.321, "update_time_ms": 5.346}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 12.379146575927734, "min_q": 3.4879307746887207, "max_q": 18.079330444335938, "mean_td_error": 0.8179231882095337, "model": {}}, "td_error": [4.244068145751953, 0.2479257583618164, 1.2821760177612305, 0.5106711387634277, 0.13973426818847656, 0.16023826599121094, 0.5268173217773438, -0.03212547302246094, 0.04497718811035156, 0.15457582473754883, -0.9327940940856934, 0.009710311889648438, 2.8369598388671875, 3.130638599395752, 0.5811424255371094, -0.19289875030517578, 8.376919746398926, 4.487930774688721, -1.5588436126708984, 0.13973426818847656, 0.16023826599121094, 0.04497718811035156, 2.944424629211426, 0.04497718811035156, 0.16023826599121094, 0.16023826599121094, -0.8092732429504395, 0.2928600311279297, 0.009710311889648438, -0.22675800323486328, -0.4293994903564453, -0.33624839782714844], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.91433334350586, "min_q": -2.036345958709717, "max_q": 17.77707290649414, "mean_td_error": -0.009869039058685303, "model": {}}, "td_error": [-0.23769378662109375, -0.5850238800048828, -0.09538650512695312, -1.783731460571289, 1.8636374473571777, -1.4282007217407227, 2.789639472961426, -1.6115379333496094, -0.16949462890625, -0.18845462799072266, 1.1268224716186523, -3.0377657413482666, -0.5850238800048828, -1.0363459587097168, -1.6285929679870605, 3.9088306427001953, -1.5059003829956055, 2.9185104370117188, -2.5849685668945312, 0.6042108535766602, 0.18687057495117188, -0.06760787963867188, 3.4379913806915283, -0.5850238800048828, 0.37142229080200195, 0.22287750244140625, 3.292435884475708, -2.2257776260375977, 0.11223840713500977, 0.18687057495117188, -1.61981999874115, -0.3618173599243164], "custom_metrics": {}}}, "num_steps_sampled": 28312, "num_agent_steps_sampled": 56624, "num_steps_trained": 91168, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 182336, "last_target_update_ts": 28216, "num_target_updates": 254}, "done": false, "episodes_total": 3994, "training_iteration": 113, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-10", "timestamp": 1648811650, "time_this_iter_s": 1.6568498611450195, "time_total_s": 150.73937368392944, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020126440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020126440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 150.73937368392944, "timesteps_since_restore": 3616, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 39.25, "ram_util_percent": 62.75}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.36880974283196316, "mean_inference_ms": 1.6805405948540908, "mean_action_processing_ms": 0.11242583228357571, "mean_env_wait_ms": 0.07352739878667162, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28516, "timesteps_this_iter": 32, "agent_timesteps_total": 57032, "timers": {"load_time_ms": 0.482, "load_throughput": 66365.57, "learn_time_ms": 8.985, "learn_throughput": 3561.682, "update_time_ms": 5.662}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.65644645690918, "min_q": -0.5855923891067505, "max_q": 17.47077178955078, "mean_td_error": 0.22272047400474548, "model": {}}, "td_error": [-1.1159367561340332, -0.05482673645019531, 0.032221317291259766, -0.6959676742553711, -0.23948955535888672, -1.416788101196289, 0.4293484687805176, 0.7381691932678223, -0.4195232391357422, 0.581934928894043, 0.581934928894043, -5.605388641357422, 1.056790828704834, 2.044928550720215, -0.4988727569580078, 0.20688915252685547, -0.289186954498291, 1.052755355834961, 1.831493616104126, -0.7470664978027344, 0.25075775384902954, -0.7744789123535156, 4.692395210266113, 7.6085309982299805, -0.4206886291503906, 1.0022649765014648, -0.23948955535888672, -0.7201499938964844, 0.0099029541015625, 0.41820597648620605, -1.7540931701660156, -0.4195213317871094], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.167320251464844, "min_q": 0.17990799248218536, "max_q": 18.184112548828125, "mean_td_error": 0.3846641480922699, "model": {}}, "td_error": [0.006224393844604492, -0.12558817863464355, -6.39587926864624, -0.37346839904785156, 2.0114517211914062, 0.7771005630493164, 1.179908037185669, 1.5624971389770508, -0.805699348449707, -0.4045586585998535, 3.164684295654297, -0.09880447387695312, -0.3017559051513672, 1.8401155471801758, 2.8985257148742676, -0.7993831634521484, -0.5220279693603516, -0.7220668792724609, -0.37346839904785156, 4.33591365814209, 0.2979774475097656, -0.3642463684082031, 1.8675556182861328, 0.9341907501220703, 2.4669594764709473, 3.164684295654297, -0.5220279693603516, -3.402559280395508, -1.506148338317871, -0.11644959449768066, 3.164684295654297, -0.5290884971618652], "custom_metrics": {}}}, "num_steps_sampled": 28516, "num_agent_steps_sampled": 57032, "num_steps_trained": 92256, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 184512, "last_target_update_ts": 28420, "num_target_updates": 256}, "done": false, "episodes_total": 4062, "training_iteration": 114, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-12", "timestamp": 1648811652, "time_this_iter_s": 1.6560804843902588, "time_total_s": 152.3954541683197, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8766170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 152.3954541683197, "timesteps_since_restore": 3648, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 40.699999999999996, "ram_util_percent": 63.333333333333336}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37030793300447923, "mean_inference_ms": 1.682683154424597, "mean_action_processing_ms": 0.11258490992728296, "mean_env_wait_ms": 0.07364072532109182, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28720, "timesteps_this_iter": 32, "agent_timesteps_total": 57440, "timers": {"load_time_ms": 0.498, "load_throughput": 64231.302, "learn_time_ms": 8.12, "learn_throughput": 3940.927, "update_time_ms": 5.345}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 12.024489402770996, "min_q": 2.923290252685547, "max_q": 17.77568244934082, "mean_td_error": -0.13698144257068634, "model": {}}, "td_error": [0.36968135833740234, -0.5135736465454102, 1.046504020690918, -0.10833549499511719, -0.6027355194091797, 1.6478519439697266, 0.03274726867675781, 0.3634309768676758, -0.10833549499511719, -0.8186893463134766, -0.10833549499511719, -0.10833549499511719, 0.6165981292724609, -0.5391883850097656, 0.8749475479125977, 0.027570247650146484, 3.035682201385498, -0.05753040313720703, 0.03274726867675781, -1.8059883117675781, -1.9894142150878906, -4.179079055786133, -0.10833549499511719, -0.5391883850097656, -0.5742301940917969, 0.24062347412109375, -0.5102272033691406, 1.69834566116333, 0.03274726867675781, 0.2421884536743164, -1.4343595504760742, -0.5391902923583984], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.142770767211914, "min_q": -0.5867009162902832, "max_q": 17.066133499145508, "mean_td_error": 0.4224279224872589, "model": {}}, "td_error": [3.1829700469970703, -0.1304607391357422, -0.1304607391357422, 2.313797950744629, 0.5285773277282715, 0.8753499984741211, -0.2340679168701172, 2.4404945373535156, 2.4589614868164062, -0.1304607391357422, -0.7432308197021484, -0.6002645492553711, 0.3397560119628906, -0.1304607391357422, -1.273094654083252, 3.304464340209961, -1.950007438659668, 3.1829700469970703, -1.0453863143920898, 1.9207286834716797, 0.5379562377929688, -1.0626716613769531, -1.1200037002563477, -0.6879253387451172, -2.6357827186584473, 0.5044946670532227, 0.4960343837738037, 0.1653904914855957, 1.4975671768188477, 0.9041767120361328, 1.1603343486785889, -0.42205238342285156], "custom_metrics": {}}}, "num_steps_sampled": 28720, "num_agent_steps_sampled": 57440, "num_steps_trained": 93344, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 186688, "last_target_update_ts": 28624, "num_target_updates": 258}, "done": false, "episodes_total": 4130, "training_iteration": 115, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-14", "timestamp": 1648811654, "time_this_iter_s": 1.651200771331787, "time_total_s": 154.0466549396515, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83c0560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 154.0466549396515, "timesteps_since_restore": 3680, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 40.2, "ram_util_percent": 63.95}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3717289004081441, "mean_inference_ms": 1.684537650120146, "mean_action_processing_ms": 0.11273318888067867, "mean_env_wait_ms": 0.07375132380348592, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28924, "timesteps_this_iter": 32, "agent_timesteps_total": 57848, "timers": {"load_time_ms": 0.45, "load_throughput": 71074.84, "learn_time_ms": 8.119, "learn_throughput": 3941.39, "update_time_ms": 5.07}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.821832656860352, "min_q": 1.1389470100402832, "max_q": 17.10832977294922, "mean_td_error": -0.3292357921600342, "model": {}}, "td_error": [-1.6570930480957031, -0.9286212921142578, 2.3837180137634277, -0.7912130355834961, -0.5771026611328125, -0.5771026611328125, 0.6812868118286133, -0.24300241470336914, -1.2149505615234375, 5.524091720581055, -1.048142433166504, -1.3132619857788086, -0.5771026611328125, -2.277866840362549, 1.2762413024902344, -0.7263317108154297, -1.7986724376678467, -0.5771026611328125, 0.2354569435119629, 0.20012235641479492, -1.3999748229980469, -0.2191925048828125, 0.21668052673339844, -1.4777674674987793, -0.2191925048828125, -1.3666973114013672, -1.3999748229980469, 0.9995989799499512, 0.0973501205444336, -0.40734195709228516, 0.014313697814941406, -1.3666973114013672], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.223163604736328, "min_q": 1.9220685958862305, "max_q": 17.569108963012695, "mean_td_error": 0.41074374318122864, "model": {}}, "td_error": [-0.82757568359375, -0.82757568359375, -1.1215553283691406, 2.925266742706299, 2.3206582069396973, -0.82757568359375, 4.797211647033691, -2.5316600799560547, 0.035137176513671875, 1.7790584564208984, 0.245513916015625, -0.82757568359375, 2.08255672454834, 1.5409605503082275, -2.1997928619384766, -0.82757568359375, -0.2912750244140625, -0.9835147857666016, -0.25391483306884766, 3.3097763061523438, -0.2912750244140625, -0.5482807159423828, 3.8997716903686523, 1.7682533264160156, 4.797211647033691, 3.3097763061523438, 0.08719158172607422, -5.3053083419799805, -0.7866058349609375, -0.8261780738830566, -0.8275737762451172, 0.3502688407897949], "custom_metrics": {}}}, "num_steps_sampled": 28924, "num_agent_steps_sampled": 57848, "num_steps_trained": 94432, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 188864, "last_target_update_ts": 28828, "num_target_updates": 260}, "done": false, "episodes_total": 4198, "training_iteration": 116, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-15", "timestamp": 1648811655, "time_this_iter_s": 1.6212563514709473, "time_total_s": 155.66791129112244, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83de440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83de440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 155.66791129112244, "timesteps_since_restore": 3712, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 39.06666666666666, "ram_util_percent": 64.39999999999999}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3730706476899328, "mean_inference_ms": 1.6863821064328386, "mean_action_processing_ms": 0.11288648976871152, "mean_env_wait_ms": 0.07385862321786112, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29128, "timesteps_this_iter": 32, "agent_timesteps_total": 58256, "timers": {"load_time_ms": 0.472, "load_throughput": 67814.131, "learn_time_ms": 8.682, "learn_throughput": 3685.65, "update_time_ms": 5.411}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 12.579675674438477, "min_q": 4.344742298126221, "max_q": 17.777618408203125, "mean_td_error": 0.17575497925281525, "model": {}}, "td_error": [-0.45543527603149414, 5.344742298126221, -0.26955223083496094, -0.17763519287109375, -0.12610912322998047, -0.12610912322998047, -0.17763519287109375, -0.23839855194091797, -0.2093982696533203, -0.8952064514160156, 2.275092601776123, -0.4650106430053711, -0.5922527313232422, -0.7426514625549316, -0.7218461036682129, 1.0516853332519531, -2.182602882385254, 3.0870370864868164, -0.17763519287109375, -0.946845531463623, -0.12798023223876953, -0.12610912322998047, -0.17763519287109375, -0.23839855194091797, -3.044114112854004, 0.8292560577392578, -0.12610912322998047, -0.5922527313232422, 3.1899757385253906, -0.17763519287109375, -0.12611103057861328, 3.087038993835449], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.116073608398438, "min_q": 0.7654206156730652, "max_q": 17.75362205505371, "mean_td_error": -0.30669352412223816, "model": {}}, "td_error": [-1.030557632446289, -1.030557632446289, -1.457718849182129, -0.06788825988769531, 0.11570358276367188, -0.06788825988769531, 1.2601168155670166, 3.1993818283081055, -0.4697456359863281, 3.7492024898529053, 0.05097770690917969, -1.2033214569091797, 2.726158618927002, -1.030557632446289, -0.4697456359863281, -6.187248229980469, -0.06788825988769531, -0.2376079559326172, -3.57529354095459, 0.4622178077697754, -1.19252347946167, 0.2452411651611328, -1.8269319534301758, -0.49590587615966797, -1.780867576599121, 1.3873319625854492, -0.2603015899658203, 0.2706904411315918, 3.1887874603271484, 4.907718658447266, -0.6905932426452637, -8.234579086303711], "custom_metrics": {}}}, "num_steps_sampled": 29128, "num_agent_steps_sampled": 58256, "num_steps_trained": 95520, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 191040, "last_target_update_ts": 29032, "num_target_updates": 262}, "done": false, "episodes_total": 4266, "training_iteration": 117, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-17", "timestamp": 1648811657, "time_this_iter_s": 1.6401407718658447, "time_total_s": 157.30805206298828, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 157.30805206298828, "timesteps_since_restore": 3744, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 39.55, "ram_util_percent": 64.65}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3746902529500823, "mean_inference_ms": 1.6894235852504602, "mean_action_processing_ms": 0.1131042812514341, "mean_env_wait_ms": 0.07399609544172496, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29332, "timesteps_this_iter": 32, "agent_timesteps_total": 58664, "timers": {"load_time_ms": 0.548, "load_throughput": 58421.576, "learn_time_ms": 9.102, "learn_throughput": 3515.863, "update_time_ms": 5.526}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 13.764782905578613, "min_q": 5.303815841674805, "max_q": 18.05947494506836, "mean_td_error": 0.17610222101211548, "model": {}}, "td_error": [2.2279796600341797, 0.21038436889648438, -1.0966205596923828, -0.14990615844726562, -1.0966205596923828, -0.28546905517578125, 0.5570449829101562, 0.5570449829101562, 0.2869596481323242, 0.5570449829101562, 1.8668041229248047, 0.25156450271606445, -0.19667911529541016, -0.26991748809814453, -0.26991748809814453, -0.9535198211669922, -0.40148258209228516, -0.07723140716552734, 0.5570449829101562, -0.26991748809814453, 0.5570449829101562, 0.9256391525268555, -0.14990615844726562, -0.26991748809814453, 0.5570449829101562, -0.9185695648193359, 0.3577594757080078, -0.14990615844726562, -0.44033002853393555, 0.5570449829101562, 0.5570449829101562, 2.047731399536133], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.648662567138672, "min_q": -3.198136329650879, "max_q": 17.723033905029297, "mean_td_error": 0.40413597226142883, "model": {}}, "td_error": [-0.24573612213134766, 0.13913440704345703, -0.8395562171936035, -0.5448818206787109, -0.28327178955078125, 4.760904312133789, -0.5084285736083984, -1.4391298294067383, -0.5084285736083984, 0.3551158905029297, 0.20314931869506836, -0.5448818206787109, 0.9196314811706543, -0.6303882598876953, -0.39934539794921875, 1.6822423934936523, -0.8550035953521729, -2.7816038131713867, 2.0908212661743164, -2.3769869804382324, -1.1147089004516602, 0.2974395751953125, -0.5084285736083984, 4.927670478820801, -0.28327178955078125, -0.29781246185302734, 3.5355491638183594, -0.5448818206787109, 4.760904312133789, -0.39934539794921875, 1.8051776885986328, 2.5607028007507324], "custom_metrics": {}}}, "num_steps_sampled": 29332, "num_agent_steps_sampled": 58664, "num_steps_trained": 96608, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 193216, "last_target_update_ts": 29236, "num_target_updates": 264}, "done": false, "episodes_total": 4334, "training_iteration": 118, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-19", "timestamp": 1648811659, "time_this_iter_s": 1.767186164855957, "time_total_s": 159.07523822784424, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 159.07523822784424, "timesteps_since_restore": 3776, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 39.96666666666667, "ram_util_percent": 64.89999999999999}}
{"episode_reward_max": 34.0, "episode_reward_min": 24.0, "episode_reward_mean": 33.64, "episode_len_mean": 3.18, "episode_media": {}, "episodes_this_iter": 62, "policy_reward_min": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.82, "policy1": 16.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 28.0, 34.0, 34.0, 24.0, 34.0, 34.0, 24.0, 24.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 8, 3, 3, 8, 8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 12.0, 17.0, 17.0, 12.0, 12.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.0, 17.0, 17.0, 12.0, 17.0, 17.0, 12.0, 12.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37603971777459383, "mean_inference_ms": 1.6920744541711583, "mean_action_processing_ms": 0.11329493627817339, "mean_env_wait_ms": 0.07410012622820185, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29536, "timesteps_this_iter": 32, "agent_timesteps_total": 59072, "timers": {"load_time_ms": 0.504, "load_throughput": 63532.012, "learn_time_ms": 8.568, "learn_throughput": 3734.817, "update_time_ms": 5.837}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.984724044799805, "min_q": 3.508751153945923, "max_q": 18.23191261291504, "mean_td_error": 0.2990318536758423, "model": {}}, "td_error": [-0.5494813919067383, 0.5132575035095215, 0.0775136947631836, -0.7470951080322266, 0.3318004608154297, 0.3318004608154297, -0.012262344360351562, 0.5399684906005859, -1.254262924194336, 0.3477306365966797, -0.05977821350097656, -0.08736038208007812, 1.166548728942871, 2.3386077880859375, 0.0775136947631836, 0.0775136947631836, 2.3209547996520996, -0.08736038208007812, 1.1781835556030273, 0.0775136947631836, -1.796133041381836, 0.8107333183288574, -0.5263054370880127, 0.14673948287963867, -0.2786121368408203, 2.3209547996520996, 2.033148765563965, -0.08736038208007812, 0.13349342346191406, 0.07602500915527344, 0.0775146484375, 0.0775146484375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 8.916749000549316, "min_q": 0.11447668075561523, "max_q": 18.2984561920166, "mean_td_error": -0.4931431710720062, "model": {}}, "td_error": [0.764617919921875, 0.667548656463623, -2.203615188598633, 1.395981788635254, 0.5833358764648438, 1.2734110355377197, -0.8187713623046875, -6.485324859619141, -1.4391679763793945, 0.1377086639404297, 0.5833358764648438, -0.43720483779907227, -0.7412834167480469, -3.7928056716918945, 0.1377086639404297, -0.9457054138183594, 0.1377086639404297, 1.395981788635254, -1.4893074035644531, -0.43845558166503906, 0.1377086639404297, 0.34886741638183594, -1.3696403503417969, 0.1377086639404297, -6.391267776489258, 2.3571834564208984, -0.22655105590820312, -1.596649169921875, -0.8854103088378906, 0.764617919921875, -0.7935652732849121, 3.4507181644439697], "custom_metrics": {}}}, "num_steps_sampled": 29536, "num_agent_steps_sampled": 59072, "num_steps_trained": 97664, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 195328, "last_target_update_ts": 29444, "num_target_updates": 266}, "done": false, "episodes_total": 4396, "training_iteration": 119, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-21", "timestamp": 1648811661, "time_this_iter_s": 1.660245656967163, "time_total_s": 160.7354838848114, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83ef7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 160.7354838848114, "timesteps_since_restore": 3808, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 40.8, "ram_util_percent": 65.15}}
{"episode_reward_max": 34.0, "episode_reward_min": 24.0, "episode_reward_mean": 33.8, "episode_len_mean": 3.1, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.9, "policy1": 16.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 24.0, 24.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 8, 8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 12.0, 12.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 12.0, 12.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37725820734354565, "mean_inference_ms": 1.6933099906521571, "mean_action_processing_ms": 0.11341305320803823, "mean_env_wait_ms": 0.07415159799886123, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29740, "timesteps_this_iter": 32, "agent_timesteps_total": 59480, "timers": {"load_time_ms": 0.455, "load_throughput": 70374.228, "learn_time_ms": 8.017, "learn_throughput": 3991.665, "update_time_ms": 4.944}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.622892379760742, "min_q": 2.279385566711426, "max_q": 17.90398406982422, "mean_td_error": -0.3017878830432892, "model": {}}, "td_error": [0.9047136306762695, -0.4504737854003906, -0.32836341857910156, -1.054896354675293, 0.007183551788330078, 0.3451066017150879, -3.386625289916992, -0.32836341857910156, -1.4152154922485352, -0.5281686782836914, -0.06172370910644531, -3.004873752593994, 0.5777871608734131, -0.06172370910644531, -0.20540332794189453, 2.926076889038086, -2.0623574256896973, 2.29824161529541, 0.108917236328125, 0.108917236328125, -0.5214767456054688, -0.06172370910644531, -0.2356281280517578, -0.2287735939025879, -0.6262855529785156, -1.7957243919372559, -0.32836341857910156, 0.2590465545654297, -0.3890237808227539, -0.32836341857910156, 0.108917236328125, 0.10143089294433594], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 9.006584167480469, "min_q": 1.522923469543457, "max_q": 17.349275588989258, "mean_td_error": 0.8124823570251465, "model": {}}, "td_error": [-0.5699386596679688, -0.4017791748046875, 1.631277084350586, -0.4017791748046875, -0.3934173583984375, 7.8581085205078125, 3.0318212509155273, 2.3810629844665527, 2.6838560104370117, -0.8702583312988281, -0.40143394470214844, 2.261343002319336, -0.613337516784668, 0.7393374443054199, 1.9593563079833984, -1.0013039112091064, 4.620256423950195, -0.4017791748046875, -0.4049372673034668, -2.0197019577026367, 2.701284408569336, -0.6158657073974609, 1.7806625366210938, 0.37709999084472656, 0.5936555862426758, -0.041062355041503906, 0.27257227897644043, 1.7768831253051758, -0.40143394470214844, 1.5190200805664062, -0.4017810821533203, -1.248354196548462], "custom_metrics": {}}}, "num_steps_sampled": 29740, "num_agent_steps_sampled": 59480, "num_steps_trained": 98752, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 197504, "last_target_update_ts": 29650, "num_target_updates": 268}, "done": false, "episodes_total": 4464, "training_iteration": 120, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-22", "timestamp": 1648811662, "time_this_iter_s": 1.5341014862060547, "time_total_s": 162.26958537101746, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83e9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 162.26958537101746, "timesteps_since_restore": 3840, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 41.0, "ram_util_percent": 65.2}}
{"episode_reward_max": 34.0, "episode_reward_min": 34.0, "episode_reward_mean": 34.0, "episode_len_mean": 3.0, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 17.0, "policy1": 17.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3783816473854724, "mean_inference_ms": 1.6941912723326562, "mean_action_processing_ms": 0.11349125750248687, "mean_env_wait_ms": 0.07419513203407183, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29944, "timesteps_this_iter": 32, "agent_timesteps_total": 59888, "timers": {"load_time_ms": 0.457, "load_throughput": 69974.312, "learn_time_ms": 8.17, "learn_throughput": 3916.982, "update_time_ms": 5.434}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 12.022104263305664, "min_q": 4.911876678466797, "max_q": 17.910423278808594, "mean_td_error": 0.2994747757911682, "model": {}}, "td_error": [-1.630746841430664, -0.25922489166259766, -0.1511859893798828, 1.489253044128418, -0.08974647521972656, 0.6202917098999023, -0.019075393676757812, -0.4653501510620117, -0.4653501510620117, -0.042072296142578125, -0.042072296142578125, 0.7232894897460938, 0.4357147216796875, -0.5577278137207031, 0.4712390899658203, 1.0615243911743164, 0.4983634948730469, -0.4653501510620117, 0.8341083526611328, 1.3837404251098633, 6.024397850036621, 0.6174840927124023, 0.4338254928588867, -0.019075393676757812, -0.08974647521972656, -0.28905677795410156, -0.28905677795410156, 0.6121807098388672, -0.28905677795410156, -0.5986843109130859, 0.1824326515197754, -0.04207420349121094], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.21706485748291, "min_q": -0.8678168058395386, "max_q": 17.292081832885742, "mean_td_error": 0.3778942823410034, "model": {}}, "td_error": [2.976480484008789, 0.5442323684692383, -0.6137905120849609, -1.1831674575805664, 0.3453683853149414, 0.44631195068359375, 2.9646191596984863, 0.7671409845352173, 1.1192150115966797, -0.6008987426757812, -0.6422004699707031, -0.4347801208496094, 1.8647871017456055, -0.6566629409790039, 1.7890958786010742, 0.7403922080993652, -0.5486793518066406, -0.52301025390625, -1.648956298828125, -0.6008987426757812, 1.3607568740844727, 1.8095383644104004, -0.4823899269104004, 0.8443527221679688, -0.52301025390625, 0.07922840118408203, -0.5486793518066406, -0.52301025390625, 2.0643961429595947, 2.3319826126098633, -0.6422004699707031, 0.2170543670654297], "custom_metrics": {}}}, "num_steps_sampled": 29944, "num_agent_steps_sampled": 59888, "num_steps_trained": 99840, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 199680, "last_target_update_ts": 29854, "num_target_updates": 270}, "done": false, "episodes_total": 4532, "training_iteration": 121, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-24", "timestamp": 1648811664, "time_this_iter_s": 1.5814387798309326, "time_total_s": 163.8510241508484, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020126b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020126b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 163.8510241508484, "timesteps_since_restore": 3872, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 41.73333333333333, "ram_util_percent": 65.33333333333333}}
{"episode_reward_max": 34.0, "episode_reward_min": 32.0, "episode_reward_mean": 33.98, "episode_len_mean": 3.01, "episode_media": {}, "episodes_this_iter": 67, "policy_reward_min": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": 16.99, "policy1": 16.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0], "episode_lengths": [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], "policy_policy0_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0], "policy_policy1_reward": [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3796016697808349, "mean_inference_ms": 1.6952667343245957, "mean_action_processing_ms": 0.11358885963466381, "mean_env_wait_ms": 0.07425440646045173, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 30146, "timesteps_this_iter": 32, "agent_timesteps_total": 60292, "timers": {"load_time_ms": 0.475, "load_throughput": 67314.172, "learn_time_ms": 8.308, "learn_throughput": 3851.917, "update_time_ms": 5.052}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 11.504793167114258, "min_q": 0.4442082643508911, "max_q": 18.256772994995117, "mean_td_error": 0.5185688138008118, "model": {}}, "td_error": [3.143796443939209, -0.24910831451416016, -0.6808938980102539, 0.17530250549316406, -0.12719345092773438, 0.4777870178222656, 0.4033021926879883, 0.38840293884277344, 0.4777870178222656, 0.38840293884277344, 0.17530250549316406, -1.026634693145752, 0.6451239585876465, 0.4777870178222656, 3.143796443939209, 0.38840293884277344, 0.1222982406616211, 1.222787857055664, -0.7691874504089355, 1.1854963302612305, -0.403958797454834, -0.12719345092773438, -0.4992713928222656, 0.09194564819335938, 0.1956644058227539, 2.9152965545654297, 0.4033021926879883, 0.5570492744445801, 2.664550304412842, 0.17032480239868164, 0.9512357711791992, -0.2875022888183594], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 10.177362442016602, "min_q": -1.7169404029846191, "max_q": 17.738323211669922, "mean_td_error": -0.19344809651374817, "model": {}}, "td_error": [-0.07377958297729492, -0.8875885009765625, 1.9649238586425781, -0.8235244750976562, -0.5381629467010498, -0.3794822692871094, -0.35564613342285156, -0.1419696807861328, 1.6529541015625, -0.1419696807861328, -0.03097677230834961, -1.478689193725586, -0.35564613342285156, 0.2412252426147461, -0.3794822692871094, -0.1419696807861328, -0.5919551849365234, -1.0376992225646973, -0.35564613342285156, -4.348989963531494, -0.9439144134521484, 0.6216421127319336, 0.5948138236999512, -0.27096450328826904, -0.2877025604248047, -0.2575511932373047, 0.7352861166000366, -0.1419696807861328, -0.36146974563598633, 3.036858081817627, -0.35564613342285156, -0.35564613342285156], "custom_metrics": {}}}, "num_steps_sampled": 30146, "num_agent_steps_sampled": 60292, "num_steps_trained": 100928, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 201856, "last_target_update_ts": 30058, "num_target_updates": 272}, "done": true, "episodes_total": 4599, "training_iteration": 122, "trial_id": "76743_00000", "experiment_id": "6af836e00d10403b9eacf3717e17bd18", "date": "2022-04-01_04-14-25", "timestamp": 1648811665, "time_this_iter_s": 1.5825769901275635, "time_total_s": 165.43360114097595, "pid": 19093, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010e290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010e290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 165.43360114097595, "timesteps_since_restore": 3904, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 41.599999999999994, "ram_util_percent": 65.5}}
