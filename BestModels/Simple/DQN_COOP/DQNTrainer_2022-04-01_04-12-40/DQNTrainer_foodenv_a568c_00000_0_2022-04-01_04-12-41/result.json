{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.566037735849058, "episode_len_mean": 18.90566037735849, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.283018867924529, "policy1": -9.283018867924529}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 0.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 14, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 0.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 0.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32518796645038023, "mean_inference_ms": 1.9571472141345743, "mean_action_processing_ms": 0.1254400251394255, "mean_env_wait_ms": 0.08096152977834074, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1002, "timesteps_this_iter": 32, "agent_timesteps_total": 2004, "timers": {"load_time_ms": 0.453, "load_throughput": 70715.347, "learn_time_ms": 484.715, "learn_throughput": 66.018, "update_time_ms": 32.897}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -0.08457187563180923, "min_q": -0.5983033776283264, "max_q": 0.4230577349662781, "mean_td_error": 0.24690082669258118, "model": {}}, "td_error": [0.46043452620506287, 1.5457409620285034, 0.5778461694717407, 1.4230577945709229, 1.029036045074463, 1.5834648609161377, 0.3528478741645813, 1.3037261962890625, 0.5653051733970642, 0.8012319803237915, 0.8068630695343018, 1.0169323682785034, 1.006462574005127, 0.6249850988388062, 1.231583595275879, 1.1929208040237427, 0.7881945371627808, -9.443419456481934, 1.2574282884597778, 0.2950010895729065, 0.6821132898330688, 0.4740676283836365, 0.9778859615325928, -9.285136222839355, 0.9353805184364319, 0.9716766476631165, 0.695185661315918, 0.9834927916526794, 0.49877744913101196, 1.12022864818573, 1.06203031539917, 0.3654804229736328], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -0.30046769976615906, "min_q": -0.8344403505325317, "max_q": 0.3036198019981384, "mean_td_error": -0.033601731061935425, "model": {}}, "td_error": [0.7733567357063293, 1.0187751054763794, 0.7679991722106934, 1.1865336894989014, 1.3224687576293945, 1.0161715745925903, 0.839877724647522, 1.2010695934295654, 0.8110891580581665, -9.633965492248535, 0.752511203289032, 1.238968849182129, 0.7056049704551697, 0.5417772531509399, 1.3239301443099976, 0.4747541546821594, 0.25121212005615234, 0.16555964946746826, 1.686934471130371, 0.6954262852668762, 1.232356309890747, 1.1829257011413574, 0.46446728706359863, -8.255008697509766, -8.737903594970703, 0.5363731384277344, 0.7018700838088989, 0.6052323579788208, 1.397223949432373, 0.845343828201294, 1.0783953666687012, 0.7334136962890625], "custom_metrics": {}}}, "num_steps_sampled": 1002, "num_agent_steps_sampled": 2004, "num_steps_trained": 32, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64, "last_target_update_ts": 1002, "num_target_updates": 1}, "done": false, "episodes_total": 53, "training_iteration": 1, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-02", "timestamp": 1648811582, "time_this_iter_s": 3.6688201427459717, "time_total_s": 3.6688201427459717, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84066cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84066cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3.6688201427459717, "timesteps_since_restore": 32, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 36.81666666666667, "ram_util_percent": 50.5}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.625, "episode_len_mean": 18.8125, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.8125, "policy1": -8.8125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 0.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -20.0, -40.0, -20.0, 18.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 14, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 0.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -10.0, 9.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 0.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -10.0, 9.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3255255413357829, "mean_inference_ms": 1.9567016972262938, "mean_action_processing_ms": 0.125797471048738, "mean_env_wait_ms": 0.08111515181595141, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1204, "timesteps_this_iter": 32, "agent_timesteps_total": 2408, "timers": {"load_time_ms": 0.44, "load_throughput": 72679.768, "learn_time_ms": 8.794, "learn_throughput": 3638.806, "update_time_ms": 23.786}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.404924392700195, "min_q": -19.600744247436523, "max_q": -0.603527307510376, "mean_td_error": 1.5462909936904907, "model": {}}, "td_error": [11.581888198852539, -2.2898168563842773, 3.0043840408325195, -5.138956069946289, 4.867708206176758, -3.903543472290039, -8.458163261413574, -3.552304267883301, 4.756601333618164, 7.431051254272461, 13.589612007141113, -7.338937759399414, -6.095875263214111, 0.5850086212158203, -0.003651142120361328, 3.57730770111084, -8.74140739440918, 10.229259490966797, -5.323343276977539, 11.128095626831055, 7.430951118469238, 11.413187980651855, 1.5358242988586426, -1.979814052581787, 0.7118072509765625, 3.841165781021118, 3.5655078887939453, -5.334619522094727, -6.217207908630371, 12.863080978393555, 0.23008346557617188, 1.516425371170044], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -17.187164306640625, "min_q": -20.62030601501465, "max_q": -5.208946228027344, "mean_td_error": -4.152561187744141, "model": {}}, "td_error": [-2.3590965270996094, -4.220790863037109, 7.761626243591309, -1.6504106521606445, -12.987787246704102, -5.412110328674316, -0.8231353759765625, -1.7400398254394531, -8.765267372131348, 0.8656044006347656, -24.439699172973633, -5.834385871887207, -2.028261184692383, -4.792290687561035, -0.5241298675537109, -5.511985778808594, -2.326578140258789, -3.5283374786376953, 0.8165950775146484, -0.9598283767700195, -5.547091484069824, -3.7799062728881836, -1.7815380096435547, -7.1351118087768555, -4.197931289672852, -4.606322288513184, 0.848515510559082, -4.606322288513184, -16.539920806884766, -0.06975841522216797, -9.271915435791016, 2.265650749206543], "custom_metrics": {}}}, "num_steps_sampled": 1204, "num_agent_steps_sampled": 2408, "num_steps_trained": 384, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 768, "last_target_update_ts": 1104, "num_target_updates": 2}, "done": false, "episodes_total": 64, "training_iteration": 2, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-03", "timestamp": 1648811583, "time_this_iter_s": 1.0934967994689941, "time_total_s": 4.762316942214966, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4.762316942214966, "timesteps_since_restore": 64, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 37.0, "ram_util_percent": 51.5}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.753086419753085, "episode_len_mean": 18.753086419753085, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.876543209876543, "policy1": -8.876543209876543}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 0.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -20.0, -40.0, -20.0, 18.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 14, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 6, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 0.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -10.0, 9.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 0.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -10.0, 9.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32508379773775065, "mean_inference_ms": 1.9459740533338215, "mean_action_processing_ms": 0.12572162620546926, "mean_env_wait_ms": 0.08097955939803189, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1519, "timesteps_this_iter": 32, "agent_timesteps_total": 3038, "timers": {"load_time_ms": 0.426, "load_throughput": 75154.112, "learn_time_ms": 7.434, "learn_throughput": 4304.637, "update_time_ms": 10.123}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.5167236328125, "min_q": -22.258787155151367, "max_q": -2.8135037422180176, "mean_td_error": -0.1251848340034485, "model": {}}, "td_error": [0.3160114288330078, -0.18777179718017578, -13.723907470703125, -1.1527099609375, 0.6501150131225586, 1.9651470184326172, 1.1055946350097656, 4.458606719970703, -0.13125991821289062, 0.384946346282959, 1.756753921508789, 0.4192314147949219, 0.5862970352172852, 4.981937885284424, 1.8110122680664062, 3.3775410652160645, -17.904747009277344, 0.5505785942077637, 0.3378467559814453, 0.586559534072876, 0.1425457000732422, 2.3859920501708984, 0.5201520919799805, 0.6369562149047852, 0.8473405838012695, -1.7707476615905762, 1.1264667510986328, -1.5964317321777344, 0.0359196662902832, 1.0806293487548828, 1.1030540466308594, 1.294424057006836], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.405726432800293, "min_q": -17.275632858276367, "max_q": -8.472719192504883, "mean_td_error": -0.8516862392425537, "model": {}}, "td_error": [-0.4067401885986328, 0.005227088928222656, -15.40587043762207, 0.4795379638671875, -0.1402292251586914, -1.2250213623046875, -1.0323352813720703, 1.0888824462890625, -0.4188709259033203, -0.01448822021484375, -0.7066974639892578, -1.1407766342163086, -0.009074211120605469, -0.6298017501831055, 0.24083805084228516, -0.0672922134399414, 1.2689056396484375, -0.4813804626464844, 0.44618988037109375, -2.4520339965820312, -8.4931001663208, 0.6207008361816406, -1.0323352813720703, 1.4717121124267578, -1.0323352813720703, 0.8390178680419922, 1.3450736999511719, -0.8827075958251953, 0.09243202209472656, -0.4802217483520508, 0.8316316604614258, 0.06720542907714844], "custom_metrics": {}}}, "num_steps_sampled": 1519, "num_agent_steps_sampled": 3038, "num_steps_trained": 928, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 1856, "last_target_update_ts": 1453, "num_target_updates": 5}, "done": false, "episodes_total": 81, "training_iteration": 3, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-05", "timestamp": 1648811585, "time_this_iter_s": 1.3024334907531738, "time_total_s": 6.06475043296814, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6.06475043296814, "timesteps_since_restore": 96, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 31.25, "ram_util_percent": 51.55}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.29787234042553, "episode_len_mean": 18.46808510638298, "episode_media": {}, "episodes_this_iter": 13, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.148936170212766, "policy1": -8.148936170212766}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 0.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -20.0, -40.0, -20.0, 18.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 28.0, 24.0, 14.0, -20.0, 12.0, 8.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 14, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 6, 8, 13, 20, 14, 16, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 0.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -10.0, 9.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 14.0, 12.0, 7.0, -10.0, 6.0, 4.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 0.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -10.0, 9.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 14.0, 12.0, 7.0, -10.0, 6.0, 4.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32481716857307996, "mean_inference_ms": 1.9388348910311257, "mean_action_processing_ms": 0.12566244474849325, "mean_env_wait_ms": 0.08090526016387313, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1736, "timesteps_this_iter": 32, "agent_timesteps_total": 3472, "timers": {"load_time_ms": 0.443, "load_throughput": 72171.709, "learn_time_ms": 7.74, "learn_throughput": 4134.521, "update_time_ms": 7.718}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.788873672485352, "min_q": -19.227041244506836, "max_q": -4.793691635131836, "mean_td_error": 0.0786391943693161, "model": {}}, "td_error": [1.211904525756836, -0.12417936325073242, -1.903928279876709, 2.1740589141845703, -0.7011885643005371, 1.0813446044921875, -0.1285877227783203, -3.793691635131836, -0.3026390075683594, -0.9675283432006836, 1.577850341796875, 0.3416938781738281, -1.2956962585449219, 0.5490531921386719, -0.4614706039428711, -0.5457267761230469, 0.5332469940185547, 0.2886810302734375, -0.8404974937438965, 1.3668632507324219, 3.0560760498046875, -0.9752330780029297, -1.2745580673217773, -0.21755313873291016, -0.9812726974487305, 2.3083953857421875, -0.36422061920166016, 1.1507720947265625, 0.9181709289550781, -0.824826717376709, -0.23161602020263672, 1.8927574157714844], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -16.183378219604492, "min_q": -20.020902633666992, "max_q": -10.279441833496094, "mean_td_error": -0.3017609417438507, "model": {}}, "td_error": [2.29864501953125, -14.070591926574707, 2.1401853561401367, 1.2581233978271484, 1.8322629928588867, 2.8136138916015625, 0.7677536010742188, 1.650862693786621, 2.1707305908203125, 2.329914093017578, 2.150022506713867, 1.5880165100097656, -17.13510513305664, 1.5309467315673828, 0.10251808166503906, 1.6627817153930664, 1.209259033203125, 1.6820411682128906, 0.9835596084594727, 2.0418567657470703, 1.4723777770996094, 2.8181581497192383, 2.291421890258789, 2.34783935546875, 0.7092485427856445, -12.934205055236816, 2.329914093017578, 1.8314313888549805, -14.002433776855469, 1.3110294342041016, 1.2093868255615234, 1.9520845413208008], "custom_metrics": {}}}, "num_steps_sampled": 1736, "num_agent_steps_sampled": 3472, "num_steps_trained": 1344, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 2688, "last_target_update_ts": 1666, "num_target_updates": 7}, "done": false, "episodes_total": 94, "training_iteration": 4, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-06", "timestamp": 1648811586, "time_this_iter_s": 0.9527027606964111, "time_total_s": 7.017453193664551, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8408cef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8408cef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 7.017453193664551, "timesteps_since_restore": 128, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 28.65, "ram_util_percent": 51.650000000000006}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.98, "episode_len_mean": 18.39, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.99, "policy1": -7.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 18.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 0.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -20.0, -40.0, -20.0, 18.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 28.0, 24.0, 14.0, -20.0, 12.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, 26.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 6, 8, 13, 20, 14, 16, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 8, 20, 20, 20, 20, 20, 16, 20, 7, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 0.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -10.0, 9.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 14.0, 12.0, 7.0, -10.0, 6.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, 13.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 9.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 0.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -10.0, 9.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 14.0, 12.0, 7.0, -10.0, 6.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, 13.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32396562067300194, "mean_inference_ms": 1.9244070177950037, "mean_action_processing_ms": 0.12540908782292068, "mean_env_wait_ms": 0.08073223538852496, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2064, "timesteps_this_iter": 32, "agent_timesteps_total": 4128, "timers": {"load_time_ms": 0.417, "load_throughput": 76652.043, "learn_time_ms": 7.828, "learn_throughput": 4088.09, "update_time_ms": 6.704}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -15.664670944213867, "min_q": -21.0815486907959, "max_q": -6.922971248626709, "mean_td_error": -0.9682706594467163, "model": {}}, "td_error": [-0.2719097137451172, 0.2083759307861328, -0.10944747924804688, 0.14352893829345703, 0.20309829711914062, -0.14472007751464844, -0.3393421173095703, 0.13311004638671875, -0.15378570556640625, -0.2461872100830078, -0.315460205078125, 0.10254383087158203, -0.15314292907714844, 0.08061790466308594, -0.44118690490722656, -0.19710445404052734, -0.4879264831542969, -0.23439979553222656, 0.30158424377441406, 0.39499330520629883, -0.06953239440917969, -0.34777259826660156, 0.10256481170654297, 0.3295316696166992, -0.011130332946777344, -0.3802680969238281, 0.22146987915039062, 0.7514996528625488, -0.5025358200073242, -0.16386795043945312, -0.1546630859375, -29.23319435119629], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -19.73444366455078, "min_q": -22.970054626464844, "max_q": -12.79745101928711, "mean_td_error": 0.6450859904289246, "model": {}}, "td_error": [0.39366722106933594, 1.2647285461425781, 0.9000530242919922, 2.0551376342773438, 0.6181907653808594, 0.7924594879150391, 0.5826778411865234, 0.7354679107666016, 0.3775157928466797, 1.8740339279174805, 0.295135498046875, 0.8106136322021484, 0.2803001403808594, 0.5925331115722656, 0.5473670959472656, -5.507192611694336, 1.1568069458007812, 0.6266345977783203, 0.8770809173583984, 0.7504367828369141, 0.6946163177490234, 0.7610092163085938, 0.5591163635253906, 2.225588798522949, 0.9437217712402344, 2.6329259872436523, 0.47846031188964844, 0.4600868225097656, 1.7209043502807617, 0.3248634338378906, -0.6404819488525391, 0.45829200744628906], "custom_metrics": {}}}, "num_steps_sampled": 2064, "num_agent_steps_sampled": 4128, "num_steps_trained": 1920, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 3840, "last_target_update_ts": 2001, "num_target_updates": 10}, "done": false, "episodes_total": 112, "training_iteration": 5, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-07", "timestamp": 1648811587, "time_this_iter_s": 1.3377456665039062, "time_total_s": 8.355198860168457, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8408cd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8408cd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 8.355198860168457, "timesteps_since_restore": 160, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 29.65, "ram_util_percent": 51.7}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.5, "episode_len_mean": 18.25, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.75, "policy1": -7.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -20.0, -40.0, -20.0, 18.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 28.0, 24.0, 14.0, -20.0, 12.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, 26.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0], "episode_lengths": [20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 6, 8, 13, 20, 14, 16, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 8, 20, 20, 20, 20, 20, 16, 20, 7, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20], "policy_policy0_reward": [-20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -10.0, 9.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 14.0, 12.0, 7.0, -10.0, 6.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, 13.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -10.0, 9.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 14.0, 12.0, 7.0, -10.0, 6.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, 13.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32311373801964605, "mean_inference_ms": 1.907620938838798, "mean_action_processing_ms": 0.12515640291259586, "mean_env_wait_ms": 0.08054668155708354, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2393, "timesteps_this_iter": 32, "agent_timesteps_total": 4786, "timers": {"load_time_ms": 0.438, "load_throughput": 73039.687, "learn_time_ms": 7.532, "learn_throughput": 4248.351, "update_time_ms": 6.536}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -15.829187393188477, "min_q": -21.175668716430664, "max_q": -9.579001426696777, "mean_td_error": -0.6925816535949707, "model": {}}, "td_error": [-14.017860412597656, 0.6197414398193359, -0.3984642028808594, 0.09636878967285156, 0.21407699584960938, -0.1569080352783203, -0.39739227294921875, -0.6380043029785156, -0.6218643188476562, -0.598088264465332, -0.24444961547851562, -0.05641365051269531, -0.4437570571899414, -3.5953102111816406, -0.3020944595336914, -0.06790733337402344, 0.024450302124023438, 0.1268157958984375, -0.5787172317504883, -0.835357666015625, -0.36981964111328125, -0.046639442443847656, -0.2994661331176758, 0.3788261413574219, 0.04912757873535156, 0.36014366149902344, 0.2691936492919922, -0.1717538833618164, -0.16559314727783203, -0.3570127487182617, -0.42123889923095703, 0.4827556610107422], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -21.037248611450195, "min_q": -23.86350440979004, "max_q": -13.399090766906738, "mean_td_error": -0.0678626000881195, "model": {}}, "td_error": [0.26178550720214844, 1.674407958984375, -13.684106826782227, 0.6123867034912109, 1.8073062896728516, 1.4969940185546875, 1.1159915924072266, 2.0107192993164062, 1.9179153442382812, 0.7921085357666016, -5.545204162597656, 1.6632041931152344, 1.6222820281982422, 1.281606674194336, 1.4066638946533203, -13.70077896118164, 1.4800910949707031, 1.2168827056884766, 0.7684421539306641, 1.5042400360107422, 0.500889778137207, 0.8731765747070312, 1.3880176544189453, 1.3661613464355469, 1.5969390869140625, 0.9604816436767578, 1.036581039428711, 1.1448745727539062, 1.6215267181396484, -5.788606643676758, 1.6898574829101562, 1.7355594635009766], "custom_metrics": {}}}, "num_steps_sampled": 2393, "num_agent_steps_sampled": 4786, "num_steps_trained": 2496, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 4992, "last_target_update_ts": 2325, "num_target_updates": 13}, "done": false, "episodes_total": 130, "training_iteration": 6, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-08", "timestamp": 1648811588, "time_this_iter_s": 1.491577386856079, "time_total_s": 9.846776247024536, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 9.846776247024536, "timesteps_since_restore": 192, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 30.7, "ram_util_percent": 51.7}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.06, "episode_len_mean": 18.13, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -7.03, "policy1": -7.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -20.0, -20.0, -40.0, -20.0, 18.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 28.0, 24.0, 14.0, -20.0, 12.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, 26.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, 24.0, -20.0, -20.0, 8.0, 18.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 11, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 6, 8, 13, 20, 14, 16, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 8, 20, 20, 20, 20, 20, 16, 20, 7, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 20, 20, 20, 19, 20, 8, 20, 20, 16, 11, 20, 20, 20, 20], "policy_policy0_reward": [0.0, -10.0, -10.0, -20.0, -10.0, 9.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 14.0, 12.0, 7.0, -10.0, 6.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, 13.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, 12.0, -10.0, -10.0, 4.0, 9.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [0.0, -10.0, -10.0, -20.0, -10.0, 9.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 14.0, 12.0, 7.0, -10.0, 6.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, 13.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, 12.0, -10.0, -10.0, 4.0, 9.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32226136590686333, "mean_inference_ms": 1.8902988304748223, "mean_action_processing_ms": 0.12488113707759496, "mean_env_wait_ms": 0.08034724433882212, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2715, "timesteps_this_iter": 32, "agent_timesteps_total": 5430, "timers": {"load_time_ms": 0.484, "load_throughput": 66126.88, "learn_time_ms": 7.443, "learn_throughput": 4299.384, "update_time_ms": 8.121}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -21.699859619140625, "min_q": -28.791950225830078, "max_q": -11.929051399230957, "mean_td_error": -1.4986363649368286, "model": {}}, "td_error": [-2.094188690185547, -1.9627304077148438, -0.5887851715087891, -2.0329952239990234, -0.05245208740234375, -0.5002346038818359, -2.2104225158691406, -0.3586597442626953, -0.48566627502441406, -1.9562740325927734, -2.3689136505126953, -0.234710693359375, -2.274242401123047, 0.5190677642822266, -2.034830093383789, -2.3833160400390625, 0.7435741424560547, -0.2558250427246094, -2.1562576293945312, -2.466686248779297, -1.8008995056152344, 0.3660755157470703, -0.17741012573242188, -13.404353141784668, -2.5088233947753906, -0.4795036315917969, -0.22036170959472656, 0.08408164978027344, -1.9964847564697266, -0.5736484527587891, -2.553335189819336, 0.4628467559814453], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -20.916732788085938, "min_q": -24.903627395629883, "max_q": -12.11778450012207, "mean_td_error": -2.025939464569092, "model": {}}, "td_error": [-1.6343927383422852, -0.23995590209960938, 0.23731422424316406, -0.103485107421875, -0.24761390686035156, 0.11944770812988281, 0.2575817108154297, 0.25318145751953125, -0.2284564971923828, 0.16379356384277344, 0.2217121124267578, -13.937239646911621, 0.23867416381835938, -23.708805084228516, 0.6439142227172852, 0.9417991638183594, -2.516880989074707, 0.2907886505126953, 0.14856719970703125, -0.1499805450439453, -0.2741050720214844, -0.09967803955078125, -0.1282825469970703, 0.3319549560546875, -0.2703056335449219, -5.404897689819336, -5.709117889404297, 0.2222309112548828, -14.479751586914062, 0.07576751708984375, 0.2445697784423828, -0.08840751647949219], "custom_metrics": {}}}, "num_steps_sampled": 2715, "num_agent_steps_sampled": 5430, "num_steps_trained": 3072, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 6144, "last_target_update_ts": 2675, "num_target_updates": 16}, "done": false, "episodes_total": 148, "training_iteration": 7, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-10", "timestamp": 1648811590, "time_this_iter_s": 1.370835542678833, "time_total_s": 11.21761178970337, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8406df80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8406df80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 11.21761178970337, "timesteps_since_restore": 224, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 30.25, "ram_util_percent": 51.7}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.58, "episode_len_mean": 18.19, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -7.29, "policy1": -7.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 28.0, 24.0, 14.0, -20.0, 12.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, 26.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, 24.0, -20.0, -20.0, 8.0, 18.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 6, 8, 13, 20, 14, 16, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 8, 20, 20, 20, 20, 20, 16, 20, 7, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 20, 20, 20, 19, 20, 8, 20, 20, 16, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 14.0, 12.0, 7.0, -10.0, 6.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, 13.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, 12.0, -10.0, -10.0, 4.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 14.0, 12.0, 7.0, -10.0, 6.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, 13.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, 12.0, -10.0, -10.0, 4.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3209073920472241, "mean_inference_ms": 1.87243615647284, "mean_action_processing_ms": 0.12427604873253545, "mean_env_wait_ms": 0.07998042580295722, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3023, "timesteps_this_iter": 32, "agent_timesteps_total": 6046, "timers": {"load_time_ms": 0.473, "load_throughput": 67581.938, "learn_time_ms": 7.799, "learn_throughput": 4102.887, "update_time_ms": 7.089}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -19.166790008544922, "min_q": -25.090023040771484, "max_q": -13.776782035827637, "mean_td_error": -0.26986977458000183, "model": {}}, "td_error": [0.9433517456054688, 0.6511192321777344, 0.5652236938476562, 0.19335269927978516, 0.6091079711914062, 0.5330524444580078, 0.3565654754638672, -12.420064926147461, 0.5296745300292969, 0.5544166564941406, 0.3474311828613281, 0.6393976211547852, 0.5734310150146484, -1.4189376831054688, 0.5820369720458984, 0.8956851959228516, 0.3272247314453125, 0.5195159912109375, 0.9348773956298828, 0.4607734680175781, 0.4777984619140625, 1.0237274169921875, 0.8174648284912109, 0.3322563171386719, 1.234548568725586, 0.4891471862792969, -12.776782035827637, 0.6233444213867188, 1.121419906616211, 0.6623725891113281, 0.3395557403564453, 0.6420783996582031], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -23.0494327545166, "min_q": -27.76969337463379, "max_q": -16.737028121948242, "mean_td_error": -1.3269922733306885, "model": {}}, "td_error": [0.8416976928710938, 0.3660430908203125, -0.7458629608154297, -21.582597732543945, -0.3710174560546875, -0.5448226928710938, 0.8694572448730469, -0.2994728088378906, -0.18561363220214844, -0.6230030059814453, 0.35865211486816406, 0.2999458312988281, 0.4828643798828125, -0.6286792755126953, -0.12740516662597656, 1.4421195983886719, 0.7583751678466797, 0.6360492706298828, -0.06405830383300781, -0.4884815216064453, -0.07575607299804688, 1.1799049377441406, 0.5442752838134766, 1.2950668334960938, 0.022268295288085938, -0.20499229431152344, 0.7520599365234375, -0.4141864776611328, 0.3223552703857422, 0.09937477111816406, -26.39199447631836, 0.01367950439453125], "custom_metrics": {}}}, "num_steps_sampled": 3023, "num_agent_steps_sampled": 6046, "num_steps_trained": 3584, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 7168, "last_target_update_ts": 3023, "num_target_updates": 19}, "done": false, "episodes_total": 164, "training_iteration": 8, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-11", "timestamp": 1648811591, "time_this_iter_s": 1.2048823833465576, "time_total_s": 12.422494173049927, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840433b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840433b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 12.422494173049927, "timesteps_since_restore": 256, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 30.75, "ram_util_percent": 51.75}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.0, "episode_len_mean": 17.9, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -6.5, "policy1": -6.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 28.0, 24.0, 14.0, -20.0, 12.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, 26.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, 24.0, -20.0, -20.0, 8.0, 18.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 10.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 6, 8, 13, 20, 14, 16, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 8, 20, 20, 20, 20, 20, 16, 20, 7, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 20, 20, 20, 19, 20, 8, 20, 20, 16, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 12, 20, 16, 15, 20, 20, 20, 20, 7, 20, 8, 20, 8, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 14.0, 12.0, 7.0, -10.0, 6.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, 13.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, 12.0, -10.0, -10.0, 4.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 5.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 14.0, 12.0, 7.0, -10.0, 6.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, 13.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, 12.0, -10.0, -10.0, 4.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 5.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3196968945933014, "mean_inference_ms": 1.8584349924579875, "mean_action_processing_ms": 0.12369924784598078, "mean_env_wait_ms": 0.0796681691165084, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3349, "timesteps_this_iter": 32, "agent_timesteps_total": 6698, "timers": {"load_time_ms": 0.461, "load_throughput": 69485.26, "learn_time_ms": 7.952, "learn_throughput": 4024.194, "update_time_ms": 8.545}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -21.542715072631836, "min_q": -27.28545379638672, "max_q": -16.111230850219727, "mean_td_error": -0.6227915287017822, "model": {}}, "td_error": [-3.4882593154907227, 0.6434593200683594, 1.2030582427978516, -28.41297149658203, -0.35196495056152344, 0.5831108093261719, 0.3764152526855469, -18.624332427978516, 2.0313682556152344, 1.6089324951171875, 0.06686592102050781, 0.2622108459472656, 1.9473342895507812, 1.0104351043701172, 1.441598892211914, 0.7957077026367188, 0.7123508453369141, 1.31182861328125, 0.41582489013671875, 0.9017734527587891, 2.3956756591796875, 0.9209918975830078, 1.0048389434814453, 1.429574966430664, 2.2412471771240234, -0.45087242126464844, 1.9230155944824219, 1.0013084411621094, 1.8183650970458984, 0.8402347564697266, 1.8133544921875, 0.6981887817382812], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -28.540239334106445, "min_q": -33.85508728027344, "max_q": -21.063682556152344, "mean_td_error": -2.7140440940856934, "model": {}}, "td_error": [-0.06414794921875, -0.3566150665283203, 0.6084098815917969, -42.77198028564453, -0.0921478271484375, 0.5044422149658203, -0.7465381622314453, -3.3031959533691406, 0.12573814392089844, 0.4823169708251953, 0.5342884063720703, -32.01870346069336, 0.5188179016113281, 0.25112152099609375, 0.38164329528808594, -0.11113357543945312, -0.06920623779296875, 0.0795440673828125, -0.0746002197265625, 0.4141693115234375, 0.5710372924804688, -0.22769927978515625, 0.1824626922607422, -0.032222747802734375, 0.1756000518798828, 0.5217189788818359, 0.24727630615234375, 1.2379112243652344, 0.034740447998046875, 0.11250495910644531, 0.09086990356445312, -14.055841445922852], "custom_metrics": {}}}, "num_steps_sampled": 3349, "num_agent_steps_sampled": 6698, "num_steps_trained": 4192, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 8384, "last_target_update_ts": 3349, "num_target_updates": 22}, "done": false, "episodes_total": 183, "training_iteration": 9, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-13", "timestamp": 1648811593, "time_this_iter_s": 1.3548853397369385, "time_total_s": 13.777379512786865, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 13.777379512786865, "timesteps_since_restore": 288, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 30.9, "ram_util_percent": 51.75}}
{"episode_reward_max": 26.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.54, "episode_len_mean": 18.27, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 13.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -7.27, "policy1": -7.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, 26.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 14.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, 24.0, -20.0, -20.0, 8.0, 18.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 10.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 2.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 8, 20, 20, 20, 20, 20, 16, 20, 7, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 20, 20, 20, 19, 20, 8, 20, 20, 16, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 12, 20, 16, 15, 20, 20, 20, 20, 7, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, 13.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, 12.0, -10.0, -10.0, 4.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 5.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 1.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, 13.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 7.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, 12.0, -10.0, -10.0, 4.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 5.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 1.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3188079546642284, "mean_inference_ms": 1.8493144404565494, "mean_action_processing_ms": 0.12331738223246048, "mean_env_wait_ms": 0.07944975325004949, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3660, "timesteps_this_iter": 32, "agent_timesteps_total": 7320, "timers": {"load_time_ms": 0.477, "load_throughput": 67035.125, "learn_time_ms": 7.703, "learn_throughput": 4154.409, "update_time_ms": 5.28}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -24.04160499572754, "min_q": -28.82244873046875, "max_q": -17.30162811279297, "mean_td_error": -0.06321382522583008, "model": {}}, "td_error": [1.4726314544677734, 1.2910385131835938, 1.6593017578125, 1.436532974243164, 0.6596508026123047, 0.12117195129394531, 1.7724800109863281, -0.38098716735839844, 1.0257320404052734, 1.5639724731445312, 0.6665439605712891, -0.73956298828125, 1.254995346069336, -0.06794357299804688, 1.076406478881836, 1.6945247650146484, 0.6874370574951172, 0.8580799102783203, 0.1458740234375, 0.9963874816894531, 0.8684444427490234, 1.4946937561035156, -0.46016883850097656, 1.5275096893310547, 0.8559684753417969, 0.4745063781738281, -27.202537536621094, 0.455169677734375, 1.2910385131835938, 0.5271244049072266, 0.34622764587402344, 0.6049137115478516], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -29.683422088623047, "min_q": -34.76997375488281, "max_q": -23.659530639648438, "mean_td_error": -0.13631808757781982, "model": {}}, "td_error": [0.7762546539306641, 0.41454124450683594, 1.9339027404785156, 1.7652397155761719, 0.5850067138671875, 0.7239646911621094, 0.7748813629150391, -33.76353073120117, 0.7032661437988281, 0.6387348175048828, 0.04975128173828125, -1.075408935546875, 0.8351211547851562, 0.5530414581298828, 1.1735763549804688, 0.8464698791503906, 1.8198928833007812, -1.4531879425048828, 0.8039169311523438, 1.9221763610839844, 1.6280632019042969, 0.6986446380615234, 1.9339599609375, 1.8329315185546875, 1.1244735717773438, 0.6405715942382812, 1.9060401916503906, 0.7024269104003906, 0.6291351318359375, 1.8394126892089844, 0.7354488372802734, 1.9391021728515625], "custom_metrics": {}}}, "num_steps_sampled": 3660, "num_agent_steps_sampled": 7320, "num_steps_trained": 4704, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 9408, "last_target_update_ts": 3580, "num_target_updates": 24}, "done": false, "episodes_total": 199, "training_iteration": 10, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-14", "timestamp": 1648811594, "time_this_iter_s": 1.2679998874664307, "time_total_s": 15.045379400253296, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8406dd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8406dd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 15.045379400253296, "timesteps_since_restore": 320, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 28.5, "ram_util_percent": 51.8}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.2, "episode_len_mean": 18.3, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -7.1, "policy1": -7.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, 14.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, 24.0, -20.0, -20.0, 8.0, 18.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 10.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 2.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 28.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 13, 20, 20, 10, 20, 20, 20, 20, 20, 8, 20, 20, 8, 20, 20, 20, 20, 20, 19, 20, 8, 20, 20, 16, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 12, 20, 16, 15, 20, 20, 20, 20, 7, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 6, 20, 20, 10, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, 7.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, 12.0, -10.0, -10.0, 4.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 5.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 1.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 14.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, 7.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1.0, -10.0, 12.0, -10.0, -10.0, 4.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 5.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 1.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 14.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3180726619312449, "mean_inference_ms": 1.8418220476640579, "mean_action_processing_ms": 0.12301112850858914, "mean_env_wait_ms": 0.07926368196393098, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3972, "timesteps_this_iter": 32, "agent_timesteps_total": 7944, "timers": {"load_time_ms": 0.427, "load_throughput": 74973.594, "learn_time_ms": 7.886, "learn_throughput": 4057.797, "update_time_ms": 5.041}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -26.022151947021484, "min_q": -33.64024353027344, "max_q": -19.51875877380371, "mean_td_error": -2.6572818756103516, "model": {}}, "td_error": [0.0731658935546875, -0.47454071044921875, 0.03840827941894531, -28.51875877380371, -31.30379867553711, -0.2853717803955078, 0.13377761840820312, 1.1492938995361328, 0.25269317626953125, -18.98296546936035, 0.42871665954589844, -0.6462764739990234, -1.2510871887207031, 0.15505027770996094, 0.06197357177734375, 0.16202163696289062, -0.6048507690429688, -0.67388916015625, -0.6132774353027344, -1.1489982604980469, -0.14544677734375, -1.1711044311523438, -0.8958263397216797, 0.2795867919921875, 0.03128242492675781, -0.2902870178222656, 0.3420448303222656, 0.3535175323486328, 0.34490394592285156, -1.1553573608398438, -1.4425582885742188, 0.7649402618408203], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -36.46398162841797, "min_q": -40.98944854736328, "max_q": -28.709421157836914, "mean_td_error": -0.07144367694854736, "model": {}}, "td_error": [-0.4957122802734375, 0.43645477294921875, -0.2973823547363281, 0.5128211975097656, -0.12413406372070312, -0.21381759643554688, -0.4906768798828125, -0.4419097900390625, 0.6325340270996094, -0.4885292053222656, -0.5477142333984375, -4.3062286376953125, 0.6849422454833984, 0.5682754516601562, 0.6837100982666016, 0.5087089538574219, 0.6370735168457031, -0.093658447265625, 0.7482376098632812, 0.31105804443359375, 1.2424468994140625, -0.4946861267089844, 0.5027999877929688, 0.6294631958007812, 0.5175819396972656, -3.697986602783203, 0.06936454772949219, -0.18885040283203125, -0.4593696594238281, 0.6025733947753906, 1.0031757354736328, -0.23676300048828125], "custom_metrics": {}}}, "num_steps_sampled": 3972, "num_agent_steps_sampled": 7944, "num_steps_trained": 5248, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 10496, "last_target_update_ts": 3932, "num_target_updates": 27}, "done": false, "episodes_total": 216, "training_iteration": 11, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-15", "timestamp": 1648811595, "time_this_iter_s": 1.244156837463379, "time_total_s": 16.289536237716675, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840840e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840840e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 16.289536237716675, "timesteps_since_restore": 352, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 30.200000000000003, "ram_util_percent": 51.8}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.96, "episode_len_mean": 18.18, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -6.98, "policy1": -6.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 2.0, -20.0, 24.0, -20.0, -20.0, 8.0, 18.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 10.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 2.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 28.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 26.0, 16.0, -40.0, 20.0, 10.0, -20.0, 14.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0], "episode_lengths": [20, 20, 19, 20, 8, 20, 20, 16, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 12, 20, 16, 15, 20, 20, 20, 20, 7, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 6, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 7, 12, 20, 10, 15, 20, 13, 20, 20, 20, 20, 20, 20, 20, 10, 20], "policy_policy0_reward": [-10.0, -10.0, 1.0, -10.0, 12.0, -10.0, -10.0, 4.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 5.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 1.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 14.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 13.0, 8.0, -20.0, 10.0, 5.0, -10.0, 7.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 1.0, -10.0, 12.0, -10.0, -10.0, 4.0, 9.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 5.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 1.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 14.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 13.0, 8.0, -20.0, 10.0, 5.0, -10.0, 7.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31703733912079135, "mean_inference_ms": 1.832255159281927, "mean_action_processing_ms": 0.12255642938456804, "mean_env_wait_ms": 0.07897874587263189, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4299, "timesteps_this_iter": 32, "agent_timesteps_total": 8598, "timers": {"load_time_ms": 0.441, "load_throughput": 72620.781, "learn_time_ms": 7.64, "learn_throughput": 4188.388, "update_time_ms": 4.833}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -28.71212387084961, "min_q": -36.62871551513672, "max_q": -21.136821746826172, "mean_td_error": -1.4758834838867188, "model": {}}, "td_error": [0.5489692687988281, -0.9926948547363281, -1.4577293395996094, -1.3098793029785156, 0.5288143157958984, 0.5879077911376953, 0.44747352600097656, -0.3432941436767578, -0.879180908203125, -0.8782234191894531, -2.68121337890625, -1.1579360961914062, 0.08483695983886719, 0.1863269805908203, 0.12436103820800781, -21.587980270385742, -12.442352294921875, -0.4560813903808594, -1.0914840698242188, -0.9253463745117188, -0.09354019165039062, 0.014047622680664062, 0.7415733337402344, 0.2276592254638672, -2.1456222534179688, -0.9688911437988281, 0.265899658203125, -1.2959060668945312, -0.08714485168457031, 0.10081863403320312, 0.1909809112548828, -0.4834403991699219], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -37.356197357177734, "min_q": -41.744014739990234, "max_q": -30.686141967773438, "mean_td_error": -2.557058334350586, "model": {}}, "td_error": [-1.0888099670410156, -0.6670684814453125, -40.3016471862793, -0.171661376953125, -0.5033798217773438, -16.05266571044922, -0.94366455078125, -0.7353935241699219, -3.572795867919922, -1.0103988647460938, -0.676177978515625, -1.3408317565917969, -1.1036872863769531, -1.0269298553466797, -0.09317779541015625, -0.7519340515136719, -0.4833488464355469, -1.1261978149414062, -0.98846435546875, -1.5664405822753906, 0.18035316467285156, -1.1719779968261719, -0.7698783874511719, -0.2639122009277344, -1.3556671142578125, -0.28787994384765625, -0.4796333312988281, -1.1473541259765625, -0.8327293395996094, 0.3367500305175781, -0.7030677795410156, -1.1261978149414062], "custom_metrics": {}}}, "num_steps_sampled": 4299, "num_agent_steps_sampled": 8598, "num_steps_trained": 5856, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 11712, "last_target_update_ts": 4269, "num_target_updates": 30}, "done": false, "episodes_total": 235, "training_iteration": 12, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-17", "timestamp": 1648811597, "time_this_iter_s": 1.2877039909362793, "time_total_s": 17.577240228652954, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84064200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84064200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 17.577240228652954, "timesteps_since_restore": 384, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 29.75, "ram_util_percent": 51.8}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.3, "episode_len_mean": 18.15, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -7.15, "policy1": -7.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 10.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 2.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 28.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 26.0, 16.0, -40.0, 20.0, 10.0, -20.0, 14.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 12.0, 24.0, -20.0, 8.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 12, 20, 16, 15, 20, 20, 20, 20, 7, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 6, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 7, 12, 20, 10, 15, 20, 13, 20, 20, 20, 20, 20, 20, 20, 10, 20, 13, 20, 20, 20, 20, 14, 8, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 5.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 1.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 14.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 13.0, 8.0, -20.0, 10.0, 5.0, -10.0, 7.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 6.0, 12.0, -10.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 5.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 1.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 14.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 13.0, 8.0, -20.0, 10.0, 5.0, -10.0, 7.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 6.0, 12.0, -10.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3161890769647048, "mean_inference_ms": 1.8243075661495778, "mean_action_processing_ms": 0.12222968115901661, "mean_env_wait_ms": 0.07874312758950336, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4610, "timesteps_this_iter": 32, "agent_timesteps_total": 9220, "timers": {"load_time_ms": 0.442, "load_throughput": 72319.483, "learn_time_ms": 7.972, "learn_throughput": 4014.012, "update_time_ms": 5.014}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -32.32667541503906, "min_q": -37.727046966552734, "max_q": -23.834291458129883, "mean_td_error": -3.090480327606201, "model": {}}, "td_error": [-36.62364196777344, 1.313079833984375, -0.22152137756347656, 0.7822608947753906, 1.1714096069335938, -0.5304927825927734, -26.313203811645508, 0.5629539489746094, 1.8513336181640625, 0.0997772216796875, 0.0013294219970703125, -0.3397674560546875, 1.3637886047363281, -0.5017261505126953, 1.0453643798828125, 1.4243698120117188, 1.6316070556640625, -0.27649497985839844, -36.159034729003906, -0.10887527465820312, 1.0349617004394531, 1.5595474243164062, 1.5946083068847656, 1.0190925598144531, -0.5432777404785156, -0.44522666931152344, -0.3609294891357422, 1.4999122619628906, -1.2601737976074219, -0.40122032165527344, 1.2454338073730469, -14.010618209838867], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -38.79138946533203, "min_q": -41.01911926269531, "max_q": -32.33428955078125, "mean_td_error": -4.931521415710449, "model": {}}, "td_error": [1.3097076416015625, -39.36526107788086, 0.7592849731445312, 0.46026611328125, -0.17924118041992188, -0.16829299926757812, 0.8386459350585938, -6.1293487548828125, -0.2654151916503906, -0.07244873046875, 0.7431221008300781, -0.07199859619140625, -0.039154052734375, 0.06413650512695312, -0.36202239990234375, -38.719329833984375, 1.1147422790527344, -0.26336669921875, 0.4784393310546875, 0.5803184509277344, -0.28250885009765625, 1.1487655639648438, 0.7224082946777344, -39.60587692260742, -0.2520561218261719, -0.2752532958984375, 0.08908843994140625, -0.220977783203125, -0.11012649536132812, 0.12767791748046875, -0.16395187377929688, -39.69864273071289], "custom_metrics": {}}}, "num_steps_sampled": 4610, "num_agent_steps_sampled": 9220, "num_steps_trained": 6400, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 12800, "last_target_update_ts": 4610, "num_target_updates": 33}, "done": false, "episodes_total": 252, "training_iteration": 13, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-18", "timestamp": 1648811598, "time_this_iter_s": 1.2616379261016846, "time_total_s": 18.83887815475464, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8408cb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8408cb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 18.83887815475464, "timesteps_since_restore": 416, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 30.2, "ram_util_percent": 51.8}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.48, "episode_len_mean": 18.34, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -7.74, "policy1": -7.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 2.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 28.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 26.0, 16.0, -40.0, 20.0, 10.0, -20.0, 14.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 12.0, 24.0, -20.0, 8.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0], "episode_lengths": [20, 20, 20, 20, 7, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 6, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 7, 12, 20, 10, 15, 20, 13, 20, 20, 20, 20, 20, 20, 20, 10, 20, 13, 20, 20, 20, 20, 14, 8, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 12, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 1.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 14.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 13.0, 8.0, -20.0, 10.0, 5.0, -10.0, 7.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 6.0, 12.0, -10.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 1.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 14.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 13.0, 8.0, -20.0, 10.0, 5.0, -10.0, 7.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 6.0, 12.0, -10.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3155125126847718, "mean_inference_ms": 1.818065569533237, "mean_action_processing_ms": 0.12197534142123567, "mean_env_wait_ms": 0.07856517707103665, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4940, "timesteps_this_iter": 32, "agent_timesteps_total": 9880, "timers": {"load_time_ms": 0.427, "load_throughput": 74898.286, "learn_time_ms": 7.904, "learn_throughput": 4048.629, "update_time_ms": 4.988}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -29.456233978271484, "min_q": -39.514739990234375, "max_q": -15.871820449829102, "mean_td_error": -3.0468571186065674, "model": {}}, "td_error": [0.43935394287109375, 0.37581825256347656, 0.37581825256347656, 0.6070518493652344, 1.5012435913085938, 0.40390777587890625, 1.7963294982910156, -2.633068084716797, 0.47132110595703125, 1.3307571411132812, 0.5350360870361328, 0.2457733154296875, 0.596466064453125, 0.8197479248046875, 0.35126686096191406, 0.49194908142089844, 0.24973487854003906, 1.1863441467285156, -2.0035457611083984, -30.879230499267578, -35.919044494628906, 0.4212150573730469, 0.4786548614501953, 0.3575019836425781, -27.210567474365234, -0.7350063323974609, -13.136642456054688, -0.1894969940185547, -0.06950759887695312, 1.3737220764160156, 0.05049896240234375, 0.8171672821044922], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -37.87470626831055, "min_q": -41.701255798339844, "max_q": -32.17985153198242, "mean_td_error": -3.4981775283813477, "model": {}}, "td_error": [0.896148681640625, -5.379295349121094, 0.7677574157714844, 0.6445999145507812, 0.6373786926269531, 0.7012367248535156, 1.1369972229003906, -5.7619476318359375, 0.4840202331542969, 0.556793212890625, 0.6562614440917969, 1.007537841796875, -1.5451164245605469, 1.236846923828125, 1.0698623657226562, -31.404129028320312, 0.9002494812011719, -39.89767837524414, 0.7183265686035156, 0.9205398559570312, 0.5221405029296875, 0.5180473327636719, 0.6105880737304688, 0.4370155334472656, 0.9826011657714844, 0.6425743103027344, 0.67083740234375, 1.1155319213867188, -41.54161834716797, -5.416454315185547, 0.5831031799316406, 0.5875625610351562], "custom_metrics": {}}}, "num_steps_sampled": 4940, "num_agent_steps_sampled": 9880, "num_steps_trained": 6944, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 13888, "last_target_update_ts": 4848, "num_target_updates": 35}, "done": false, "episodes_total": 269, "training_iteration": 14, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-19", "timestamp": 1648811599, "time_this_iter_s": 1.2639567852020264, "time_total_s": 20.102834939956665, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fdc20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fdc20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 20.102834939956665, "timesteps_since_restore": 448, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 29.25, "ram_util_percent": 51.849999999999994}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.0, "episode_len_mean": 18.4, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.0, "policy1": -8.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 28.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 26.0, 16.0, -40.0, 20.0, 10.0, -20.0, 14.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 12.0, 24.0, -20.0, 8.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, 16.0, -20.0, 18.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 10.0, -20.0], "episode_lengths": [20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 6, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 7, 12, 20, 10, 15, 20, 13, 20, 20, 20, 20, 20, 20, 20, 10, 20, 13, 20, 20, 20, 20, 14, 8, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 10, 12, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20], "policy_policy0_reward": [-10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 14.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 13.0, 8.0, -20.0, 10.0, 5.0, -10.0, 7.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 6.0, 12.0, -10.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 8.0, -10.0, 9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0], "policy_policy1_reward": [-10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 14.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 13.0, 8.0, -20.0, 10.0, 5.0, -10.0, 7.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 6.0, 12.0, -10.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 8.0, -10.0, 9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31491824411932007, "mean_inference_ms": 1.8129162903761784, "mean_action_processing_ms": 0.12178216285742352, "mean_env_wait_ms": 0.07842277397560336, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5268, "timesteps_this_iter": 32, "agent_timesteps_total": 10536, "timers": {"load_time_ms": 0.448, "load_throughput": 71487.472, "learn_time_ms": 8.219, "learn_throughput": 3893.461, "update_time_ms": 5.278}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -34.264808654785156, "min_q": -43.48369598388672, "max_q": -19.9578914642334, "mean_td_error": 0.415136456489563, "model": {}}, "td_error": [-0.9275608062744141, 0.88885498046875, -0.1734485626220703, 0.9842376708984375, -0.43416786193847656, -0.12403678894042969, -1.1809425354003906, 0.8126678466796875, 1.3754844665527344, -0.5319538116455078, -0.028966903686523438, 2.4357852935791016, -0.2015705108642578, 0.9512176513671875, 0.696502685546875, 0.79736328125, 0.94451904296875, -0.17049789428710938, 0.07993888854980469, -0.29965972900390625, 1.2240180969238281, 1.6494560241699219, -1.1809425354003906, -0.049335479736328125, 0.15866851806640625, 0.09474563598632812, -0.32187843322753906, -0.3979511260986328, -0.6568527221679688, 0.93902587890625, 0.7580757141113281, 5.17357063293457], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -41.227386474609375, "min_q": -45.260337829589844, "max_q": -32.32868576049805, "mean_td_error": -1.181244134902954, "model": {}}, "td_error": [2.855571746826172, 1.1781196594238281, 3.0384140014648438, 2.254924774169922, -31.328685760498047, -2.9734954833984375, 2.1007614135742188, 2.0301437377929688, -13.954090118408203, 2.482311248779297, 0.883636474609375, 2.143413543701172, 2.1016845703125, 2.3119163513183594, 2.1704750061035156, 0.9569664001464844, 2.7638206481933594, -2.359485626220703, -3.3899803161621094, 2.306751251220703, 0.8841438293457031, 2.668407440185547, -34.48368453979492, 1.863983154296875, 2.3930892944335938, 1.9951171875, 2.2196197509765625, 2.3467140197753906, 2.766937255859375, -2.6838912963867188, 2.2520790100097656, 2.404499053955078], "custom_metrics": {}}}, "num_steps_sampled": 5268, "num_agent_steps_sampled": 10536, "num_steps_trained": 7520, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 15040, "last_target_update_ts": 5173, "num_target_updates": 38}, "done": false, "episodes_total": 287, "training_iteration": 15, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-21", "timestamp": 1648811601, "time_this_iter_s": 1.3393669128417969, "time_total_s": 21.442201852798462, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 21.442201852798462, "timesteps_since_restore": 480, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 30.75, "ram_util_percent": 51.9}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.96, "episode_len_mean": 18.48, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.48, "policy1": -8.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, 8.0, 28.0, -20.0, -20.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 26.0, 16.0, -40.0, 20.0, 10.0, -20.0, 14.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 12.0, 24.0, -20.0, 8.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, 16.0, -20.0, 18.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 10.0, -20.0, -20.0, 0.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 16, 6, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 7, 12, 20, 10, 15, 20, 13, 20, 20, 20, 20, 20, 20, 20, 10, 20, 13, 20, 20, 20, 20, 14, 8, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 10, 12, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, 4.0, 14.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 13.0, 8.0, -20.0, 10.0, 5.0, -10.0, 7.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 6.0, 12.0, -10.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 8.0, -10.0, 9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -10.0, 0.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, 4.0, 14.0, -10.0, -10.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 13.0, 8.0, -20.0, 10.0, 5.0, -10.0, 7.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 6.0, 12.0, -10.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 8.0, -10.0, 9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -10.0, 0.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31433755204059655, "mean_inference_ms": 1.8082096616223882, "mean_action_processing_ms": 0.12157875919125705, "mean_env_wait_ms": 0.07827985422669284, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5568, "timesteps_this_iter": 32, "agent_timesteps_total": 11136, "timers": {"load_time_ms": 0.437, "load_throughput": 73234.969, "learn_time_ms": 7.724, "learn_throughput": 4142.791, "update_time_ms": 4.979}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -40.725341796875, "min_q": -47.72454071044922, "max_q": -24.570171356201172, "mean_td_error": -3.6772541999816895, "model": {}}, "td_error": [-0.3436279296875, -1.3449554443359375, -3.127155303955078, -1.8049697875976562, -1.122344970703125, -1.7837295532226562, -1.63409423828125, -37.85108184814453, -40.77150344848633, -0.4224815368652344, -0.8300209045410156, -0.11310577392578125, -0.714263916015625, -0.6985626220703125, -1.3697547912597656, -0.20206832885742188, -1.8997421264648438, -1.0792045593261719, -0.9116096496582031, -0.7032318115234375, -3.2638282775878906, -10.78177261352539, 6.931730270385742, -2.0466766357421875, -2.0082359313964844, 0.033489227294921875, -0.5614166259765625, -1.0037345886230469, -1.0789146423339844, -2.2850265502929688, -0.8562088012695312, -2.024036407470703], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -49.00220489501953, "min_q": -51.966651916503906, "max_q": -28.300537109375, "mean_td_error": -5.324231147766113, "model": {}}, "td_error": [-4.414447784423828, -3.5867233276367188, -3.97357177734375, -4.326515197753906, -11.781620025634766, -3.811267852783203, -4.744777679443359, -4.055000305175781, -3.8609886169433594, -3.9423255920410156, -3.5318527221679688, 8.12160873413086, -3.5162506103515625, -3.4488563537597656, -4.00372314453125, -4.415805816650391, -4.387882232666016, -5.716484069824219, -4.180000305175781, -4.380283355712891, -3.5221214294433594, -3.9558982849121094, -4.391139984130859, -3.1452713012695312, -4.018573760986328, -50.445587158203125, -2.9888572692871094, -4.266349792480469, -4.131858825683594, -3.9737014770507812, -4.20562744140625, -3.3736419677734375], "custom_metrics": {}}}, "num_steps_sampled": 5568, "num_agent_steps_sampled": 11136, "num_steps_trained": 8000, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 16000, "last_target_update_ts": 5528, "num_target_updates": 41}, "done": false, "episodes_total": 302, "training_iteration": 16, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-22", "timestamp": 1648811602, "time_this_iter_s": 1.1392796039581299, "time_total_s": 22.581481456756592, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 22.581481456756592, "timesteps_since_restore": 512, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 30.549999999999997, "ram_util_percent": 51.9}}
{"episode_reward_max": 26.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.14, "episode_len_mean": 18.57, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 13.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -9.07, "policy1": -9.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.0, 16.0, -40.0, 20.0, 10.0, -20.0, 14.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 12.0, 24.0, -20.0, 8.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, 16.0, -20.0, 18.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 10.0, -20.0, -20.0, 0.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, 22.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [7, 12, 20, 10, 15, 20, 13, 20, 20, 20, 20, 20, 20, 20, 10, 20, 13, 20, 20, 20, 20, 14, 8, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 10, 12, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20], "policy_policy0_reward": [13.0, 8.0, -20.0, 10.0, 5.0, -10.0, 7.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 6.0, 12.0, -10.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 8.0, -10.0, 9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -10.0, 0.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, 11.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [13.0, 8.0, -20.0, 10.0, 5.0, -10.0, 7.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 6.0, 12.0, -10.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 8.0, -10.0, 9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -10.0, 0.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, 11.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3136030003703399, "mean_inference_ms": 1.8021652324125774, "mean_action_processing_ms": 0.12127401289989262, "mean_env_wait_ms": 0.07807783908508344, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5889, "timesteps_this_iter": 32, "agent_timesteps_total": 11778, "timers": {"load_time_ms": 0.46, "load_throughput": 69521.251, "learn_time_ms": 7.569, "learn_throughput": 4227.983, "update_time_ms": 4.668}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -41.74291229248047, "min_q": -49.23870086669922, "max_q": -28.49603271484375, "mean_td_error": -4.316622734069824, "model": {}}, "td_error": [0.8598594665527344, 0.2440185546875, 0.854827880859375, -0.6410484313964844, -0.8368949890136719, -0.09079360961914062, 0.2108306884765625, 0.17123794555664062, -2.130290985107422, -0.77069091796875, -0.31322479248046875, 0.6009368896484375, 0.6135597229003906, -32.90666198730469, -2.7139129638671875, 0.5535354614257812, 0.49239349365234375, -0.5725364685058594, 0.3357124328613281, 0.2440185546875, 0.7607917785644531, 0.21976089477539062, 0.0269012451171875, 0.2908744812011719, 0.1909332275390625, 0.8557243347167969, -1.1592483520507812, -1.0551872253417969, 1.3197097778320312, 0.2707862854003906, -56.63039016723633, -47.42745590209961], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -43.81379699707031, "min_q": -49.307498931884766, "max_q": -36.36367416381836, "mean_td_error": 0.500755786895752, "model": {}}, "td_error": [1.4340858459472656, 0.5224151611328125, 0.4969062805175781, 1.2802238464355469, -0.025150299072265625, 0.1078338623046875, 0.6254615783691406, 0.2883338928222656, 0.08230972290039062, 0.5097770690917969, 0.8759193420410156, 0.5580902099609375, 0.533447265625, 1.0972824096679688, 0.6163063049316406, -0.4228630065917969, 0.9081192016601562, 0.9289665222167969, 0.3334197998046875, 0.693023681640625, -0.2831611633300781, 0.5992774963378906, 0.3996543884277344, 0.8305854797363281, 0.6886024475097656, 0.516845703125, -0.4831123352050781, 0.1454620361328125, 0.6273078918457031, 0.0842132568359375, 0.4103431701660156, 1.0442581176757812], "custom_metrics": {}}}, "num_steps_sampled": 5889, "num_agent_steps_sampled": 11778, "num_steps_trained": 8544, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 17088, "last_target_update_ts": 5869, "num_target_updates": 44}, "done": false, "episodes_total": 319, "training_iteration": 17, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-23", "timestamp": 1648811603, "time_this_iter_s": 1.1899583339691162, "time_total_s": 23.771439790725708, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840847a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840847a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 23.771439790725708, "timesteps_since_restore": 544, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 30.849999999999998, "ram_util_percent": 51.9}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.6, "episode_len_mean": 19.1, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -10.8, "policy1": -10.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 12.0, 24.0, -20.0, 8.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, 16.0, -20.0, 18.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 10.0, -20.0, -20.0, 0.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, 22.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 13, 20, 20, 20, 20, 14, 8, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 10, 12, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 6.0, 12.0, -10.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 8.0, -10.0, 9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -10.0, 0.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, 11.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 6.0, 12.0, -10.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 8.0, -10.0, 9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -10.0, 0.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, 11.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3131208873691574, "mean_inference_ms": 1.798708801788754, "mean_action_processing_ms": 0.12113407339839004, "mean_env_wait_ms": 0.07797298234408367, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6189, "timesteps_this_iter": 32, "agent_timesteps_total": 12378, "timers": {"load_time_ms": 0.461, "load_throughput": 69416.979, "learn_time_ms": 7.946, "learn_throughput": 4027.188, "update_time_ms": 5.45}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -40.497093200683594, "min_q": -49.81220626831055, "max_q": -18.006210327148438, "mean_td_error": -2.273552417755127, "model": {}}, "td_error": [0.6991729736328125, 0.43238067626953125, -0.26371192932128906, -48.78644561767578, 0.5278053283691406, 0.5779876708984375, 10.686136245727539, -0.7734489440917969, 0.5630149841308594, 0.7143478393554688, 1.4377403259277344, 0.5293235778808594, 0.31479644775390625, 0.10221481323242188, 0.58734130859375, 0.59344482421875, 0.2658348083496094, 0.18283843994140625, 2.6422061920166016, 0.3994178771972656, 0.5167160034179688, 0.5238227844238281, -1.0358238220214844, 0.7921257019042969, 0.6081123352050781, 0.2554283142089844, 0.19471359252929688, 0.4666862487792969, -48.41484451293945, -2.831796646118164, 1.0318412780761719, 3.706941604614258], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -41.509765625, "min_q": -50.759544372558594, "max_q": -35.248348236083984, "mean_td_error": -2.7757012844085693, "model": {}}, "td_error": [0.5740623474121094, 0.5340461730957031, -7.244651794433594, -0.4274940490722656, -3.2844810485839844, -6.707172393798828, 0.3238792419433594, -4.0990142822265625, 0.41225433349609375, 0.5692710876464844, 1.1002845764160156, 0.8265876770019531, 0.5051612854003906, 0.5428199768066406, 0.7655754089355469, 2.4080238342285156, -3.1192359924316406, 0.7871246337890625, -3.5998153686523438, 0.5340461730957031, 0.7783584594726562, -7.584403991699219, -4.430202484130859, -6.433635711669922, 0.5712547302246094, -44.759788513183594, -3.541057586669922, 0.3896369934082031, 0.49617767333984375, 0.9147872924804688, -0.776336669921875, -5.848506927490234], "custom_metrics": {}}}, "num_steps_sampled": 6189, "num_agent_steps_sampled": 12378, "num_steps_trained": 9024, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 18048, "last_target_update_ts": 6109, "num_target_updates": 46}, "done": false, "episodes_total": 334, "training_iteration": 18, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-24", "timestamp": 1648811604, "time_this_iter_s": 1.196911334991455, "time_total_s": 24.968351125717163, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 24.968351125717163, "timesteps_since_restore": 576, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 29.35, "ram_util_percent": 51.9}}
{"episode_reward_max": 22.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.26, "episode_len_mean": 19.23, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 11.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -11.63, "policy1": -11.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 0.0, -20.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, 16.0, -20.0, 18.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 10.0, -20.0, -20.0, 0.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, 22.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, 12.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 10, 12, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 8.0, -10.0, 9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -10.0, 0.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, 11.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, 6.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 8.0, -10.0, 9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -10.0, 0.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, 11.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, 6.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3126464090469222, "mean_inference_ms": 1.7954744328352696, "mean_action_processing_ms": 0.12096386541295603, "mean_env_wait_ms": 0.07787994697293135, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6493, "timesteps_this_iter": 32, "agent_timesteps_total": 12986, "timers": {"load_time_ms": 0.451, "load_throughput": 71010.914, "learn_time_ms": 8.313, "learn_throughput": 3849.619, "update_time_ms": 5.138}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -46.10193634033203, "min_q": -72.0427474975586, "max_q": -9.06889533996582, "mean_td_error": -6.839799880981445, "model": {}}, "td_error": [-0.39046478271484375, -52.46456527709961, -2.1224212646484375, -1.4216499328613281, -0.4882087707519531, -0.5847816467285156, -23.456018447875977, -1.7932548522949219, -58.702606201171875, -1.4763069152832031, -2.0699691772460938, -0.6645965576171875, 0.24623870849609375, -0.6339073181152344, -0.9268989562988281, -1.6349525451660156, -0.6783866882324219, -1.733795166015625, -0.7603416442871094, -0.5897216796875, 4.686519622802734, -0.7419319152832031, -0.9940414428710938, -52.65927505493164, -0.5618534088134766, -1.5485877990722656, -1.51129150390625, -10.574604988098145, -1.6695404052734375, 0.517242431640625, -1.0338096618652344, -0.4358024597167969], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -43.08002471923828, "min_q": -48.540042877197266, "max_q": -37.91752243041992, "mean_td_error": -2.742976665496826, "model": {}}, "td_error": [-1.6946487426757812, -1.1443748474121094, -1.4814033508300781, -2.396862030029297, -0.7781829833984375, -0.5770378112792969, -0.5354385375976562, -2.012409210205078, -1.7293853759765625, -2.643695831298828, -1.2663307189941406, -1.7811050415039062, -2.16729736328125, -0.09539794921875, -2.435405731201172, -2.1349220275878906, 0.3448829650878906, -1.1868019104003906, -1.2181549072265625, -2.121601104736328, -45.59001159667969, -1.8916397094726562, -1.1254806518554688, -0.4550628662109375, -1.252899169921875, -1.0482635498046875, -0.19338607788085938, -0.4087677001953125, -1.4531745910644531, -1.305267333984375, -2.2429733276367188, -1.7527503967285156], "custom_metrics": {}}}, "num_steps_sampled": 6493, "num_agent_steps_sampled": 12986, "num_steps_trained": 9536, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 19072, "last_target_update_ts": 6453, "num_target_updates": 49}, "done": false, "episodes_total": 350, "training_iteration": 19, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-26", "timestamp": 1648811606, "time_this_iter_s": 1.226987600326538, "time_total_s": 26.1953387260437, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84066ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84066ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 26.1953387260437, "timesteps_since_restore": 608, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 28.3, "ram_util_percent": 51.9}}
{"episode_reward_max": 22.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.3, "episode_len_mean": 19.25, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 11.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -12.15, "policy1": -12.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, 20.0, 16.0, -20.0, 18.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 10.0, -20.0, -20.0, 0.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, 22.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, 12.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 12, 20, 20, 20, 20, 20, 10, 12, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 8.0, -10.0, 9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -10.0, 0.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, 11.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, 10.0, 8.0, -10.0, 9.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -10.0, 0.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, 11.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3122889565596687, "mean_inference_ms": 1.7930220001798205, "mean_action_processing_ms": 0.12083292720012245, "mean_env_wait_ms": 0.07781251040216994, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6793, "timesteps_this_iter": 32, "agent_timesteps_total": 13586, "timers": {"load_time_ms": 0.456, "load_throughput": 70149.86, "learn_time_ms": 7.481, "learn_throughput": 4277.324, "update_time_ms": 5.008}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -47.223716735839844, "min_q": -55.64163589477539, "max_q": -23.01936149597168, "mean_td_error": -2.2553772926330566, "model": {}}, "td_error": [0.2962074279785156, 0.4450225830078125, 0.09386062622070312, -0.3164939880371094, 1.1959457397460938, -54.12562561035156, -29.41280746459961, -1.6392078399658203, 0.6286964416503906, 0.07302093505859375, 0.11688995361328125, 0.20322799682617188, 0.35958099365234375, 0.36573028564453125, 2.056612014770508, 0.4279823303222656, 0.8716926574707031, 0.2966651916503906, 0.5120010375976562, 0.16179275512695312, 0.09386062622070312, 0.8946685791015625, 0.3990821838378906, -0.18300628662109375, 0.4664878845214844, 0.22311782836914062, 1.4773292541503906, 0.151702880859375, 0.4807853698730469, 0.28804779052734375, 0.16917037963867188, 0.7558841705322266], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -44.582298278808594, "min_q": -50.53657531738281, "max_q": -38.63519287109375, "mean_td_error": -2.1889305114746094, "model": {}}, "td_error": [0.054615020751953125, -5.285633087158203, 0.4743499755859375, 0.21700286865234375, -0.592071533203125, -0.04345703125, 0.046478271484375, -1.1455917358398438, -0.16153335571289062, -0.06811904907226562, 0.5973281860351562, -0.004833221435546875, 0.33116912841796875, 0.34824371337890625, -12.22622299194336, 1.41436767578125, -0.9163856506347656, -2.220317840576172, 6.368503570556641, 0.3835105895996094, -58.55750274658203, 0.2109527587890625, -0.18751907348632812, -0.07412338256835938, 0.31075286865234375, 0.38153076171875, -1.0333671569824219, 0.3015632629394531, 0.03781890869140625, -0.18309783935546875, 1.28936767578125, -0.113555908203125], "custom_metrics": {}}}, "num_steps_sampled": 6793, "num_agent_steps_sampled": 13586, "num_steps_trained": 10016, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 20032, "last_target_update_ts": 6693, "num_target_updates": 51}, "done": false, "episodes_total": 365, "training_iteration": 20, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-27", "timestamp": 1648811607, "time_this_iter_s": 1.1521942615509033, "time_total_s": 27.347532987594604, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 27.347532987594604, "timesteps_since_restore": 640, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 30.1, "ram_util_percent": 51.9}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.18, "episode_len_mean": 19.09, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -11.59, "policy1": -11.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 10.0, -20.0, -20.0, 0.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, 22.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, 12.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 14.0, 24.0, 18.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 13, 8, 11, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 5.0, -10.0, -10.0, 0.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, 11.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 7.0, 12.0, 9.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, 5.0, -10.0, -10.0, 0.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, 11.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 7.0, 12.0, 9.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3117265830660654, "mean_inference_ms": 1.7888629597408567, "mean_action_processing_ms": 0.12057712681982082, "mean_env_wait_ms": 0.07767737756717978, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7122, "timesteps_this_iter": 32, "agent_timesteps_total": 14244, "timers": {"load_time_ms": 0.427, "load_throughput": 74986.16, "learn_time_ms": 7.574, "learn_throughput": 4225.241, "update_time_ms": 5.089}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -47.59577178955078, "min_q": -56.33478546142578, "max_q": -22.49323272705078, "mean_td_error": -3.9029488563537598, "model": {}}, "td_error": [-28.008459091186523, 0.24377059936523438, -0.23607635498046875, 0.7811660766601562, 0.7538337707519531, -0.5250930786132812, 0.3549919128417969, 0.8164710998535156, 0.3894615173339844, 1.0184898376464844, 0.8061141967773438, 0.8928413391113281, 0.9091873168945312, 0.4044189453125, 1.0154151916503906, -0.11400222778320312, 0.2861518859863281, 0.5226554870605469, 0.6917190551757812, -55.2758903503418, 0.677947998046875, 0.75384521484375, -35.840370178222656, 0.6505126953125, 0.601043701171875, 4.845027923583984, -24.911252975463867, 0.3173065185546875, 0.3902435302734375, 0.7604179382324219, 0.47985076904296875, 0.653900146484375], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -45.423126220703125, "min_q": -51.91131591796875, "max_q": -39.98411560058594, "mean_td_error": -5.049310207366943, "model": {}}, "td_error": [-11.992923736572266, -0.29174041748046875, -0.2528343200683594, 0.03894805908203125, -0.3882560729980469, -2.7061538696289062, -0.6383399963378906, 0.289520263671875, -0.057315826416015625, -4.651012420654297, -0.2929344177246094, -3.3646507263183594, -0.10488510131835938, 0.21976852416992188, -0.3589630126953125, 0.07152938842773438, 0.3629875183105469, -46.97609329223633, 0.13268661499023438, -0.00800323486328125, 0.11232376098632812, -0.032497406005859375, 0.09176254272460938, 0.051326751708984375, 0.33148956298828125, -0.17076492309570312, 0.128143310546875, -50.451175689697266, 0.1322174072265625, 0.38190460205078125, -41.01905059814453, -0.16493988037109375], "custom_metrics": {}}}, "num_steps_sampled": 7122, "num_agent_steps_sampled": 14244, "num_steps_trained": 10624, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 21248, "last_target_update_ts": 7022, "num_target_updates": 54}, "done": false, "episodes_total": 384, "training_iteration": 21, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-28", "timestamp": 1648811608, "time_this_iter_s": 1.276416540145874, "time_total_s": 28.62394952774048, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 28.62394952774048, "timesteps_since_restore": 672, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 29.65, "ram_util_percent": 51.95}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.32, "episode_len_mean": 18.66, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -10.66, "policy1": -10.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, 22.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, 12.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 14.0, 24.0, 18.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 4.0, 26.0, 34.0, -40.0, -40.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 13, 8, 11, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 18, 7, 3, 20, 20, 19, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, 11.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 7.0, 12.0, 9.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, 13.0, 17.0, -20.0, -20.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, 11.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 7.0, 12.0, 9.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, 13.0, 17.0, -20.0, -20.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31133187632160025, "mean_inference_ms": 1.7852465930295247, "mean_action_processing_ms": 0.1203613519063228, "mean_env_wait_ms": 0.07753838992051261, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7454, "timesteps_this_iter": 32, "agent_timesteps_total": 14908, "timers": {"load_time_ms": 0.441, "load_throughput": 72632.571, "learn_time_ms": 8.008, "learn_throughput": 3995.812, "update_time_ms": 5.183}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -45.9864387512207, "min_q": -54.60914993286133, "max_q": -8.296843528747559, "mean_td_error": -3.266430616378784, "model": {}}, "td_error": [4.890922546386719, 1.5716896057128906, 4.735080718994141, -6.112703323364258, 4.218559265136719, 4.565704345703125, -53.249027252197266, 3.8483924865722656, -31.59583282470703, 2.8919448852539062, -61.981605529785156, 3.3727760314941406, -52.67850112915039, 3.1458053588867188, 3.2672805786132812, 3.2686843872070312, 4.674736022949219, 4.2178497314453125, 1.272439956665039, 1.3229637145996094, 4.642059326171875, 3.3270492553710938, 4.40716552734375, 5.066272735595703, 1.8119525909423828, 3.4805755615234375, 7.470998764038086, 3.1670303344726562, 3.057422637939453, 4.234233856201172, 4.170795440673828, 4.991512298583984], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -46.60997009277344, "min_q": -51.77755355834961, "max_q": -42.48223114013672, "mean_td_error": -6.720208168029785, "model": {}}, "td_error": [-0.19333267211914062, 0.2853050231933594, 1.0804862976074219, -0.20405960083007812, 0.140869140625, -0.3222007751464844, -0.15974807739257812, -0.05603790283203125, -0.007816314697265625, -50.04011535644531, -0.19449615478515625, 0.48789215087890625, 0.31982421875, -0.3127479553222656, 0.5980453491210938, -49.66849899291992, -0.02393341064453125, 0.6212692260742188, -12.050262451171875, 0.019199371337890625, -50.77755355834961, -0.23166656494140625, -0.28928375244140625, -0.44582366943359375, -49.607234954833984, -3.1156463623046875, -0.0571746826171875, -0.0635833740234375, -0.024379730224609375, -0.1214752197265625, -0.4390373229980469, -0.19344329833984375], "custom_metrics": {}}}, "num_steps_sampled": 7454, "num_agent_steps_sampled": 14908, "num_steps_trained": 11200, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 22400, "last_target_update_ts": 7362, "num_target_updates": 57}, "done": false, "episodes_total": 403, "training_iteration": 22, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-29", "timestamp": 1648811609, "time_this_iter_s": 1.3248653411865234, "time_total_s": 29.948814868927002, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 29.948814868927002, "timesteps_since_restore": 704, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 30.0, "ram_util_percent": 52.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.12, "episode_len_mean": 18.56, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -10.06, "policy1": -10.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, 12.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 14.0, 24.0, 18.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 4.0, 26.0, 34.0, -40.0, -40.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, 2.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 13, 8, 11, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 18, 7, 3, 20, 20, 19, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 14, 20, 8, 20, 10, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 7.0, 12.0, 9.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, 13.0, 17.0, -20.0, -20.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, 1.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 7.0, 12.0, 9.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, 13.0, 17.0, -20.0, -20.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, 1.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3112033565060074, "mean_inference_ms": 1.7834660768698114, "mean_action_processing_ms": 0.12030392945764073, "mean_env_wait_ms": 0.07747028641222259, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7765, "timesteps_this_iter": 32, "agent_timesteps_total": 15530, "timers": {"load_time_ms": 0.428, "load_throughput": 74685.731, "learn_time_ms": 7.831, "learn_throughput": 4086.534, "update_time_ms": 4.981}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -49.14715576171875, "min_q": -58.036476135253906, "max_q": -8.0211763381958, "mean_td_error": -5.437248229980469, "model": {}}, "td_error": [-2.4868850708007812, -66.54521179199219, -1.7923927307128906, -1.3465080261230469, -3.049945831298828, -1.2687263488769531, -2.33782958984375, -1.3827629089355469, -2.56793212890625, -1.20269775390625, -26.843168258666992, -1.7491073608398438, -2.2865371704101562, -1.1217689514160156, -13.100069046020508, -2.2587852478027344, -2.4902305603027344, 3.2101402282714844, -4.336162567138672, -2.380687713623047, -1.5424003601074219, -7.392429351806641, -3.7531204223632812, -15.101152420043945, -0.9329833984375, -2.3455657958984375, -0.9375648498535156, -1.754241943359375, -2.56793212890625, -1.5800933837890625, -1.2467613220214844, 2.4995603561401367], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -47.63151550292969, "min_q": -51.649436950683594, "max_q": -42.693260192871094, "mean_td_error": -6.1868696212768555, "model": {}}, "td_error": [0.39839935302734375, -3.204570770263672, -1.34375, -0.2710456848144531, 0.3119773864746094, 0.7253608703613281, -0.15541458129882812, 0.2647972106933594, 0.31832122802734375, 0.4875946044921875, -0.11040496826171875, 0.3816108703613281, -0.31357574462890625, -48.98643112182617, 0.46035003662109375, -0.4280738830566406, -42.204010009765625, -50.28390884399414, 0.1279449462890625, -0.002948760986328125, -0.21242904663085938, -0.3797569274902344, -0.5516548156738281, 0.07516860961914062, -0.31145477294921875, -0.0068359375, -0.14116287231445312, -0.060291290283203125, -49.820194244384766, 0.79656982421875, 0.39330291748046875, -3.9333229064941406], "custom_metrics": {}}}, "num_steps_sampled": 7765, "num_agent_steps_sampled": 15530, "num_steps_trained": 11744, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 23488, "last_target_update_ts": 7705, "num_target_updates": 60}, "done": false, "episodes_total": 420, "training_iteration": 23, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-31", "timestamp": 1648811611, "time_this_iter_s": 1.2556571960449219, "time_total_s": 31.204472064971924, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 31.204472064971924, "timesteps_since_restore": 736, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 30.35, "ram_util_percent": 52.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.22, "episode_len_mean": 18.31, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.11, "policy1": -9.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 20.0, 12.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 14.0, 24.0, 18.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 4.0, 26.0, 34.0, -40.0, -40.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, 2.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, 22.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, -20.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 13, 8, 11, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 18, 7, 3, 20, 20, 19, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 14, 20, 8, 20, 10, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 9, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 7.0, 12.0, 9.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, 13.0, 17.0, -20.0, -20.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, 1.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, 11.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 10.0, 6.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 7.0, 12.0, 9.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, 13.0, 17.0, -20.0, -20.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, 1.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, 11.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31091756773257884, "mean_inference_ms": 1.78044778413894, "mean_action_processing_ms": 0.12014405149645187, "mean_env_wait_ms": 0.07735697718399626, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8080, "timesteps_this_iter": 32, "agent_timesteps_total": 16160, "timers": {"load_time_ms": 0.453, "load_throughput": 70611.178, "learn_time_ms": 7.627, "learn_throughput": 4195.51, "update_time_ms": 4.893}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -49.39529800415039, "min_q": -60.65957260131836, "max_q": -9.77969741821289, "mean_td_error": -7.706936836242676, "model": {}}, "td_error": [0.11992645263671875, -2.1261634826660156, -13.248435020446777, -4.783391952514648, 1.9526262283325195, -2.151073455810547, -59.30958938598633, -2.1226806640625, -2.003398895263672, -0.07447052001953125, -59.440818786621094, 1.1831207275390625, 1.242279052734375, -6.040061950683594, -2.9080209732055664, -0.4758491516113281, -51.76721954345703, -1.8466911315917969, -2.1316757202148438, -0.22364425659179688, -4.0513916015625, -2.1029396057128906, -1.8433799743652344, 0.08493804931640625, -10.078819274902344, -1.2105674743652344, -0.02353668212890625, 0.429656982421875, 0.18241500854492188, -1.4962692260742188, -18.77969741821289, -1.5771675109863281], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -48.77101135253906, "min_q": -52.09486770629883, "max_q": -44.86712646484375, "mean_td_error": -1.3855005502700806, "model": {}}, "td_error": [0.3571624755859375, 0.40142059326171875, -43.86712646484375, 0.2901649475097656, 1.12213134765625, 0.08893966674804688, -3.9452590942382812, 0.10573196411132812, 0.43198394775390625, 0.2543182373046875, 0.22231674194335938, 0.2224273681640625, -0.15353775024414062, 0.20827102661132812, -0.6754493713378906, -0.12583541870117188, -0.22459030151367188, -0.14577484130859375, -0.026264190673828125, 0.01641845703125, 0.8248748779296875, 0.3248329162597656, -0.105712890625, -0.05228424072265625, 0.06885528564453125, -0.09867095947265625, 0.18837356567382812, -0.004924774169921875, 0.4203033447265625, 0.492889404296875, -0.3854637145996094, -0.5665397644042969], "custom_metrics": {}}}, "num_steps_sampled": 8080, "num_agent_steps_sampled": 16160, "num_steps_trained": 12288, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 24576, "last_target_update_ts": 8040, "num_target_updates": 63}, "done": false, "episodes_total": 437, "training_iteration": 24, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-32", "timestamp": 1648811612, "time_this_iter_s": 1.2089698314666748, "time_total_s": 32.4134418964386, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84066cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84066cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 32.4134418964386, "timesteps_since_restore": 768, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 29.45, "ram_util_percent": 52.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.64, "episode_len_mean": 18.32, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.82, "policy1": -9.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 14.0, 24.0, 18.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 4.0, 26.0, 34.0, -40.0, -40.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, 2.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, 22.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 20.0, -40.0, -40.0, 10.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 13, 8, 11, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 18, 7, 3, 20, 20, 19, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 14, 20, 8, 20, 10, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 9, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 10, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 7.0, 12.0, 9.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, 13.0, 17.0, -20.0, -20.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, 1.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, 11.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 10.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 7.0, 12.0, 9.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, 13.0, 17.0, -20.0, -20.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, 1.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, 11.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 10.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31062007952249227, "mean_inference_ms": 1.7776770855912207, "mean_action_processing_ms": 0.11998708422264943, "mean_env_wait_ms": 0.07724770845187146, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8385, "timesteps_this_iter": 32, "agent_timesteps_total": 16770, "timers": {"load_time_ms": 0.432, "load_throughput": 74116.587, "learn_time_ms": 7.629, "learn_throughput": 4194.776, "update_time_ms": 5.38}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -48.44065856933594, "min_q": -57.9813232421875, "max_q": -11.717613220214844, "mean_td_error": 0.4487421214580536, "model": {}}, "td_error": [0.9155311584472656, -0.2683677673339844, 4.03596305847168, 1.2811241149902344, 1.1023139953613281, 0.6750717163085938, 0.1393890380859375, -0.01071929931640625, -1.5582542419433594, 2.226806640625, 0.3422393798828125, 2.2713756561279297, 0.5840187072753906, 1.5917587280273438, 0.7559127807617188, 0.802433967590332, 2.134185791015625, -0.9137191772460938, 0.6146888732910156, 1.23541259765625, 0.6761627197265625, 0.583622932434082, 0.7532577514648438, -1.9239873886108398, 0.5407257080078125, 0.17964935302734375, -1.5582542419433594, -7.439430236816406, 1.06256103515625, 1.5771102905273438, 0.14482879638671875, 1.80633544921875], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -48.33938217163086, "min_q": -52.43534469604492, "max_q": -45.00465774536133, "mean_td_error": -2.3740477561950684, "model": {}}, "td_error": [-5.1759796142578125, -51.43534469604492, -0.5967330932617188, -0.2860870361328125, -0.4276771545410156, -0.7416877746582031, -0.2330474853515625, -0.5819435119628906, -0.7917900085449219, -0.5825347900390625, -0.8935432434082031, -0.3831787109375, -1.2498245239257812, -0.47657012939453125, -0.9976081848144531, -0.9907264709472656, -1.2498245239257812, -0.4830474853515625, -0.721282958984375, -0.846771240234375, -0.4359169006347656, -0.7393150329589844, -0.58697509765625, -0.3713569641113281, -0.7891273498535156, -0.44068145751953125, -0.6682510375976562, -0.5115165710449219, -0.6341361999511719, -0.46550750732421875, -0.4075431823730469, -0.7739982604980469], "custom_metrics": {}}}, "num_steps_sampled": 8385, "num_agent_steps_sampled": 16770, "num_steps_trained": 12800, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 25600, "last_target_update_ts": 8385, "num_target_updates": 66}, "done": false, "episodes_total": 453, "training_iteration": 25, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-33", "timestamp": 1648811613, "time_this_iter_s": 1.2171566486358643, "time_total_s": 33.63059854507446, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 33.63059854507446, "timesteps_since_restore": 800, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 30.8, "ram_util_percent": 52.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.04, "episode_len_mean": 18.12, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.52, "policy1": -9.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 14.0, 24.0, 18.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 4.0, 26.0, 34.0, -40.0, -40.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, 2.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, 22.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 20.0, -40.0, -40.0, 10.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 34.0, -20.0, -20.0], "episode_lengths": [6, 13, 8, 11, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 18, 7, 3, 20, 20, 19, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 14, 20, 8, 20, 10, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 9, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 10, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20], "policy_policy0_reward": [14.0, 7.0, 12.0, 9.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, 13.0, 17.0, -20.0, -20.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, 1.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, 11.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 10.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 17.0, -10.0, -10.0], "policy_policy1_reward": [14.0, 7.0, 12.0, 9.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, 13.0, 17.0, -20.0, -20.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, 1.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, 11.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 10.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 17.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31035351536344874, "mean_inference_ms": 1.7751044022736273, "mean_action_processing_ms": 0.11984141388933522, "mean_env_wait_ms": 0.0771457880252584, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8705, "timesteps_this_iter": 32, "agent_timesteps_total": 17410, "timers": {"load_time_ms": 0.486, "load_throughput": 65893.136, "learn_time_ms": 8.16, "learn_throughput": 3921.731, "update_time_ms": 4.851}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -52.162879943847656, "min_q": -59.1957893371582, "max_q": -11.092641830444336, "mean_td_error": -5.911640167236328, "model": {}}, "td_error": [-0.07501983642578125, -0.3519630432128906, 0.547943115234375, -0.11684417724609375, -1.2755851745605469, -0.6987686157226562, -0.108184814453125, -0.5645980834960938, -5.694286346435547, -4.531181335449219, -5.165218353271484, -0.15346908569335938, -0.1255645751953125, 0.0509185791015625, -58.1957893371582, 0.38813018798828125, -0.18108749389648438, -0.12479019165039062, -0.001979827880859375, -50.655242919921875, -0.2514152526855469, -1.8255767822265625, 0.6924781799316406, -0.23729705810546875, -0.42592620849609375, -0.5430870056152344, -57.98442077636719, 0.07268524169921875, -0.9110145568847656, 0.1049652099609375, -0.1241912841796875, -0.7070999145507812], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -48.58887481689453, "min_q": -52.595298767089844, "max_q": -45.76649856567383, "mean_td_error": -3.052236557006836, "model": {}}, "td_error": [-0.10732269287109375, 0.3398551940917969, -0.20759963989257812, 0.5861663818359375, 0.6130332946777344, -45.1361198425293, 0.2823944091796875, 0.2765655517578125, -11.408893585205078, 0.1978607177734375, 0.3255157470703125, 0.3725242614746094, 0.6466064453125, 0.11734390258789062, 0.027069091796875, 0.3336372375488281, -0.15902328491210938, -46.77997589111328, 0.11853408813476562, 0.02149200439453125, 0.4060783386230469, 0.3718528747558594, 0.207916259765625, 0.08932113647460938, 0.427398681640625, 0.060871124267578125, 0.2861824035644531, -0.03459930419921875, -0.21790313720703125, -0.24134063720703125, 0.365966796875, 0.14702606201171875], "custom_metrics": {}}}, "num_steps_sampled": 8705, "num_agent_steps_sampled": 17410, "num_steps_trained": 13312, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 26624, "last_target_update_ts": 8622, "num_target_updates": 68}, "done": false, "episodes_total": 470, "training_iteration": 26, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-35", "timestamp": 1648811615, "time_this_iter_s": 1.2230172157287598, "time_total_s": 34.85361576080322, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 34.85361576080322, "timesteps_since_restore": 832, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 30.7, "ram_util_percent": 52.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.82, "episode_len_mean": 18.31, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -10.41, "policy1": -10.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.0, 34.0, -40.0, -40.0, 2.0, -20.0, -20.0, 14.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, 12.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, 2.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, 22.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 20.0, -40.0, -40.0, 10.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 34.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 26.0, -40.0, 26.0, -40.0], "episode_lengths": [7, 3, 20, 20, 19, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 14, 20, 8, 20, 10, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 9, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 10, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 7, 20], "policy_policy0_reward": [13.0, 17.0, -20.0, -20.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, 1.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, 11.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 10.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 13.0, -20.0, 13.0, -20.0], "policy_policy1_reward": [13.0, 17.0, -20.0, -20.0, 1.0, -10.0, -10.0, 7.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, 1.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, 11.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 10.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 13.0, -20.0, 13.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31015825071660624, "mean_inference_ms": 1.7730462322616365, "mean_action_processing_ms": 0.11973982892520929, "mean_env_wait_ms": 0.07709098998736681, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9031, "timesteps_this_iter": 32, "agent_timesteps_total": 18062, "timers": {"load_time_ms": 0.476, "load_throughput": 67277.057, "learn_time_ms": 7.871, "learn_throughput": 4065.442, "update_time_ms": 5.359}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -47.52778625488281, "min_q": -63.66520690917969, "max_q": -12.651065826416016, "mean_td_error": -4.742696762084961, "model": {}}, "td_error": [-4.347282409667969, -1.16943359375, -2.9610252380371094, -23.71276092529297, 1.1825599670410156, -3.9700241088867188, 0.9626007080078125, 1.7290763854980469, 0.6322860717773438, -1.6325359344482422, -42.226844787597656, -3.6050682067871094, 0.8826904296875, -1.7448854446411133, -0.6740989685058594, -4.006092071533203, -3.564105987548828, 1.1893882751464844, -3.1236419677734375, -0.7228126525878906, -4.647335052490234, 0.9694595336914062, -3.413421630859375, -42.39836883544922, -2.7223739624023438, -0.06489181518554688, 0.6322860717773438, -3.8163185119628906, -3.439189910888672, 1.212127685546875, 1.0795860290527344, -4.275856018066406], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -49.995880126953125, "min_q": -52.98311996459961, "max_q": -47.87877655029297, "mean_td_error": 0.9545608758926392, "model": {}}, "td_error": [1.8825721740722656, 1.6266288757324219, 0.7224922180175781, 1.4796981811523438, 1.0464401245117188, 1.0198745727539062, 1.2319068908691406, 0.96490478515625, 1.1911849975585938, 1.5622673034667969, 1.5986747741699219, 0.6003837585449219, 1.1003532409667969, 1.010467529296875, 1.067047119140625, 1.1397476196289062, 1.4445381164550781, 1.0799026489257812, 0.9049491882324219, 1.5063133239746094, 1.0947341918945312, 0.9923019409179688, 1.3414802551269531, 1.2715187072753906, 0.35617828369140625, -5.143260955810547, 1.3559455871582031, 0.8038597106933594, 1.0655364990234375, 1.2970466613769531, 0.7462425231933594, 1.1840171813964844], "custom_metrics": {}}}, "num_steps_sampled": 9031, "num_agent_steps_sampled": 18062, "num_steps_trained": 13888, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 27776, "last_target_update_ts": 8957, "num_target_updates": 71}, "done": false, "episodes_total": 488, "training_iteration": 27, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-36", "timestamp": 1648811616, "time_this_iter_s": 1.306518793106079, "time_total_s": 36.1601345539093, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 36.1601345539093, "timesteps_since_restore": 864, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 29.8, "ram_util_percent": 52.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.28, "episode_len_mean": 18.74, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -11.64, "policy1": -11.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 12.0, -20.0, 24.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, 2.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, 22.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 20.0, -40.0, -40.0, 10.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 34.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 26.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 6.0, -40.0], "episode_lengths": [20, 14, 20, 8, 20, 10, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 9, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 10, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20], "policy_policy0_reward": [-20.0, 6.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, 1.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, 11.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 10.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 13.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 3.0, -20.0], "policy_policy1_reward": [-20.0, 6.0, -10.0, 12.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, 1.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, 11.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 10.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 13.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 3.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3099874745416217, "mean_inference_ms": 1.7713161880888386, "mean_action_processing_ms": 0.11965407127608373, "mean_env_wait_ms": 0.07706090726537546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9348, "timesteps_this_iter": 32, "agent_timesteps_total": 18696, "timers": {"load_time_ms": 0.428, "load_throughput": 74781.44, "learn_time_ms": 7.859, "learn_throughput": 4071.683, "update_time_ms": 4.975}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -52.091941833496094, "min_q": -62.444496154785156, "max_q": -9.819905281066895, "mean_td_error": -4.796023845672607, "model": {}}, "td_error": [-2.6541900634765625, -2.2241363525390625, -2.1093788146972656, -2.3503456115722656, -1.5878753662109375, -1.8065643310546875, -1.7035369873046875, 1.6200370788574219, -2.107097625732422, -70.8487319946289, -2.1770401000976562, -6.857204437255859, -2.5302047729492188, 0.11440181732177734, -2.5401878356933594, -1.8399009704589844, -28.31102180480957, -2.4638748168945312, -1.0573558807373047, -0.9147720336914062, -1.7950553894042969, -2.1975173950195312, -0.14289474487304688, -2.2522125244140625, -1.6959686279296875, -1.4990081787109375, -2.3449363708496094, -2.6059303283691406, -2.1133651733398438, 1.7768898010253906, -1.7228584289550781, -2.530914306640625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -51.53278732299805, "min_q": -54.173282623291016, "max_q": -50.096797943115234, "mean_td_error": -2.918539047241211, "model": {}}, "td_error": [-0.8208541870117188, -0.7790756225585938, -1.6856918334960938, -1.7366828918457031, -1.19195556640625, -1.5681495666503906, -1.0705337524414062, -1.0456695556640625, -1.1597251892089844, -1.9974441528320312, -1.3789100646972656, -1.1408271789550781, -1.3738670349121094, -0.97015380859375, -1.3515853881835938, -1.2671089172363281, -1.1471748352050781, -0.8894500732421875, -0.7246665954589844, -1.6519966125488281, -1.1321563720703125, -0.8160552978515625, -1.2408256530761719, -0.9267082214355469, -7.447307586669922, -1.6849441528320312, -1.3013076782226562, -0.7784080505371094, -1.7674407958984375, -0.8880882263183594, -49.59307098388672, -0.8654212951660156], "custom_metrics": {}}}, "num_steps_sampled": 9348, "num_agent_steps_sampled": 18696, "num_steps_trained": 14400, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 28800, "last_target_update_ts": 9311, "num_target_updates": 74}, "done": false, "episodes_total": 504, "training_iteration": 28, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-37", "timestamp": 1648811617, "time_this_iter_s": 1.2274940013885498, "time_total_s": 37.38762855529785, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8408cb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8408cb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 37.38762855529785, "timesteps_since_restore": 896, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 30.65, "ram_util_percent": 52.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.96, "episode_len_mean": 18.88, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -12.48, "policy1": -12.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 4.0, -20.0, -40.0, 22.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 24.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 20.0, -40.0, -40.0, 10.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 34.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 26.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 6.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, -20.0], "episode_lengths": [20, 20, 18, 20, 20, 9, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 10, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20], "policy_policy0_reward": [-10.0, -10.0, 2.0, -10.0, -20.0, 11.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 10.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 13.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 3.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 2.0, -10.0, -20.0, 11.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 10.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 13.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 3.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30983228569204063, "mean_inference_ms": 1.770211469812998, "mean_action_processing_ms": 0.11959839197324121, "mean_env_wait_ms": 0.07706440587864707, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9653, "timesteps_this_iter": 32, "agent_timesteps_total": 19306, "timers": {"load_time_ms": 0.428, "load_throughput": 74743.959, "learn_time_ms": 8.086, "learn_throughput": 3957.637, "update_time_ms": 5.528}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -51.4237174987793, "min_q": -60.490509033203125, "max_q": -13.988248825073242, "mean_td_error": -1.736189365386963, "model": {}}, "td_error": [0.10814285278320312, 0.022548675537109375, -0.6711921691894531, -0.3772850036621094, 0.11870193481445312, -0.17589569091796875, 0.5334281921386719, 0.391143798828125, -0.4360809326171875, 0.5798406600952148, -0.15869140625, -1.0303382873535156, 0.41641712188720703, 0.36724853515625, 0.43731689453125, 0.3209419250488281, 0.032845497131347656, -0.11541748046875, -0.567626953125, -0.346588134765625, -0.3400840759277344, 0.055805206298828125, -0.6978683471679688, 0.34075927734375, -0.2853965759277344, 0.637904167175293, -55.31661605834961, 0.2543487548828125, -0.10844993591308594, -0.13674163818359375, 0.4377899169921875, 0.151031494140625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -51.64696502685547, "min_q": -54.227806091308594, "max_q": -49.55580139160156, "mean_td_error": -0.7806930541992188, "model": {}}, "td_error": [0.3047332763671875, -0.6497879028320312, -0.4267997741699219, -0.28668975830078125, 0.3698005676269531, 0.54656982421875, -0.7489776611328125, -0.4613990783691406, 0.3250617980957031, 0.4378776550292969, -0.5112838745117188, -0.4761619567871094, -0.4704093933105469, 0.9375762939453125, -0.11800003051757812, -0.37389373779296875, -0.335296630859375, -0.08019638061523438, 0.1569366455078125, 0.11686325073242188, 0.21412277221679688, -0.3459053039550781, -11.508125305175781, 0.31131744384765625, -0.3878669738769531, 0.41034698486328125, -11.499210357666016, -0.4682121276855469, -0.6739883422851562, 0.24782562255859375, -0.013896942138671875, 0.47489166259765625], "custom_metrics": {}}}, "num_steps_sampled": 9653, "num_agent_steps_sampled": 19306, "num_steps_trained": 14912, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 29824, "last_target_update_ts": 9653, "num_target_updates": 77}, "done": false, "episodes_total": 520, "training_iteration": 29, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-39", "timestamp": 1648811619, "time_this_iter_s": 1.260465383529663, "time_total_s": 38.648093938827515, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84066cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84066cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 38.648093938827515, "timesteps_since_restore": 928, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 30.75, "ram_util_percent": 52.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.9, "episode_len_mean": 18.95, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -12.45, "policy1": -12.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 20.0, -40.0, -40.0, 10.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 34.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 26.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 6.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, -20.0, -40.0, -20.0, -20.0, 26.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 10, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, 10.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 13.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 3.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, 13.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, 10.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 13.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 3.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, 13.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3097601280578348, "mean_inference_ms": 1.7696172442209905, "mean_action_processing_ms": 0.11956994175980983, "mean_env_wait_ms": 0.07708906773557583, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9975, "timesteps_this_iter": 32, "agent_timesteps_total": 19950, "timers": {"load_time_ms": 0.443, "load_throughput": 72202.769, "learn_time_ms": 8.348, "learn_throughput": 3833.478, "update_time_ms": 5.45}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -56.992408752441406, "min_q": -61.179161071777344, "max_q": -16.6361083984375, "mean_td_error": -0.6393650770187378, "model": {}}, "td_error": [-0.0924072265625, -0.4343109130859375, -0.06177520751953125, -0.657440185546875, -0.09873580932617188, -7.169506072998047, -0.024318695068359375, 0.028026580810546875, -0.06984329223632812, -0.6907806396484375, -0.12305450439453125, -0.2715721130371094, -0.6080093383789062, 0.3791847229003906, -0.46532440185546875, -0.8217849731445312, -7.022712707519531, -0.3130302429199219, -0.5333366394042969, 0.4695472717285156, -0.4640235900878906, -0.4785614013671875, -0.42328643798828125, -0.282012939453125, 1.9258384704589844, -0.2548065185546875, -0.3941001892089844, -0.13683700561523438, -0.22152328491210938, -0.5950431823730469, -0.31908416748046875, -0.23505783081054688], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -53.10279083251953, "min_q": -55.25624084472656, "max_q": -51.41609191894531, "mean_td_error": -3.9329662322998047, "model": {}}, "td_error": [0.2567138671875, -53.285545349121094, -7.4114532470703125, -0.3872413635253906, -52.94907760620117, -0.8454399108886719, -0.19403076171875, -0.9166297912597656, -0.37079620361328125, -0.9017372131347656, -0.8660202026367188, -0.801300048828125, -0.0055999755859375, -0.5455818176269531, 0.6381645202636719, -0.386993408203125, 0.12476348876953125, -0.20447540283203125, -0.09170913696289062, -1.0638389587402344, -0.37636566162109375, -0.3282127380371094, -0.5455818176269531, -0.8214569091796875, -0.15692520141601562, -0.3741111755371094, -0.35221099853515625, -0.16111373901367188, -0.4333305358886719, -0.6058540344238281, -1.1253547668457031, -0.36656951904296875], "custom_metrics": {}}}, "num_steps_sampled": 9975, "num_agent_steps_sampled": 19950, "num_steps_trained": 15456, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 30912, "last_target_update_ts": 9880, "num_target_updates": 79}, "done": false, "episodes_total": 537, "training_iteration": 30, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-40", "timestamp": 1648811620, "time_this_iter_s": 1.2703404426574707, "time_total_s": 39.918434381484985, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 39.918434381484985, "timesteps_since_restore": 960, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 30.6, "ram_util_percent": 52.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.2, "episode_len_mean": 19.1, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -12.1, "policy1": -12.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -20.0, -20.0, 6.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 34.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 26.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 6.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, -20.0, -40.0, -20.0, -20.0, 26.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 13.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 3.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, 13.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -10.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 17.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 13.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 3.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, 13.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3096703188080949, "mean_inference_ms": 1.7687689530330346, "mean_action_processing_ms": 0.11952853138200442, "mean_env_wait_ms": 0.07710940592347636, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10275, "timesteps_this_iter": 32, "agent_timesteps_total": 20550, "timers": {"load_time_ms": 0.469, "load_throughput": 68269.445, "learn_time_ms": 8.125, "learn_throughput": 3938.279, "update_time_ms": 5.92}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -53.818641662597656, "min_q": -59.175228118896484, "max_q": -18.796581268310547, "mean_td_error": -3.8280224800109863, "model": {}}, "td_error": [0.7294578552246094, 0.6517143249511719, -7.131263732910156, 0.4381294250488281, 0.4924812316894531, 0.1717071533203125, 0.39780426025390625, 0.4834785461425781, 0.22715377807617188, 0.3902549743652344, 0.7944488525390625, 1.2482681274414062, -55.49607849121094, 0.5331001281738281, 0.4328956604003906, 0.4010047912597656, 2.2461509704589844, 0.30965423583984375, -7.429954528808594, 0.3459205627441406, 0.8364715576171875, -0.1971588134765625, -67.80247497558594, -0.16167640686035156, 0.6360855102539062, 0.5391349792480469, 0.463714599609375, 0.8967857360839844, 0.5318527221679688, 0.26734161376953125, 0.5247383117675781, 0.7321281433105469], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -52.35054397583008, "min_q": -56.41837692260742, "max_q": -50.6462287902832, "mean_td_error": 0.195611834526062, "model": {}}, "td_error": [0.7250289916992188, 0.17000198364257812, 0.3807334899902344, -0.9634590148925781, 0.5375137329101562, 0.7530555725097656, -0.07242965698242188, 0.4134025573730469, 0.22925567626953125, -4.547679901123047, 1.0919227600097656, -1.3112258911132812, 0.8669471740722656, -0.5261650085449219, 0.44104766845703125, 0.8495521545410156, 1.1238059997558594, -0.2161407470703125, 1.3297691345214844, 0.4539833068847656, 0.5938873291015625, 0.9665565490722656, 0.8453903198242188, 0.7711677551269531, -1.0852165222167969, 1.0001564025878906, 0.25543212890625, 0.5306854248046875, 0.3474922180175781, 0.336212158203125, -0.507598876953125, 0.47649383544921875], "custom_metrics": {}}}, "num_steps_sampled": 10275, "num_agent_steps_sampled": 20550, "num_steps_trained": 15936, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 31872, "last_target_update_ts": 10235, "num_target_updates": 82}, "done": false, "episodes_total": 552, "training_iteration": 31, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-41", "timestamp": 1648811621, "time_this_iter_s": 1.1562607288360596, "time_total_s": 41.074695110321045, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8408cb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8408cb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 41.074695110321045, "timesteps_since_restore": 992, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 30.35, "ram_util_percent": 52.2}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.92, "episode_len_mean": 19.16, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -12.46, "policy1": -12.46}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 26.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 6.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, -20.0, -40.0, -20.0, -20.0, 26.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, 14.0, -40.0, 14.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 13.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 3.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, 13.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 7.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 13.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 3.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, 13.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 7.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30962799316258655, "mean_inference_ms": 1.7682216621655487, "mean_action_processing_ms": 0.11952582673647222, "mean_env_wait_ms": 0.07714530640344999, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10581, "timesteps_this_iter": 32, "agent_timesteps_total": 21162, "timers": {"load_time_ms": 0.436, "load_throughput": 73359.056, "learn_time_ms": 8.212, "learn_throughput": 3896.898, "update_time_ms": 5.506}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -53.77690124511719, "min_q": -58.849674224853516, "max_q": -16.97295570373535, "mean_td_error": -0.12206727266311646, "model": {}}, "td_error": [0.6962127685546875, 0.7024726867675781, 0.8049163818359375, 0.9793510437011719, 0.04663848876953125, -0.4339599609375, 0.2483978271484375, 0.42314910888671875, -0.3136444091796875, -7.529003143310547, 0.68084716796875, 0.357513427734375, -0.034534454345703125, 0.14139556884765625, 0.7149848937988281, 0.48072052001953125, 0.5940628051757812, 0.02909088134765625, 0.11301803588867188, 0.26219940185546875, 1.8275089263916016, 0.8898963928222656, 0.3216438293457031, 0.22415542602539062, 0.31858062744140625, -7.809967041015625, 0.12917709350585938, 0.7407379150390625, 0.6678695678710938, -0.6777534484863281, 0.3211402893066406, 0.17702865600585938], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -53.289772033691406, "min_q": -55.28057098388672, "max_q": -52.14082717895508, "mean_td_error": -9.771444320678711, "model": {}}, "td_error": [-61.14082717895508, 0.1726226806640625, 0.13665008544921875, -52.24025344848633, -0.051349639892578125, -51.51755905151367, 0.402313232421875, 0.08935928344726562, 0.17574691772460938, -51.774070739746094, -7.589237213134766, 0.18240737915039062, -0.037502288818359375, -53.77257537841797, -10.076530456542969, 0.390716552734375, -0.07971572875976562, -6.191295623779297, -0.033405303955078125, 0.9202919006347656, 0.1451873779296875, -10.494991302490234, 0.6752510070800781, 0.19192123413085938, 0.7947540283203125, 0.2012939453125, 0.43000030517578125, -6.524219512939453, -0.19992828369140625, -6.4590301513671875, 0.08015060424804688, 0.5075836181640625], "custom_metrics": {}}}, "num_steps_sampled": 10581, "num_agent_steps_sampled": 21162, "num_steps_trained": 16448, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 32896, "last_target_update_ts": 10581, "num_target_updates": 85}, "done": false, "episodes_total": 568, "training_iteration": 32, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-42", "timestamp": 1648811622, "time_this_iter_s": 1.2397260665893555, "time_total_s": 42.3144211769104, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 42.3144211769104, "timesteps_since_restore": 1024, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 30.5, "ram_util_percent": 52.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.08, "episode_len_mean": 18.94, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -12.04, "policy1": -12.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 6.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, -20.0, -40.0, -20.0, -20.0, 26.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, 14.0, -40.0, 14.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0], "episode_lengths": [7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20], "policy_policy0_reward": [13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 3.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, 13.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 7.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0], "policy_policy1_reward": [13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 3.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, 13.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 7.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3096150019488959, "mean_inference_ms": 1.767689697408091, "mean_action_processing_ms": 0.11952407267628837, "mean_env_wait_ms": 0.07717631369286207, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10898, "timesteps_this_iter": 32, "agent_timesteps_total": 21796, "timers": {"load_time_ms": 0.452, "load_throughput": 70726.526, "learn_time_ms": 7.95, "learn_throughput": 4025.099, "update_time_ms": 5.098}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -52.94689178466797, "min_q": -60.55805206298828, "max_q": -19.75939178466797, "mean_td_error": -2.721278667449951, "model": {}}, "td_error": [-1.5751686096191406, -1.6905097961425781, -1.9165534973144531, -1.5466156005859375, -59.19749069213867, -1.4792709350585938, -1.6700897216796875, -1.73895263671875, -0.6251316070556641, -1.1900615692138672, -1.7824821472167969, -1.4016609191894531, 0.7329483032226562, -0.32421112060546875, -1.2170639038085938, 0.7091712951660156, -1.5932197570800781, -0.21677398681640625, 0.2913818359375, -0.6256370544433594, -1.4929046630859375, -1.483612060546875, -1.6656112670898438, -0.9051132202148438, 0.6601943969726562, 0.5375022888183594, 0.16030120849609375, -0.206573486328125, -1.3514480590820312, -0.06211090087890625, -1.5839729309082031, -1.6301765441894531], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -53.522865295410156, "min_q": -57.45005798339844, "max_q": -50.59953689575195, "mean_td_error": -2.35158634185791, "model": {}}, "td_error": [-0.7117881774902344, -0.434112548828125, -0.7400360107421875, -0.22796249389648438, -0.11493301391601562, -0.198944091796875, 0.045261383056640625, -0.583221435546875, -0.655364990234375, -0.5319862365722656, -0.2824554443359375, -0.7168846130371094, -0.20220565795898438, -0.43563079833984375, 0.12674331665039062, -0.97601318359375, -0.7224693298339844, 0.11241531372070312, -0.8980598449707031, -0.36577606201171875, -0.15449905395507812, -0.5114479064941406, -0.4430084228515625, 0.057811737060546875, 0.044910430908203125, -56.45005798339844, -0.5631523132324219, -0.6240463256835938, -0.4636878967285156, -6.752109527587891, -0.3710670471191406, -0.5069847106933594], "custom_metrics": {}}}, "num_steps_sampled": 10898, "num_agent_steps_sampled": 21796, "num_steps_trained": 17024, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 34048, "last_target_update_ts": 10898, "num_target_updates": 88}, "done": false, "episodes_total": 586, "training_iteration": 33, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-44", "timestamp": 1648811624, "time_this_iter_s": 1.2802629470825195, "time_total_s": 43.59468412399292, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 43.59468412399292, "timesteps_since_restore": 1056, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 30.15, "ram_util_percent": 52.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.24, "episode_len_mean": 18.92, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -12.12, "policy1": -12.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, 30.0, -20.0, -40.0, -20.0, -20.0, 26.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, 14.0, -40.0, 14.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, 30.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20], "policy_policy0_reward": [3.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, 13.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 7.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [3.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, 13.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 7.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3095568015375285, "mean_inference_ms": 1.767198958515835, "mean_action_processing_ms": 0.11951200572712029, "mean_env_wait_ms": 0.07719946457446702, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11203, "timesteps_this_iter": 32, "agent_timesteps_total": 22406, "timers": {"load_time_ms": 0.464, "load_throughput": 69006.544, "learn_time_ms": 7.916, "learn_throughput": 4042.24, "update_time_ms": 5.203}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -51.786834716796875, "min_q": -61.067562103271484, "max_q": -14.573872566223145, "mean_td_error": -3.7867305278778076, "model": {}}, "td_error": [0.8177566528320312, 0.8203697204589844, 0.121826171875, 0.5827140808105469, 0.6563262939453125, -2.029125213623047, 0.5768051147460938, 0.8175926208496094, 0.7867927551269531, -0.6366710662841797, 1.0111885070800781, 0.0776519775390625, 0.26943206787109375, -0.3821849822998047, 0.12813758850097656, 0.4834403991699219, -69.86825561523438, 1.0247211456298828, 0.60076904296875, -1.809800148010254, 0.2996826171875, -60.03986740112305, 0.39167022705078125, 0.005191802978515625, 0.7900238037109375, 0.14941024780273438, 0.6729164123535156, 0.9555091857910156, 0.5048866271972656, 0.6679916381835938, 0.2689685821533203, 0.10874557495117188], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -53.421783447265625, "min_q": -56.14228820800781, "max_q": -50.244407653808594, "mean_td_error": -1.3230924606323242, "model": {}}, "td_error": [0.20947647094726562, 0.45096588134765625, 0.7104949951171875, 0.4579315185546875, 0.1918182373046875, -50.829986572265625, -0.131683349609375, 0.158447265625, 0.41216278076171875, 0.2609710693359375, 0.05594635009765625, 0.2778282165527344, 0.2913970947265625, 0.6961479187011719, 0.16856765747070312, 0.38509368896484375, 0.054676055908203125, 0.37044525146484375, 0.39471435546875, -0.006343841552734375, 0.079864501953125, 0.4277229309082031, 0.31707763671875, 0.3191642761230469, 0.18129348754882812, 0.030422210693359375, 0.24888992309570312, 0.43607330322265625, -0.16781234741210938, 0.6506690979003906, 0.3838005065917969, 0.1748046875], "custom_metrics": {}}}, "num_steps_sampled": 11203, "num_agent_steps_sampled": 22406, "num_steps_trained": 17536, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 35072, "last_target_update_ts": 11123, "num_target_updates": 90}, "done": false, "episodes_total": 602, "training_iteration": 34, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-45", "timestamp": 1648811625, "time_this_iter_s": 1.2009799480438232, "time_total_s": 44.79566407203674, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8408cb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8408cb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 44.79566407203674, "timesteps_since_restore": 1088, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 29.700000000000003, "ram_util_percent": 52.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.5, "episode_len_mean": 18.95, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -12.25, "policy1": -12.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 30.0, -20.0, -40.0, -20.0, -20.0, 26.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, 14.0, -40.0, 14.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 5, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 15.0, -10.0, -20.0, -10.0, -10.0, 13.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 7.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 15.0, -10.0, -20.0, -10.0, -10.0, 13.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 7.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3094456503147359, "mean_inference_ms": 1.7662992446678794, "mean_action_processing_ms": 0.11946086305230452, "mean_env_wait_ms": 0.07718854849725361, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11503, "timesteps_this_iter": 32, "agent_timesteps_total": 23006, "timers": {"load_time_ms": 0.436, "load_throughput": 73347.029, "learn_time_ms": 7.916, "learn_throughput": 4042.666, "update_time_ms": 5.271}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -57.548709869384766, "min_q": -60.288734436035156, "max_q": -23.427541732788086, "mean_td_error": -4.33408784866333, "model": {}}, "td_error": [0.4641914367675781, 0.4552192687988281, 0.4414558410644531, 0.34568023681640625, 0.4759674072265625, 0.6211090087890625, 0.6028480529785156, 0.3771629333496094, 0.37087249755859375, -59.031864166259766, 0.4000511169433594, -59.086063385009766, -22.427541732788086, 0.21320343017578125, -8.768402099609375, 0.3704872131347656, 0.2848472595214844, 0.3011207580566406, 0.5599136352539062, 0.2909698486328125, 0.23320388793945312, 0.22340011596679688, 0.3308258056640625, 0.4871253967285156, 0.429779052734375, 0.217864990234375, 0.37757110595703125, 0.4109230041503906, 0.3555450439453125, 0.2733612060546875, 0.2938957214355469, 0.4144706726074219], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -53.331485748291016, "min_q": -56.00471496582031, "max_q": -50.63872146606445, "mean_td_error": -3.1971969604492188, "model": {}}, "td_error": [0.5144424438476562, 0.3824615478515625, 0.4916229248046875, -4.895366668701172, 0.5012245178222656, 0.6210784912109375, -0.120452880859375, 0.6695060729980469, 0.3303718566894531, 0.4221992492675781, 0.5739822387695312, 0.28456878662109375, 0.3903617858886719, 0.21190643310546875, -49.63872146606445, 0.6913528442382812, 0.13113021850585938, 0.23288726806640625, 0.13959503173828125, 0.9965171813964844, 0.390228271484375, 0.3731498718261719, 0.7297401428222656, 0.47241973876953125, -53.830867767333984, 0.4392662048339844, 0.1088714599609375, 0.21303558349609375, 0.3049507141113281, -5.464473724365234, 0.296722412109375, 0.7259864807128906], "custom_metrics": {}}}, "num_steps_sampled": 11503, "num_agent_steps_sampled": 23006, "num_steps_trained": 18016, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 36032, "last_target_update_ts": 11483, "num_target_updates": 93}, "done": false, "episodes_total": 617, "training_iteration": 35, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-46", "timestamp": 1648811626, "time_this_iter_s": 1.151050329208374, "time_total_s": 45.94671440124512, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840453b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840453b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 45.94671440124512, "timesteps_since_restore": 1120, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 30.95, "ram_util_percent": 52.3}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.28, "episode_len_mean": 19.04, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -12.64, "policy1": -12.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, 14.0, -40.0, 14.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -40.0, -20.0, -40.0, -40.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 7.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -10.0, -20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 7.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -10.0, -20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30924220993486734, "mean_inference_ms": 1.76475706690327, "mean_action_processing_ms": 0.11936236962155547, "mean_env_wait_ms": 0.0771458083353094, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11819, "timesteps_this_iter": 32, "agent_timesteps_total": 23638, "timers": {"load_time_ms": 0.416, "load_throughput": 76875.954, "learn_time_ms": 7.058, "learn_throughput": 4533.556, "update_time_ms": 5.049}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -53.416099548339844, "min_q": -60.45939636230469, "max_q": -24.687223434448242, "mean_td_error": -2.858915328979492, "model": {}}, "td_error": [0.5144004821777344, -9.23635482788086, 0.3664970397949219, 0.5015792846679688, -0.3528404235839844, 0.6309394836425781, 0.1399059295654297, 0.4211845397949219, 0.4121246337890625, 0.6780948638916016, -0.17533493041992188, 0.16481399536132812, 0.29227447509765625, 0.10150527954101562, 0.3921089172363281, 0.36893463134765625, 0.6552658081054688, -0.904327392578125, 0.5925521850585938, 0.6141433715820312, 0.4081459045410156, 0.4862327575683594, 0.4528923034667969, 0.6695938110351562, 0.44202423095703125, 0.5711135864257812, 0.30971527099609375, -23.975645065307617, 0.6983261108398438, 0.5272636413574219, -68.8177490234375, 0.5653266906738281], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -52.774383544921875, "min_q": -54.68754577636719, "max_q": -51.08243179321289, "mean_td_error": -2.7931840419769287, "model": {}}, "td_error": [0.251373291015625, 0.6927833557128906, 0.317230224609375, 1.2494049072265625, -0.030517578125, 1.0804557800292969, 0.7476081848144531, 0.4869270324707031, 0.7326622009277344, -50.972801208496094, 0.23687362670898438, 0.5323333740234375, -0.10223770141601562, 0.9637413024902344, 0.15055084228515625, 0.7245025634765625, -52.986995697021484, 0.6599578857421875, -0.03670501708984375, 0.705810546875, 1.0264053344726562, 0.2803840637207031, 0.15747833251953125, 1.2956199645996094, -0.4410057067871094, -0.2939033508300781, 0.8122329711914062, 0.4177818298339844, 0.695404052734375, 0.36145782470703125, 0.14492416381835938, 0.7583732604980469], "custom_metrics": {}}}, "num_steps_sampled": 11819, "num_agent_steps_sampled": 23638, "num_steps_trained": 18560, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 37120, "last_target_update_ts": 11819, "num_target_updates": 96}, "done": false, "episodes_total": 634, "training_iteration": 36, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-47", "timestamp": 1648811627, "time_this_iter_s": 1.1854379177093506, "time_total_s": 47.13215231895447, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84045830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84045830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 47.13215231895447, "timesteps_since_restore": 1152, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 30.6, "ram_util_percent": 52.3}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.66, "episode_len_mean": 18.93, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -12.83, "policy1": -12.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, 14.0, -40.0, 14.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -40.0, -20.0, -40.0, -40.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 22.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 13, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, 7.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -10.0, -20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, 7.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -10.0, -20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30901227977590184, "mean_inference_ms": 1.762985251795299, "mean_action_processing_ms": 0.11924701057462866, "mean_env_wait_ms": 0.0770788824092078, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12128, "timesteps_this_iter": 32, "agent_timesteps_total": 24256, "timers": {"load_time_ms": 0.415, "load_throughput": 77172.107, "learn_time_ms": 7.713, "learn_throughput": 4148.733, "update_time_ms": 4.96}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -61.698997497558594, "min_q": -63.99828338623047, "max_q": -29.072431564331055, "mean_td_error": -4.3843488693237305, "model": {}}, "td_error": [-7.9971466064453125, 0.5293121337890625, 0.22640609741210938, 0.153656005859375, 0.422393798828125, 0.3407745361328125, 0.6499214172363281, -42.03704071044922, 0.28430938720703125, 0.6218147277832031, 0.7575035095214844, 0.9393272399902344, 0.4569091796875, 0.3897132873535156, 0.6177635192871094, 0.7208824157714844, 0.2607536315917969, 0.8035202026367188, -41.828758239746094, 0.8133316040039062, 0.5346641540527344, 0.11359405517578125, 0.10076904296875, -61.56600570678711, 0.7581748962402344, 0.5360527038574219, 0.41777801513671875, 0.216827392578125, 0.6437606811523438, 0.25150299072265625, 0.4028968811035156, 0.16546630859375], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -53.60563278198242, "min_q": -55.114891052246094, "max_q": -51.35459899902344, "mean_td_error": -0.8780422210693359, "model": {}}, "td_error": [0.8873634338378906, 0.82281494140625, 0.4897499084472656, 0.7498435974121094, 0.3641242980957031, 1.3383445739746094, 0.8634376525878906, 0.445556640625, 1.065643310546875, 0.7380294799804688, 0.29949188232421875, 1.0501480102539062, -0.10849380493164062, 1.0665969848632812, -51.04306411743164, 0.3387947082519531, 0.77215576171875, 1.0728340148925781, 0.4215240478515625, 0.8033981323242188, 0.47354888916015625, 1.2635726928710938, 0.7389450073242188, 0.72607421875, 0.5516281127929688, 0.6287078857421875, 0.6400566101074219, 0.837432861328125, 0.906036376953125, 0.5532341003417969, 1.0767555236816406, 1.0683631896972656], "custom_metrics": {}}}, "num_steps_sampled": 12128, "num_agent_steps_sampled": 24256, "num_steps_trained": 19072, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 38144, "last_target_update_ts": 12048, "num_target_updates": 98}, "done": false, "episodes_total": 650, "training_iteration": 37, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-49", "timestamp": 1648811629, "time_this_iter_s": 1.144554615020752, "time_total_s": 48.27670693397522, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 48.27670693397522, "timesteps_since_restore": 1184, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 27.5, "ram_util_percent": 52.3}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -26.14, "episode_len_mean": 19.07, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -13.07, "policy1": -13.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -40.0, 26.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -40.0, -20.0, -40.0, -40.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 22.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -10.0, -20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -20.0, 13.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -10.0, -20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3088910804073809, "mean_inference_ms": 1.7620223787051585, "mean_action_processing_ms": 0.11917662952179917, "mean_env_wait_ms": 0.07704158143749071, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12328, "timesteps_this_iter": 32, "agent_timesteps_total": 24656, "timers": {"load_time_ms": 0.452, "load_throughput": 70845.99, "learn_time_ms": 8.178, "learn_throughput": 3912.962, "update_time_ms": 5.094}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -53.434410095214844, "min_q": -62.16598129272461, "max_q": -1.927699327468872, "mean_td_error": -4.458906173706055, "model": {}}, "td_error": [0.8085136413574219, 1.0411300659179688, 0.8352928161621094, 1.1949348449707031, 0.41020965576171875, -0.9276993274688721, -38.327396392822266, 1.2032203674316406, 0.562347412109375, 1.0906181335449219, 1.2030410766601562, 1.1264266967773438, 1.3096351623535156, 1.2969017028808594, -0.7746734619140625, 1.169342041015625, 1.3221817016601562, 1.1786918640136719, 0.4428672790527344, -61.07564163208008, 1.3091621398925781, 0.9958686828613281, 1.0468063354492188, 1.1571884155273438, -0.08938789367675781, 0.1143646240234375, 1.7309303283691406, 1.3221549987792969, 1.1428146362304688, 0.26086997985839844, -59.66827392578125, -7.097431182861328], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -55.47542190551758, "min_q": -57.47532653808594, "max_q": -54.022544860839844, "mean_td_error": -1.3418432474136353, "model": {}}, "td_error": [-1.4733657836914062, -0.5351676940917969, -0.6393356323242188, -0.6338424682617188, -0.5521240234375, -1.3111534118652344, -1.3544960021972656, -0.4341011047363281, -0.384735107421875, -1.4202423095703125, -0.5294380187988281, -1.1383285522460938, -1.4830856323242188, -0.6231155395507812, -0.8488616943359375, -1.3102302551269531, -0.90814208984375, -0.840576171875, -8.059860229492188, -1.2655448913574219, -0.7598609924316406, -0.6079025268554688, -0.838653564453125, -0.5635566711425781, -0.49839019775390625, -8.695510864257812, -0.5192489624023438, -1.4028816223144531, -0.4502754211425781, -1.4614028930664062, -0.8801116943359375, -0.51544189453125], "custom_metrics": {}}}, "num_steps_sampled": 12328, "num_agent_steps_sampled": 24656, "num_steps_trained": 19392, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 38784, "last_target_update_ts": 12288, "num_target_updates": 100}, "done": false, "episodes_total": 660, "training_iteration": 38, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-50", "timestamp": 1648811630, "time_this_iter_s": 0.9824419021606445, "time_total_s": 49.259148836135864, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840434d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840434d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 49.259148836135864, "timesteps_since_restore": 1216, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 28.8, "ram_util_percent": 52.3}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.28, "episode_len_mean": 19.34, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -13.64, "policy1": -13.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -40.0, -20.0, -40.0, -40.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 22.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -10.0, -20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -10.0, -20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30870482357067835, "mean_inference_ms": 1.760841230570373, "mean_action_processing_ms": 0.11909512146572154, "mean_env_wait_ms": 0.07699984227658946, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12628, "timesteps_this_iter": 32, "agent_timesteps_total": 25256, "timers": {"load_time_ms": 0.468, "load_throughput": 68342.445, "learn_time_ms": 8.152, "learn_throughput": 3925.562, "update_time_ms": 5.435}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -59.79167938232422, "min_q": -63.63960647583008, "max_q": -32.70143127441406, "mean_td_error": -4.760636329650879, "model": {}}, "td_error": [0.12067794799804688, 0.20985031127929688, 0.1389312744140625, -0.00292205810546875, 1.2506790161132812, 0.014835357666015625, 0.3322792053222656, 0.11896514892578125, 0.18073654174804688, 1.4054374694824219, -0.4891548156738281, -0.506072998046875, 0.10356903076171875, 0.08116912841796875, 0.14467239379882812, 0.09514236450195312, 1.581573486328125, -38.3389892578125, 1.1586494445800781, 0.08893585205078125, 0.001125335693359375, 1.3742408752441406, -0.5544013977050781, 0.011882781982421875, -0.24335861206054688, 1.2892570495605469, -62.63960647583008, 1.1683158874511719, 1.3189010620117188, -61.62172317504883, -0.057159423828125, -0.07680892944335938], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -54.82451629638672, "min_q": -56.03721237182617, "max_q": -53.62192916870117, "mean_td_error": -3.5446746349334717, "model": {}}, "td_error": [0.6478271484375, -0.2960319519042969, 0.029895782470703125, 0.651824951171875, 0.7469978332519531, 0.6095542907714844, 0.5436248779296875, 0.4091606140136719, 0.40468597412109375, -7.550468444824219, -7.117481231689453, -0.42340850830078125, 0.12668609619140625, 0.19552993774414062, 0.13745498657226562, -0.032501220703125, 0.8281631469726562, -0.3105316162109375, 0.3022422790527344, 0.4216499328613281, 0.3207893371582031, 0.046539306640625, 0.3413543701171875, -54.71572494506836, 1.4148674011230469, 0.6070365905761719, -52.97132873535156, 0.20011138916015625, 0.17584991455078125, -0.09435272216796875, 0.6647262573242188, 0.25566864013671875], "custom_metrics": {}}}, "num_steps_sampled": 12628, "num_agent_steps_sampled": 25256, "num_steps_trained": 19872, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 39744, "last_target_update_ts": 12528, "num_target_updates": 102}, "done": false, "episodes_total": 675, "training_iteration": 39, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-51", "timestamp": 1648811631, "time_this_iter_s": 1.201340913772583, "time_total_s": 50.46048974990845, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 50.46048974990845, "timesteps_since_restore": 1248, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 29.5, "ram_util_percent": 52.3}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.84, "episode_len_mean": 19.42, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -13.92, "policy1": -13.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -40.0, -20.0, -20.0, -40.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -40.0, -20.0, -40.0, -40.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 22.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 16.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -10.0, -20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -10.0, -20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3084810211307951, "mean_inference_ms": 1.7594914863086866, "mean_action_processing_ms": 0.11900232872361942, "mean_env_wait_ms": 0.07695887331737539, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12940, "timesteps_this_iter": 32, "agent_timesteps_total": 25880, "timers": {"load_time_ms": 0.429, "load_throughput": 74581.978, "learn_time_ms": 7.598, "learn_throughput": 4211.373, "update_time_ms": 4.873}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -59.97772979736328, "min_q": -64.39933776855469, "max_q": -33.334442138671875, "mean_td_error": -0.3819373846054077, "model": {}}, "td_error": [-0.12530136108398438, -0.3426475524902344, 0.48333740234375, -0.5467529296875, -0.40024566650390625, -0.2443695068359375, 0.16013336181640625, 0.337860107421875, -0.23899459838867188, -0.27075958251953125, -0.12668228149414062, -7.065402984619141, -0.4182548522949219, 0.6528205871582031, 0.9838447570800781, -0.2020721435546875, -0.22283172607421875, 0.177001953125, -0.3383941650390625, -0.5070304870605469, -0.420684814453125, 0.6091575622558594, 0.22274398803710938, -0.31412506103515625, -1.7402496337890625, -0.3050193786621094, -0.7908592224121094, -2.6032333374023438, -0.4573974609375, 0.550079345703125, 0.6324462890625, 0.6498870849609375], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -54.86082458496094, "min_q": -57.52280807495117, "max_q": -53.1338996887207, "mean_td_error": -5.010773658752441, "model": {}}, "td_error": [-0.10387039184570312, -0.04488372802734375, -52.792152404785156, 0.5421829223632812, 0.07255935668945312, 0.3141441345214844, -6.476444244384766, -0.14937210083007812, 0.0153350830078125, 0.5990371704101562, 0.12189483642578125, 0.213836669921875, 0.635162353515625, 0.6290779113769531, 0.260345458984375, 0.14300918579101562, 0.6773185729980469, 0.6862907409667969, -54.77621078491211, 0.7094879150390625, 0.5274124145507812, 0.122222900390625, 0.902099609375, -0.34464263916015625, 0.3325386047363281, 0.8474044799804688, 0.5947723388671875, 0.22689056396484375, -0.3333702087402344, -54.45880889892578, -0.6217575073242188, 0.5837440490722656], "custom_metrics": {}}}, "num_steps_sampled": 12940, "num_agent_steps_sampled": 25880, "num_steps_trained": 20384, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 40768, "last_target_update_ts": 12880, "num_target_updates": 105}, "done": false, "episodes_total": 691, "training_iteration": 40, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-52", "timestamp": 1648811632, "time_this_iter_s": 1.184528112411499, "time_total_s": 51.645017862319946, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 51.645017862319946, "timesteps_since_restore": 1280, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 35.9, "ram_util_percent": 52.4}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -28.94, "episode_len_mean": 19.57, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -14.47, "policy1": -14.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -40.0, -40.0, -20.0, -40.0, -40.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 22.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 16.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -10.0, -20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -10.0, -20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.308333380690395, "mean_inference_ms": 1.7583903488691845, "mean_action_processing_ms": 0.11892751180160996, "mean_env_wait_ms": 0.07692014619271031, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13240, "timesteps_this_iter": 32, "agent_timesteps_total": 26480, "timers": {"load_time_ms": 0.449, "load_throughput": 71199.262, "learn_time_ms": 8.226, "learn_throughput": 3889.907, "update_time_ms": 5.044}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -59.358577728271484, "min_q": -66.32315826416016, "max_q": -31.253162384033203, "mean_td_error": -5.553414344787598, "model": {}}, "td_error": [0.24430084228515625, 0.13199996948242188, 0.19648361206054688, 0.0526580810546875, 0.1309661865234375, -59.954986572265625, -0.3018341064453125, -60.53462600708008, -0.07342529296875, -0.054172515869140625, 0.23189544677734375, -58.08073806762695, -0.40953826904296875, 0.07093429565429688, -0.6829299926757812, 0.2906227111816406, 1.161224365234375, -0.00087738037109375, 0.000888824462890625, 0.09057998657226562, -0.012760162353515625, 0.1724853515625, 0.18239593505859375, 0.2371826171875, -0.31063079833984375, 0.19765853881835938, 0.19668960571289062, 0.10434722900390625, 0.16638565063476562, -0.5208816528320312, -0.3093719482421875, -0.3221912384033203], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -54.90956497192383, "min_q": -56.84960174560547, "max_q": -53.30793762207031, "mean_td_error": -2.092703342437744, "model": {}}, "td_error": [-0.5138702392578125, -55.10039520263672, -6.356475830078125, 0.18592071533203125, -0.3492317199707031, 0.19950103759765625, 0.0148162841796875, -0.19143295288085938, -0.3323211669921875, -0.12841415405273438, 0.20912933349609375, -0.29372406005859375, -0.48943328857421875, 0.028812408447265625, -0.4520301818847656, -0.3761444091796875, -0.4580078125, 0.35205841064453125, -0.2601509094238281, -0.3896751403808594, -0.3679466247558594, 0.036319732666015625, -0.220916748046875, -0.59881591796875, 0.41490936279296875, -0.28809356689453125, 0.3547630310058594, -0.12591934204101562, -0.8175926208496094, -0.273101806640625, -0.013515472412109375, -0.36553192138671875], "custom_metrics": {}}}, "num_steps_sampled": 13240, "num_agent_steps_sampled": 26480, "num_steps_trained": 20864, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 41728, "last_target_update_ts": 13240, "num_target_updates": 108}, "done": false, "episodes_total": 706, "training_iteration": 41, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-53", "timestamp": 1648811633, "time_this_iter_s": 1.1718831062316895, "time_total_s": 52.816900968551636, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 52.816900968551636, "timesteps_since_restore": 1312, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 29.75, "ram_util_percent": 52.4}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.24, "episode_len_mean": 19.42, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -13.62, "policy1": -13.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, 32.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 22.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 16.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, 16.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3081720917433453, "mean_inference_ms": 1.757089954847229, "mean_action_processing_ms": 0.11883611519373394, "mean_env_wait_ms": 0.07686945572978822, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13557, "timesteps_this_iter": 32, "agent_timesteps_total": 27114, "timers": {"load_time_ms": 0.42, "load_throughput": 76160.545, "learn_time_ms": 7.604, "learn_throughput": 4208.178, "update_time_ms": 4.919}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -58.22063446044922, "min_q": -64.65541076660156, "max_q": -32.20533752441406, "mean_td_error": 0.36666953563690186, "model": {}}, "td_error": [0.620635986328125, 1.290863037109375, 2.0900726318359375, 1.7820968627929688, -31.205337524414062, 2.0331954956054688, 1.6779975891113281, 1.710723876953125, 1.8920364379882812, 1.9429435729980469, 1.5691261291503906, 1.1170578002929688, 1.7425041198730469, 1.7782135009765625, 1.6894607543945312, 0.7305221557617188, 1.7483100891113281, 1.8489532470703125, 1.9475631713867188, 1.7482147216796875, 1.9956016540527344, 1.0882377624511719, 1.0751686096191406, 1.2205276489257812, 0.41861724853515625, 1.8063316345214844, 1.8793907165527344, -3.5343856811523438, 1.9460525512695312, 1.8431549072265625, 1.2274627685546875, 1.0121116638183594], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -55.55464172363281, "min_q": -58.087684631347656, "max_q": -53.8564453125, "mean_td_error": -4.734941005706787, "model": {}}, "td_error": [-66.65400695800781, -57.043880462646484, -6.653606414794922, -0.3369903564453125, -0.7114639282226562, -0.6704864501953125, -0.9224128723144531, -0.2901153564453125, -0.09839630126953125, -0.6935310363769531, -0.7345314025878906, -0.9671554565429688, -0.8210258483886719, -0.37050628662109375, -1.0212287902832031, -1.1202812194824219, -0.9069137573242188, -0.7630844116210938, -0.2796783447265625, -0.6638603210449219, -0.23036575317382812, -1.0539474487304688, -0.8243560791015625, -1.1966934204101562, -0.4933662414550781, -0.7540245056152344, -0.8144912719726562, -0.434478759765625, -0.7626914978027344, -1.2992935180664062, -1.2064743041992188, -0.7247810363769531], "custom_metrics": {}}}, "num_steps_sampled": 13557, "num_agent_steps_sampled": 27114, "num_steps_trained": 21408, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 42816, "last_target_update_ts": 13457, "num_target_updates": 110}, "done": false, "episodes_total": 723, "training_iteration": 42, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-55", "timestamp": 1648811635, "time_this_iter_s": 1.2092561721801758, "time_total_s": 54.02615714073181, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 54.02615714073181, "timesteps_since_restore": 1344, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 31.349999999999998, "ram_util_percent": 52.5}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.34, "episode_len_mean": 19.47, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -13.67, "policy1": -13.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -40.0, 22.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 16.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30813294119192236, "mean_inference_ms": 1.7566494206820118, "mean_action_processing_ms": 0.11881453530257204, "mean_env_wait_ms": 0.0768560402530386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13866, "timesteps_this_iter": 32, "agent_timesteps_total": 27732, "timers": {"load_time_ms": 0.437, "load_throughput": 73175.078, "learn_time_ms": 8.098, "learn_throughput": 3951.776, "update_time_ms": 5.24}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -58.73869323730469, "min_q": -67.55763244628906, "max_q": -31.103248596191406, "mean_td_error": -7.53976583480835, "model": {}}, "td_error": [-1.2892227172851562, -0.41846466064453125, -1.2657432556152344, -0.0264739990234375, -0.5826873779296875, -1.6134376525878906, 1.436767578125, -0.157379150390625, -63.557701110839844, -1.3301506042480469, -1.0396804809570312, -37.13134765625, -0.244720458984375, 0.3911590576171875, -62.18840408325195, 0.6567668914794922, -0.8105545043945312, 0.6682224273681641, -1.4654884338378906, -1.3279876708984375, -0.032398223876953125, -1.2564659118652344, -0.24420928955078125, -0.9117012023925781, -1.1783523559570312, 0.6603813171386719, -0.06964874267578125, 0.7496490478515625, -0.102386474609375, -1.6681175231933594, -0.16961669921875, -65.75311279296875], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -55.56660842895508, "min_q": -57.652774810791016, "max_q": -54.052669525146484, "mean_td_error": -2.3660061359405518, "model": {}}, "td_error": [-0.34436798095703125, -0.7888069152832031, 0.002300262451171875, -0.40148162841796875, -0.4568939208984375, -0.6292800903320312, -0.048259735107421875, -0.6010589599609375, -53.39051818847656, -0.323028564453125, -0.56903076171875, -1.1263198852539062, -8.644622802734375, -0.7137069702148438, -0.9799270629882812, -0.4422454833984375, -0.17100143432617188, -0.1691436767578125, -0.005954742431640625, -0.6026077270507812, -0.9143409729003906, -0.42739105224609375, -0.602386474609375, -0.5882720947265625, -0.5582733154296875, 0.10332489013671875, -0.23924636840820312, -0.5886917114257812, -0.6380500793457031, -0.370208740234375, -0.4771690368652344, -0.005527496337890625], "custom_metrics": {}}}, "num_steps_sampled": 13866, "num_agent_steps_sampled": 27732, "num_steps_trained": 21920, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 43840, "last_target_update_ts": 13806, "num_target_updates": 113}, "done": false, "episodes_total": 739, "training_iteration": 43, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-56", "timestamp": 1648811636, "time_this_iter_s": 1.2361202239990234, "time_total_s": 55.262277364730835, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 55.262277364730835, "timesteps_since_restore": 1376, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 32.25, "ram_util_percent": 52.85}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.26, "episode_len_mean": 19.53, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -13.63, "policy1": -13.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 16.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.308250919216398, "mean_inference_ms": 1.7572389879952839, "mean_action_processing_ms": 0.11886398325811971, "mean_env_wait_ms": 0.07687854928354594, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14081, "timesteps_this_iter": 32, "agent_timesteps_total": 28162, "timers": {"load_time_ms": 0.503, "load_throughput": 63601.255, "learn_time_ms": 8.741, "learn_throughput": 3661.059, "update_time_ms": 5.545}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.870361328125, "min_q": -70.39409637451172, "max_q": -33.147857666015625, "mean_td_error": -2.1571178436279297, "model": {}}, "td_error": [-2.2830352783203125, -2.1398773193359375, -2.4852828979492188, -2.597991943359375, -2.7060623168945312, -2.3246612548828125, -2.1215286254882812, -2.3431320190429688, -2.2107696533203125, -2.4202194213867188, -2.5717010498046875, -2.7127151489257812, -2.4658889770507812, 0.44107818603515625, -2.6917266845703125, -2.4831390380859375, -2.4786758422851562, -2.6034088134765625, -0.4411468505859375, -2.7532806396484375, -2.4364395141601562, -0.566497802734375, -2.3422698974609375, -1.6627349853515625, -2.9856643676757812, -2.2676467895507812, -2.520721435546875, -2.7796401977539062, -2.5443954467773438, -2.2793426513671875, -2.435302734375, 0.1860504150390625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -55.138458251953125, "min_q": -57.53719711303711, "max_q": -53.93634033203125, "mean_td_error": -1.3645215034484863, "model": {}}, "td_error": [0.830718994140625, 1.402130126953125, 0.2349395751953125, 1.0800857543945312, 1.3685531616210938, 1.1256332397460938, 1.24371337890625, 0.3576622009277344, 1.0109291076660156, 1.454345703125, 0.927459716796875, 1.52301025390625, -0.0575103759765625, 1.3621482849121094, 1.2992668151855469, 1.0625267028808594, -65.47932434082031, 0.043613433837890625, 0.2563667297363281, 0.4663543701171875, -7.8573760986328125, 1.5233497619628906, 1.2057685852050781, 0.8898696899414062, 1.0497169494628906, 0.9621696472167969, 1.2868804931640625, 1.5192108154296875, 0.5979537963867188, 1.1620216369628906, 1.2576141357421875, 1.2255096435546875], "custom_metrics": {}}}, "num_steps_sampled": 14081, "num_agent_steps_sampled": 28162, "num_steps_trained": 22272, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 44544, "last_target_update_ts": 14041, "num_target_updates": 115}, "done": false, "episodes_total": 750, "training_iteration": 44, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-57", "timestamp": 1648811637, "time_this_iter_s": 0.9960999488830566, "time_total_s": 56.25837731361389, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 56.25837731361389, "timesteps_since_restore": 1408, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 33.5, "ram_util_percent": 53.1}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.26, "episode_len_mean": 19.53, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -13.63, "policy1": -13.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 16.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3085268681330626, "mean_inference_ms": 1.7586106689507728, "mean_action_processing_ms": 0.11898647600119695, "mean_env_wait_ms": 0.07692874108046109, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14281, "timesteps_this_iter": 32, "agent_timesteps_total": 28562, "timers": {"load_time_ms": 0.679, "load_throughput": 47115.431, "learn_time_ms": 10.312, "learn_throughput": 3103.214, "update_time_ms": 7.182}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -65.08766174316406, "min_q": -70.14826965332031, "max_q": -34.33588790893555, "mean_td_error": -3.701417922973633, "model": {}}, "td_error": [0.8422698974609375, 0.5469436645507812, 0.1761932373046875, 0.5622177124023438, 0.6378402709960938, 0.7137680053710938, 0.77301025390625, -1.0045127868652344, 0.9559173583984375, 0.84783935546875, 0.4799041748046875, 0.8027267456054688, 1.0086212158203125, 0.33698272705078125, 0.42881011962890625, -67.48117065429688, 0.8984527587890625, 0.5016708374023438, 1.0957412719726562, 1.0422515869140625, 0.7069625854492188, 0.9334259033203125, 0.2245330810546875, 0.42430877685546875, 0.5259170532226562, 0.17502593994140625, 0.48773956298828125, -67.69786071777344, 0.842559814453125, 0.97882080078125, 1.052947998046875, -1.2652206420898438], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -57.01155090332031, "min_q": -60.487632751464844, "max_q": -55.391910552978516, "mean_td_error": -5.417422294616699, "model": {}}, "td_error": [0.9822044372558594, -1.060089111328125, -0.7699623107910156, -56.9018669128418, -1.9483070373535156, 0.8545303344726562, -8.085865020751953, -2.2185211181640625, -0.4580230712890625, -0.37322998046875, 1.2875022888183594, 1.6025009155273438, -54.68937301635742, 1.1306304931640625, -54.391910552978516, 1.0237960815429688, -6.741825103759766, 0.6525154113769531, 1.1361274719238281, -1.8261947631835938, 1.3990745544433594, -0.5454673767089844, 0.7022132873535156, 1.4698028564453125, 1.6078033447265625, 1.259857177734375, 1.3663330078125, 1.5958442687988281, -1.4554862976074219, -0.2791900634765625, -1.1243095397949219, 1.4413833618164062], "custom_metrics": {}}}, "num_steps_sampled": 14281, "num_agent_steps_sampled": 28562, "num_steps_trained": 22592, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 45184, "last_target_update_ts": 14281, "num_target_updates": 117}, "done": false, "episodes_total": 760, "training_iteration": 45, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-13-58", "timestamp": 1648811638, "time_this_iter_s": 1.0986196994781494, "time_total_s": 57.35699701309204, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 57.35699701309204, "timesteps_since_restore": 1440, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 44.45, "ram_util_percent": 53.85}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.06, "episode_len_mean": 19.53, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -13.53, "policy1": -13.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 16.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 8.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.309089047405017, "mean_inference_ms": 1.761648498565153, "mean_action_processing_ms": 0.11922891675903483, "mean_env_wait_ms": 0.07702509131316139, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14581, "timesteps_this_iter": 32, "agent_timesteps_total": 29162, "timers": {"load_time_ms": 0.535, "load_throughput": 59841.156, "learn_time_ms": 9.137, "learn_throughput": 3502.322, "update_time_ms": 5.675}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -74.40602111816406, "min_q": -81.73078155517578, "max_q": -39.749271392822266, "mean_td_error": -13.813089370727539, "model": {}}, "td_error": [-1.5740585327148438, -1.3474884033203125, -1.1099319458007812, -76.54175567626953, -1.4668197631835938, -48.67469787597656, -1.9430618286132812, -1.51708984375, -76.25202178955078, -1.1800613403320312, -1.3702774047851562, -1.853729248046875, -69.87152862548828, -3.757354736328125, -3.1534576416015625, -1.6128387451171875, -1.6459579467773438, -1.0730819702148438, -0.443145751953125, -0.1086883544921875, -46.26993179321289, -1.1122512817382812, -3.4350814819335938, -2.0047760009765625, -1.353271484375, -2.8091812133789062, -2.9527359008789062, -1.3699264526367188, -1.6757354736328125, -0.3023414611816406, -1.5848770141601562, -80.6517105102539], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -62.65986633300781, "min_q": -65.8664779663086, "max_q": -59.53219223022461, "mean_td_error": -12.32448959350586, "model": {}}, "td_error": [-3.7098655700683594, -3.571136474609375, -3.2813453674316406, -62.72419357299805, -0.7581939697265625, -10.693397521972656, -0.5056037902832031, -0.1083526611328125, -4.338069915771484, -3.183208465576172, -3.8330078125, -62.99674606323242, -4.0507965087890625, -4.244113922119141, 0.298980712890625, -2.6857032775878906, -0.23360443115234375, -0.6594276428222656, -4.792087554931641, -3.9368743896484375, -3.415569305419922, -4.107311248779297, 0.1025543212890625, -0.47614288330078125, -60.563480377197266, -3.3671798706054688, -3.7737884521484375, -2.6186447143554688, -62.02024841308594, -4.003528594970703, -64.8664779663086, -5.267124176025391], "custom_metrics": {}}}, "num_steps_sampled": 14581, "num_agent_steps_sampled": 29162, "num_steps_trained": 23072, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 46144, "last_target_update_ts": 14521, "num_target_updates": 119}, "done": false, "episodes_total": 775, "training_iteration": 46, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-00", "timestamp": 1648811640, "time_this_iter_s": 1.3846218585968018, "time_total_s": 58.74161887168884, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 58.74161887168884, "timesteps_since_restore": 1472, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 39.65, "ram_util_percent": 54.45}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.62, "episode_len_mean": 19.61, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -13.81, "policy1": -13.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30952926654763746, "mean_inference_ms": 1.763987596112045, "mean_action_processing_ms": 0.11934865120751063, "mean_env_wait_ms": 0.07707426680686498, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14681, "timesteps_this_iter": 32, "agent_timesteps_total": 29362, "timers": {"load_time_ms": 0.628, "load_throughput": 50922.991, "learn_time_ms": 13.742, "learn_throughput": 2328.693, "update_time_ms": 13.097}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -75.65434265136719, "min_q": -85.52095031738281, "max_q": -42.1660041809082, "mean_td_error": -3.03305983543396, "model": {}}, "td_error": [-2.86614990234375, -3.0608901977539062, -2.6585617065429688, -3.400299072265625, -3.3527603149414062, -2.766815185546875, -2.9347152709960938, -3.1645431518554688, -3.0634918212890625, -5.533226013183594, -4.6975860595703125, -3.0032501220703125, -3.2175064086914062, -3.215728759765625, -2.7932968139648438, -2.4623031616210938, -2.8067855834960938, -4.7762298583984375, -2.8042144775390625, -3.756011962890625, -3.3115386962890625, -4.0894775390625, -2.6338119506835938, -3.7646255493164062, -3.08984375, -2.8375625610351562, -3.8445816040039062, -0.17560577392578125, -0.4167900085449219, -0.22484970092773438, -3.3673019409179688, -2.967559814453125], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -61.03501892089844, "min_q": -63.893489837646484, "max_q": -59.39484405517578, "mean_td_error": -11.415876388549805, "model": {}}, "td_error": [-1.9091110229492188, -61.05528259277344, -2.5290565490722656, -2.225841522216797, -2.5552825927734375, -3.2076492309570312, -2.544086456298828, -2.3257980346679688, -62.550662994384766, -2.3182945251464844, -2.321735382080078, -2.4526596069335938, -2.797351837158203, -2.4217185974121094, -58.83883285522461, -58.44446563720703, -2.5205459594726562, -1.9000740051269531, -2.3047256469726562, -2.4049911499023438, -2.8132591247558594, -1.5997734069824219, -2.1226654052734375, -3.1558265686035156, -2.455913543701172, -2.3218994140625, -58.625553131103516, -2.500232696533203, -2.6351776123046875, -2.436237335205078, -2.7347335815429688, -2.27862548828125], "custom_metrics": {}}}, "num_steps_sampled": 14681, "num_agent_steps_sampled": 29362, "num_steps_trained": 23232, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 46464, "last_target_update_ts": 14641, "num_target_updates": 120}, "done": false, "episodes_total": 780, "training_iteration": 47, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-01", "timestamp": 1648811641, "time_this_iter_s": 1.169506311416626, "time_total_s": 59.91112518310547, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84066cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84066cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 59.91112518310547, "timesteps_since_restore": 1504, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 76.7, "ram_util_percent": 56.150000000000006}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.62, "episode_len_mean": 19.61, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -13.81, "policy1": -13.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31003699825012215, "mean_inference_ms": 1.7676458606720127, "mean_action_processing_ms": 0.11950629975214459, "mean_env_wait_ms": 0.0771400466326471, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14781, "timesteps_this_iter": 32, "agent_timesteps_total": 29562, "timers": {"load_time_ms": 1.255, "load_throughput": 25503.587, "learn_time_ms": 16.809, "learn_throughput": 1903.733, "update_time_ms": 19.476}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -76.86117553710938, "min_q": -82.04694366455078, "max_q": -45.2369270324707, "mean_td_error": -4.3624043464660645, "model": {}}, "td_error": [-4.678428649902344, 0.005859375, -0.271942138671875, -0.32269287109375, -0.09429931640625, -0.032196044921875, -0.0856475830078125, -1.4385604858398438, -54.2369270324707, -75.03838348388672, -0.244232177734375, -0.13250732421875, -0.0270538330078125, -0.29613494873046875, -1.1287460327148438, 0.467132568359375, -0.6646041870117188, -0.00537872314453125, -0.00946807861328125, -0.05886077880859375, 0.2014312744140625, 0.11516571044921875, 0.20477294921875, -0.6952896118164062, -0.09992218017578125, 0.0048370361328125, 0.00665283203125, -0.02886199951171875, 0.04034423828125, -0.13852691650390625, -0.3050689697265625, -0.6093978881835938], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -59.55225372314453, "min_q": -63.73227310180664, "max_q": -56.828285217285156, "mean_td_error": -10.052781105041504, "model": {}}, "td_error": [0.14740753173828125, 0.35825347900390625, 0.2519798278808594, -6.492633819580078, 0.16534805297851562, -61.95417022705078, 0.051868438720703125, -0.13648605346679688, -0.12875747680664062, 0.5710830688476562, 0.5212783813476562, 0.3256492614746094, -60.199371337890625, 0.412200927734375, 0.2982292175292969, 0.2966194152832031, 0.07513427734375, -0.08144378662109375, -6.848548889160156, 0.25246429443359375, 0.3736419677734375, 0.4012565612792969, 0.06597137451171875, 0.4211006164550781, -0.6729736328125, 0.9246902465820312, -58.89479446411133, 0.4698219299316406, -71.97279357910156, -61.71406936645508, 0.9638595581054688, 0.059192657470703125], "custom_metrics": {}}}, "num_steps_sampled": 14781, "num_agent_steps_sampled": 29562, "num_steps_trained": 23392, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 46784, "last_target_update_ts": 14761, "num_target_updates": 121}, "done": false, "episodes_total": 785, "training_iteration": 48, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-02", "timestamp": 1648811642, "time_this_iter_s": 1.0553719997406006, "time_total_s": 60.96649718284607, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 60.96649718284607, "timesteps_since_restore": 1536, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 98.7, "ram_util_percent": 58.8}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -26.26, "episode_len_mean": 19.33, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -13.13, "policy1": -13.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 30.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 26.0, -20.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3113662655933728, "mean_inference_ms": 1.7774790992794403, "mean_action_processing_ms": 0.11995330750395419, "mean_env_wait_ms": 0.07733542339005116, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14993, "timesteps_this_iter": 32, "agent_timesteps_total": 29986, "timers": {"load_time_ms": 0.584, "load_throughput": 54778.274, "learn_time_ms": 9.046, "learn_throughput": 3537.547, "update_time_ms": 6.433}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -74.39344787597656, "min_q": -82.0698013305664, "max_q": -44.836769104003906, "mean_td_error": -7.595364570617676, "model": {}}, "td_error": [-40.09169006347656, -0.1703643798828125, -0.04271697998046875, -0.08164215087890625, 0.5402679443359375, 0.3353843688964844, -0.017669677734375, -0.16937255859375, -0.1302490234375, -0.01381683349609375, -53.836769104003906, -3.07373046875, 0.02358245849609375, 0.0578155517578125, 0.07405853271484375, 0.2795867919921875, 0.45833587646484375, -0.9632339477539062, 0.2068939208984375, 0.05779266357421875, 0.15015411376953125, -2.3316116333007812, -0.039703369140625, 0.21379852294921875, 0.13994598388671875, -0.0816497802734375, -0.08164215087890625, -68.16058349609375, -73.89936065673828, -0.0628509521484375, -2.366668701171875, 0.0260467529296875], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -60.9149055480957, "min_q": -65.5937271118164, "max_q": -58.62631607055664, "mean_td_error": 0.14013957977294922, "model": {}}, "td_error": [-0.04209136962890625, 1.2978858947753906, 0.10012435913085938, 0.6437835693359375, 0.11505889892578125, -0.038349151611328125, 0.2695770263671875, -0.056911468505859375, 0.08629608154296875, 0.4027519226074219, 1.0794868469238281, 0.3789329528808594, -0.16841888427734375, 0.41440582275390625, 0.31966400146484375, 0.13713455200195312, 0.297576904296875, 0.340484619140625, -6.722545623779297, -0.0320587158203125, 0.053691864013671875, 0.19918060302734375, 0.5614471435546875, 0.6034088134765625, 0.29364013671875, 0.28969573974609375, 0.5066490173339844, 0.7512664794921875, 0.3935089111328125, 0.3935089111328125, 0.7634811401367188, 0.8521995544433594], "custom_metrics": {}}}, "num_steps_sampled": 14993, "num_agent_steps_sampled": 29986, "num_steps_trained": 23776, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 47552, "last_target_update_ts": 14973, "num_target_updates": 123}, "done": false, "episodes_total": 797, "training_iteration": 49, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-03", "timestamp": 1648811643, "time_this_iter_s": 1.1324307918548584, "time_total_s": 62.09892797470093, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 62.09892797470093, "timesteps_since_restore": 1568, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 60.849999999999994, "ram_util_percent": 60.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.96, "episode_len_mean": 19.18, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -12.98, "policy1": -12.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 30.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 26.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 30.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0], "episode_lengths": [8, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3126894876621431, "mean_inference_ms": 1.7874474291119027, "mean_action_processing_ms": 0.12042779209023631, "mean_env_wait_ms": 0.07754659592206785, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15198, "timesteps_this_iter": 32, "agent_timesteps_total": 30396, "timers": {"load_time_ms": 0.565, "load_throughput": 56588.974, "learn_time_ms": 9.45, "learn_throughput": 3386.395, "update_time_ms": 6.493}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -74.54808044433594, "min_q": -82.77687072753906, "max_q": -42.79642105102539, "mean_td_error": -3.6683244705200195, "model": {}}, "td_error": [-1.7179794311523438, -0.6152191162109375, -0.06445693969726562, -2.2662734985351562, -1.42437744140625, -1.0573196411132812, -1.071929931640625, -0.5387496948242188, -2.7654266357421875, -0.7868423461914062, -0.9719161987304688, -1.9278182983398438, -0.7212295532226562, -0.845733642578125, -0.7982025146484375, -0.6940841674804688, -1.20965576171875, -1.9089889526367188, -1.8855972290039062, -0.8870925903320312, -2.5878829956054688, -80.79620361328125, -1.8144607543945312, -1.0466156005859375, -0.7110671997070312, -0.596160888671875, -0.0027313232421875, -1.9152984619140625, 0.147552490234375, -1.2447128295898438, -1.8901748657226562, -0.7697296142578125], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -58.1400260925293, "min_q": -63.759620666503906, "max_q": -55.12961959838867, "mean_td_error": -5.205750942230225, "model": {}}, "td_error": [4.7046051025390625, 6.364757537841797, 5.314975738525391, 4.616641998291016, 6.190067291259766, 4.727302551269531, 7.092800140380859, 5.489757537841797, 0.28401947021484375, 5.107517242431641, 4.612937927246094, 0.45514678955078125, 5.687358856201172, 5.591152191162109, -60.11648178100586, 6.011024475097656, -59.920494079589844, 5.6982574462890625, 1.1168708801269531, 6.1843414306640625, -60.63923645019531, 4.370601654052734, 3.537921905517578, 6.867828369140625, 6.508087158203125, 3.6752967834472656, -59.02864074707031, 5.522998809814453, -60.43901062011719, 5.76812744140625, 6.408721923828125, 5.650718688964844], "custom_metrics": {}}}, "num_steps_sampled": 15198, "num_agent_steps_sampled": 30396, "num_steps_trained": 24128, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 48256, "last_target_update_ts": 15198, "num_target_updates": 125}, "done": false, "episodes_total": 808, "training_iteration": 50, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-04", "timestamp": 1648811644, "time_this_iter_s": 1.0685112476348877, "time_total_s": 63.167439222335815, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405b560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405b560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 63.167439222335815, "timesteps_since_restore": 1600, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 40.15, "ram_util_percent": 60.6}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.34, "episode_len_mean": 19.37, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -13.67, "policy1": -13.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 30.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 26.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 30.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -40.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31418857827145535, "mean_inference_ms": 1.7987582790386367, "mean_action_processing_ms": 0.12100820494286112, "mean_env_wait_ms": 0.07780244984156347, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15414, "timesteps_this_iter": 32, "agent_timesteps_total": 30828, "timers": {"load_time_ms": 0.563, "load_throughput": 56864.69, "learn_time_ms": 9.614, "learn_throughput": 3328.375, "update_time_ms": 6.32}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -69.82304382324219, "min_q": -78.96562194824219, "max_q": -42.71080780029297, "mean_td_error": -1.7834057807922363, "model": {}}, "td_error": [0.7424087524414062, 1.1571426391601562, 0.7655258178710938, 1.0686187744140625, 0.9681320190429688, 1.0112838745117188, 0.74224853515625, 1.666107177734375, 1.4954452514648438, 0.06597900390625, 0.6765289306640625, -1.2996749877929688, 1.022247314453125, 0.9226226806640625, -41.71080780029297, 1.039215087890625, 0.6327743530273438, -0.9024505615234375, 0.341888427734375, 0.8368377685546875, 1.5794296264648438, 0.9119491577148438, 0.8125762939453125, 0.2575225830078125, 0.754241943359375, 1.0627517700195312, 1.0332412719726562, 0.921478271484375, 0.8198089599609375, -36.09217834472656, 0.6956939697265625, -1.0675735473632812], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -58.96642303466797, "min_q": -61.2278938293457, "max_q": -55.81407928466797, "mean_td_error": -8.453178405761719, "model": {}}, "td_error": [-0.6050033569335938, -0.6443252563476562, 0.3801155090332031, -0.9934616088867188, -0.5697593688964844, -0.5683784484863281, -1.0582199096679688, -0.48690032958984375, -1.1126899719238281, -1.2251472473144531, -2.3040428161621094, -0.9336662292480469, -1.1085853576660156, -1.1819076538085938, 1.2108840942382812, -0.6552391052246094, -0.40926361083984375, -0.5328521728515625, 0.957763671875, -0.9286766052246094, -59.788047790527344, -1.3234062194824219, -57.363502502441406, -0.8998222351074219, -0.5697593688964844, -1.2598648071289062, -0.6292915344238281, -1.2187423706054688, -7.351776123046875, -69.90807342529297, -0.6795501708984375, -56.740509033203125], "custom_metrics": {}}}, "num_steps_sampled": 15414, "num_agent_steps_sampled": 30828, "num_steps_trained": 24480, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 48960, "last_target_update_ts": 15318, "num_target_updates": 126}, "done": false, "episodes_total": 819, "training_iteration": 51, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-06", "timestamp": 1648811646, "time_this_iter_s": 1.152369499206543, "time_total_s": 64.31980872154236, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405ae60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405ae60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 64.31980872154236, "timesteps_since_restore": 1632, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 41.4, "ram_util_percent": 61.2}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.5, "episode_len_mean": 19.25, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -13.75, "policy1": -13.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, 22.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 30.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 26.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 30.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, 24.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, 11.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31577194410276216, "mean_inference_ms": 1.8106335404830392, "mean_action_processing_ms": 0.12162721254552306, "mean_env_wait_ms": 0.07808153896580855, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15622, "timesteps_this_iter": 32, "agent_timesteps_total": 31244, "timers": {"load_time_ms": 0.627, "load_throughput": 51008.144, "learn_time_ms": 9.84, "learn_throughput": 3252.084, "update_time_ms": 5.758}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -74.6527328491211, "min_q": -80.67327117919922, "max_q": -44.908470153808594, "mean_td_error": -7.718195915222168, "model": {}}, "td_error": [0.2094879150390625, -1.4025039672851562, -1.1989898681640625, 0.21212005615234375, 0.5754623413085938, -0.8310699462890625, -1.0888900756835938, 0.522491455078125, -0.8417243957519531, -1.0254440307617188, -79.0316390991211, -2.6190567016601562, -77.33123779296875, -1.36956787109375, 0.8734359741210938, 0.08913421630859375, -0.398406982421875, -0.97637939453125, -0.7365951538085938, -1.3388137817382812, -2.0789871215820312, -1.196014404296875, -1.0294723510742188, -0.9024658203125, 0.36829376220703125, -70.46919250488281, 0.5738372802734375, -1.3965072631835938, -0.48679351806640625, -0.8006668090820312, -0.8547592163085938, -1.0013504028320312], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -56.41302490234375, "min_q": -61.20249557495117, "max_q": -53.604732513427734, "mean_td_error": -0.4404129981994629, "model": {}}, "td_error": [0.2826080322265625, 2.485942840576172, -2.2529525756835938, 2.690135955810547, 1.3301277160644531, 1.8862190246582031, 2.118114471435547, 2.2941513061523438, 1.7442131042480469, 2.158519744873047, 0.7293128967285156, 2.3212013244628906, 1.4730224609375, -3.9003868103027344, 0.7201347351074219, 0.5853462219238281, 2.7677536010742188, -53.283565521240234, 2.266490936279297, 2.3116416931152344, 0.8790779113769531, 2.138031005859375, 1.9450302124023438, 1.77777099609375, 0.6940155029296875, 2.0708999633789062, 0.6288604736328125, 1.3474693298339844, 0.9025421142578125, 1.12103271484375, 0.49092864990234375, 1.1830940246582031], "custom_metrics": {}}}, "num_steps_sampled": 15622, "num_agent_steps_sampled": 31244, "num_steps_trained": 24832, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 49664, "last_target_update_ts": 15554, "num_target_updates": 128}, "done": false, "episodes_total": 830, "training_iteration": 52, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-07", "timestamp": 1648811647, "time_this_iter_s": 1.0353267192840576, "time_total_s": 65.35513544082642, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84043950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 65.35513544082642, "timesteps_since_restore": 1664, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 44.2, "ram_util_percent": 61.9}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -28.52, "episode_len_mean": 19.36, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -14.26, "policy1": -14.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 30.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 26.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 30.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, 24.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3173618582274963, "mean_inference_ms": 1.8223418690069446, "mean_action_processing_ms": 0.12226430872621757, "mean_env_wait_ms": 0.07837402371297907, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15822, "timesteps_this_iter": 32, "agent_timesteps_total": 31644, "timers": {"load_time_ms": 0.666, "load_throughput": 48055.04, "learn_time_ms": 10.435, "learn_throughput": 3066.586, "update_time_ms": 6.522}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -73.00514221191406, "min_q": -84.1780776977539, "max_q": -45.39909362792969, "mean_td_error": -12.186695098876953, "model": {}}, "td_error": [-1.7315139770507812, -83.1780776977539, -0.7356185913085938, -0.5310821533203125, -0.20104598999023438, -0.35642242431640625, -0.408111572265625, -0.40478515625, -70.3025894165039, -0.443939208984375, -82.55642700195312, -69.75137329101562, -0.321533203125, -0.5326995849609375, -0.7175827026367188, -0.6076278686523438, 0.7897491455078125, -0.6055984497070312, 0.9565391540527344, -0.685577392578125, -0.5797653198242188, -70.74703216552734, -0.717620849609375, -0.7478179931640625, -2.1813583374023438, 1.1937332153320312, -2.4852066040039062, 0.3835563659667969, -0.5233535766601562, -0.53509521484375, -0.327972412109375, -0.3809661865234375], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -58.73567199707031, "min_q": -62.86536407470703, "max_q": -56.10639572143555, "mean_td_error": -1.580376386642456, "model": {}}, "td_error": [1.0195999145507812, 0.9751434326171875, -0.04205322265625, 0.8829841613769531, 0.6208534240722656, 1.1724700927734375, 0.5795211791992188, -0.001129150390625, 1.1450386047363281, -0.17144775390625, 1.1456527709960938, 0.4041633605957031, 1.5226821899414062, 0.14853286743164062, 0.3587760925292969, 0.9674949645996094, 0.33037567138671875, 0.7422981262207031, 0.7466468811035156, 0.322052001953125, 1.0019149780273438, 1.0585899353027344, 0.6678390502929688, 0.3178558349609375, 0.8787002563476562, -3.5053977966308594, 1.1408615112304688, -56.56163024902344, 0.721710205078125, 0.7444839477539062, -4.892940521240234, -5.0136871337890625], "custom_metrics": {}}}, "num_steps_sampled": 15822, "num_agent_steps_sampled": 31644, "num_steps_trained": 25152, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 50304, "last_target_update_ts": 15782, "num_target_updates": 130}, "done": false, "episodes_total": 840, "training_iteration": 53, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-08", "timestamp": 1648811648, "time_this_iter_s": 1.11271071434021, "time_total_s": 66.46784615516663, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84045560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84045560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 66.46784615516663, "timesteps_since_restore": 1696, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 40.9, "ram_util_percent": 62.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -29.02, "episode_len_mean": 19.41, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -14.51, "policy1": -14.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 30.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 26.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 30.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, 24.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31891805485620134, "mean_inference_ms": 1.833992339707941, "mean_action_processing_ms": 0.12289987680826518, "mean_env_wait_ms": 0.07866120867072796, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16022, "timesteps_this_iter": 32, "agent_timesteps_total": 32044, "timers": {"load_time_ms": 0.551, "load_throughput": 58047.629, "learn_time_ms": 8.641, "learn_throughput": 3703.069, "update_time_ms": 5.897}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -73.80716705322266, "min_q": -84.84720611572266, "max_q": -44.7202033996582, "mean_td_error": -2.4638168811798096, "model": {}}, "td_error": [-1.1856460571289062, -1.1474990844726562, -2.4282608032226562, 0.5682830810546875, -1.4762344360351562, -1.9195327758789062, -1.1093368530273438, -2.5970611572265625, -0.48046875, -1.6565475463867188, -1.124114990234375, 0.16645431518554688, -1.53741455078125, -2.2877197265625, -1.3150787353515625, -1.529205322265625, -1.4845046997070312, -2.5894775390625, -1.7119827270507812, -1.5608749389648438, -1.7882843017578125, -2.6868515014648438, -1.4890060424804688, -1.4731063842773438, 0.007259368896484375, -2.1081924438476562, -1.153411865234375, -2.3860702514648438, -1.2558212280273438, -36.023094177246094, -1.389617919921875, 1.3102798461914062], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -61.125919342041016, "min_q": -64.59994506835938, "max_q": -58.203006744384766, "mean_td_error": -4.108132362365723, "model": {}}, "td_error": [-62.70157241821289, 0.6651992797851562, -1.13128662109375, -0.9413528442382812, -0.09936141967773438, -0.6552467346191406, 0.007709503173828125, -1.4864387512207031, 0.040287017822265625, -59.78417205810547, -1.3140754699707031, -0.12889480590820312, -0.9589080810546875, -0.0428314208984375, -1.0656166076660156, -0.7826881408691406, -0.203460693359375, -0.05011749267578125, -0.2747344970703125, -1.0424575805664062, 1.2614784240722656, 0.5692481994628906, 0.4498405456542969, -0.1197509765625, 0.5692481994628906, 0.17688369750976562, -1.1206932067871094, 0.7440414428710938, -1.0922012329101562, 0.4966392517089844, -1.9589195251464844, 0.5139694213867188], "custom_metrics": {}}}, "num_steps_sampled": 16022, "num_agent_steps_sampled": 32044, "num_steps_trained": 25472, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 50944, "last_target_update_ts": 16022, "num_target_updates": 132}, "done": false, "episodes_total": 850, "training_iteration": 54, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-09", "timestamp": 1648811649, "time_this_iter_s": 0.9391846656799316, "time_total_s": 67.40703082084656, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84068a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 67.40703082084656, "timesteps_since_restore": 1728, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 37.9, "ram_util_percent": 62.3}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -29.42, "episode_len_mean": 19.41, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -14.71, "policy1": -14.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, 30.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 26.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 30.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, 24.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3209617772686169, "mean_inference_ms": 1.8498921968705095, "mean_action_processing_ms": 0.12373619799292034, "mean_env_wait_ms": 0.07904588217782242, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16322, "timesteps_this_iter": 32, "agent_timesteps_total": 32644, "timers": {"load_time_ms": 0.463, "load_throughput": 69109.587, "learn_time_ms": 8.232, "learn_throughput": 3887.462, "update_time_ms": 5.505}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -76.21122741699219, "min_q": -89.92613220214844, "max_q": -47.054840087890625, "mean_td_error": -2.7064993381500244, "model": {}}, "td_error": [0.5291366577148438, -74.77116394042969, -2.3051605224609375, -0.5549774169921875, -0.098236083984375, -0.4931488037109375, 0.885162353515625, -3.9238662719726562, -0.47399139404296875, -1.0633926391601562, -0.8541030883789062, -1.1627578735351562, -1.5427322387695312, -0.8573760986328125, -0.44597625732421875, 1.5184707641601562, 3.3092117309570312, -0.5648117065429688, -0.342041015625, 0.47907257080078125, -0.21822357177734375, -0.1736602783203125, -0.9998779296875, -0.6578369140625, -1.4660110473632812, 0.1727447509765625, 0.5786590576171875, -0.31269073486328125, 0.6977157592773438, -0.7542037963867188, -0.5031585693359375, -0.2387542724609375], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -61.76103973388672, "min_q": -65.46077728271484, "max_q": -59.434410095214844, "mean_td_error": -0.3794722557067871, "model": {}}, "td_error": [0.6806182861328125, -5.775569915771484, -0.004650115966796875, 0.7442283630371094, -6.383918762207031, 1.4445762634277344, 1.050018310546875, 0.9548263549804688, -1.5608787536621094, 1.1640701293945312, 0.27654266357421875, 0.7010765075683594, -5.788169860839844, 0.7795562744140625, 0.34078216552734375, 0.9722557067871094, 0.405853271484375, -0.12888336181640625, 0.019916534423828125, 1.4981727600097656, -0.2769584655761719, 0.3983497619628906, -0.2461395263671875, 0.06365585327148438, 0.047443389892578125, -6.348724365234375, 0.8901939392089844, -0.206298828125, 0.3131904602050781, 1.2759857177734375, 0.2778511047363281, 0.27791595458984375], "custom_metrics": {}}}, "num_steps_sampled": 16322, "num_agent_steps_sampled": 32644, "num_steps_trained": 25952, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 51904, "last_target_update_ts": 16262, "num_target_updates": 134}, "done": false, "episodes_total": 865, "training_iteration": 55, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-10", "timestamp": 1648811650, "time_this_iter_s": 1.2860114574432373, "time_total_s": 68.6930422782898, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 68.6930422782898, "timesteps_since_restore": 1760, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 39.7, "ram_util_percent": 62.75}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -28.38, "episode_len_mean": 19.09, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -14.19, "policy1": -14.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, 30.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, 26.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 30.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, 24.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, 15.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32287311803320834, "mean_inference_ms": 1.8652216266894994, "mean_action_processing_ms": 0.12460532537745168, "mean_env_wait_ms": 0.07943759864393027, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16630, "timesteps_this_iter": 32, "agent_timesteps_total": 33260, "timers": {"load_time_ms": 0.458, "load_throughput": 69915.991, "learn_time_ms": 8.588, "learn_throughput": 3726.086, "update_time_ms": 5.936}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -75.81103515625, "min_q": -90.94515228271484, "max_q": -44.38169860839844, "mean_td_error": -3.1016013622283936, "model": {}}, "td_error": [-0.9292068481445312, -0.7426910400390625, -0.5438919067382812, -0.6960601806640625, -0.17978668212890625, -0.3048858642578125, -0.01424407958984375, -1.837249755859375, -0.20853424072265625, -0.1444549560546875, 0.30926513671875, -1.3261642456054688, -0.6338729858398438, 0.08013153076171875, -0.163970947265625, -0.39032745361328125, -0.7468795776367188, -1.2616348266601562, -0.00682830810546875, -0.8125381469726562, -1.4425430297851562, -1.480499267578125, -0.363739013671875, -0.981536865234375, 3.3743438720703125, -0.151763916015625, 2.6595458984375, -0.046905517578125, -89.29654693603516, -0.0826568603515625, -0.5750198364257812, -0.31009674072265625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -60.74167251586914, "min_q": -64.80432891845703, "max_q": -58.18035125732422, "mean_td_error": -2.962900161743164, "model": {}}, "td_error": [1.6101417541503906, 0.20629119873046875, 1.4820823669433594, -3.4271469116210938, 1.460845947265625, 1.2938499450683594, 0.5616836547851562, 1.3848724365234375, -63.10234832763672, 1.865936279296875, 1.6735382080078125, 0.49214935302734375, 1.3116378784179688, 1.3582916259765625, 2.197925567626953, 1.5455970764160156, 1.5465202331542969, 1.9104118347167969, 1.1970939636230469, 0.9011955261230469, 1.3972625732421875, 1.4199409484863281, 1.2516593933105469, 0.5918655395507812, 1.2895698547363281, 1.6641807556152344, 1.2519569396972656, -3.6233139038085938, 1.3252296447753906, -61.08135986328125, 1.2909393310546875, 0.9386940002441406], "custom_metrics": {}}}, "num_steps_sampled": 16630, "num_agent_steps_sampled": 33260, "num_steps_trained": 26496, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 52992, "last_target_update_ts": 16590, "num_target_updates": 137}, "done": false, "episodes_total": 882, "training_iteration": 56, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-12", "timestamp": 1648811652, "time_this_iter_s": 1.4003379344940186, "time_total_s": 70.09338021278381, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405b830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405b830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 70.09338021278381, "timesteps_since_restore": 1792, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 40.45, "ram_util_percent": 63.25}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -29.74, "episode_len_mean": 19.37, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -14.87, "policy1": -14.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 30.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, 24.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, 15.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3239024108495869, "mean_inference_ms": 1.8723516462968741, "mean_action_processing_ms": 0.12517951561352342, "mean_env_wait_ms": 0.07968641270486264, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16930, "timesteps_this_iter": 32, "agent_timesteps_total": 33860, "timers": {"load_time_ms": 0.444, "load_throughput": 72043.869, "learn_time_ms": 8.302, "learn_throughput": 3854.439, "update_time_ms": 6.095}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -77.95647430419922, "min_q": -88.98089599609375, "max_q": -46.62763977050781, "mean_td_error": -1.9564411640167236, "model": {}}, "td_error": [-0.08094406127929688, 0.4788169860839844, -0.187896728515625, 0.806640625, 0.17673492431640625, 0.47223663330078125, -0.9116439819335938, -0.17258453369140625, -62.45957565307617, 0.24193572998046875, -0.5900344848632812, -0.6148223876953125, -0.428436279296875, -0.02629852294921875, -1.2308731079101562, -0.10449981689453125, 0.42147064208984375, 0.08394622802734375, 0.30265045166015625, 0.367767333984375, 0.06299591064453125, 0.39452362060546875, -0.29297637939453125, -0.042449951171875, -0.038330078125, 0.20154571533203125, -0.5349960327148438, 0.6919479370117188, 0.43328857421875, 0.13511276245117188, -0.3613739013671875, 0.20000457763671875], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.0700912475586, "min_q": -67.59329986572266, "max_q": -61.74441146850586, "mean_td_error": -2.931011199951172, "model": {}}, "td_error": [-0.22518157958984375, -1.2568016052246094, -1.0452728271484375, -63.853355407714844, -0.9112472534179688, -1.6007232666015625, -0.056461334228515625, -0.96600341796875, -0.7526473999023438, 0.3091697692871094, -0.2935791015625, -0.8037033081054688, -0.2559242248535156, -0.7804183959960938, -1.3828811645507812, -1.1411056518554688, -1.4218063354492188, -0.2767181396484375, -1.089996337890625, -1.3018417358398438, -1.3759384155273438, -5.5328521728515625, -0.8695297241210938, -0.3964653015136719, -0.4342918395996094, -0.9738845825195312, -0.7325401306152344, -0.5677452087402344, 0.08770370483398438, -1.1854629516601562, -1.3171463012695312, -1.3877029418945312], "custom_metrics": {}}}, "num_steps_sampled": 16930, "num_agent_steps_sampled": 33860, "num_steps_trained": 26976, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 53952, "last_target_update_ts": 16830, "num_target_updates": 139}, "done": false, "episodes_total": 897, "training_iteration": 57, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-13", "timestamp": 1648811653, "time_this_iter_s": 1.315080165863037, "time_total_s": 71.40846037864685, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405bef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405bef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 71.40846037864685, "timesteps_since_restore": 1824, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 40.5, "ram_util_percent": 63.8}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -30.64, "episode_len_mean": 19.52, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -15.32, "policy1": -15.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 8.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, 24.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3247493119765511, "mean_inference_ms": 1.8780389220272604, "mean_action_processing_ms": 0.1256510042821654, "mean_env_wait_ms": 0.07988234213407984, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17230, "timesteps_this_iter": 32, "agent_timesteps_total": 34460, "timers": {"load_time_ms": 0.475, "load_throughput": 67418.991, "learn_time_ms": 8.416, "learn_throughput": 3802.202, "update_time_ms": 5.573}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -79.02496337890625, "min_q": -90.45410919189453, "max_q": -45.93523406982422, "mean_td_error": -6.843774795532227, "model": {}}, "td_error": [-75.12584686279297, 0.0084686279296875, -0.520599365234375, -0.5465774536132812, -0.39173126220703125, -65.76492309570312, 1.0646247863769531, -77.40292358398438, 0.6870880126953125, -0.8752059936523438, -0.514373779296875, -0.11579132080078125, 0.7558975219726562, -0.667083740234375, 0.6352310180664062, 0.918792724609375, -0.11541748046875, 0.5025100708007812, 0.5828475952148438, -0.49761962890625, 0.30248260498046875, -0.691680908203125, -1.238372802734375, -0.2977447509765625, 0.20892333984375, -1.170135498046875, 1.1418838500976562, -0.22595977783203125, 1.0765571594238281, 0.3591461181640625, -0.53533935546875, -0.54791259765625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.13551330566406, "min_q": -65.78997802734375, "max_q": -61.753475189208984, "mean_td_error": -2.4564785957336426, "model": {}}, "td_error": [0.06568527221679688, -0.19354629516601562, -0.3873481750488281, -0.5428390502929688, -0.13309478759765625, -0.13975143432617188, -0.348541259765625, -0.3127479553222656, -0.5511894226074219, 0.3104400634765625, -0.9962425231933594, -0.280517578125, 0.7467536926269531, -0.3729400634765625, -0.3104133605957031, -0.2531623840332031, -0.5970115661621094, -0.3172149658203125, -1.6066055297851562, 0.3856658935546875, -0.4880714416503906, -0.2711296081542969, 0.04540252685546875, -0.5154380798339844, -7.838611602783203, -0.2582244873046875, -0.486602783203125, -0.25244903564453125, -0.30373382568359375, 0.20743560791015625, -62.18194580078125, -0.4293327331542969], "custom_metrics": {}}}, "num_steps_sampled": 17230, "num_agent_steps_sampled": 34460, "num_steps_trained": 27456, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 54912, "last_target_update_ts": 17190, "num_target_updates": 142}, "done": false, "episodes_total": 912, "training_iteration": 58, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-15", "timestamp": 1648811655, "time_this_iter_s": 1.3260867595672607, "time_total_s": 72.73454713821411, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84045050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84045050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 72.73454713821411, "timesteps_since_restore": 1856, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 39.1, "ram_util_percent": 64.19999999999999}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -31.16, "episode_len_mean": 19.68, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -15.58, "policy1": -15.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32537512646341116, "mean_inference_ms": 1.8820320142307942, "mean_action_processing_ms": 0.12600101096488017, "mean_env_wait_ms": 0.08002093763529249, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17530, "timesteps_this_iter": 32, "agent_timesteps_total": 35060, "timers": {"load_time_ms": 0.443, "load_throughput": 72179.472, "learn_time_ms": 8.225, "learn_throughput": 3890.764, "update_time_ms": 5.349}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -75.31301879882812, "min_q": -89.65026092529297, "max_q": -48.61328125, "mean_td_error": -4.550873756408691, "model": {}}, "td_error": [0.6565093994140625, 0.6763381958007812, 0.0925445556640625, 0.7323455810546875, 1.2470626831054688, 0.4282989501953125, -0.14899063110351562, 0.21071624755859375, 2.03857421875, 0.5618209838867188, 0.49787139892578125, -0.22023391723632812, 0.6233367919921875, -0.051513671875, 0.9046249389648438, 0.416412353515625, 1.0693206787109375, 0.51385498046875, 1.1007766723632812, 0.6342849731445312, -74.77853393554688, -0.21851730346679688, 0.46186065673828125, 0.36077117919921875, 0.210357666015625, 0.3055419921875, -85.8513412475586, 0.187713623046875, 0.29018402099609375, 1.0257644653320312, 0.43544769287109375, -0.041168212890625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -61.20575714111328, "min_q": -63.3447151184082, "max_q": -59.39321517944336, "mean_td_error": 0.8104792833328247, "model": {}}, "td_error": [1.7275886535644531, 1.3549385070800781, -5.327587127685547, 1.0017013549804688, 1.2322349548339844, 0.7935714721679688, 1.4076461791992188, 1.5230293273925781, 1.0622367858886719, 0.7603569030761719, 1.2322349548339844, 1.5107994079589844, 1.1654777526855469, 0.9475250244140625, 1.0231971740722656, 1.3946533203125, 0.9843254089355469, 0.9748344421386719, 1.7465553283691406, 1.0523643493652344, 1.042266845703125, 0.9434165954589844, 0.7395668029785156, 1.6578788757324219, 1.9394989013671875, -5.635982513427734, 1.1433639526367188, 1.6148757934570312, 1.2205162048339844, 1.4614486694335938, 0.8987197875976562, 1.3420829772949219], "custom_metrics": {}}}, "num_steps_sampled": 17530, "num_agent_steps_sampled": 35060, "num_steps_trained": 27936, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 55872, "last_target_update_ts": 17430, "num_target_updates": 144}, "done": false, "episodes_total": 927, "training_iteration": 59, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-16", "timestamp": 1648811656, "time_this_iter_s": 1.2095530033111572, "time_total_s": 73.94410014152527, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840439e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840439e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 73.94410014152527, "timesteps_since_restore": 1888, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 39.349999999999994, "ram_util_percent": 64.45}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -30.56, "episode_len_mean": 19.68, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -15.28, "policy1": -15.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3257857738357574, "mean_inference_ms": 1.8849102400014361, "mean_action_processing_ms": 0.12625999298527288, "mean_env_wait_ms": 0.08011821063053888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17830, "timesteps_this_iter": 32, "agent_timesteps_total": 35660, "timers": {"load_time_ms": 0.493, "load_throughput": 64852.014, "learn_time_ms": 8.472, "learn_throughput": 3776.962, "update_time_ms": 5.597}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -74.091552734375, "min_q": -87.08706665039062, "max_q": -48.029788970947266, "mean_td_error": -3.1351125240325928, "model": {}}, "td_error": [1.1731033325195312, 0.6643142700195312, 1.1577987670898438, 1.308746337890625, 1.3571853637695312, -72.44783020019531, 2.63427734375, 1.5032882690429688, 1.132659912109375, 0.555877685546875, 2.5432052612304688, 0.8296318054199219, 2.43597412109375, 2.137481689453125, 1.1555633544921875, 1.4017105102539062, 2.6154403686523438, 2.3015975952148438, 0.9181900024414062, 0.9374465942382812, 2.380126953125, -0.3964385986328125, -0.06103515625, -69.67192077636719, 2.4489288330078125, 3.0999298095703125, 0.8557624816894531, 1.1952056884765625, 0.5302696228027344, 1.471527099609375, 0.47501373291015625, 1.0333633422851562], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.44954681396484, "min_q": -66.74983215332031, "max_q": -62.32767105102539, "mean_td_error": -6.589778423309326, "model": {}}, "td_error": [-1.0725936889648438, -0.25212860107421875, -0.15961456298828125, -0.6286468505859375, -0.654815673828125, -64.42981719970703, -0.12264251708984375, -0.7364006042480469, 0.3101654052734375, -0.44173431396484375, -0.48433685302734375, -0.8907279968261719, -0.414886474609375, -0.7460098266601562, -0.8118247985839844, -0.6131515502929688, -0.71697998046875, -1.0764617919921875, -0.5179367065429688, -0.0136871337890625, -64.91093444824219, -0.69415283203125, -0.6943321228027344, -0.8983993530273438, -0.25753021240234375, -0.8196296691894531, -0.6637420654296875, -0.41072845458984375, -0.8596725463867188, -1.1408119201660156, -0.8847160339355469, -64.16403198242188], "custom_metrics": {}}}, "num_steps_sampled": 17830, "num_agent_steps_sampled": 35660, "num_steps_trained": 28416, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 56832, "last_target_update_ts": 17790, "num_target_updates": 147}, "done": false, "episodes_total": 942, "training_iteration": 60, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-17", "timestamp": 1648811657, "time_this_iter_s": 1.332184076309204, "time_total_s": 75.27628421783447, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405b680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405b680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 75.27628421783447, "timesteps_since_restore": 1920, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 39.55, "ram_util_percent": 64.65}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -30.76, "episode_len_mean": 19.68, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -15.38, "policy1": -15.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 32.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32615103169544674, "mean_inference_ms": 1.8876255963259814, "mean_action_processing_ms": 0.12649355496593928, "mean_env_wait_ms": 0.08021127453334398, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18130, "timesteps_this_iter": 32, "agent_timesteps_total": 36260, "timers": {"load_time_ms": 0.582, "load_throughput": 54939.717, "learn_time_ms": 9.322, "learn_throughput": 3432.854, "update_time_ms": 6.077}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -73.40611267089844, "min_q": -88.12339782714844, "max_q": -49.13017272949219, "mean_td_error": 0.7092187404632568, "model": {}}, "td_error": [0.9105987548828125, 1.4800643920898438, -0.23328399658203125, 0.977569580078125, 0.3636932373046875, 0.1125335693359375, 0.75274658203125, 0.16280364990234375, 0.29120635986328125, 0.1074676513671875, 0.3679046630859375, 1.7475051879882812, -0.19594573974609375, 0.26397705078125, 0.6954116821289062, 0.16841506958007812, 0.9728164672851562, 1.057342529296875, 0.2927055358886719, 2.0979843139648438, 0.6494140625, 1.6031951904296875, -0.0646820068359375, 0.9547195434570312, 1.304656982421875, 1.3204498291015625, -0.0675811767578125, 1.0379486083984375, 1.1086883544921875, 0.7837448120117188, 0.9885787963867188, 0.6823501586914062], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.39949035644531, "min_q": -66.66488647460938, "max_q": -62.619876861572266, "mean_td_error": -0.47392141819000244, "model": {}}, "td_error": [-0.4242820739746094, -0.42317962646484375, -1.3810195922851562, -0.23678970336914062, 0.11188888549804688, -0.4436187744140625, -0.0695343017578125, -0.26316070556640625, -0.42807769775390625, 0.133087158203125, -0.3175048828125, -0.9276123046875, -0.39730072021484375, -0.18597793579101562, -0.4351654052734375, -1.3804550170898438, -0.5547142028808594, -0.21944046020507812, -0.7918472290039062, 0.4105415344238281, 0.040187835693359375, -0.186859130859375, -0.4016532897949219, -0.57330322265625, -1.1972198486328125, -1.2530746459960938, -0.6557769775390625, -1.1440811157226562, -0.4362220764160156, -0.07783126831054688, -0.5801239013671875, -0.47536468505859375], "custom_metrics": {}}}, "num_steps_sampled": 18130, "num_agent_steps_sampled": 36260, "num_steps_trained": 28896, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 57792, "last_target_update_ts": 18030, "num_target_updates": 149}, "done": false, "episodes_total": 957, "training_iteration": 61, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-19", "timestamp": 1648811659, "time_this_iter_s": 1.4279327392578125, "time_total_s": 76.70421695709229, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 76.70421695709229, "timesteps_since_restore": 1952, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 40.1, "ram_util_percent": 64.85}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -30.28, "episode_len_mean": 19.54, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -15.14, "policy1": -15.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 26.0, -20.0, -20.0, -40.0, -40.0, 34.0, -40.0], "episode_lengths": [4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 3, 20], "policy_policy0_reward": [16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0], "policy_policy1_reward": [16.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32657867269331464, "mean_inference_ms": 1.8909216359601597, "mean_action_processing_ms": 0.12675623910875256, "mean_env_wait_ms": 0.08031240430657327, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18440, "timesteps_this_iter": 32, "agent_timesteps_total": 36880, "timers": {"load_time_ms": 0.495, "load_throughput": 64586.751, "learn_time_ms": 8.615, "learn_throughput": 3714.321, "update_time_ms": 5.643}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -69.34396362304688, "min_q": -84.39960479736328, "max_q": -48.1147575378418, "mean_td_error": -5.7985639572143555, "model": {}}, "td_error": [3.7366867065429688, 4.4491424560546875, 3.99224853515625, 3.1157379150390625, 0.8640518188476562, 3.6722564697265625, 3.2638397216796875, 0.8350448608398438, 3.4471435546875, 3.9379196166992188, 2.6336212158203125, 3.4867019653320312, 3.2533493041992188, 2.8322296142578125, 2.8585205078125, 2.9363861083984375, -64.85916900634766, 3.3228912353515625, 3.8571090698242188, 3.2404708862304688, 3.7737655639648438, -83.39960479736328, 3.9599227905273438, -63.591941833496094, 3.90264892578125, -64.97608947753906, 4.104499816894531, 3.5977630615234375, 3.878326416015625, 3.3317947387695312, 1.3181266784667969, 3.6705551147460938], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.067604064941406, "min_q": -65.53872680664062, "max_q": -61.361019134521484, "mean_td_error": 0.37770819664001465, "model": {}}, "td_error": [0.6578941345214844, 1.4618339538574219, 2.0506324768066406, 1.7452850341796875, 2.1020851135253906, 0.4082298278808594, 1.5141639709472656, 1.8827552795410156, 0.5881500244140625, 0.6962127685546875, 0.0125732421875, 0.312713623046875, 0.08805084228515625, 0.45639801025390625, 0.5730743408203125, -9.197620391845703, 0.29561614990234375, 2.7578811645507812, 0.7928199768066406, -0.5513458251953125, -7.773170471191406, 0.9014549255371094, 1.7284698486328125, 0.0441131591796875, 1.8874969482421875, 1.7978248596191406, 0.8709678649902344, 1.3236503601074219, 0.7029190063476562, 0.4783172607421875, 2.1769065856933594, -0.6996917724609375], "custom_metrics": {}}}, "num_steps_sampled": 18440, "num_agent_steps_sampled": 36880, "num_steps_trained": 29408, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 58816, "last_target_update_ts": 18377, "num_target_updates": 152}, "done": false, "episodes_total": 974, "training_iteration": 62, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-20", "timestamp": 1648811660, "time_this_iter_s": 1.4107580184936523, "time_total_s": 78.11497497558594, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 78.11497497558594, "timesteps_since_restore": 1984, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 40.5, "ram_util_percent": 65.05}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -30.82, "episode_len_mean": 19.61, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -15.41, "policy1": -15.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 26.0, -20.0, -20.0, -40.0, -40.0, 34.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.326907831483608, "mean_inference_ms": 1.8934992152985888, "mean_action_processing_ms": 0.12696561054052005, "mean_env_wait_ms": 0.0803884913204342, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18751, "timesteps_this_iter": 32, "agent_timesteps_total": 37502, "timers": {"load_time_ms": 0.461, "load_throughput": 69388.269, "learn_time_ms": 8.214, "learn_throughput": 3895.642, "update_time_ms": 4.818}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -80.6095962524414, "min_q": -92.98191833496094, "max_q": -51.78245162963867, "mean_td_error": -1.0825421810150146, "model": {}}, "td_error": [-1.9223403930664062, 3.1913986206054688, -1.0782623291015625, -1.2070999145507812, -1.4579696655273438, -1.64141845703125, -0.9723739624023438, -0.6383590698242188, -1.4007949829101562, -2.0082321166992188, -0.5464935302734375, -1.2945785522460938, -0.7911300659179688, -1.2130355834960938, -0.6462783813476562, -1.8093032836914062, -1.4620285034179688, -1.8248291015625, -0.5423011779785156, -1.1725997924804688, -2.0242996215820312, -0.9337539672851562, -1.2781448364257812, -1.43115234375, 0.2659721374511719, -1.227081298828125, -0.86578369140625, -0.5636978149414062, -2.2404403686523438, -1.6969070434570312, -0.7520370483398438, -1.45599365234375], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -62.465576171875, "min_q": -67.70955657958984, "max_q": -59.52613067626953, "mean_td_error": 0.6648229360580444, "model": {}}, "td_error": [1.6571235656738281, 0.07100677490234375, 0.16002655029296875, 1.2633399963378906, 1.9316024780273438, 1.349639892578125, 0.016387939453125, 1.8443832397460938, 1.6094551086425781, 1.4228553771972656, 1.8884201049804688, 0.09059906005859375, 1.1760673522949219, -0.23055267333984375, -6.125389099121094, 0.8467941284179688, 0.15276336669921875, 1.7917213439941406, 0.00612640380859375, 1.218292236328125, 1.7659683227539062, 0.003875732421875, 1.7698440551757812, -5.9698028564453125, 0.8731956481933594, 0.9477500915527344, 1.4521598815917969, 1.4180450439453125, 2.0676803588867188, 1.2854537963867188, 1.7797317504882812, 1.7397689819335938], "custom_metrics": {}}}, "num_steps_sampled": 18751, "num_agent_steps_sampled": 37502, "num_steps_trained": 29920, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 59840, "last_target_update_ts": 18711, "num_target_updates": 155}, "done": false, "episodes_total": 990, "training_iteration": 63, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-22", "timestamp": 1648811662, "time_this_iter_s": 1.2833092212677002, "time_total_s": 79.39828419685364, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405bb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405bb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 79.39828419685364, "timesteps_since_restore": 2016, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 41.2, "ram_util_percent": 65.2}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -31.02, "episode_len_mean": 19.61, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -15.51, "policy1": -15.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 26.0, -20.0, -20.0, -40.0, -40.0, 34.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3271408859300448, "mean_inference_ms": 1.8953362756412642, "mean_action_processing_ms": 0.1271143047022715, "mean_env_wait_ms": 0.08043749651919581, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19051, "timesteps_this_iter": 32, "agent_timesteps_total": 38102, "timers": {"load_time_ms": 0.466, "load_throughput": 68720.356, "learn_time_ms": 8.254, "learn_throughput": 3876.75, "update_time_ms": 5.314}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -79.04545593261719, "min_q": -92.77792358398438, "max_q": -51.85041046142578, "mean_td_error": -8.28448486328125, "model": {}}, "td_error": [-1.5863723754882812, -0.12645721435546875, -0.23099517822265625, -0.1308441162109375, -0.0804901123046875, -0.53948974609375, -0.336700439453125, -0.063995361328125, -0.21246337890625, -0.25806427001953125, -0.8772430419921875, -0.13776397705078125, 5.5615234375, -90.57745361328125, 0.4835357666015625, -0.353515625, -0.314971923828125, -0.14171600341796875, -0.1408538818359375, -0.425140380859375, -0.11046600341796875, -0.23670196533203125, -0.42273712158203125, -0.6010971069335938, 0.03985595703125, -51.708885192871094, -88.443115234375, -33.446990966796875, -0.40639495849609375, -0.4769744873046875, 1.2482681274414062, -0.04880523681640625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.01087951660156, "min_q": -68.01712799072266, "max_q": -61.705997467041016, "mean_td_error": -0.24106740951538086, "model": {}}, "td_error": [0.09221649169921875, 0.05821990966796875, -0.34857177734375, -0.6624374389648438, 0.002655029296875, -0.2517547607421875, -0.08331298828125, -0.3710136413574219, -0.11701202392578125, -0.21863937377929688, -0.01963043212890625, -0.3165626525878906, -0.212371826171875, -0.3039054870605469, -0.8603401184082031, -0.36080169677734375, -0.4356040954589844, -0.048095703125, -0.4168548583984375, -0.021938323974609375, -0.32636260986328125, -0.28574371337890625, -0.3463401794433594, -0.3894805908203125, -0.7020378112792969, 0.157562255859375, -0.11616134643554688, 0.02010345458984375, -0.7269554138183594, 0.5658798217773438, -0.09656524658203125, -0.5722999572753906], "custom_metrics": {}}}, "num_steps_sampled": 19051, "num_agent_steps_sampled": 38102, "num_steps_trained": 30400, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 60800, "last_target_update_ts": 18951, "num_target_updates": 157}, "done": false, "episodes_total": 1005, "training_iteration": 64, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-23", "timestamp": 1648811663, "time_this_iter_s": 1.216705322265625, "time_total_s": 80.61498951911926, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405b4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405b4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 80.61498951911926, "timesteps_since_restore": 2048, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 41.5, "ram_util_percent": 65.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -31.62, "episode_len_mean": 19.61, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -15.81, "policy1": -15.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 26.0, -20.0, -20.0, -40.0, -40.0, 34.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3273375604964583, "mean_inference_ms": 1.8969735579250928, "mean_action_processing_ms": 0.12725311462231048, "mean_env_wait_ms": 0.08048261462224032, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19351, "timesteps_this_iter": 32, "agent_timesteps_total": 38702, "timers": {"load_time_ms": 0.467, "load_throughput": 68523.882, "learn_time_ms": 8.784, "learn_throughput": 3643.093, "update_time_ms": 5.166}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -80.62403869628906, "min_q": -91.67681121826172, "max_q": -52.43122482299805, "mean_td_error": -10.011098861694336, "model": {}}, "td_error": [-0.3815765380859375, -0.6216812133789062, -0.7366561889648438, 0.32110595703125, 0.5386276245117188, -0.189727783203125, 0.43216705322265625, 0.13519287109375, -0.7244415283203125, 0.2897186279296875, -0.3847923278808594, 0.5380172729492188, -76.38726806640625, -99.22985076904297, 0.3247833251953125, 0.25801849365234375, -0.7781524658203125, -0.42315673828125, -0.7751998901367188, -51.43122482299805, 0.5156936645507812, 0.7912445068359375, -0.6404190063476562, -0.6830368041992188, 0.23542022705078125, -0.9832000732421875, 0.28784942626953125, -0.621795654296875, -89.86772918701172, -0.32097625732421875, 0.5333099365234375, -0.37543487548828125], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -61.869815826416016, "min_q": -65.77099609375, "max_q": -59.53836441040039, "mean_td_error": -4.91241979598999, "model": {}}, "td_error": [1.683624267578125, 1.766143798828125, 0.19125747680664062, 1.716522216796875, 1.23541259765625, 1.7280311584472656, 0.816741943359375, 1.4181365966796875, -62.527549743652344, 0.897308349609375, 1.2833251953125, 1.1761817932128906, 0.6090316772460938, 0.764739990234375, 1.5393600463867188, 0.9534072875976562, 0.7447128295898438, 0.9655532836914062, -4.729373931884766, 1.3532791137695312, 1.2290534973144531, 1.5406837463378906, 2.0218124389648438, -62.95198440551758, 1.801605224609375, 2.0567245483398438, 1.593353271484375, 1.3555641174316406, 1.6641921997070312, -64.56635284423828, 1.5894622802734375, 1.8826103210449219], "custom_metrics": {}}}, "num_steps_sampled": 19351, "num_agent_steps_sampled": 38702, "num_steps_trained": 30880, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 61760, "last_target_update_ts": 19311, "num_target_updates": 160}, "done": false, "episodes_total": 1020, "training_iteration": 65, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-24", "timestamp": 1648811664, "time_this_iter_s": 1.237877607345581, "time_total_s": 81.85286712646484, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 81.85286712646484, "timesteps_since_restore": 2080, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 41.15, "ram_util_percent": 65.35}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -32.22, "episode_len_mean": 19.61, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -16.11, "policy1": -16.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 26.0, -20.0, -20.0, -40.0, -40.0, 34.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3275050794911681, "mean_inference_ms": 1.8984013600237637, "mean_action_processing_ms": 0.1273771848756985, "mean_env_wait_ms": 0.08051484407232098, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19651, "timesteps_this_iter": 32, "agent_timesteps_total": 39302, "timers": {"load_time_ms": 0.49, "load_throughput": 65296.876, "learn_time_ms": 8.653, "learn_throughput": 3698.314, "update_time_ms": 5.181}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -74.4617691040039, "min_q": -89.1791000366211, "max_q": -53.06987762451172, "mean_td_error": 1.2786800861358643, "model": {}}, "td_error": [1.3576889038085938, 1.8430328369140625, 1.1999435424804688, 1.490692138671875, 1.7718124389648438, -0.14846420288085938, 1.0314102172851562, -0.27979278564453125, 1.7899932861328125, 1.614837646484375, 0.4051475524902344, 1.4556808471679688, 1.5493240356445312, 1.3290786743164062, 1.09002685546875, 1.90350341796875, 0.3577461242675781, 1.2578887939453125, -0.5277328491210938, 1.3529891967773438, 1.219696044921875, 0.31093597412109375, 1.9990768432617188, 5.779884338378906, 1.23797607421875, 1.1605377197265625, 1.2701644897460938, 2.1179428100585938, -0.05194854736328125, 1.5833511352539062, 0.3640708923339844, 2.081268310546875], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -65.74885559082031, "min_q": -67.7926025390625, "max_q": -63.30173873901367, "mean_td_error": -9.61553955078125, "model": {}}, "td_error": [-1.4247970581054688, -1.3168106079101562, -0.5004615783691406, -1.4340629577636719, -0.9228897094726562, -0.7728500366210938, -0.6714096069335938, -66.07996368408203, -0.7109375, -7.816669464111328, -1.1810417175292969, -1.0304412841796875, -75.79989624023438, -0.9210014343261719, -0.86248779296875, -1.1329421997070312, -1.0779495239257812, -0.7712173461914062, -0.9491500854492188, -66.5394287109375, -1.0908546447753906, -0.8241195678710938, -1.0766258239746094, -0.19301605224609375, -0.7495498657226562, -66.7926025390625, -0.5469207763671875, -1.1289901733398438, 0.14409637451171875, -2.0276565551757812, -0.36025238037109375, -1.1343841552734375], "custom_metrics": {}}}, "num_steps_sampled": 19651, "num_agent_steps_sampled": 39302, "num_steps_trained": 31360, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 62720, "last_target_update_ts": 19551, "num_target_updates": 162}, "done": false, "episodes_total": 1035, "training_iteration": 66, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-25", "timestamp": 1648811665, "time_this_iter_s": 1.2460663318634033, "time_total_s": 83.09893345832825, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 83.09893345832825, "timesteps_since_restore": 2112, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 42.0, "ram_util_percent": 65.55}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -33.02, "episode_len_mean": 19.61, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -16.51, "policy1": -16.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 26.0, -20.0, -20.0, -40.0, -40.0, 34.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3277335497807739, "mean_inference_ms": 1.8998521653370408, "mean_action_processing_ms": 0.1275342038112327, "mean_env_wait_ms": 0.08054846582387962, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19951, "timesteps_this_iter": 32, "agent_timesteps_total": 39902, "timers": {"load_time_ms": 0.478, "load_throughput": 66941.51, "learn_time_ms": 8.93, "learn_throughput": 3583.392, "update_time_ms": 5.739}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -82.73435974121094, "min_q": -92.15031433105469, "max_q": -55.12263107299805, "mean_td_error": -3.551647424697876, "model": {}}, "td_error": [-2.029266357421875, -2.0173721313476562, -2.7186126708984375, -3.1155166625976562, -1.9478530883789062, -1.3832321166992188, -2.3210525512695312, -54.12263107299805, -1.00537109375, -2.1259918212890625, -2.3560714721679688, -1.3163299560546875, -2.0571670532226562, -2.4281997680664062, -1.1427536010742188, -2.2970046997070312, -2.3250503540039062, -4.169593811035156, -1.7415847778320312, -2.4676513671875, -2.127655029296875, -1.1283111572265625, -2.0882492065429688, -1.5974502563476562, -0.0468902587890625, -1.5621109008789062, -2.16046142578125, -1.8705825805664062, -0.7120513916015625, -2.002471923828125, -1.432769775390625, -1.8354110717773438], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -61.96837615966797, "min_q": -65.91212463378906, "max_q": -60.36458206176758, "mean_td_error": -12.464343070983887, "model": {}}, "td_error": [0.5530471801757812, -1.5358619689941406, -1.2021636962890625, -1.3898429870605469, -1.4276084899902344, 0.035724639892578125, 0.11742782592773438, -0.242706298828125, -59.998104095458984, -0.00286102294921875, -1.1358718872070312, -60.002471923828125, -62.92143630981445, -0.15028762817382812, -0.667572021484375, 0.1908111572265625, -0.4223365783691406, -73.10636901855469, -0.8640785217285156, 0.4699554443359375, -64.91212463378906, -0.24576568603515625, -0.47090911865234375, -0.2229156494140625, -0.6394157409667969, -6.532215118408203, -0.1798553466796875, -0.449432373046875, -0.4871101379394531, -0.3020477294921875, -59.78306579589844, -0.9315223693847656], "custom_metrics": {}}}, "num_steps_sampled": 19951, "num_agent_steps_sampled": 39902, "num_steps_trained": 31840, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 63680, "last_target_update_ts": 19911, "num_target_updates": 165}, "done": false, "episodes_total": 1050, "training_iteration": 67, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-27", "timestamp": 1648811667, "time_this_iter_s": 1.4308545589447021, "time_total_s": 84.52978801727295, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 84.52978801727295, "timesteps_since_restore": 2144, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 37.400000000000006, "ram_util_percent": 60.099999999999994}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -33.42, "episode_len_mean": 19.61, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -16.71, "policy1": -16.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 26.0, -20.0, -20.0, -40.0, -40.0, 34.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 7, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, 13.0, -10.0, -10.0, -20.0, -20.0, 17.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3279312690766206, "mean_inference_ms": 1.9008947972088714, "mean_action_processing_ms": 0.127665406154018, "mean_env_wait_ms": 0.08057371295137981, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20251, "timesteps_this_iter": 32, "agent_timesteps_total": 40502, "timers": {"load_time_ms": 0.518, "load_throughput": 61814.456, "learn_time_ms": 8.711, "learn_throughput": 3673.444, "update_time_ms": 5.489}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -85.62620544433594, "min_q": -94.26918029785156, "max_q": -56.262290954589844, "mean_td_error": -3.4760711193084717, "model": {}}, "td_error": [-0.1759185791015625, 0.13317489624023438, -85.70379638671875, 0.247528076171875, -1.24786376953125, -1.1859588623046875, -1.3457870483398438, -1.8135299682617188, -1.5684814453125, 0.3421630859375, 0.02298736572265625, -1.49072265625, -1.5602645874023438, -1.5019454956054688, 0.6021499633789062, -1.6133499145507812, -1.244354248046875, -1.3359909057617188, -0.01572418212890625, 0.00200653076171875, -1.1367416381835938, -1.1157760620117188, -1.1751861572265625, 0.12521743774414062, 0.40787506103515625, -1.4767913818359375, -1.6479034423828125, -1.1128387451171875, -0.0391387939453125, -1.5652999877929688, -1.1371231079101562, -0.906890869140625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -59.067832946777344, "min_q": -63.02864456176758, "max_q": -57.5063591003418, "mean_td_error": 0.3108487129211426, "model": {}}, "td_error": [0.5283317565917969, 0.48484039306640625, 0.5019302368164062, -0.3017692565917969, 0.8900070190429688, 0.8099136352539062, 0.7035369873046875, 0.6558113098144531, 0.5928573608398438, 0.49005889892578125, 0.7783393859863281, 0.17353057861328125, -0.3167839050292969, -4.767341613769531, 0.17116546630859375, 0.40148162841796875, 0.19900894165039062, 0.6250724792480469, 0.3168144226074219, 0.6702804565429688, 0.4793815612792969, 0.94586181640625, 0.7260856628417969, 0.7978782653808594, 0.4480857849121094, 0.4564018249511719, 0.17116546630859375, -0.0748138427734375, 0.7375144958496094, 0.7035369873046875, 0.6420936584472656, 0.3068809509277344], "custom_metrics": {}}}, "num_steps_sampled": 20251, "num_agent_steps_sampled": 40502, "num_steps_trained": 32320, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64640, "last_target_update_ts": 20151, "num_target_updates": 167}, "done": false, "episodes_total": 1065, "training_iteration": 68, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-28", "timestamp": 1648811668, "time_this_iter_s": 1.336498737335205, "time_total_s": 85.86628675460815, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 85.86628675460815, "timesteps_since_restore": 2176, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 30.25, "ram_util_percent": 58.8}}
{"episode_reward_max": 18.0, "episode_reward_min": -40.0, "episode_reward_mean": -35.02, "episode_len_mean": 19.91, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 9.0, "policy1": 9.0}, "policy_reward_mean": {"policy0": -17.51, "policy1": -17.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, 18.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3280885379565725, "mean_inference_ms": 1.9017271726055012, "mean_action_processing_ms": 0.12776149127894876, "mean_env_wait_ms": 0.08059288349795386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20451, "timesteps_this_iter": 32, "agent_timesteps_total": 40902, "timers": {"load_time_ms": 0.674, "load_throughput": 47463.657, "learn_time_ms": 9.469, "learn_throughput": 3379.31, "update_time_ms": 6.697}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -85.17832946777344, "min_q": -91.4901123046875, "max_q": -55.727779388427734, "mean_td_error": -7.157551288604736, "model": {}}, "td_error": [1.3747634887695312, 0.14554595947265625, 0.6884689331054688, 1.6041107177734375, 0.7103424072265625, 0.840911865234375, 1.3702774047851562, 0.9669113159179688, 2.45257568359375, 0.9971199035644531, -0.033203125, 0.8544235229492188, 0.42771148681640625, 1.1679229736328125, 0.38105010986328125, 1.2703475952148438, 0.38532257080078125, 0.7281990051269531, 1.0731277465820312, -88.39611053466797, 0.6762008666992188, 1.2606430053710938, 0.84075927734375, 0.6301040649414062, -83.77732849121094, 1.2293777465820312, 0.38890838623046875, -0.32230377197265625, 0.728973388671875, -82.23699951171875, 1.3812026977539062, 1.1490020751953125], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -61.766048431396484, "min_q": -65.2083740234375, "max_q": -60.02182388305664, "mean_td_error": -2.3392016887664795, "model": {}}, "td_error": [0.29705810546875, -0.4253425598144531, -0.6379051208496094, -0.3675498962402344, -1.0321731567382812, -0.756256103515625, -0.3532562255859375, -1.5093345642089844, 0.4883918762207031, -0.6934814453125, -0.6974029541015625, -0.10190200805664062, -0.0809326171875, -0.888458251953125, -0.08823776245117188, 0.24306869506835938, -0.7342758178710938, -0.56219482421875, 0.24119949340820312, -1.2040939331054688, -0.6429214477539062, -0.8586578369140625, -0.5260810852050781, -0.353515625, -0.24184417724609375, -0.1393280029296875, -0.181365966796875, 0.20772933959960938, -0.5949592590332031, -61.978515625, -0.2531890869140625, -0.4287300109863281], "custom_metrics": {}}}, "num_steps_sampled": 20451, "num_agent_steps_sampled": 40902, "num_steps_trained": 32640, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 65280, "last_target_update_ts": 20391, "num_target_updates": 169}, "done": false, "episodes_total": 1075, "training_iteration": 69, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-29", "timestamp": 1648811669, "time_this_iter_s": 0.9511773586273193, "time_total_s": 86.81746411323547, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84045a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84045a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 86.81746411323547, "timesteps_since_restore": 2208, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 33.9, "ram_util_percent": 58.6}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -35.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -17.5, "policy1": -17.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32827119674709493, "mean_inference_ms": 1.902767636553088, "mean_action_processing_ms": 0.12788702807682006, "mean_env_wait_ms": 0.08061664349664331, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20751, "timesteps_this_iter": 32, "agent_timesteps_total": 41502, "timers": {"load_time_ms": 0.546, "load_throughput": 58656.467, "learn_time_ms": 7.823, "learn_throughput": 4090.757, "update_time_ms": 5.009}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -82.74600982666016, "min_q": -92.84465026855469, "max_q": -57.18349838256836, "mean_td_error": -7.9473724365234375, "model": {}}, "td_error": [-0.1048126220703125, -0.2431640625, -84.48565673828125, -0.8169174194335938, 0.7481918334960938, -83.20974731445312, -0.96331787109375, 0.6935310363769531, -0.1829071044921875, -83.588623046875, -0.6153335571289062, -0.9523468017578125, -0.12204742431640625, -0.8141250610351562, -0.42388153076171875, -0.43772125244140625, 0.51275634765625, -0.266845703125, -0.306976318359375, 1.1602821350097656, 0.6426506042480469, 0.75360107421875, -0.3465576171875, 0.00577545166015625, 0.0020751953125, -0.6459274291992188, 0.8891448974609375, 0.8108596801757812, -0.9379730224609375, -0.15848541259765625, -0.32581329345703125, -0.5856094360351562], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.57538604736328, "min_q": -65.72184753417969, "max_q": -61.80028533935547, "mean_td_error": -8.351350784301758, "model": {}}, "td_error": [-0.8636322021484375, -0.5355491638183594, -0.6446609497070312, -0.6689834594726562, -0.9926300048828125, -0.5880050659179688, -0.8558425903320312, -0.8680191040039062, -0.7810440063476562, -0.6446609497070312, -0.15028762817382812, -0.6393356323242188, -0.7839469909667969, -61.43075180053711, -0.4769439697265625, -0.9854011535644531, -0.41556549072265625, -1.1364784240722656, -64.72184753417969, -0.8586158752441406, -0.7248611450195312, -63.782798767089844, -61.731781005859375, -0.3290977478027344, 0.12769699096679688, -0.4769439697265625, 0.10418701171875, -0.291900634765625, -0.7794876098632812, 0.15340805053710938, -0.29785919189453125, -0.17160797119140625], "custom_metrics": {}}}, "num_steps_sampled": 20751, "num_agent_steps_sampled": 41502, "num_steps_trained": 33120, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 66240, "last_target_update_ts": 20751, "num_target_updates": 172}, "done": false, "episodes_total": 1090, "training_iteration": 70, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-31", "timestamp": 1648811671, "time_this_iter_s": 1.1634881496429443, "time_total_s": 87.98095226287842, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 87.98095226287842, "timesteps_since_restore": 2240, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 31.55, "ram_util_percent": 58.3}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -35.6, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -17.8, "policy1": -17.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32843662240122046, "mean_inference_ms": 1.9036956348174159, "mean_action_processing_ms": 0.12801345414978552, "mean_env_wait_ms": 0.08064753837187784, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21051, "timesteps_this_iter": 32, "agent_timesteps_total": 42102, "timers": {"load_time_ms": 0.498, "load_throughput": 64231.302, "learn_time_ms": 7.991, "learn_throughput": 4004.407, "update_time_ms": 5.009}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -83.20954132080078, "min_q": -93.08943939208984, "max_q": -59.35860061645508, "mean_td_error": -5.105442047119141, "model": {}}, "td_error": [0.44249725341796875, -0.5719528198242188, -1.786865234375, 0.3506317138671875, -83.91731262207031, -0.15432357788085938, 0.22721099853515625, -0.17938995361328125, 0.41115570068359375, 0.0040283203125, 0.09267425537109375, -0.586517333984375, 0.40636444091796875, 0.9856338500976562, 0.2568817138671875, 0.02629852294921875, -81.82479095458984, -1.0578155517578125, 0.5084304809570312, -0.026866912841796875, -0.38608551025390625, 1.0630035400390625, 0.33966064453125, 0.34038543701171875, 0.6976318359375, -1.0094451904296875, -0.08969497680664062, 1.612823486328125, 1.0897216796875, 0.16123199462890625, -1.0546417236328125, 0.2552947998046875], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -62.84334182739258, "min_q": -64.40243530273438, "max_q": -61.50812911987305, "mean_td_error": -0.445895791053772, "model": {}}, "td_error": [-0.49558258056640625, 0.571563720703125, -0.49523162841796875, -7.246746063232422, -0.6374053955078125, -0.48090362548828125, -0.6792182922363281, 0.4521827697753906, 0.5944633483886719, -7.010555267333984, -0.4215278625488281, -0.11513900756835938, 0.3292503356933594, 0.731201171875, -0.5292854309082031, -0.4687004089355469, 0.7726478576660156, -0.29412078857421875, 0.0661468505859375, -0.8472671508789062, -0.12509536743164062, 0.5273780822753906, -0.220855712890625, 0.734832763671875, 0.540069580078125, 0.21856689453125, -0.311614990234375, 0.5477752685546875, -0.42891693115234375, 0.36798858642578125, 0.0669403076171875, 0.01849365234375], "custom_metrics": {}}}, "num_steps_sampled": 21051, "num_agent_steps_sampled": 42102, "num_steps_trained": 33600, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 67200, "last_target_update_ts": 20991, "num_target_updates": 174}, "done": false, "episodes_total": 1105, "training_iteration": 71, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-32", "timestamp": 1648811672, "time_this_iter_s": 1.1747753620147705, "time_total_s": 89.15572762489319, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 89.15572762489319, "timesteps_since_restore": 2272, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 30.8, "ram_util_percent": 58.3}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -36.2, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -18.1, "policy1": -18.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3285614523745938, "mean_inference_ms": 1.9043175347000187, "mean_action_processing_ms": 0.12811540521378956, "mean_env_wait_ms": 0.08068125185478608, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21351, "timesteps_this_iter": 32, "agent_timesteps_total": 42702, "timers": {"load_time_ms": 0.47, "load_throughput": 68148.123, "learn_time_ms": 8.148, "learn_throughput": 3927.561, "update_time_ms": 5.394}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -82.9687271118164, "min_q": -93.92440795898438, "max_q": -59.50544357299805, "mean_td_error": -0.3270142078399658, "model": {}}, "td_error": [-0.2453460693359375, -1.3517074584960938, 0.15264129638671875, -0.21791839599609375, -1.1470870971679688, -1.8707122802734375, 0.6036758422851562, -0.9970474243164062, -0.013858795166015625, -0.6948471069335938, -0.3077659606933594, -0.293304443359375, 0.5280647277832031, -0.3796234130859375, 0.21540069580078125, -0.1446380615234375, -0.8859176635742188, 0.47544097900390625, -1.2922744750976562, -0.13709259033203125, -0.005828857421875, 0.3607940673828125, -1.1376800537109375, -0.4574737548828125, 0.33304595947265625, -1.2281341552734375, 0.1507415771484375, -1.03363037109375, -0.22963714599609375, 0.13959121704101562, 0.14945220947265625, 0.49822235107421875], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -62.5378532409668, "min_q": -66.61538696289062, "max_q": -60.72315216064453, "mean_td_error": 1.9763691425323486, "model": {}}, "td_error": [2.6125717163085938, 0.8029708862304688, 3.5561065673828125, 2.486156463623047, 1.2253799438476562, 2.4786720275878906, 1.6808815002441406, 3.5945663452148438, 1.0595016479492188, 2.2441368103027344, 1.76788330078125, 1.1216278076171875, 2.371623992919922, 0.9809188842773438, 0.8653945922851562, 4.292816162109375, 3.6136131286621094, 3.1156692504882812, 2.0844955444335938, 3.4720993041992188, 2.1361465454101562, 3.7356224060058594, 1.62457275390625, 1.8283462524414062, 3.0618133544921875, 1.173004150390625, 2.7785186767578125, 0.9809188842773438, 3.7835121154785156, 1.5718345642089844, 1.5191001892089844, -6.3766632080078125], "custom_metrics": {}}}, "num_steps_sampled": 21351, "num_agent_steps_sampled": 42702, "num_steps_trained": 34080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 68160, "last_target_update_ts": 21351, "num_target_updates": 177}, "done": false, "episodes_total": 1120, "training_iteration": 72, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-33", "timestamp": 1648811673, "time_this_iter_s": 1.1610488891601562, "time_total_s": 90.31677651405334, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 90.31677651405334, "timesteps_since_restore": 2304, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 31.75, "ram_util_percent": 58.4}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -36.2, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -18.1, "policy1": -18.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3286624447148473, "mean_inference_ms": 1.9047437880994265, "mean_action_processing_ms": 0.1282005092896882, "mean_env_wait_ms": 0.08071659988066675, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21651, "timesteps_this_iter": 32, "agent_timesteps_total": 43302, "timers": {"load_time_ms": 0.45, "load_throughput": 71135.111, "learn_time_ms": 8.036, "learn_throughput": 3982.143, "update_time_ms": 5.326}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -83.74736022949219, "min_q": -91.89869689941406, "max_q": -57.74858856201172, "mean_td_error": -7.5017852783203125, "model": {}}, "td_error": [-0.10859298706054688, -98.4527816772461, 0.5980072021484375, 0.2288665771484375, 0.6813430786132812, 0.9110870361328125, 0.758697509765625, -0.45070648193359375, 0.765716552734375, -0.12620925903320312, 0.6566619873046875, -89.45140075683594, 0.7832489013671875, 1.176788330078125, 0.284637451171875, -68.85841369628906, 0.6920852661132812, 1.50567626953125, -0.47769927978515625, 0.5930023193359375, 0.864959716796875, -0.14368438720703125, 0.77667236328125, 0.35063934326171875, 0.4183349609375, 0.5512619018554688, 0.668548583984375, 1.0277252197265625, 0.7771682739257812, 0.52020263671875, 0.8599700927734375, 1.561065673828125], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -62.036766052246094, "min_q": -66.67632293701172, "max_q": -60.27741241455078, "mean_td_error": -6.432131290435791, "model": {}}, "td_error": [-65.31775665283203, -0.08255386352539062, 0.1153411865234375, -0.49542236328125, -0.3429145812988281, 0.3459625244140625, -0.5214118957519531, -0.18367767333984375, -0.10938644409179688, -0.21738815307617188, -0.8979835510253906, -0.6648139953613281, -0.2674674987792969, -0.3171119689941406, -0.4136962890625, -1.3447380065917969, 0.1464691162109375, -59.27741241455078, -0.7585029602050781, 0.034374237060546875, 0.3332023620605469, -0.26678466796875, -0.4849815368652344, 0.1140899658203125, -1.2856941223144531, -0.08406829833984375, -0.07640838623046875, -0.6065254211425781, -0.9349708557128906, -0.6807098388671875, -70.63798522949219, -0.6472930908203125], "custom_metrics": {}}}, "num_steps_sampled": 21651, "num_agent_steps_sampled": 43302, "num_steps_trained": 34560, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 69120, "last_target_update_ts": 21591, "num_target_updates": 179}, "done": false, "episodes_total": 1135, "training_iteration": 73, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-34", "timestamp": 1648811674, "time_this_iter_s": 1.1935994625091553, "time_total_s": 91.5103759765625, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405a290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 91.5103759765625, "timesteps_since_restore": 2336, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 30.2, "ram_util_percent": 58.4}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -36.4, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -18.2, "policy1": -18.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32858302269948064, "mean_inference_ms": 1.9041386589240228, "mean_action_processing_ms": 0.12818577341892146, "mean_env_wait_ms": 0.08071490184964207, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21951, "timesteps_this_iter": 32, "agent_timesteps_total": 43902, "timers": {"load_time_ms": 0.595, "load_throughput": 53764.512, "learn_time_ms": 8.475, "learn_throughput": 3775.857, "update_time_ms": 5.175}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -80.5811538696289, "min_q": -91.38789367675781, "max_q": -59.54993438720703, "mean_td_error": 1.3307627439498901, "model": {}}, "td_error": [-0.38964080810546875, 2.3855819702148438, 1.5265731811523438, 1.9461746215820312, 1.74871826171875, 1.89996337890625, 1.6302947998046875, 2.1302261352539062, 1.5569076538085938, 2.0845489501953125, 1.5995864868164062, 1.3697280883789062, 1.8485565185546875, 0.6281661987304688, 1.9385452270507812, 1.2790451049804688, -0.0654449462890625, 0.47011566162109375, -0.03072357177734375, 1.6981735229492188, 1.4954452514648438, 0.3358268737792969, 1.94140625, 1.8159713745117188, 1.5745162963867188, 1.985595703125, -0.29709625244140625, 1.983001708984375, 1.7899246215820312, 0.4415283203125, 0.428436279296875, 1.8347549438476562], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.70574951171875, "min_q": -66.8514404296875, "max_q": -62.6862678527832, "mean_td_error": -2.585840940475464, "model": {}}, "td_error": [-1.1555366516113281, -0.345977783203125, 0.49981689453125, -0.25278472900390625, -0.5918655395507812, -0.8197669982910156, -62.63742446899414, -0.6399765014648438, -1.1800765991210938, -1.2451667785644531, 0.3108711242675781, -0.99383544921875, -0.6099090576171875, -0.5596809387207031, 0.17898178100585938, -0.5049591064453125, 0.3108711242675781, -1.1810531616210938, -0.30545806884765625, 0.49799346923828125, -0.7132339477539062, 0.23748397827148438, -1.1557273864746094, -5.889270782470703, -0.8049507141113281, -0.921966552734375, -0.8500595092773438, 0.7739334106445312, -1.0517997741699219, -0.6156501770019531, 0.099273681640625, -0.6300048828125], "custom_metrics": {}}}, "num_steps_sampled": 21951, "num_agent_steps_sampled": 43902, "num_steps_trained": 35040, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 70080, "last_target_update_ts": 21951, "num_target_updates": 182}, "done": false, "episodes_total": 1150, "training_iteration": 74, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-35", "timestamp": 1648811675, "time_this_iter_s": 1.1671204566955566, "time_total_s": 92.67749643325806, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840309e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840309e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 92.67749643325806, "timesteps_since_restore": 2368, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 29.15, "ram_util_percent": 58.4}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -36.4, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -18.2, "policy1": -18.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3284150608938605, "mean_inference_ms": 1.9029863376290002, "mean_action_processing_ms": 0.12813405120023932, "mean_env_wait_ms": 0.0806972729355028, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22251, "timesteps_this_iter": 32, "agent_timesteps_total": 44502, "timers": {"load_time_ms": 0.434, "load_throughput": 73689.32, "learn_time_ms": 7.958, "learn_throughput": 4021.276, "update_time_ms": 4.974}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -88.70661163330078, "min_q": -94.11285400390625, "max_q": -85.54464721679688, "mean_td_error": -5.570966720581055, "model": {}}, "td_error": [0.711090087890625, -0.29736328125, -0.2726898193359375, -0.6426544189453125, -0.3728179931640625, -84.66473388671875, -0.066497802734375, -0.5052642822265625, -0.09259033203125, 0.280487060546875, 0.15460205078125, 0.26116180419921875, 0.8005294799804688, -0.2921905517578125, 0.624725341796875, 1.3817214965820312, 1.030181884765625, -0.9684982299804688, -0.1131744384765625, -99.83531951904297, 1.0112075805664062, 0.9420547485351562, 0.363922119140625, 0.8088455200195312, 0.68536376953125, 0.7149505615234375, -0.5307998657226562, 0.495391845703125, 0.898956298828125, -0.356597900390625, -0.2507476806640625, -0.17420196533203125], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -65.234130859375, "min_q": -69.0847396850586, "max_q": -63.324623107910156, "mean_td_error": -4.017060279846191, "model": {}}, "td_error": [-0.7132339477539062, 0.48880767822265625, 0.3570404052734375, -0.18404388427734375, -0.4887237548828125, -0.20147705078125, -0.036952972412109375, -0.6912384033203125, 0.05229949951171875, 0.15672683715820312, 0.25162506103515625, 0.45793914794921875, -62.802730560302734, -0.11045074462890625, -0.29607391357421875, -0.11151123046875, -0.8088150024414062, 0.0996246337890625, 0.07331466674804688, 0.45400238037109375, 0.2078399658203125, -0.3888397216796875, 0.09460830688476562, 0.07840347290039062, -0.365234375, -0.9092254638671875, -0.5239791870117188, -0.5781936645507812, 0.8355941772460938, -0.0759429931640625, -62.35282516479492, -0.514251708984375], "custom_metrics": {}}}, "num_steps_sampled": 22251, "num_agent_steps_sampled": 44502, "num_steps_trained": 35520, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 71040, "last_target_update_ts": 22191, "num_target_updates": 184}, "done": false, "episodes_total": 1165, "training_iteration": 75, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-37", "timestamp": 1648811677, "time_this_iter_s": 1.1561894416809082, "time_total_s": 93.83368587493896, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84030d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84030d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 93.83368587493896, "timesteps_since_restore": 2400, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 30.25, "ram_util_percent": 58.4}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -37.4, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -18.7, "policy1": -18.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32815560029942203, "mean_inference_ms": 1.901190347278582, "mean_action_processing_ms": 0.1280413349969292, "mean_env_wait_ms": 0.08066553109751723, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22551, "timesteps_this_iter": 32, "agent_timesteps_total": 45102, "timers": {"load_time_ms": 0.458, "load_throughput": 69850.496, "learn_time_ms": 7.63, "learn_throughput": 4194.121, "update_time_ms": 4.858}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -89.02803802490234, "min_q": -93.85316467285156, "max_q": -61.90995407104492, "mean_td_error": -8.541234970092773, "model": {}}, "td_error": [-0.491302490234375, -0.5615997314453125, 0.13303375244140625, -0.5385322570800781, -0.12409210205078125, -85.48878479003906, 0.161895751953125, -0.23847198486328125, -0.9087142944335938, -0.4564971923828125, -0.0319061279296875, -0.45635223388671875, -87.57141876220703, -0.3422088623046875, -0.270660400390625, -0.4655914306640625, -0.5195541381835938, -0.47562408447265625, 0.0257110595703125, 0.3292694091796875, -0.25267791748046875, -0.7721405029296875, -0.5195541381835938, -0.3590545654296875, -0.6517715454101562, -85.48916625976562, 0.06636810302734375, -0.13909149169921875, -0.19533538818359375, -0.29932403564453125, -1.0983657836914062, -5.3180084228515625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.63294219970703, "min_q": -67.85557556152344, "max_q": -63.4620361328125, "mean_td_error": -4.3789143562316895, "model": {}}, "td_error": [-0.5153274536132812, -0.24004364013671875, -0.21907806396484375, 0.0552520751953125, 0.0080413818359375, -0.19625473022460938, -0.4229583740234375, -0.0960845947265625, -0.2786712646484375, -6.53887939453125, -63.48632049560547, -0.3125, -0.5847625732421875, -0.7335662841796875, -0.35692596435546875, -0.2770843505859375, -0.6657867431640625, -0.3214263916015625, -0.2954750061035156, 0.05583953857421875, -0.054470062255859375, -0.11362075805664062, -0.07703399658203125, -63.071014404296875, -0.03275299072265625, -0.7140655517578125, -0.07305908203125, -0.361968994140625, -0.23601531982421875, -0.305206298828125, 0.46002960205078125, -0.1240692138671875], "custom_metrics": {}}}, "num_steps_sampled": 22551, "num_agent_steps_sampled": 45102, "num_steps_trained": 36000, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 72000, "last_target_update_ts": 22551, "num_target_updates": 187}, "done": false, "episodes_total": 1180, "training_iteration": 76, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-38", "timestamp": 1648811678, "time_this_iter_s": 1.1523723602294922, "time_total_s": 94.98605823516846, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 94.98605823516846, "timesteps_since_restore": 2432, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 28.2, "ram_util_percent": 58.4}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -37.4, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -18.7, "policy1": -18.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3279232972327752, "mean_inference_ms": 1.8997048802128407, "mean_action_processing_ms": 0.12797345795877685, "mean_env_wait_ms": 0.08063813664293808, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22851, "timesteps_this_iter": 32, "agent_timesteps_total": 45702, "timers": {"load_time_ms": 0.57, "load_throughput": 56146.299, "learn_time_ms": 8.792, "learn_throughput": 3639.714, "update_time_ms": 5.046}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -86.35993957519531, "min_q": -91.05174255371094, "max_q": -63.79676818847656, "mean_td_error": -5.142543792724609, "model": {}}, "td_error": [0.665740966796875, 0.9308624267578125, 0.0480499267578125, 0.2030487060546875, 1.6065673828125, 0.5921249389648438, -0.13561248779296875, 1.0316848754882812, 0.48217010498046875, 0.718536376953125, 0.9335784912109375, 0.8459548950195312, 0.43698883056640625, 0.81689453125, -89.71683502197266, 0.0644683837890625, 0.47660064697265625, 0.8391265869140625, -0.38805389404296875, -84.98284149169922, 0.9041900634765625, -0.3725090026855469, 0.6357269287109375, 0.6831130981445312, 0.29878997802734375, 0.331298828125, 0.3114471435546875, 0.5869216918945312, -5.1504364013671875, 0.687103271484375, 0.735321044921875, 0.3185882568359375], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.215667724609375, "min_q": -66.49580383300781, "max_q": -61.7688102722168, "mean_td_error": -2.896918296813965, "model": {}}, "td_error": [0.01586151123046875, -0.45185089111328125, 0.4731292724609375, 0.31250762939453125, 0.1068267822265625, 0.2723579406738281, 0.35843658447265625, 0.2676582336425781, -0.8942108154296875, 0.035186767578125, 0.4693565368652344, 0.47582244873046875, -0.5147171020507812, -0.31488037109375, -0.5464210510253906, -1.0400848388671875, -1.2373275756835938, 0.6707687377929688, -0.08523178100585938, 0.20362472534179688, 0.6337661743164062, 0.5821723937988281, 0.9006996154785156, 0.6319313049316406, -9.893966674804688, -1.300445556640625, -11.025859832763672, 0.4093170166015625, 0.5472450256347656, 0.30802154541015625, -1.5553092956542969, -71.51576232910156], "custom_metrics": {}}}, "num_steps_sampled": 22851, "num_agent_steps_sampled": 45702, "num_steps_trained": 36480, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 72960, "last_target_update_ts": 22791, "num_target_updates": 189}, "done": false, "episodes_total": 1195, "training_iteration": 77, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-39", "timestamp": 1648811679, "time_this_iter_s": 1.2269017696380615, "time_total_s": 96.21296000480652, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84045a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84045a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 96.21296000480652, "timesteps_since_restore": 2464, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 31.3, "ram_util_percent": 58.5}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -37.8, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -18.9, "policy1": -18.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3277212853940092, "mean_inference_ms": 1.8984291665590194, "mean_action_processing_ms": 0.12791425224729103, "mean_env_wait_ms": 0.08061667822483881, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23151, "timesteps_this_iter": 32, "agent_timesteps_total": 46302, "timers": {"load_time_ms": 0.452, "load_throughput": 70864.693, "learn_time_ms": 7.923, "learn_throughput": 4038.7, "update_time_ms": 4.909}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -84.1703109741211, "min_q": -90.60607147216797, "max_q": -63.501529693603516, "mean_td_error": -3.3164353370666504, "model": {}}, "td_error": [0.46527099609375, 0.39304351806640625, 0.36072540283203125, 0.0826873779296875, 0.16719818115234375, 0.014446258544921875, 0.6523208618164062, 0.9627532958984375, -84.05418395996094, 0.5534210205078125, 0.663909912109375, 0.44525909423828125, 0.5911941528320312, 0.89825439453125, 0.17885971069335938, 0.46791839599609375, 0.77813720703125, 0.288848876953125, 0.660003662109375, 0.5421905517578125, 0.36191558837890625, 0.223846435546875, 0.7885208129882812, -0.01825714111328125, 0.16192626953125, -31.296337127685547, 0.28304290771484375, 0.09178924560546875, -3.7547149658203125, 0.6708526611328125, 0.41426849365234375, 0.8349533081054688], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.89015197753906, "min_q": -68.68868255615234, "max_q": -64.98949432373047, "mean_td_error": -3.1212520599365234, "model": {}}, "td_error": [-2.3015899658203125, -1.36285400390625, -1.659423828125, -0.03267669677734375, -1.9752311706542969, -0.9746856689453125, -1.54974365234375, -1.7183074951171875, -1.16015625, -1.538818359375, -0.9715194702148438, -1.8431167602539062, -0.5006942749023438, -0.5483245849609375, -1.0907211303710938, -1.8976516723632812, -0.10861968994140625, -1.7538032531738281, -1.1205673217773438, 0.18834686279296875, -2.7054443359375, -0.10861968994140625, 0.0134735107421875, -65.0742416381836, -1.2606430053710938, -3.020843505859375, -2.2582168579101562, -0.5609512329101562, 0.01303863525390625, -1.418609619140625, 0.6348419189453125, -0.21369171142578125], "custom_metrics": {}}}, "num_steps_sampled": 23151, "num_agent_steps_sampled": 46302, "num_steps_trained": 36960, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 73920, "last_target_update_ts": 23151, "num_target_updates": 192}, "done": false, "episodes_total": 1210, "training_iteration": 78, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-40", "timestamp": 1648811680, "time_this_iter_s": 1.2022240161895752, "time_total_s": 97.4151840209961, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 97.4151840209961, "timesteps_since_restore": 2496, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 30.45, "ram_util_percent": 58.5}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -38.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.0, "policy1": -19.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32752460782496934, "mean_inference_ms": 1.897169142120038, "mean_action_processing_ms": 0.12785111372056324, "mean_env_wait_ms": 0.08059731075166898, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23451, "timesteps_this_iter": 32, "agent_timesteps_total": 46902, "timers": {"load_time_ms": 0.465, "load_throughput": 68861.386, "learn_time_ms": 8.223, "learn_throughput": 3891.486, "update_time_ms": 5.242}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -87.194580078125, "min_q": -94.36603546142578, "max_q": -63.48500061035156, "mean_td_error": -2.7650129795074463, "model": {}}, "td_error": [1.0447998046875, 1.0927963256835938, 1.2702560424804688, 1.3608856201171875, 0.9085807800292969, 1.5514450073242188, 1.644683837890625, 1.4414138793945312, 1.5353851318359375, 1.3086013793945312, 0.97723388671875, 1.2255020141601562, 1.2449951171875, 1.0005874633789062, 0.9676971435546875, 1.1736984252929688, 0.9470291137695312, 1.84368896484375, 0.9603347778320312, 1.3147125244140625, 0.8653640747070312, 1.1749801635742188, -87.13286590576172, 0.9432907104492188, -2.4116363525390625, 0.9432907104492188, 0.8560943603515625, 1.0685653686523438, 1.4967422485351562, 1.5431137084960938, -33.658512115478516, 1.0168380737304688], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.59555053710938, "min_q": -68.46127319335938, "max_q": -64.31993865966797, "mean_td_error": -3.6906845569610596, "model": {}}, "td_error": [0.7470855712890625, 0.677581787109375, 0.984649658203125, 0.1192779541015625, -0.08403778076171875, -0.0886688232421875, 0.6928939819335938, 0.0669708251953125, 0.703338623046875, 0.02332305908203125, 0.2475738525390625, -0.6211166381835938, 1.0404510498046875, 0.3378448486328125, 0.066864013671875, -0.27301788330078125, 0.8003311157226562, -65.98139190673828, 0.83074951171875, -0.0398406982421875, -0.0794219970703125, -0.074676513671875, 0.9943313598632812, 0.831573486328125, -0.08220672607421875, 1.1501083374023438, -0.20619964599609375, 0.6923675537109375, 0.7784271240234375, -63.480064392089844, 0.8765029907226562, 0.246490478515625], "custom_metrics": {}}}, "num_steps_sampled": 23451, "num_agent_steps_sampled": 46902, "num_steps_trained": 37440, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 74880, "last_target_update_ts": 23391, "num_target_updates": 194}, "done": false, "episodes_total": 1225, "training_iteration": 79, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-42", "timestamp": 1648811682, "time_this_iter_s": 1.1563942432403564, "time_total_s": 98.57157826423645, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84030710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84030710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 98.57157826423645, "timesteps_since_restore": 2528, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 30.65, "ram_util_percent": 58.5}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -38.4, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.2, "policy1": -19.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3273101683750486, "mean_inference_ms": 1.8957430705395577, "mean_action_processing_ms": 0.12777087314286958, "mean_env_wait_ms": 0.08057275133043733, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23751, "timesteps_this_iter": 32, "agent_timesteps_total": 47502, "timers": {"load_time_ms": 0.434, "load_throughput": 73790.603, "learn_time_ms": 7.801, "learn_throughput": 4101.883, "update_time_ms": 4.623}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -89.09540557861328, "min_q": -94.60346221923828, "max_q": -65.99596405029297, "mean_td_error": -3.4208261966705322, "model": {}}, "td_error": [-0.5431976318359375, -0.49207305908203125, -93.60346221923828, -1.0311508178710938, 0.111846923828125, -0.6149139404296875, -0.6903533935546875, -0.451202392578125, -0.6772537231445312, -0.11641693115234375, -0.44530487060546875, -0.6621780395507812, -0.5479812622070312, -0.25067138671875, 0.17230987548828125, -0.49929046630859375, -0.3927001953125, -0.5715713500976562, -0.35309600830078125, -0.5995712280273438, -0.506011962890625, -0.49631500244140625, -4.3219757080078125, -0.22705841064453125, -0.39652252197265625, -0.16699981689453125, -0.40589141845703125, -0.7108306884765625, 0.094696044921875, -0.365509033203125, 0.07157135009765625, 0.2226409912109375], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.49958038330078, "min_q": -67.5853271484375, "max_q": -65.30084991455078, "mean_td_error": -4.18509578704834, "model": {}}, "td_error": [0.26419830322265625, 0.29502105712890625, -0.02741241455078125, 0.48979949951171875, 0.10239410400390625, 0.03502655029296875, 0.23145294189453125, 0.5927963256835938, 0.35979461669921875, 0.37469482421875, 0.248443603515625, 0.0309295654296875, -0.13980865478515625, 0.047271728515625, 0.669281005859375, 0.055511474609375, 0.46828460693359375, 0.25267791748046875, -0.02225494384765625, 0.35996246337890625, -66.4445571899414, 0.09021759033203125, 0.11423492431640625, -74.56879425048828, 0.29763031005859375, -0.35176849365234375, 0.22735595703125, 0.52294921875, 0.9086227416992188, -0.0321807861328125, 0.5216827392578125, 0.103485107421875], "custom_metrics": {}}}, "num_steps_sampled": 23751, "num_agent_steps_sampled": 47502, "num_steps_trained": 37920, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 75840, "last_target_update_ts": 23751, "num_target_updates": 197}, "done": false, "episodes_total": 1240, "training_iteration": 80, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-43", "timestamp": 1648811683, "time_this_iter_s": 1.1296746730804443, "time_total_s": 99.7012529373169, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 99.7012529373169, "timesteps_since_restore": 2560, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 30.9, "ram_util_percent": 58.5}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.5, "policy1": -19.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3270942143991379, "mean_inference_ms": 1.8943623222639456, "mean_action_processing_ms": 0.12768723259830295, "mean_env_wait_ms": 0.0805507889507364, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24051, "timesteps_this_iter": 32, "agent_timesteps_total": 48102, "timers": {"load_time_ms": 0.487, "load_throughput": 65706.04, "learn_time_ms": 8.176, "learn_throughput": 3913.921, "update_time_ms": 6.142}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -88.92768859863281, "min_q": -94.46661376953125, "max_q": -66.40829467773438, "mean_td_error": -8.805517196655273, "model": {}}, "td_error": [-0.3972320556640625, -92.8260726928711, -0.48148345947265625, -0.20386505126953125, -5.256965637207031, -0.304595947265625, -0.28221893310546875, -0.36667633056640625, -0.437469482421875, -0.283050537109375, -0.23480224609375, -0.45676422119140625, -0.6403350830078125, -0.263397216796875, -87.30462646484375, -0.3456268310546875, -0.4780426025390625, -0.39764404296875, 0.5070571899414062, -0.4141845703125, -0.5777816772460938, -0.3686676025390625, -0.2390899658203125, -0.31342315673828125, -0.8684921264648438, -0.0682373046875, -0.2799835205078125, -0.48249053955078125, -87.35820770263672, 0.0085296630859375, -0.0385894775390625, -0.3221282958984375], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -68.21243286132812, "min_q": -70.0238265991211, "max_q": -65.86071014404297, "mean_td_error": -0.11964702606201172, "model": {}}, "td_error": [-0.0786590576171875, -0.9225387573242188, -0.35315704345703125, -0.03803253173828125, -0.28487396240234375, -0.14112091064453125, 0.498016357421875, -0.47910308837890625, -0.7168807983398438, 0.1175079345703125, 0.25667572021484375, -0.5028152465820312, 0.02866363525390625, -0.36075592041015625, -0.16938018798828125, 0.2895660400390625, -0.096923828125, -0.59942626953125, -0.43047332763671875, -0.6471939086914062, 0.5570297241210938, -0.296905517578125, 0.8275680541992188, -0.00247955322265625, -0.11461639404296875, -0.4311065673828125, 0.05402374267578125, -0.5990447998046875, 0.27436065673828125, -0.036712646484375, 0.14324188232421875, 0.42684173583984375], "custom_metrics": {}}}, "num_steps_sampled": 24051, "num_agent_steps_sampled": 48102, "num_steps_trained": 38400, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 76800, "last_target_update_ts": 23991, "num_target_updates": 199}, "done": false, "episodes_total": 1255, "training_iteration": 81, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-44", "timestamp": 1648811684, "time_this_iter_s": 1.187854290008545, "time_total_s": 100.88910722732544, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840533b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840533b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 100.88910722732544, "timesteps_since_restore": 2592, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 29.75, "ram_util_percent": 58.5}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.5, "policy1": -19.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.326912261752199, "mean_inference_ms": 1.8932707358791192, "mean_action_processing_ms": 0.12762304554200773, "mean_env_wait_ms": 0.08053977546618996, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24351, "timesteps_this_iter": 32, "agent_timesteps_total": 48702, "timers": {"load_time_ms": 0.413, "load_throughput": 77569.05, "learn_time_ms": 8.114, "learn_throughput": 3943.706, "update_time_ms": 5.21}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -86.62187194824219, "min_q": -94.07866668701172, "max_q": -66.4405746459961, "mean_td_error": -8.435251235961914, "model": {}}, "td_error": [-0.09131622314453125, -85.0374755859375, -0.49897003173828125, -3.3220672607421875, 0.14687347412109375, -0.2040252685546875, 0.158416748046875, 0.299591064453125, 0.2432861328125, -0.0404205322265625, -0.49886322021484375, -0.14823150634765625, -0.2138519287109375, -0.42111968994140625, -0.11971282958984375, -0.5557327270507812, -0.7059478759765625, 0.16605377197265625, -0.5943069458007812, -0.106658935546875, -85.98818969726562, -0.04986572265625, 0.00457000732421875, 0.03206634521484375, -0.10286712646484375, -0.16058349609375, 0.06780242919921875, 0.2134857177734375, -91.6493911743164, -0.622039794921875, -0.29120635986328125, 0.16263580322265625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -68.06212615966797, "min_q": -69.41950988769531, "max_q": -65.49604797363281, "mean_td_error": -4.2837982177734375, "model": {}}, "td_error": [-0.07372283935546875, 0.618377685546875, 0.47061920166015625, 0.09326934814453125, 0.21233367919921875, 0.8539886474609375, -0.05743408203125, -64.8542709350586, 0.62115478515625, -11.632156372070312, 0.11945343017578125, 0.275787353515625, -0.16730499267578125, 0.01848602294921875, 0.0518035888671875, 0.7135543823242188, 0.21317291259765625, 0.36100006103515625, -0.11522674560546875, -67.17671966552734, 0.07299041748046875, 0.02295684814453125, -0.29001617431640625, 0.5525283813476562, 0.7510833740234375, 0.12774658203125, 0.1869964599609375, 0.7447967529296875, 0.09326934814453125, -0.1458587646484375, 0.2890625, -0.03325653076171875], "custom_metrics": {}}}, "num_steps_sampled": 24351, "num_agent_steps_sampled": 48702, "num_steps_trained": 38880, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 77760, "last_target_update_ts": 24351, "num_target_updates": 202}, "done": false, "episodes_total": 1270, "training_iteration": 82, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-45", "timestamp": 1648811685, "time_this_iter_s": 1.2171008586883545, "time_total_s": 102.1062080860138, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 102.1062080860138, "timesteps_since_restore": 2624, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 31.15, "ram_util_percent": 58.55}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.5, "policy1": -19.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32672293985060913, "mean_inference_ms": 1.8921286607414332, "mean_action_processing_ms": 0.1275522558466284, "mean_env_wait_ms": 0.08052559711213556, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24651, "timesteps_this_iter": 32, "agent_timesteps_total": 49302, "timers": {"load_time_ms": 0.414, "load_throughput": 77314.359, "learn_time_ms": 8.226, "learn_throughput": 3890.121, "update_time_ms": 4.965}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -88.75757598876953, "min_q": -94.20720672607422, "max_q": -86.0959243774414, "mean_td_error": -11.577774047851562, "model": {}}, "td_error": [-0.8106689453125, -0.9527130126953125, -1.113555908203125, -0.9265289306640625, -0.4677886962890625, -1.5737991333007812, -0.78826904296875, -0.9512252807617188, -1.0134963989257812, -0.01294708251953125, -86.32317352294922, -1.0658111572265625, -86.4866943359375, -4.5975189208984375, -0.9893112182617188, -0.46137237548828125, -0.36505889892578125, -86.01355743408203, -0.8106689453125, -1.0654983520507812, -0.1775360107421875, -86.30623626708984, -0.7894515991210938, -0.61376953125, -0.9267501831054688, -0.36505889892578125, -0.6226654052734375, -0.19641876220703125, -0.30226898193359375, -0.8252410888671875, -1.58319091796875, -0.9905319213867188], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -67.5988998413086, "min_q": -68.85406494140625, "max_q": -66.05379486083984, "mean_td_error": -2.6704859733581543, "model": {}}, "td_error": [-0.60699462890625, -0.2902069091796875, -0.7344284057617188, -0.7929000854492188, -0.5438690185546875, -0.4549713134765625, -0.9993438720703125, -0.8594589233398438, -0.260101318359375, -0.9759597778320312, -0.7678375244140625, -0.3183135986328125, -0.4830322265625, -0.31995391845703125, -0.7977981567382812, -67.62267303466797, -0.778167724609375, -0.17938232421875, -0.88092041015625, -0.5532379150390625, -0.403289794921875, -0.8529891967773438, -0.4136962890625, -0.5498580932617188, -0.6490554809570312, -0.716827392578125, -0.36767578125, -0.30800628662109375, -0.22222900390625, -0.7969131469726562, -0.84466552734375, -0.1107940673828125], "custom_metrics": {}}}, "num_steps_sampled": 24651, "num_agent_steps_sampled": 49302, "num_steps_trained": 39360, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 78720, "last_target_update_ts": 24591, "num_target_updates": 204}, "done": false, "episodes_total": 1285, "training_iteration": 83, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-47", "timestamp": 1648811687, "time_this_iter_s": 1.1666853427886963, "time_total_s": 103.27289342880249, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840fd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 103.27289342880249, "timesteps_since_restore": 2656, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 30.65, "ram_util_percent": 58.6}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.4, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.7, "policy1": -19.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32650432040699834, "mean_inference_ms": 1.8906587811962066, "mean_action_processing_ms": 0.12745594681094174, "mean_env_wait_ms": 0.08050382907724668, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24951, "timesteps_this_iter": 32, "agent_timesteps_total": 49902, "timers": {"load_time_ms": 0.481, "load_throughput": 66549.845, "learn_time_ms": 8.233, "learn_throughput": 3886.696, "update_time_ms": 4.985}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -85.69972229003906, "min_q": -93.4454116821289, "max_q": -68.13761901855469, "mean_td_error": -0.3659958839416504, "model": {}}, "td_error": [0.17864990234375, 0.27124786376953125, 0.6317596435546875, -0.1067047119140625, -0.45528411865234375, -0.5293121337890625, -0.34856414794921875, -0.5539016723632812, -0.5317230224609375, -0.7598876953125, 0.30945587158203125, -0.49611663818359375, -0.87359619140625, -0.43509674072265625, -0.5593490600585938, -0.402679443359375, 0.2686004638671875, -0.4441986083984375, -0.6597061157226562, -0.55865478515625, -0.4383087158203125, -0.4587249755859375, -0.8655853271484375, -0.7852249145507812, -0.30609130859375, -0.3249053955078125, -0.7428512573242188, -0.3245391845703125, -0.5306854248046875, -0.29158782958984375, -0.13806915283203125, -0.45023345947265625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.41056823730469, "min_q": -68.24313354492188, "max_q": -64.18130493164062, "mean_td_error": -2.221245050430298, "model": {}}, "td_error": [0.4036712646484375, -0.01087188720703125, 0.36492919921875, -0.043914794921875, 0.132354736328125, 0.353118896484375, -0.522247314453125, -0.1401214599609375, -0.11252593994140625, 0.2313079833984375, -0.5845947265625, 0.2379913330078125, -0.0825958251953125, 0.47943115234375, -0.1940765380859375, 0.13486480712890625, -0.19284820556640625, -0.3555908203125, -1.0420074462890625, 0.353118896484375, -0.5698394775390625, -0.6763229370117188, -0.43169403076171875, -0.229827880859375, -0.40203857421875, -0.3494720458984375, -0.9261703491210938, -0.165557861328125, -0.4194488525390625, 0.24764251708984375, 0.37241363525390625, -66.93891906738281], "custom_metrics": {}}}, "num_steps_sampled": 24951, "num_agent_steps_sampled": 49902, "num_steps_trained": 39840, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 79680, "last_target_update_ts": 24951, "num_target_updates": 207}, "done": false, "episodes_total": 1300, "training_iteration": 84, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-48", "timestamp": 1648811688, "time_this_iter_s": 1.1318483352661133, "time_total_s": 104.4047417640686, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 104.4047417640686, "timesteps_since_restore": 2688, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 30.3, "ram_util_percent": 58.6}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.6, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.8, "policy1": -19.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32627756227330174, "mean_inference_ms": 1.8891507365356188, "mean_action_processing_ms": 0.12736166506780264, "mean_env_wait_ms": 0.08047225457122653, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25251, "timesteps_this_iter": 32, "agent_timesteps_total": 50502, "timers": {"load_time_ms": 0.492, "load_throughput": 65040.574, "learn_time_ms": 8.096, "learn_throughput": 3952.602, "update_time_ms": 5.44}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -88.82781982421875, "min_q": -94.96416473388672, "max_q": -86.05445861816406, "mean_td_error": -5.854911804199219, "model": {}}, "td_error": [-0.6571121215820312, -0.7261734008789062, -0.7778472900390625, -0.6808319091796875, -0.01894378662109375, -0.32735443115234375, -0.22473907470703125, -0.5710830688476562, -0.5030593872070312, -0.12140655517578125, -1.0017013549804688, -0.27896881103515625, -0.9583053588867188, -0.20259857177734375, -0.9191741943359375, -0.41463470458984375, -0.1937255859375, -0.26708221435546875, -0.315826416015625, -0.29105377197265625, -0.22682952880859375, -0.21202850341796875, -0.3520965576171875, -1.4396591186523438, -0.7235565185546875, -85.79886627197266, -0.7261734008789062, -0.7278213500976562, -86.76072692871094, -0.3795928955078125, -0.10561370849609375, -0.45259857177734375], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.64134979248047, "min_q": -68.5349349975586, "max_q": -64.97175598144531, "mean_td_error": 0.6328139305114746, "model": {}}, "td_error": [0.6065292358398438, 0.9382476806640625, 0.4944305419921875, 0.7589187622070312, 0.674530029296875, 0.9001007080078125, 0.37764739990234375, 0.5274429321289062, 1.3892822265625, 0.42780303955078125, 0.4951934814453125, 0.7649765014648438, 0.9184417724609375, 0.5502471923828125, 0.81488037109375, 0.7319412231445312, 0.35726165771484375, 0.10002899169921875, 0.10449981689453125, 0.9532623291015625, 0.8557815551757812, 1.2279739379882812, 0.8261871337890625, 0.8140029907226562, -0.20752716064453125, 0.12567901611328125, 0.37952423095703125, 0.7354507446289062, 0.8493270874023438, 0.7878189086914062, 0.41010284423828125, 0.56005859375], "custom_metrics": {}}}, "num_steps_sampled": 25251, "num_agent_steps_sampled": 50502, "num_steps_trained": 40320, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 80640, "last_target_update_ts": 25191, "num_target_updates": 209}, "done": false, "episodes_total": 1315, "training_iteration": 85, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-49", "timestamp": 1648811689, "time_this_iter_s": 1.175950050354004, "time_total_s": 105.58069181442261, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c7d9dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c7d9dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 105.58069181442261, "timesteps_since_restore": 2720, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 29.6, "ram_util_percent": 58.6}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.8, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.9, "policy1": -19.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3260678669804746, "mean_inference_ms": 1.8876765084116445, "mean_action_processing_ms": 0.12727250882992386, "mean_env_wait_ms": 0.08043133206525223, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25551, "timesteps_this_iter": 32, "agent_timesteps_total": 51102, "timers": {"load_time_ms": 0.477, "load_throughput": 67092.091, "learn_time_ms": 7.737, "learn_throughput": 4136.012, "update_time_ms": 5.023}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -88.9363021850586, "min_q": -95.10552978515625, "max_q": -69.55548095703125, "mean_td_error": -1.6968669891357422, "model": {}}, "td_error": [-1.1846694946289062, -0.513092041015625, -0.822906494140625, -0.5763397216796875, -0.8194732666015625, -1.27777099609375, -28.878021240234375, -0.9083786010742188, -0.9616470336914062, -0.39239501953125, -0.7817535400390625, -0.48192596435546875, -1.6682586669921875, -0.860504150390625, -1.0276031494140625, -1.209259033203125, -0.6696090698242188, -1.6574783325195312, -0.7691879272460938, -0.7311859130859375, -0.5682525634765625, -0.7602462768554688, -0.8023300170898438, -0.83782958984375, -0.13189697265625, -0.5916213989257812, -1.3018112182617188, -0.8869781494140625, 0.4725341796875, -0.7691879272460938, -1.2779388427734375, -0.6527252197265625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -68.72413635253906, "min_q": -71.29337310791016, "max_q": -66.5724868774414, "mean_td_error": -4.742552280426025, "model": {}}, "td_error": [0.362884521484375, 0.28131103515625, -0.08342742919921875, 1.655670166015625, 2.2249221801757812, 2.741180419921875, 1.7472915649414062, 3.4948043823242188, 3.8922958374023438, -0.1490478515625, 2.8740692138671875, 4.039878845214844, 2.4688339233398438, 2.887237548828125, 1.5078353881835938, 1.3397750854492188, -0.5247344970703125, -65.86052703857422, 3.9458847045898438, -67.46661376953125, 2.1190414428710938, -0.34903717041015625, 0.227020263671875, 2.5951995849609375, 2.282470703125, 2.9906997680664062, 1.9117507934570312, 3.2865066528320312, -0.09989166259765625, -75.88141632080078, 3.8841552734375, 3.892303466796875], "custom_metrics": {}}}, "num_steps_sampled": 25551, "num_agent_steps_sampled": 51102, "num_steps_trained": 40800, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 81600, "last_target_update_ts": 25551, "num_target_updates": 212}, "done": false, "episodes_total": 1330, "training_iteration": 86, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-50", "timestamp": 1648811690, "time_this_iter_s": 1.1564664840698242, "time_total_s": 106.73715829849243, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 106.73715829849243, "timesteps_since_restore": 2752, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 31.1, "ram_util_percent": 58.6}}
{"episode_reward_max": -20.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.8, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.9, "policy1": -19.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32587388133274614, "mean_inference_ms": 1.8863270745023026, "mean_action_processing_ms": 0.1271976574355449, "mean_env_wait_ms": 0.08038453073328683, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25851, "timesteps_this_iter": 32, "agent_timesteps_total": 51702, "timers": {"load_time_ms": 0.472, "load_throughput": 67851.842, "learn_time_ms": 8.218, "learn_throughput": 3894.128, "update_time_ms": 5.131}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -82.81314086914062, "min_q": -90.2326889038086, "max_q": -67.20201873779297, "mean_td_error": -2.696511745452881, "model": {}}, "td_error": [0.0194244384765625, 0.40572357177734375, 0.11159515380859375, -0.6288833618164062, 0.01639556884765625, -0.24497222900390625, -0.11533355712890625, 0.38394927978515625, 0.17597198486328125, -0.1093292236328125, -0.0906219482421875, -0.4806671142578125, 0.26894378662109375, 0.08740997314453125, 0.22739410400390625, 0.09449005126953125, 0.09641265869140625, 0.29412078857421875, -0.09197998046875, -0.15569305419921875, 0.18578338623046875, 0.25098419189453125, 0.21181488037109375, -0.1867828369140625, -0.3008270263671875, 0.2901458740234375, -0.5118026733398438, -0.1469573974609375, 0.1097869873046875, -86.59396362304688, 0.0194244384765625, 0.11966705322265625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -79.54095458984375, "min_q": -80.63951873779297, "max_q": -77.21493530273438, "mean_td_error": -4.569281578063965, "model": {}}, "td_error": [-0.9227676391601562, -78.34869384765625, -2.2419052124023438, -3.3221817016601562, -2.2825851440429688, -1.108734130859375, -3.5242538452148438, -1.6415328979492188, -1.2314453125, -3.1713638305664062, -3.081817626953125, -4.134819030761719, -1.0882949829101562, -1.8816909790039062, -2.6264801025390625, -1.8843154907226562, -1.9876861572265625, -1.5426788330078125, -3.3221817016601562, 0.1836395263671875, -1.8816909790039062, -1.7174301147460938, -2.0298995971679688, -2.3800201416015625, -2.0500259399414062, -1.251068115234375, -1.178375244140625, -3.7026443481445312, -2.2453536987304688, -2.2419052124023438, -4.192481994628906, -2.1843338012695312], "custom_metrics": {}}}, "num_steps_sampled": 25851, "num_agent_steps_sampled": 51702, "num_steps_trained": 41280, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 82560, "last_target_update_ts": 25791, "num_target_updates": 214}, "done": false, "episodes_total": 1345, "training_iteration": 87, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-51", "timestamp": 1648811691, "time_this_iter_s": 1.1716187000274658, "time_total_s": 107.9087769985199, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 107.9087769985199, "timesteps_since_restore": 2784, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 33.55, "ram_util_percent": 58.7}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32573978696500633, "mean_inference_ms": 1.8853533637238684, "mean_action_processing_ms": 0.1271517462020616, "mean_env_wait_ms": 0.08034439023800204, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26151, "timesteps_this_iter": 32, "agent_timesteps_total": 52302, "timers": {"load_time_ms": 0.504, "load_throughput": 63432.926, "learn_time_ms": 8.56, "learn_throughput": 3738.156, "update_time_ms": 5.539}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -79.33157348632812, "min_q": -86.7397232055664, "max_q": -66.745849609375, "mean_td_error": -9.20549488067627, "model": {}}, "td_error": [-1.0640869140625, 0.4863128662109375, 0.8688507080078125, -0.350494384765625, 0.12432098388671875, 0.01944732666015625, -0.6056976318359375, 0.296478271484375, -0.136688232421875, 0.7438735961914062, -79.80313873291016, 0.2223968505859375, 0.1656646728515625, 0.07392120361328125, -78.60100555419922, 0.5746994018554688, 0.09220123291015625, -0.43442535400390625, -1.0129165649414062, 1.3947677612304688, 0.14685821533203125, 1.2584991455078125, 0.063385009765625, 0.7272796630859375, 0.13904571533203125, -1.108367919921875, -65.745849609375, 0.9183120727539062, 0.503326416015625, 1.2763519287109375, -76.26705932617188, 0.4579010009765625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -76.28132629394531, "min_q": -81.2729263305664, "max_q": -71.38011932373047, "mean_td_error": -5.822780609130859, "model": {}}, "td_error": [-11.343986511230469, -2.0051803588867188, 0.8158111572265625, -1.1861724853515625, -1.6913909912109375, -1.0521011352539062, -77.41641235351562, -2.68017578125, -2.7724227905273438, -1.2439041137695312, 1.5834808349609375, -1.8326568603515625, 0.794097900390625, -0.9021453857421875, 0.33544158935546875, -0.34832763671875, -1.0913848876953125, 0.5627059936523438, -73.4485092163086, -1.7139816284179688, 0.23639678955078125, -1.0481719970703125, 0.00582122802734375, 0.36302947998046875, -2.7074813842773438, -0.4661102294921875, -0.0806121826171875, -1.8851852416992188, -1.9811325073242188, 0.31011199951171875, -1.8326568603515625, -0.60577392578125], "custom_metrics": {}}}, "num_steps_sampled": 26151, "num_agent_steps_sampled": 52302, "num_steps_trained": 41760, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 83520, "last_target_update_ts": 26151, "num_target_updates": 217}, "done": false, "episodes_total": 1360, "training_iteration": 88, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-53", "timestamp": 1648811693, "time_this_iter_s": 1.2783007621765137, "time_total_s": 109.18707776069641, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84030440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84030440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 109.18707776069641, "timesteps_since_restore": 2816, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 43.6, "ram_util_percent": 59.2}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3256224859236525, "mean_inference_ms": 1.8843675970916456, "mean_action_processing_ms": 0.12710561641487575, "mean_env_wait_ms": 0.0802983085269096, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26451, "timesteps_this_iter": 32, "agent_timesteps_total": 52902, "timers": {"load_time_ms": 0.465, "load_throughput": 68808.432, "learn_time_ms": 8.094, "learn_throughput": 3953.464, "update_time_ms": 5.136}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -82.26180267333984, "min_q": -85.44013977050781, "max_q": -79.66441345214844, "mean_td_error": -4.775205135345459, "model": {}}, "td_error": [0.389495849609375, 0.27378082275390625, 0.2711029052734375, 1.3475418090820312, 0.483154296875, 0.482330322265625, 0.6749114990234375, 0.26633453369140625, 0.245635986328125, 0.31621551513671875, 0.5151748657226562, 0.7108078002929688, 0.5918121337890625, 0.4349822998046875, 0.30013275146484375, 0.7038803100585938, 0.6323089599609375, 0.31621551513671875, 0.0949249267578125, 0.5236740112304688, 0.49573516845703125, -83.41368103027344, 0.5121383666992188, 0.4966583251953125, 0.8310317993164062, 0.49233245849609375, 0.49573516845703125, 0.1622161865234375, 0.6951751708984375, 0.824188232421875, 0.467620849609375, -84.44013977050781], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -79.0870361328125, "min_q": -85.70952606201172, "max_q": -72.74340057373047, "mean_td_error": -10.347543716430664, "model": {}}, "td_error": [-4.315467834472656, -2.3572845458984375, -2.9529800415039062, -1.9401626586914062, -0.2117919921875, -4.311759948730469, -0.17055511474609375, -2.1684494018554688, -14.750045776367188, -1.9825210571289062, -1.8995819091796875, -2.0498199462890625, 1.0115509033203125, -4.88812255859375, -16.925704956054688, -0.22048187255859375, -79.99095916748047, -0.626617431640625, -0.143341064453125, -1.57208251953125, -1.9243316650390625, -5.9806060791015625, 0.10228729248046875, -2.2235488891601562, -2.8765869140625, -2.3431625366210938, -82.535400390625, -1.8219833374023438, -84.16900634765625, -0.358123779296875, -4.1704864501953125, -0.35427093505859375], "custom_metrics": {}}}, "num_steps_sampled": 26451, "num_agent_steps_sampled": 52902, "num_steps_trained": 42240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 84480, "last_target_update_ts": 26391, "num_target_updates": 219}, "done": false, "episodes_total": 1375, "training_iteration": 89, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-54", "timestamp": 1648811694, "time_this_iter_s": 1.2089228630065918, "time_total_s": 110.396000623703, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c7d95f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c7d95f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 110.396000623703, "timesteps_since_restore": 2848, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 40.3, "ram_util_percent": 60.0}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3255536294853765, "mean_inference_ms": 1.8836737907595906, "mean_action_processing_ms": 0.1270806785892917, "mean_env_wait_ms": 0.08025921547407183, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26751, "timesteps_this_iter": 32, "agent_timesteps_total": 53502, "timers": {"load_time_ms": 0.536, "load_throughput": 59652.324, "learn_time_ms": 8.665, "learn_throughput": 3692.87, "update_time_ms": 5.13}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -81.05783081054688, "min_q": -87.44660949707031, "max_q": -67.22396850585938, "mean_td_error": -5.499171257019043, "model": {}}, "td_error": [-80.30830383300781, -0.5641021728515625, -1.14056396484375, -0.5641021728515625, -0.5306930541992188, -0.5415496826171875, -0.5289993286132812, -0.532440185546875, -0.43402862548828125, -0.5641021728515625, -0.5651397705078125, -0.8833694458007812, -0.550079345703125, -0.6387939453125, -0.35723876953125, -1.2465667724609375, -1.070037841796875, -0.5453720092773438, -0.456268310546875, -0.37415313720703125, -0.6422271728515625, -0.40923309326171875, -0.5641021728515625, -0.43402862548828125, -0.3006134033203125, -80.66136169433594, -0.39227294921875, 0.2873382568359375, -0.5233230590820312, -0.16829681396484375, -0.440673828125, 0.6712112426757812], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -80.95350646972656, "min_q": -83.64014434814453, "max_q": -76.76594543457031, "mean_td_error": -1.494260311126709, "model": {}}, "td_error": [-7.86236572265625, 3.4781646728515625, -13.79718017578125, 0.05693817138671875, 0.7576141357421875, 4.512664794921875, 4.6284027099609375, 1.6854019165039062, 1.4654312133789062, 3.489166259765625, 0.796630859375, 4.5830841064453125, 1.1007537841796875, 0.5446701049804688, 2.2354278564453125, 1.598602294921875, 0.8529129028320312, -81.1234359741211, 2.5129776000976562, -1.07769775390625, 1.6130294799804688, 0.08736419677734375, 2.2516250610351562, 1.3405914306640625, 5.23358154296875, -0.09133148193359375, 5.621650695800781, 1.1370391845703125, 2.2331466674804688, 1.6256027221679688, 0.6128921508789062, 0.08031463623046875], "custom_metrics": {}}}, "num_steps_sampled": 26751, "num_agent_steps_sampled": 53502, "num_steps_trained": 42720, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 85440, "last_target_update_ts": 26751, "num_target_updates": 222}, "done": false, "episodes_total": 1390, "training_iteration": 90, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-55", "timestamp": 1648811695, "time_this_iter_s": 1.2298800945281982, "time_total_s": 111.6258807182312, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c7d9950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c7d9950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 111.6258807182312, "timesteps_since_restore": 2880, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 38.349999999999994, "ram_util_percent": 60.5}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32552366647212766, "mean_inference_ms": 1.8832776730855192, "mean_action_processing_ms": 0.1270741452321356, "mean_env_wait_ms": 0.08022578139015751, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27051, "timesteps_this_iter": 32, "agent_timesteps_total": 54102, "timers": {"load_time_ms": 0.467, "load_throughput": 68569.392, "learn_time_ms": 8.043, "learn_throughput": 3978.602, "update_time_ms": 5.237}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -82.56836700439453, "min_q": -87.11856842041016, "max_q": -80.23245239257812, "mean_td_error": -2.164217710494995, "model": {}}, "td_error": [-0.16968536376953125, 0.74462890625, -0.1248321533203125, 0.44025421142578125, -0.36560821533203125, 0.3629608154296875, 0.6101913452148438, 0.5828094482421875, 0.4754638671875, 1.8277053833007812, 0.94415283203125, 1.1751022338867188, 0.6554336547851562, 0.48749542236328125, -0.08119964599609375, 0.6502609252929688, -81.87741088867188, 0.720458984375, 0.5828094482421875, 0.5671539306640625, -0.7766799926757812, 0.6479721069335938, 0.6072845458984375, 0.48076629638671875, -0.7766799926757812, -0.08119964599609375, 0.4436492919921875, 0.453765869140625, 0.5003128051757812, -0.14199066162109375, 0.7052841186523438, 0.47440338134765625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -88.41886901855469, "min_q": -91.58123016357422, "max_q": -85.33826446533203, "mean_td_error": -4.225050926208496, "model": {}}, "td_error": [-0.22754669189453125, -3.6726760864257812, -0.44736480712890625, -89.11695861816406, -0.4877166748046875, -9.807151794433594, 0.11579132080078125, -0.1645660400390625, -1.5388336181640625, -1.09661865234375, -2.3916549682617188, -1.4161911010742188, -0.83184814453125, 0.6818313598632812, -11.087516784667969, 0.08722686767578125, -0.5403213500976562, -1.5749359130859375, -1.6006011962890625, -1.8524932861328125, -0.5681610107421875, -1.119384765625, -1.08056640625, 0.18840789794921875, -1.83575439453125, 0.1965484619140625, -0.7963943481445312, -0.8029632568359375, -1.3363418579101562, 0.6818313598632812, -1.8524856567382812, 0.09377288818359375], "custom_metrics": {}}}, "num_steps_sampled": 27051, "num_agent_steps_sampled": 54102, "num_steps_trained": 43200, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 86400, "last_target_update_ts": 26991, "num_target_updates": 224}, "done": false, "episodes_total": 1405, "training_iteration": 91, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-56", "timestamp": 1648811696, "time_this_iter_s": 1.2154741287231445, "time_total_s": 112.84135484695435, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84030320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84030320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 112.84135484695435, "timesteps_since_restore": 2912, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 39.2, "ram_util_percent": 61.2}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32548381109960994, "mean_inference_ms": 1.8828209780050995, "mean_action_processing_ms": 0.1270615851769007, "mean_env_wait_ms": 0.08018636091533635, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27351, "timesteps_this_iter": 32, "agent_timesteps_total": 54702, "timers": {"load_time_ms": 0.453, "load_throughput": 70592.609, "learn_time_ms": 8.369, "learn_throughput": 3823.834, "update_time_ms": 4.938}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -82.53486633300781, "min_q": -87.36493682861328, "max_q": -68.90827941894531, "mean_td_error": -5.686911106109619, "model": {}}, "td_error": [-0.5598678588867188, -0.824737548828125, -0.34698486328125, -0.521240234375, -0.08336639404296875, -0.1676177978515625, -0.5208358764648438, -0.8995513916015625, -0.6717453002929688, -0.0936279296875, -0.17562103271484375, -0.824737548828125, -0.7279281616210938, -0.5603790283203125, -0.5208358764648438, -0.8048553466796875, -0.749481201171875, 0.19124603271484375, -0.5208358764648438, -0.31488037109375, -0.45706939697265625, -0.24788665771484375, -0.6820755004882812, -0.16199493408203125, -81.11952209472656, -0.8920669555664062, -1.0284042358398438, -0.5774765014648438, -85.65621948242188, -0.629425048828125, -1.0420608520507812, 0.21092987060546875], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -88.80671691894531, "min_q": -91.06410217285156, "max_q": -86.73330688476562, "mean_td_error": -2.1266324520111084, "model": {}}, "td_error": [-1.3815994262695312, -2.2280807495117188, -1.1471710205078125, -17.022178649902344, -2.7167205810546875, -0.8545989990234375, -1.75909423828125, -2.8249282836914062, -1.4504013061523438, -2.4481430053710938, -1.5013961791992188, -1.386962890625, -1.6451339721679688, -1.2249603271484375, -3.2963027954101562, -0.967926025390625, -1.6505355834960938, 0.2463226318359375, -0.43550872802734375, -2.2911605834960938, -1.401947021484375, -2.5419921875, -2.7586822509765625, -2.1529617309570312, -2.0455322265625, -2.2710800170898438, -1.4315643310546875, -1.3971481323242188, -2.0845947265625, -0.6725540161132812, -0.8408355712890625, -0.46686553955078125], "custom_metrics": {}}}, "num_steps_sampled": 27351, "num_agent_steps_sampled": 54702, "num_steps_trained": 43680, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 87360, "last_target_update_ts": 27351, "num_target_updates": 227}, "done": false, "episodes_total": 1420, "training_iteration": 92, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-58", "timestamp": 1648811698, "time_this_iter_s": 1.1422386169433594, "time_total_s": 113.9835934638977, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840309e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c840309e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 113.9835934638977, "timesteps_since_restore": 2944, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 39.3, "ram_util_percent": 61.75}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3254707905008381, "mean_inference_ms": 1.8826130377442427, "mean_action_processing_ms": 0.12706955707163087, "mean_env_wait_ms": 0.08015335834304188, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27651, "timesteps_this_iter": 32, "agent_timesteps_total": 55302, "timers": {"load_time_ms": 0.473, "load_throughput": 67721.746, "learn_time_ms": 8.112, "learn_throughput": 3944.68, "update_time_ms": 5.216}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -81.56929016113281, "min_q": -83.70442962646484, "max_q": -69.4746322631836, "mean_td_error": -3.5359768867492676, "model": {}}, "td_error": [-0.2393341064453125, -0.33249664306640625, -0.5519027709960938, -4.67864990234375, -0.143585205078125, -0.35306549072265625, -1.0077362060546875, 0.204071044921875, 1.2744598388671875, -0.44979095458984375, -0.13842010498046875, -0.6215286254882812, 0.0051116943359375, -0.07791900634765625, 0.025787353515625, 0.40406036376953125, -0.0496673583984375, -0.43326568603515625, -23.00505828857422, 0.33826446533203125, -81.3340835571289, -0.6215286254882812, -0.29166412353515625, -0.28118896484375, -0.35306549072265625, 0.21974945068359375, 0.376983642578125, -0.04407501220703125, -0.171356201171875, -0.5561447143554688, -0.3009185791015625, 0.0366973876953125], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -84.90802001953125, "min_q": -87.62175750732422, "max_q": -83.21825408935547, "mean_td_error": -11.069901466369629, "model": {}}, "td_error": [-86.62175750732422, -1.8031768798828125, -1.610321044921875, -0.994232177734375, -82.21825408935547, -0.7570266723632812, -83.31414031982422, -0.6345062255859375, -0.58868408203125, -0.06632232666015625, 0.35387420654296875, -0.030242919921875, 0.24399566650390625, -0.05477142333984375, -0.4720001220703125, -83.72908020019531, -1.1070480346679688, 0.9009628295898438, -2.6269912719726562, -0.37593841552734375, -0.138885498046875, -0.38986968994140625, -1.5732955932617188, -0.7960891723632812, -1.2316970825195312, 0.23748779296875, -0.15129852294921875, -1.1073455810546875, -0.6345062255859375, -1.2978439331054688, 0.9463577270507812, -2.5942001342773438], "custom_metrics": {}}}, "num_steps_sampled": 27651, "num_agent_steps_sampled": 55302, "num_steps_trained": 44160, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 88320, "last_target_update_ts": 27591, "num_target_updates": 229}, "done": false, "episodes_total": 1435, "training_iteration": 93, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-14-59", "timestamp": 1648811699, "time_this_iter_s": 1.2261693477630615, "time_total_s": 115.20976281166077, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 115.20976281166077, "timesteps_since_restore": 2976, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 38.5, "ram_util_percent": 62.55}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3254612236943724, "mean_inference_ms": 1.882276659255975, "mean_action_processing_ms": 0.12706802355027083, "mean_env_wait_ms": 0.0801204019951572, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27951, "timesteps_this_iter": 32, "agent_timesteps_total": 55902, "timers": {"load_time_ms": 0.462, "load_throughput": 69262.941, "learn_time_ms": 7.935, "learn_throughput": 4032.718, "update_time_ms": 4.92}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -82.97726440429688, "min_q": -88.58818817138672, "max_q": -69.28347778320312, "mean_td_error": -8.254322052001953, "model": {}}, "td_error": [-82.09749603271484, 0.1025848388671875, -3.874755859375, 0.0022735595703125, -0.7567214965820312, 0.251922607421875, 0.22653961181640625, 0.2552490234375, -0.010833740234375, -86.31354522705078, -0.27283477783203125, -0.5007858276367188, -0.43164825439453125, -85.9326400756836, -0.5098419189453125, -0.179656982421875, -0.4024200439453125, -0.43164825439453125, -0.07488250732421875, 0.003875732421875, -0.14655303955078125, -0.5675811767578125, -0.44904327392578125, -0.19483184814453125, -0.1341400146484375, 0.8665542602539062, -0.32666015625, -0.38695526123046875, -0.187103271484375, -0.6906509399414062, -0.0467376708984375, -0.9273300170898438], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -85.52043151855469, "min_q": -89.00675201416016, "max_q": -82.46149444580078, "mean_td_error": -2.273686170578003, "model": {}}, "td_error": [0.6906967163085938, -0.7180252075195312, -1.3349990844726562, 0.80364990234375, 0.2491912841796875, 1.8495941162109375, -0.32910919189453125, 0.1067962646484375, 0.80364990234375, -0.390594482421875, -84.35810852050781, -0.22097015380859375, -0.03369903564453125, 1.4039993286132812, 0.40991973876953125, -0.26495361328125, 0.9578094482421875, 1.4533462524414062, -0.25145721435546875, 0.7789764404296875, 0.7789764404296875, 0.6773834228515625, 1.3683395385742188, -0.14324951171875, -0.183319091796875, 0.03606414794921875, 2.285369873046875, 0.13858795166015625, -0.32910919189453125, -0.33441162109375, 0.5156478881835938, 0.8260498046875], "custom_metrics": {}}}, "num_steps_sampled": 27951, "num_agent_steps_sampled": 55902, "num_steps_trained": 44640, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 89280, "last_target_update_ts": 27951, "num_target_updates": 232}, "done": false, "episodes_total": 1450, "training_iteration": 94, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-15-00", "timestamp": 1648811700, "time_this_iter_s": 1.1741046905517578, "time_total_s": 116.38386750221252, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84030b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84030b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 116.38386750221252, "timesteps_since_restore": 3008, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 37.6, "ram_util_percent": 63.0}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3254430151602612, "mean_inference_ms": 1.8818599484319334, "mean_action_processing_ms": 0.1270597720217712, "mean_env_wait_ms": 0.08008797510309655, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28251, "timesteps_this_iter": 32, "agent_timesteps_total": 56502, "timers": {"load_time_ms": 0.45, "load_throughput": 71086.133, "learn_time_ms": 8.016, "learn_throughput": 3992.068, "update_time_ms": 5.046}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -81.9579849243164, "min_q": -86.06889343261719, "max_q": -69.60830688476562, "mean_td_error": -7.673030376434326, "model": {}}, "td_error": [-0.779022216796875, 0.49468231201171875, -81.6756362915039, -0.21129608154296875, -1.0510940551757812, -0.6608810424804688, -0.511993408203125, -0.16098785400390625, -0.33240509033203125, -0.38079071044921875, -0.6232986450195312, -0.4447479248046875, -0.3682861328125, -0.9013595581054688, -0.300689697265625, -68.70795440673828, -80.38101196289062, -0.35657501220703125, 0.1809539794921875, 0.0706024169921875, -0.35657501220703125, -0.6165313720703125, 0.12326812744140625, -4.90301513671875, -0.487396240234375, -0.265350341796875, -0.04322052001953125, -0.42006683349609375, -0.4447479248046875, -0.300689697265625, -0.38080596923828125, -0.34004974365234375], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -85.53011322021484, "min_q": -87.84149932861328, "max_q": -83.60343170166016, "mean_td_error": -11.159834861755371, "model": {}}, "td_error": [-0.9929351806640625, -9.26507568359375, -0.6957931518554688, -0.4743194580078125, -0.42636871337890625, 0.56329345703125, -1.1186370849609375, -0.6301040649414062, -0.8791580200195312, -83.18132781982422, 0.6475372314453125, -0.13053131103515625, -0.7641983032226562, -0.4498138427734375, -0.14423370361328125, -0.27947235107421875, -1.1126785278320312, -0.580810546875, -0.21692657470703125, -0.7215728759765625, -83.1539306640625, -0.13053131103515625, -83.28739929199219, 0.16144561767578125, -1.0351715087890625, 0.2058868408203125, -85.86119079589844, -0.30429840087890625, -0.15785980224609375, -0.7641983032226562, -1.4515914916992188, -0.48274993896484375], "custom_metrics": {}}}, "num_steps_sampled": 28251, "num_agent_steps_sampled": 56502, "num_steps_trained": 45120, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 90240, "last_target_update_ts": 28191, "num_target_updates": 234}, "done": false, "episodes_total": 1465, "training_iteration": 95, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-15-01", "timestamp": 1648811701, "time_this_iter_s": 1.2201495170593262, "time_total_s": 117.60401701927185, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405b200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405b200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 117.60401701927185, "timesteps_since_restore": 3040, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 39.8, "ram_util_percent": 63.4}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3254101548293733, "mean_inference_ms": 1.8814180129089693, "mean_action_processing_ms": 0.12704602678455001, "mean_env_wait_ms": 0.08005762297645873, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28551, "timesteps_this_iter": 32, "agent_timesteps_total": 57102, "timers": {"load_time_ms": 0.441, "load_throughput": 72636.502, "learn_time_ms": 8.589, "learn_throughput": 3725.59, "update_time_ms": 5.396}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -83.36872863769531, "min_q": -88.86444091796875, "max_q": -81.45561218261719, "mean_td_error": -5.825300216674805, "model": {}}, "td_error": [0.8488845825195312, 0.5970382690429688, 0.8592605590820312, 0.7293624877929688, 0.5377578735351562, 0.3264923095703125, -81.59956359863281, 0.9595184326171875, 1.2963790893554688, 0.6207427978515625, -22.607284545898438, -82.08018493652344, 0.6912612915039062, 1.0434722900390625, 1.142333984375, -0.11920928955078125, 0.8391647338867188, 0.8999404907226562, -22.804443359375, 0.7769088745117188, 1.1580352783203125, 1.2963790893554688, 1.4313507080078125, 1.1142654418945312, 1.0401763916015625, 0.7369766235351562, 0.8163299560546875, 1.1142654418945312, 0.6084060668945312, 0.4426727294921875, 0.44061279296875, 0.43308258056640625], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -81.99699401855469, "min_q": -83.74055480957031, "max_q": -80.23876190185547, "mean_td_error": 0.33733534812927246, "model": {}}, "td_error": [1.5419921875, 3.3537750244140625, -0.07547760009765625, -0.24954986572265625, 0.7136611938476562, 1.6867752075195312, -1.633941650390625, -0.597076416015625, -0.3134002685546875, 0.9100265502929688, 0.87579345703125, 0.1913909912109375, 0.27721405029296875, 0.9100265502929688, 1.7686920166015625, 0.91265869140625, 2.1799850463867188, 0.7288131713867188, 0.416656494140625, 2.057464599609375, 1.1063995361328125, -1.6817703247070312, 0.7288131713867188, -9.484107971191406, 2.5398101806640625, 0.42809295654296875, 0.25292205810546875, 0.9100265502929688, -1.48980712890625, 0.9100265502929688, 0.5881423950195312, 0.3307037353515625], "custom_metrics": {}}}, "num_steps_sampled": 28551, "num_agent_steps_sampled": 57102, "num_steps_trained": 45600, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 91200, "last_target_update_ts": 28551, "num_target_updates": 237}, "done": false, "episodes_total": 1480, "training_iteration": 96, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-15-03", "timestamp": 1648811703, "time_this_iter_s": 1.2149837017059326, "time_total_s": 118.81900072097778, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 118.81900072097778, "timesteps_since_restore": 3072, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 39.9, "ram_util_percent": 63.650000000000006}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3253618007973265, "mean_inference_ms": 1.8808608395463693, "mean_action_processing_ms": 0.12702658987110774, "mean_env_wait_ms": 0.08002688690029297, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28851, "timesteps_this_iter": 32, "agent_timesteps_total": 57702, "timers": {"load_time_ms": 0.466, "load_throughput": 68643.036, "learn_time_ms": 8.026, "learn_throughput": 3987.147, "update_time_ms": 5.183}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -82.2008056640625, "min_q": -86.56031799316406, "max_q": -71.14591217041016, "mean_td_error": -0.7548894882202148, "model": {}}, "td_error": [-0.9037399291992188, -0.8721389770507812, -0.2347869873046875, -0.9478302001953125, -0.32082366943359375, -0.25275421142578125, -0.02789306640625, -0.8326873779296875, -0.9172286987304688, -0.8489837646484375, -0.4032745361328125, -6.014739990234375, -0.4976043701171875, -0.8926925659179688, -0.505462646484375, -0.5378875732421875, 0.099700927734375, -0.48491668701171875, -1.5654983520507812, -0.9679031372070312, 0.266937255859375, -0.3019561767578125, -0.9679031372070312, -0.3019561767578125, -0.3853759765625, -0.9174423217773438, -0.5581588745117188, -0.9172286987304688, -0.627593994140625, -0.7387771606445312, 0.08296966552734375, -0.8608322143554688], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -83.55308532714844, "min_q": -86.57308197021484, "max_q": -81.0232925415039, "mean_td_error": 0.19094419479370117, "model": {}}, "td_error": [-0.8180694580078125, 1.2043914794921875, 0.6169052124023438, 0.9883575439453125, 0.2787017822265625, 0.9974517822265625, -0.6272659301757812, 1.061981201171875, -0.5495071411132812, 1.3809890747070312, 0.4608917236328125, 1.2043914794921875, -0.9638290405273438, 1.2043914794921875, -0.2127227783203125, -0.8166656494140625, 0.02407073974609375, 0.9151611328125, -0.6112594604492188, 0.22803497314453125, -0.9745025634765625, 1.4648361206054688, 1.3065338134765625, -0.2140960693359375, -0.8259353637695312, 1.830535888671875, -3.3864364624023438, -1.5727462768554688, 0.02407073974609375, -0.06401824951171875, 0.9785232543945312, 1.5770492553710938], "custom_metrics": {}}}, "num_steps_sampled": 28851, "num_agent_steps_sampled": 57702, "num_steps_trained": 46080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 92160, "last_target_update_ts": 28791, "num_target_updates": 239}, "done": false, "episodes_total": 1495, "training_iteration": 97, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-15-04", "timestamp": 1648811704, "time_this_iter_s": 1.1890826225280762, "time_total_s": 120.00808334350586, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c7d9710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c7d9710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 120.00808334350586, "timesteps_since_restore": 3104, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 38.7, "ram_util_percent": 63.95}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32531906151168327, "mean_inference_ms": 1.8802479946286694, "mean_action_processing_ms": 0.12700649794625934, "mean_env_wait_ms": 0.08000239654984942, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29151, "timesteps_this_iter": 32, "agent_timesteps_total": 58302, "timers": {"load_time_ms": 0.459, "load_throughput": 69752.483, "learn_time_ms": 7.955, "learn_throughput": 4022.795, "update_time_ms": 5.052}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -82.62068176269531, "min_q": -86.52491760253906, "max_q": -71.03434753417969, "mean_td_error": -7.700183868408203, "model": {}}, "td_error": [0.8085250854492188, 0.645538330078125, 0.6545562744140625, 0.6893310546875, 0.264495849609375, 0.0800628662109375, 1.2993545532226562, 0.46390533447265625, -81.01548767089844, 0.04528045654296875, 0.6495895385742188, 0.40151214599609375, 0.43648529052734375, 0.2042999267578125, -95.38323211669922, -81.98887634277344, 0.28387451171875, 0.4969024658203125, 0.42960357666015625, 0.32836151123046875, 0.0737152099609375, 0.19622039794921875, 0.6047134399414062, 0.21733856201171875, 0.5104827880859375, 0.5612411499023438, 0.0493316650390625, 0.31478118896484375, 0.27301788330078125, 0.4922027587890625, 0.2042999267578125, 0.30269622802734375], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -81.08888244628906, "min_q": -83.23068237304688, "max_q": -78.05475616455078, "mean_td_error": -7.3495917320251465, "model": {}}, "td_error": [-0.78167724609375, -0.5528411865234375, 0.7031784057617188, 1.1287765502929688, -0.5528411865234375, -1.2021255493164062, -1.8072967529296875, 1.4389419555664062, -0.37574005126953125, -1.600433349609375, -1.407501220703125, -77.68702697753906, 1.0760650634765625, 1.4918212890625, 1.2957687377929688, -79.44338989257812, -0.37574005126953125, -80.44842529296875, 0.9455947875976562, -2.056793212890625, -0.10601043701171875, 0.08243560791015625, 0.38162994384765625, -0.37574005126953125, 0.6544189453125, -0.33402252197265625, 1.39654541015625, 1.3919448852539062, -0.37574005126953125, -0.37574005126953125, 1.4579315185546875, 1.2270889282226562], "custom_metrics": {}}}, "num_steps_sampled": 29151, "num_agent_steps_sampled": 58302, "num_steps_trained": 46560, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 93120, "last_target_update_ts": 29151, "num_target_updates": 242}, "done": false, "episodes_total": 1510, "training_iteration": 98, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-15-05", "timestamp": 1648811705, "time_this_iter_s": 1.1720142364501953, "time_total_s": 121.18009757995605, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84053d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 121.18009757995605, "timesteps_since_restore": 3136, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 37.9, "ram_util_percent": 64.1}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3252859572627436, "mean_inference_ms": 1.8796715751002517, "mean_action_processing_ms": 0.12698999236836067, "mean_env_wait_ms": 0.07998600274516661, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29451, "timesteps_this_iter": 32, "agent_timesteps_total": 58902, "timers": {"load_time_ms": 0.482, "load_throughput": 66391.832, "learn_time_ms": 7.997, "learn_throughput": 4001.387, "update_time_ms": 5.338}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -84.26155090332031, "min_q": -87.64543151855469, "max_q": -71.22586059570312, "mean_td_error": -3.290959358215332, "model": {}}, "td_error": [-0.07349395751953125, -0.8638153076171875, -0.292755126953125, -1.1947860717773438, -0.586578369140625, -0.6613616943359375, -0.485382080078125, -0.778167724609375, -0.789093017578125, -0.8529586791992188, -0.7974853515625, -0.8546295166015625, -0.8734893798828125, -82.83488464355469, -1.7233505249023438, -0.44576263427734375, 0.209991455078125, -0.484893798828125, -1.1908187866210938, -0.8828353881835938, -0.7463531494140625, -0.5072021484375, -0.8915481567382812, -0.36603546142578125, -0.6587066650390625, -0.51885986328125, -0.81884765625, -0.7792816162109375, -0.743560791015625, -0.8894577026367188, -1.2704849243164062, -0.6638107299804688], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -80.68265533447266, "min_q": -82.77183532714844, "max_q": -79.28022766113281, "mean_td_error": -7.78580904006958, "model": {}}, "td_error": [-0.48834991455078125, -78.7640151977539, 0.01441192626953125, 0.03295135498046875, 0.03896331787109375, -0.9414596557617188, -0.7965774536132812, 0.07682037353515625, -0.7354049682617188, -2.218109130859375, -0.8519668579101562, -0.34759521484375, 0.41961669921875, -0.33968353271484375, -0.58660888671875, -0.48834991455078125, 0.29845428466796875, 0.0476837158203125, -0.46800994873046875, 0.16876983642578125, 0.319061279296875, 0.04727935791015625, -81.77183532714844, -0.5126190185546875, -0.490875244140625, -0.584869384765625, -0.4097137451171875, 1.209869384765625, -79.3204345703125, -0.7403411865234375, -0.33022308349609375, -0.6327362060546875], "custom_metrics": {}}}, "num_steps_sampled": 29451, "num_agent_steps_sampled": 58902, "num_steps_trained": 47040, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 94080, "last_target_update_ts": 29391, "num_target_updates": 244}, "done": false, "episodes_total": 1525, "training_iteration": 99, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-15-06", "timestamp": 1648811706, "time_this_iter_s": 1.1910302639007568, "time_total_s": 122.37112784385681, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84084710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 122.37112784385681, "timesteps_since_restore": 3168, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 39.45, "ram_util_percent": 64.25}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32525580812237737, "mean_inference_ms": 1.8791737875783001, "mean_action_processing_ms": 0.12697814898461682, "mean_env_wait_ms": 0.0799752771061628, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29751, "timesteps_this_iter": 32, "agent_timesteps_total": 59502, "timers": {"load_time_ms": 0.535, "load_throughput": 59859.838, "learn_time_ms": 8.298, "learn_throughput": 3856.399, "update_time_ms": 5.441}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -79.04646301269531, "min_q": -86.1051254272461, "max_q": -70.22284698486328, "mean_td_error": -3.1097311973571777, "model": {}}, "td_error": [-0.723907470703125, -0.7094650268554688, -0.9900665283203125, -0.9671096801757812, -0.617919921875, -0.9614715576171875, -0.9065475463867188, -0.9048843383789062, -77.81094360351562, -0.5023117065429688, -0.617279052734375, -0.657867431640625, -0.4051513671875, -0.97967529296875, -0.6794281005859375, -0.8715362548828125, -0.9635162353515625, -0.22077178955078125, -0.8715362548828125, -0.1581268310546875, 0.02923583984375, -0.831024169921875, -0.5070724487304688, -0.7218399047851562, -1.1870956420898438, -0.6337814331054688, -0.6938934326171875, -0.6331634521484375, -0.617279052734375, -1.314544677734375, -0.8686599731445312, -0.01276397705078125], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -80.11680603027344, "min_q": -81.81842803955078, "max_q": -78.66487121582031, "mean_td_error": -9.444517135620117, "model": {}}, "td_error": [0.288818359375, -0.34362030029296875, 0.3256072998046875, 2.1144790649414062, 0.36989593505859375, 0.34098052978515625, 0.38269805908203125, -77.96074676513672, 0.1654052734375, 0.38269805908203125, 0.25962066650390625, 0.6107025146484375, 0.5858840942382812, 0.31175994873046875, 0.21057891845703125, 0.36989593505859375, 0.36989593505859375, -78.34793853759766, 0.19979095458984375, 0.2944488525390625, -79.81774139404297, 1.193603515625, -79.32086944580078, 0.4489593505859375, 0.03185272216796875, 0.9484176635742188, 0.29693603515625, 0.4484710693359375, 0.7614898681640625, 0.17678070068359375, 0.446685791015625, 1.2300262451171875], "custom_metrics": {}}}, "num_steps_sampled": 29751, "num_agent_steps_sampled": 59502, "num_steps_trained": 47520, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 95040, "last_target_update_ts": 29751, "num_target_updates": 247}, "done": false, "episodes_total": 1540, "training_iteration": 100, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-15-08", "timestamp": 1648811708, "time_this_iter_s": 1.2331395149230957, "time_total_s": 123.60426735877991, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405bb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405bb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 123.60426735877991, "timesteps_since_restore": 3200, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 39.65, "ram_util_percent": 64.3}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3252389158685263, "mean_inference_ms": 1.8789360108631141, "mean_action_processing_ms": 0.12697713571892388, "mean_env_wait_ms": 0.07997012986797004, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29951, "timesteps_this_iter": 32, "agent_timesteps_total": 59902, "timers": {"load_time_ms": 0.472, "load_throughput": 67773.04, "learn_time_ms": 8.299, "learn_throughput": 3855.779, "update_time_ms": 5.402}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -74.28448486328125, "min_q": -86.54373168945312, "max_q": -69.61994171142578, "mean_td_error": -4.4661760330200195, "model": {}}, "td_error": [-0.5659713745117188, 0.20894622802734375, -73.35841369628906, 0.20894622802734375, -0.4313201904296875, 0.45755767822265625, 0.28105926513671875, -0.09798431396484375, 0.0803680419921875, -0.31768798828125, 0.22162628173828125, 0.2114105224609375, 0.14687347412109375, -0.0542144775390625, -0.31565093994140625, 0.5403900146484375, -0.20261383056640625, 0.642333984375, -0.5625534057617188, 0.22162628173828125, -0.381988525390625, -0.39757537841796875, 0.3784027099609375, 0.7612457275390625, 0.45755767822265625, 0.30330657958984375, -72.43917846679688, 0.22441864013671875, 0.38654327392578125, 0.45755767822265625, -0.19158172607421875, 0.20894622802734375], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -80.19490814208984, "min_q": -81.70081329345703, "max_q": -78.8244857788086, "mean_td_error": -7.991192817687988, "model": {}}, "td_error": [1.1619186401367188, -0.13848876953125, -0.5981369018554688, 0.18450164794921875, -0.0404205322265625, -0.7790908813476562, -1.24224853515625, -0.116180419921875, -1.6651535034179688, 0.2741241455078125, 0.095611572265625, -0.116180419921875, -0.4404754638671875, 0.3791046142578125, -80.53720092773438, -0.32715606689453125, -0.4404754638671875, -0.765960693359375, -1.849029541015625, -88.69477081298828, -0.5904159545898438, -0.04476165771484375, -0.19432830810546875, -0.06523895263671875, 0.31841278076171875, 0.34268951416015625, -0.1251983642578125, 0.18450164794921875, -79.29180908203125, -0.876434326171875, 0.0956268310546875, 0.18450164794921875], "custom_metrics": {}}}, "num_steps_sampled": 29951, "num_agent_steps_sampled": 59902, "num_steps_trained": 47840, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 95680, "last_target_update_ts": 29871, "num_target_updates": 248}, "done": false, "episodes_total": 1550, "training_iteration": 101, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-15-09", "timestamp": 1648811709, "time_this_iter_s": 0.8581500053405762, "time_total_s": 124.46241736412048, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84030170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c84030170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 124.46241736412048, "timesteps_since_restore": 3232, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 39.05, "ram_util_percent": 64.4}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3251866661595501, "mean_inference_ms": 1.8783820872499228, "mean_action_processing_ms": 0.1269642327265676, "mean_env_wait_ms": 0.079954820595347, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 30251, "timesteps_this_iter": 32, "agent_timesteps_total": 60502, "timers": {"load_time_ms": 0.468, "load_throughput": 68328.528, "learn_time_ms": 8.349, "learn_throughput": 3832.876, "update_time_ms": 5.063}, "info": {"learner": {"policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -75.3997802734375, "min_q": -85.66670989990234, "max_q": -69.35623931884766, "mean_td_error": -4.490921497344971, "model": {}}, "td_error": [-0.670440673828125, 0.3171234130859375, 0.2706298828125, 0.141510009765625, 0.29036712646484375, 0.2949981689453125, -68.35623931884766, 0.22559356689453125, -0.1349334716796875, 0.17052459716796875, 0.13304901123046875, 0.262603759765625, -0.10163116455078125, 0.261474609375, 0.2589263916015625, 0.6460037231445312, 0.123443603515625, 0.253814697265625, 0.4850311279296875, 0.03791046142578125, -81.85990142822266, -0.1910858154296875, 0.17376708984375, 0.2258148193359375, 0.262603759765625, -0.18682098388671875, 1.11181640625, 0.2258148193359375, 1.792510986328125, 0.4501495361328125, 0.2714996337890625, -0.8954238891601562], "custom_metrics": {}}, "policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -80.54354858398438, "min_q": -81.65680694580078, "max_q": -78.71500396728516, "mean_td_error": -2.524442195892334, "model": {}}, "td_error": [0.1088714599609375, 0.448699951171875, 0.1088714599609375, -0.16280364990234375, 0.2044830322265625, -0.434356689453125, -0.9159164428710938, -0.100311279296875, 0.1265716552734375, -0.271240234375, 0.027191162109375, 0.027923583984375, -1.45855712890625, 0.1088714599609375, 0.2862548828125, -0.100311279296875, 0.082977294921875, -0.9159164428710938, -0.15497589111328125, 0.0306549072265625, 0.1972198486328125, 0.05463409423828125, 0.5683135986328125, 0.03653717041015625, 0.1093597412109375, 0.21187591552734375, -79.37877655029297, 0.103973388671875, -0.6875686645507812, 0.8192596435546875, 0.0357208251953125, 0.10031890869140625], "custom_metrics": {}}}, "num_steps_sampled": 30251, "num_agent_steps_sampled": 60502, "num_steps_trained": 48320, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 96640, "last_target_update_ts": 30231, "num_target_updates": 251}, "done": true, "episodes_total": 1565, "training_iteration": 102, "trial_id": "a568c_00000", "experiment_id": "38f6fc7024ed4d7e8dcd24500637cdb0", "date": "2022-04-01_04-15-10", "timestamp": 1648811710, "time_this_iter_s": 1.1842565536499023, "time_total_s": 125.64667391777039, "pid": 19326, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405b9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c8405b9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 125.64667391777039, "timesteps_since_restore": 3264, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 41.1, "ram_util_percent": 64.6}}
